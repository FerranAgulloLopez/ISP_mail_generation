[{"subject": "RE: Merging from a descendant of an existing merge-set membe", "content": "The spec only requires that /v2 be added ... it doesn't require\nthat /v1 be retained.  So I'd say this is at the server's discretion.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Roy Seto [mailto:Roy.Seto@oracle.com]\nSent: Wednesday, March 27, 2002 4:21 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: Merging from a descendant of an existing merge-set member\n\n\nSuppose version /v2 is a descendant of version /v1, and that\nversion-controlled resource /vcr's DAV:merge-set property value is\n<href>/v1</href>. Now the server receives a request\n\nMERGE /vcr \n<source><href>/v2</href></source>\n\nIs the server allowed to set /vcr's DAV:merge-set property value to\n<href>/v2</href> instead of <href>/v1</href><href>/v2</href> because it\nunderstands that /v2 is a descendant of /v1?\n\nRoy\n\n\n\n", "id": "lists-007-0000000"}, {"subject": "Relative URLs, Multiple binding", "content": "Hi,\nSome queries regarding the URLs returned by a PROPFIND.\n\nAssume that we have a collection A/B/ and two members A/B/x and A/B/y.\n\n1. When a PROPFIND is issued for A/B/, is it a MUST that the return URLs are\nA/B/x and A/B/y (that is always relative to the parent), or is it possible\nthat completely different URLs are returned. \nFor example, if we maintain some unique identifiers for the resources in a\nglobal path, say VCRs/, then we could probably want to return VCRs/1234\n(representing x) and VCRs/5678 (representing y). Is this allowed?\n\n2. Is it possible that two bindings are pointing to the same Resource? To\nillustrate, assume that we had the resource A/B/x and another collection\nP/Q. Now both A/B and P/Q is checked-out. x is moved from A/B to P/Q. After\nthis, we do an UNCHECKOUT on A/B and a CHECKIN on P/Q. Now both A/B and P/Q\nhave bindings pointing to x.\n\nRegards,\nGirish\n\n\n\n", "id": "lists-007-0007645"}, {"subject": "Missing preconditions for COPY and MOVE ", "content": "Sorry, if this has already been asked - I did not find it.\n\nWhat happens if the destination header of a COPY or MOVE (with overwrite)\nidentifies a resource with a DAV:checked-in property or a version resource?\n\nAre not preconditions like DAV:cannot-modify-version-controlled-content and\nDAV:cannot-modify-version (see: 3.10) missing in 3.14 and 3.15?\n\nThanks,\nPeter\n\n\n\n", "id": "lists-007-0016074"}, {"subject": "Semantic of MOVE between working collection", "content": "Let's say we have VCR /somedir/foo.txt corresponding to version history\n/repo/vh/vh1. Now consider the following sequence of requests:\n\n1. Checkout source collection (create working collection)\nRequest:\n        CHECKOUT <apply-to-version> /somedir\nResponse:\n         Location: /repo/wr/wr1\n\n2. Checkout target collection (create working collection)\nRequest:\n        CHECKOUT <apply-to-version> /anotherdir\nResponse:\n         Location: /repo/wr/wr2\n\n3. Move resource from source to target collections\nRequest:\n        MOVE /repo/wr/wr1/foo.txt  /repo/wr/wr2/foo.txt\n\n4. Execute locate-by-history report for version history of this resource\nRequest:\n        REPORT DAV:locate-by-history  /repo/vh/vh1\nResponse:\n         ???\n        \nWhich HREF will be returned by last locate-by-history report?\n/somedir/foo.txt or /anotherdir/foo.txt or /repo/wr/wr2/foo.txt?\n\n\nIf answer is /somedir/foo.txt then behavior seems to be strange for\nthe client which performed this move - he had moved the file but find\nit under the old path. But it is no (or minor) problems with implementing this\nbehavior.\n\nIf answer is /anotherdir/foo.txt, then the question is whether all\nother clients will also receive the same answer for the same\nDAV:locate-by-history request before /anotherdir collection is\nchecked-in? If so, it seems to violate one of the most significant\nrequirements to version control system - that uncommitted changes made\nby some user will not be visible to all other clients.\nLooks like the only consistent behavior is that the client which has\nchecked out /somedir and /anotherdir collection will see foo.txt under\npath /repo/wr/wr2/foo.txt while all other clients will see it under\npath /somedir/foo.txt until first client checkout these collections.\nBut how it is possible to implement it? To be able to implement such\nbehavior I need to somehow verify that user which have done CHECKOUT\nof /anotherdir (or in other words owner of wr2 working resource)\nis the same as user requested locate-by-history report. So to be able\nto implement this behavior we need authentication and notion of\nresource owner. But both are not part neither of WebDAV neither of\nDeltaV specifications (DAV:owner is declared in WebDAV ACL draft, but\nthis standard in turn knows nothing about versioning). In other words,\nsemantic of MOVE can not be expressed in terms of the specification!\n\nIf answer is /repo/wr/wr2/foo.txt then in addition to questions and\nproblems described in previous section, there is one more question -\nhow it is possible in this case for this client to know path of\nfoo.txt resource? Lets say that client forgot that foo.txt was\nmembers of /somedir collection and later was moved to /anotherdir.\nSo the only thing client knows is version of the resource. Can client\nsomehow request server about the parent of this resource?\n\n-- \nBest regards,\n Konstantin                          mailto:KKnizhnik@togetherlab.com\n\n\n\n", "id": "lists-007-0024211"}, {"subject": "RE: Semantic of MOVE between working collection", "content": "   From: Konstantin Knizhnik [mailto:KKnizhnik@togetherlab.com]\n\n   Let's say we have VCR /somedir/foo.txt corresponding to version history\n   /repo/vh/vh1. Now consider the following sequence of requests:\n\n   1. Checkout source collection (create working collection)\n   Request:\n   CHECKOUT <apply-to-version> /somedir\n   Response:\n    Location: /repo/wr/wr1\n\n   2. Checkout target collection (create working collection)\n   Request:\n   CHECKOUT <apply-to-version> /anotherdir\n   Response:\n    Location: /repo/wr/wr2\n\n   3. Move resource from source to target collections\n   Request:\n   MOVE /repo/wr/wr1/foo.txt  /repo/wr/wr2/foo.txt\n\n   4. Execute locate-by-history report for version history of this resource\n   Request:\n   REPORT DAV:locate-by-history  /repo/vh/vh1\n   Response:\n    ???\n\n   Which HREF will be returned by last locate-by-history report?\n   /somedir/foo.txt or /anotherdir/foo.txt or /repo/wr/wr2/foo.txt?\n\nOnly /somedir/foo.txt.  /anotherdir/foo.txt will not exist until\n/repo/wr/wr2 is checked in.  /repo/wr/wr2/foo.txt is not\na version-controlled resource, and DAV:locate-by-history only\nlocates version-controlled resources.\n\n   If answer is /somedir/foo.txt then behavior seems to be strange for\n   the client which performed this move - he had moved the file but\n   find it under the old path. But it is no (or minor) problems with\n   implementing this behavior.\n\nIt shouldn't be strange for the client that performed the move.\nChanges made to a working resource are not visible until that working\nresource is checked in.\n\n   If answer is /anotherdir/foo.txt, then the question is whether all\n   other clients will also receive the same answer for the same\n   DAV:locate-by-history request before /anotherdir collection is\n   checked-in? \n\nThe answer is not /anotherdir/foo.txt, and the response to a successful\nlocate-by-history request will be independent of what client makes it.\n\n   If so, it seems to violate one of the most significant\n   requirements to version control system - that uncommitted changes made\n   by some user will not be visible to all other clients.\n\nYes, that would be bad.\n\n   Looks like the only consistent behavior is that the client which has\n   checked out /somedir and /anotherdir collection will see foo.txt under\n   path /repo/wr/wr2/foo.txt while all other clients will see it under\n   path /somedir/foo.txt until first client checkout these collections.\n\nNo, the only consistent behavior is to satisfy the semantics defined\nby the report (:-).  /repo/wr/wr2/foo.txt is not a version-controlled\nresource, and therefore will never be returned by a locate-by-history\nreport.\n\nBefore /repo/wr/wr2 is checked in, the answer will be\n/somedir/foo.txt.  After the two working collections are checked in,\nthe answer will be /otherdir/foo.txt.  Simple and consistent.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-0034931"}, {"subject": "RE: Missing preconditions for COPY and MOVE ", "content": "   From: Nevermann, Dr., Peter [mailto:Peter.Nevermann@softwareag.com]\n\n   What happens if the destination header of a COPY or MOVE (with\n   overwrite) identifies a resource with a DAV:checked-in property or\n   a version resource?\n\n   Are not preconditions like DAV:cannot-modify-version-controlled-content\nand\n   DAV:cannot-modify-version (see: 3.10) missing in 3.14 and 3.15?\n\nThese are four different questions:\n\nCOPY/overwrite to a DAV:checked-in VCR is just like a PUT to a\nDAV:checked-in VCR.  It will succeed if DAV:auto-version is set\nappropriately, and fail otherwise (see Section 3.14)\n\nFor a MOVE/overwrite to a DAV:checked-in VCR, the fact that it\nis a DAV:checked-in VCR is irrelevant ... what matters is whether\nthe collection containing it allows you to remove and add members.\nIf that collection is version-controlled, then section 14.7 applies.\n\nCOPY/overwrite to a version always fails.  This is stated in the\ndefinition of a \"version resource\" in section 1.3:\n  \"The content and dead properties of a version never change.\"\nI agree that it would have been reasonable to have a\nDAV:cannot-modify-version precondition on COPY for this case.\n\nMOVE/overwrite to a version always fails.  This is stated in the\ndefinition of a \"version resource\" in section 1.3:\n \"The server allocates a distinct new URL for each new version, and\n this URL will never be used to identify any resource other than that\n version.\"\nI agree that it would have been reasonable to have a\nDAV:cannot-modify-version precondition on MOVE for this case.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-0045548"}, {"subject": "RE: Relative URLs, Multiple binding", "content": "[freed from spam trap -rrs]\n\nDate: Fri, 5 Apr 2002 16:08:03 -0500 (EST)\nMessage-ID: <FDEHJMOEIDFPFLBKEICGGEEHCGAA.tim@ellison.name>\nFrom: \"Tim Ellison\" <tim@ellison.name>\nTo: <ietf-dav-versioning@w3.org>\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of B H, Girish\n> Sent: 04 April 2002 16:48\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: Relative URLs, Multiple bindings\n>\n>\n> Hi,\n> Some queries regarding the URLs returned by a PROPFIND.\n>\n> Assume that we have a collection A/B/ and two members A/B/x and A/B/y.\n>\n> 1. When a PROPFIND is issued for A/B/, is it a MUST that the\n> return URLs are\n> A/B/x and A/B/y (that is always relative to the parent), or is it possible\n> that completely different URLs are returned.\n> For example, if we maintain some unique identifiers for the resources in a\n> global path, say VCRs/, then we could probably want to return VCRs/1234\n> (representing x) and VCRs/5678 (representing y). Is this allowed?\n\nAlthough you may be within the letter of RFC2518 by doing so, it is unclear.\nSection 8.1 PROPFIND says:\n\"...the multistatus XML element for a collection resource with member URIs\nMUST include a response XML element for each member URI of the collection,\nto whatever depth was requested. Each response XML element MUST contain an\nhref XML element that gives the URI of the resource on which the properties\nin the prop XML element are defined.\"\n\nHere I would interpret the \"member URI of the collection\" to mean the URI\nsegment known as the internal member of the collection.\n\nEven if you could argue that the spec does not disallow the unique\nidentifiers, I strongly suspect that would break versioning unaware clients.\n\n> 2. Is it possible that two bindings are pointing to the same Resource?\n\nThis is the purpose of the bindings spec. that is in progress.\n\n> To illustrate, assume that we had the resource A/B/x and another\ncollection\n> P/Q. Now both A/B and P/Q is checked-out. x is moved from A/B to\n> P/Q.\n\nIf the collections A/B and P/Q are checked out then they will be working\ncollections, and will have bindings to history resources (i.e. the history\nof 'x').\n\n> After this, we do an UNCHECKOUT on A/B and a CHECKIN on P/Q. Now both\n> A/B and P/Q have bindings pointing to x.\n\nIf A/B and P/Q are in the same workspace, then the CHECKIN must fail to\npreserve workspace semantics; otherwise, I think it would be implementation\nsepecific behavior as to whether the move created a link to the same\nresource or a copy (that is, the spec does not state what happens, and you\nshould not rely on either case).\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0054961"}, {"subject": "RE: Missing preconditions for COPY and MOVE ", "content": "[freed from spam trap -rrs]\n\nDate: Fri, 5 Apr 2002 16:27:25 -0500 (EST)\nMessage-ID: <FDEHJMOEIDFPFLBKEICGCEEICGAA.tim@ellison.name>\nFrom: \"Tim Ellison\" <tim@ellison.name>\nTo: <ietf-dav-versioning@w3.org>\n\nI agree that would make it quite clear.\n\nRegards,\nTim\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Nevermann, Dr.,\n> Peter\n> Sent: 05 April 2002 08:55\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: Missing preconditions for COPY and MOVE ?\n> \n> \n> Sorry, if this has already been asked - I did not find it.\n> \n> What happens if the destination header of a COPY or MOVE (with overwrite)\n> identifies a resource with a DAV:checked-in property or a version \n> resource?\n> \n> Are not preconditions like \n> DAV:cannot-modify-version-controlled-content and\n> DAV:cannot-modify-version (see: 3.10) missing in 3.14 and 3.15?\n> \n> Thanks,\n> Peter\n\n\n\n", "id": "lists-007-0065953"}, {"subject": "RE: Semantic of MOVE between working collection", "content": "[freed from spam trap -rrs]\n\nDate: Fri, 5 Apr 2002 16:27:32 -0500 (EST)\nMessage-ID: <FDEHJMOEIDFPFLBKEICGEEEICGAA.tim@ellison.name>\nFrom: \"Tim Ellison\" <tim@ellison.name>\nTo: <ietf-dav-versioning@w3.org>\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Konstantin\n> Knizhnik\n> Sent: 05 April 2002 10:50\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: Semantic of MOVE between working collections\n>\n>\n> Let's say we have VCR /somedir/foo.txt corresponding to version history\n> /repo/vh/vh1. Now consider the following sequence of requests:\n>\n> 1. Checkout source collection (create working collection)\n> Request:\n>         CHECKOUT <apply-to-version> /somedir\n> Response:\n>          Location: /repo/wr/wr1\n>\n> 2. Checkout target collection (create working collection)\n> Request:\n>         CHECKOUT <apply-to-version> /anotherdir\n> Response:\n>          Location: /repo/wr/wr2\n>\n> 3. Move resource from source to target collections\n> Request:\n>         MOVE /repo/wr/wr1/foo.txt  /repo/wr/wr2/foo.txt\n>\n> 4. Execute locate-by-history report for version history of this resource\n> Request:\n>         REPORT DAV:locate-by-history  /repo/vh/vh1\n> Response:\n>          ???\n\nThe DAV:locate-by-history report is applied to a collection to find the\nmember that is a version-controlled resource for the given version history.\n\nIn this scenario, you have two working collections, whose members are\nversion histories (not version-controlled resources) so the report would be\nno use there.\n\nSince the MOVE operation was on the working collections, it had no effect on\nthe checked-in version-controlled collections for the source and target, so\nyou could use REPORT on the source with /repo/vh/vh1 to find\n/somedir/foo.txt\n\n> Which HREF will be returned by last locate-by-history report?\n> /somedir/foo.txt or /anotherdir/foo.txt or /repo/wr/wr2/foo.txt?\n>\n>\n> If answer is /somedir/foo.txt then behavior seems to be strange for\n> the client which performed this move - he had moved the file but find\n> it under the old path. But it is no (or minor) problems with\n> implementing this\n> behavior.\n>\n> If answer is /anotherdir/foo.txt, then the question is whether all\n> other clients will also receive the same answer for the same\n> DAV:locate-by-history request before /anotherdir collection is\n> checked-in? If so, it seems to violate one of the most significant\n> requirements to version control system - that uncommitted changes made\n> by some user will not be visible to all other clients.\n> Looks like the only consistent behavior is that the client which has\n> checked out /somedir and /anotherdir collection will see foo.txt under\n> path /repo/wr/wr2/foo.txt while all other clients will see it under\n> path /somedir/foo.txt until first client checkout these collections.\n> But how it is possible to implement it? To be able to implement such\n> behavior I need to somehow verify that user which have done CHECKOUT\n> of /anotherdir (or in other words owner of wr2 working resource)\n> is the same as user requested locate-by-history report. So to be able\n> to implement this behavior we need authentication and notion of\n> resource owner. But both are not part neither of WebDAV neither of\n> DeltaV specifications (DAV:owner is declared in WebDAV ACL draft, but\n> this standard in turn knows nothing about versioning). In other words,\n> semantic of MOVE can not be expressed in terms of the specification!\n>\n> If answer is /repo/wr/wr2/foo.txt then in addition to questions and\n> problems described in previous section, there is one more question -\n> how it is possible in this case for this client to know path of\n> foo.txt resource? Lets say that client forgot that foo.txt was\n> members of /somedir collection and later was moved to /anotherdir.\n> So the only thing client knows is version of the resource. Can client\n> somehow request server about the parent of this resource?\n>\n> --\n> Best regards,\n>  Konstantin                          mailto:KKnizhnik@togetherlab.com\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0075134"}, {"subject": "RE: Relative URLs, Multiple binding", "content": "   From: B H, Girish [mailto:g.b.h@sap.com]\n\n   Assume that we have a collection A/B/ and two members A/B/x and A/B/y.\n\n   1. When a PROPFIND is issued for A/B/, is it a MUST that the return URLs\nare\n   A/B/x and A/B/y (that is always relative to the parent), or is it\npossible\n   that completely different URLs are returned. \n\nMy reading of 2518 is that it MUST return URLs that are relative to\nthe parent (e.g. A/B/x and A/B/y).\n\n   2. Is it possible that two bindings are pointing to the same Resource?\n\nYes.  In fact, if you have two URLs that identify members of the\nsame workspace, and PROPFIND returns the same DAV:version-history\nvalue for both of those URLs, then those two URL's MUST identify\nthe same resource.\n\n   To illustrate, assume that we had the resource A/B/x and another\n   collection P/Q. Now both A/B and P/Q is checked-out. x is moved\n   from A/B to P/Q. After this, we do an UNCHECKOUT on A/B and a\n   CHECKIN on P/Q. Now both A/B and P/Q have bindings pointing to x.\n\nIf both A/B and P/Q are members of the same workspace, then yes,\nthey must both be bindings to the same resource.  But if they are not\nmembers of the same workspace, then they could be two different resources\nthat happen to have identical DAV:version-history propertis.\n\nCheers\nGeoff\n\n\n\n", "id": "lists-007-0088446"}, {"subject": "AW: server defined activity URL", "content": "Hi,\n\nThe <DAV:displayname> of the activity could be set to the URL defined in \nthe client request. I.e. for the sample given below <DAV:displayname> of \nthe activity would be \n/act/test-23\n\nBut still my question is open if it would be legal that the server moves \nthe activity permanently directly on creation ...\n\nregards\nMatthias\n\n   -----Urspr?ngliche Nachricht-----\n   Von: Sohn, Matthias \n   Gesendet: Dienstag, 26. M?rz 2002 10:58\n   An: Ietf-Dav-Versioning@W3. Org\n   Betreff: server defined activity URLs\n   \n   \n   Hi,\n   \n   suppose we want to implement a distributed DeltaV server which allows\n   propagation \n   between workspaces residing on different servers. In order \n   to ensure unique\n   activity names\n   (needed to ensure activity URL uniqueness if activities are also\n   distributed) in this scenario \n   we would like to have server defined activity URLs.\n   \n   Would it be DeltaV compliant to achieve that by using the \n   response defined \n   in section \"10.3.2 301 Moved Permanently\" of the HTTP 1.1 \n   spec (rfc2616) ?\n   \n      >>REQUEST\n   \n        MKACTIVITY /act/test-23 HTTP/1.1\n        Host: repo.webdav.org\n        Content-Length: 0\n   \n   instead of\n   \n      >>RESPONSE\n   \n        HTTP/1.1 201 Created\n        Cache-Control: no-cache\n   \n   we would like to use\n   \n      >>RESPONSE\n   \n        HTTP/1.1 301 Moved Permanently\n        Location: /act/test-23-9C0BC5DA776811D5B3490001021DCD13\n        Cache-Control: no-cache\n   \n        <HTML body containing href to new URL>\n   \n   regards\n   Matthias\n   \n   \n\n\n\n", "id": "lists-007-0097059"}, {"subject": "RE: server defined activity URL", "content": "I agree that this is generally useful functionality.\n\nI'll get this written up as an extension, so we can fold it into\nthe next version of the protocol.\n\nI'd suggest the following variant:\n\nWhen the MKACTIVITY is applied to one of the collections identified in\nthe DAV:activity-collection-set OPTIONS response, the server MUST create\na new activity in that collection, and return the location of that new\nactivity in a Location header.\n\nI'd just return a 201 (Created), and use the presence of the Location\nheader to indicate that it has been created somewhere other than the\nrequest-URL.  A compliant client won't be trying to create activities\nat this location anyway.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Sohn, Matthias [mailto:matthias.sohn@sap.com]\nSent: Tuesday, March 26, 2002 4:58 AM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: server defined activity URLs\n\n\nHi,\n\nsuppose we want to implement a distributed DeltaV server which allows\npropagation \nbetween workspaces residing on different servers. In order to ensure unique\nactivity names\n(needed to ensure activity URL uniqueness if activities are also\ndistributed) in this scenario \nwe would like to have server defined activity URLs.\n\nWould it be DeltaV compliant to achieve that by using the response defined \nin section \"10.3.2 301 Moved Permanently\" of the HTTP 1.1 spec (rfc2616) ?\n\n   >>REQUEST\n\n     MKACTIVITY /act/test-23 HTTP/1.1\n     Host: repo.webdav.org\n     Content-Length: 0\n\ninstead of\n\n   >>RESPONSE\n\n     HTTP/1.1 201 Created\n     Cache-Control: no-cache\n\nwe would like to use\n\n   >>RESPONSE\n\n     HTTP/1.1 301 Moved Permanently\n     Location: /act/test-23-9C0BC5DA776811D5B3490001021DCD13\n     Cache-Control: no-cache\n\n     <HTML body containing href to new URL>\n\nregards\nMatthias\n\n\n\n", "id": "lists-007-0105241"}, {"subject": "Re[2]: Semantic of MOVE between working collection", "content": "Saturday, April 06, 2002, 4:35:59 PM, you wrote:\n\n>> Let's say we have VCR /somedir/foo.txt corresponding to version history\n>> /repo/vh/vh1. Now consider the following sequence of requests:\n>>\n>> 1. Checkout source collection (create working collection)\n>> Request:\n>>         CHECKOUT <apply-to-version> /somedir\n>> Response:\n>>          Location: /repo/wr/wr1\n>>\n>> 2. Checkout target collection (create working collection)\n>> Request:\n>>         CHECKOUT <apply-to-version> /anotherdir\n>> Response:\n>>          Location: /repo/wr/wr2\n>>\n>> 3. Move resource from source to target collections\n>> Request:\n>>         MOVE /repo/wr/wr1/foo.txt  /repo/wr/wr2/foo.txt\n>>\n>> 4. Execute locate-by-history report for version history of this resource\n>> Request:\n>>         REPORT DAV:locate-by-history  /repo/vh/vh1\n>> Response:\n>>          ???\n\nTE> The DAV:locate-by-history report is applied to a collection to find the\nTE> member that is a version-controlled resource for the given version history.\n\nTE> In this scenario, you have two working collections, whose members are\nTE> version histories (not version-controlled resources) so the report would be\nTE> no use there.\n\nSo, PROPFIND with DEPTH=1 for working collection will return set of\nversion histories, not VCR, right?\n\n\nTE> Since the MOVE operation was on the working collections, it had no effect on\nTE> the checked-in version-controlled collections for the source and target, so\nTE> you could use REPORT on the source with /repo/vh/vh1 to find\nTE> /somedir/foo.txt\n\nOk, there are some other things not clear to me in the example above.\nSo what happens after\n   MOVE /repo/wr/wr1/foo.txt  /repo/wr/wr2/foo.txt\n(assuming that foo.txt belongs to the version history /repo/vh/vh1)\n   \n   \nBinding to MOVE /repo/vh/vh1 is removed from  /repo/wr/wr1\nand is added to /repo/wr/wr2, isn't it?\nThen, let's say, we checkin /repo/wr/wr1. The VCR foo.txt should be\nremoved, right?\nThen we checkin /repo/wr/wr2. The VCR with name foo.txt referring to\nthe history /repo/vh/vh1 should be created, right?\nBut which version this VCR should select in its DAV:checked-in property?\nThe obvious answer - the same as was selected by foo.txt VCR\nbefore MOVE. But working collection contains only bindings to versions\nhistories, so there is no way to store information about checked-in\nversion.\n\nAnd one more obscure item for me: if we perform MOVE from versioned\ncollection to not-versioned collection. Is it allowed operation?\nWhat is the result of such operation? For example:\n\n   MOVE /repo/wr/wr1/foo.txt /new.txt\n\nShould new.txt be a new resource (with new resource ID and the same\ncontent as cehcked-in version of foo.txt)? Or it should be foo.txt VCR\nitself? Then what is the value of DAV:displayname property of this\nresource?\n   \n\n-- \nThanks in advance,\n Konstantin                            mailto:KKnizhnik@togetherlab.com\n\n\n\n", "id": "lists-007-0113837"}, {"subject": "RE: Re[2]: Semantic of MOVE between working collection", "content": "   From: Konstantin Knizhnik [mailto:KKnizhnik@togetherlab.com]\n\n   So, PROPFIND with DEPTH=1 for working collection will return set of\n   version histories, not VCR, right?\n\nRight.\n\n   TE> Since the MOVE operation was on the working collections, it had\n   TE> no effect on the checked-in version-controlled collections for\n   TE> the source and target, so you could use REPORT on the source\n   TE> with /repo/vh/vh1 to find /somedir/foo.txt\n\n   Ok, there are some other things not clear to me in the example above.\n   So what happens after\n      MOVE /repo/wr/wr1/foo.txt  /repo/wr/wr2/foo.txt\n   (assuming that foo.txt belongs to the version history /repo/vh/vh1)\n   Binding to MOVE /repo/vh/vh1 is removed from  /repo/wr/wr1\n   and is added to /repo/wr/wr2, isn't it?\n\nYes.\n\n   Then, let's say, we checkin /repo/wr/wr1. The VCR foo.txt should be\n   removed, right?\n\nYes (from /somedir).\n\n   Then we checkin /repo/wr/wr2. The VCR with name foo.txt referring to\n   the history /repo/vh/vh1 should be created, right?\n\nYes (in /otherdir).\n\n   But which version this VCR should select in its DAV:checked-in property?\n\nIt's up to the server.\n\n   The obvious answer - the same as was selected by foo.txt VCR\n   before MOVE. But working collection contains only bindings to versions\n   histories, so there is no way to store information about checked-in\n   version.\n\nThat's correct.  One way a server could know to do the expected thing\nwould be if both working collections were in the same activity, and\nthe user checked in the activity as a whole.  In this case, the\nserver could remember information about VCR checked-in versions,\nand use those as the versions when creating a new VCR.\n\nNote that this is only an issue with working collections.  With\nchecked-out version-controlled collections, the MOVE actually moves\nthe VCR, so the DAV:checked-in value just goes along for the ride.\n\n   And one more obscure item for me: if we perform MOVE from versioned\n   collection to not-versioned collection. Is it allowed operation?\n\nDepends on the server.  I would expect that most servers would not\nsupport this, but they certainly could do so.\n\n   What is the result of such operation? For example:\n\n      MOVE /repo/wr/wr1/foo.txt /new.txt\n\n   Should new.txt be a new resource (with new resource ID and the same\n   content as cehcked-in version of foo.txt)? Or it should be foo.txt VCR\n   itself? Then what is the value of DAV:displayname property of this\n   resource?\n\nRFC-3253 requires that a MOVE keep all the RFC-3253 defined\nproperties, so such a MOVE would have to expose the version history\nresource itself at the new location (not a new resource, and not a\nVCR).  It's DAV:displayname would be whatever was the DAV:displayname\nof the VCR before the MOVE.  A server is likely to restrict the location\nof version history resources to be in working collections and its\noriginal server-defined location, which is why such MOVE's are\nunlikely to be supported.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-0124962"}, {"subject": "Comment and author for a new version", "content": "Hi all,\nmy repository wants to have some information when I create a new\nversion.\nSo I would like to put a resource under version control like this:\n\nVERSION-CONTROL /test.html HTTP/1.1\nHost: work.edgarschwarz.de\nContent-Type: text/xml; charset=\"utf-8\"\nContent-Length: xxxx\n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<version-control xmlns=\"DAV:\">\n<creator-displayname>Edgar Schwarz</creator-displayname>\n<comment>This is a comment for a version</comment>\n</version-control>\n\nThis also would apply to CHECKIN and BASELINE_CONTROL naturally.\nOr should I do a PROPPATCH for creator-displayname and comment before\nVERSION-CONTROL ?\n\nCheers, Edgar\n\n\n\n", "id": "lists-007-0135493"}, {"subject": "Meaning of precondition DAV:supported-live-propert", "content": "In our group we are discussing about the exact meaning of the additional\nprecondition(s) DAV:supported-live-property for PROPFIND and PROPPATCH (3.11\nand 3.12 in RFC 3253). In particular, the meaning of \"the semantics of a\nproperty being supported by the server\".\n\nIs the following an example?\nA PROPPATCH request intends to modify the value of a \"checkout-fork\"\nproperty of a checked-out VCR to something different than DAV:forbidden or\nDAV:discouraged, say, to an empty value. Then the\nDAV:supported-live-property precondition is violated.\n\nAnother interpretation is, that it has to do with properties which are not\nREQUIRED (...but there are not such properties as fas as I can see!).\n\nThanks,\nPeter\n\n\n\n", "id": "lists-007-0143117"}, {"subject": "Re: Meaning of precondition DAV:supported-live-propert", "content": "As I understand it, the precondition will prevent that a resource\ncan have dead properties of the same name as a deltav live property.\n\nSo, on a deltav compliant server, you cannot retrieve or set the\nproperty DAV:version-history on a non-VCR resource (e.g. plain,\nunversioned resource of RFC 2518 style).\n\nA server, just followin 2518, would allow the setting of such\na property. It would be a dead properties without any meaning,\nbut returned on a PROPFIND nevertheless.\n\n//Stefan\n\nAm Donnerstag den, 11. April 2002, um 14:38, schrieb Nevermann, \nDr., Peter:\n\n> In our group we are discussing about the exact meaning of the \n> additional\n> precondition(s) DAV:supported-live-property for PROPFIND and \n> PROPPATCH (3.11\n> and 3.12 in RFC 3253). In particular, the meaning of \"the \n> semantics of a\n> property being supported by the server\".\n>\n> Is the following an example?\n> A PROPPATCH request intends to modify the value of a \"checkout-fork\"\n> property of a checked-out VCR to something different than \n> DAV:forbidden or\n> DAV:discouraged, say, to an empty value. Then the\n> DAV:supported-live-property precondition is violated.\n>\n> Another interpretation is, that it has to do with properties which \n> are not\n> REQUIRED (...but there are not such properties as fas as I can see!).\n>\n> Thanks,\n> Peter\n>\n\n\n\n", "id": "lists-007-0151745"}, {"subject": "RE: Meaning of precondition DAV:supported-live-propert", "content": "Speaking of PROPPATCH preconditions, I can't help noticing that\n\n(DAV:cannot-modify-version-controlled-property): If the request attempts to\nmodify a dead property, same semantics as PUT (see Section 3.10).\n\n(DAV:cannot-modify-version): If the request attempts to modify a dead\nproperty, same semantics as PUT (see Section 3.10).\n\nare identical.\n\nWhich one should be reported?\n\n\n\n", "id": "lists-007-0161198"}, {"subject": "RE: Meaning of precondition DAV:supported-live-propert", "content": "By inference from Section 3.10, it looks like\nDAV:cannot-modify-version-controlled-property should be reported\nwhen the request-URL identifies a resource with a DAV:checked-in\nproperty, and DAV:cannot-modify-version should be reported when\nthe request-URL identifies a version resource.\n\nRoy\n\n-----Original Message-----\nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Julian\nReschke\nSent: Thursday, April 11, 2002 6:38 AM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: Meaning of precondition DAV:supported-live-property\n\n\nSpeaking of PROPPATCH preconditions, I can't help noticing that\n\n(DAV:cannot-modify-version-controlled-property): If the request\nattempts to\nmodify a dead property, same semantics as PUT (see Section 3.10).\n\n(DAV:cannot-modify-version): If the request attempts to modify a\ndead\nproperty, same semantics as PUT (see Section 3.10).\n\nare identical.\n\nWhich one should be reported?\n\n\n\n", "id": "lists-007-0169252"}, {"subject": "RE: Comment and author for a new version", "content": "The protocol currently does not support property initialization\nin the VERSION-CONTROL method, so you'd have to PROPPATCH it\nafter the resource was created.  Note that there are three different\nresources, each with their own DAV:creator-displayname and DAV:comment,\ni.e. the VCR, the version history, and the initial version.\nThe VCR would contain the DAV:creator-displayname and DAV:comment\nof the unversioned resource (i.e. the VERSION-CONTROL request does not\nchange those properties).  The initial value for those properties of\nthe new version history and the new initial version is server defined.\nThe protocol only defines what happens with dead properties.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Edgar Schwarz [mailto:edgar@edgarschwarz.de]\nSent: Thursday, April 11, 2002 8:15 AM\nTo: ietf-dav-versioning@w3.org\nSubject: Comment and author for a new version.\n\n\nHi all,\nmy repository wants to have some information when I create a new\nversion.\nSo I would like to put a resource under version control like this:\n\nVERSION-CONTROL /test.html HTTP/1.1\nHost: work.edgarschwarz.de\nContent-Type: text/xml; charset=\"utf-8\"\nContent-Length: xxxx\n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<version-control xmlns=\"DAV:\">\n<creator-displayname>Edgar Schwarz</creator-displayname>\n<comment>This is a comment for a version</comment>\n</version-control>\n\nThis also would apply to CHECKIN and BASELINE_CONTROL naturally.\nOr should I do a PROPPATCH for creator-displayname and comment before\nVERSION-CONTROL ?\n\nCheers, Edgar\n\n\n\n", "id": "lists-007-0178331"}, {"subject": "RE: Meaning of precondition DAV:supported-live-propert", "content": "Stefan is correct.  These conditions ensure that you will see\nthose properties on a (3253 compliant) resource if and only if\nthey have the 3253 defined semantics.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\n\nAs I understand it, the precondition will prevent that a resource\ncan have dead properties of the same name as a deltav live property.\n\nSo, on a deltav compliant server, you cannot retrieve or set the\nproperty DAV:version-history on a non-VCR resource (e.g. plain,\nunversioned resource of RFC 2518 style).\n\nA server, just followin 2518, would allow the setting of such\na property. It would be a dead properties without any meaning,\nbut returned on a PROPFIND nevertheless.\n\n\nAm Donnerstag den, 11. April 2002, um 14:38, schrieb Nevermann, \nDr., Peter:\n\n> In our group we are discussing about the exact meaning of the \n> additional\n> precondition(s) DAV:supported-live-property for PROPFIND and \n> PROPPATCH (3.11\n> and 3.12 in RFC 3253). In particular, the meaning of \"the \n> semantics of a\n> property being supported by the server\".\n>\n> Is the following an example?\n> A PROPPATCH request intends to modify the value of a \"checkout-fork\"\n> property of a checked-out VCR to something different than \n> DAV:forbidden or\n> DAV:discouraged, say, to an empty value. Then the\n> DAV:supported-live-property precondition is violated.\n>\n> Another interpretation is, that it has to do with properties which \n> are not\n> REQUIRED (...but there are not such properties as fas as I can see!).\n>\n> Thanks,\n> Peter\n>\n\n\n\n", "id": "lists-007-0187284"}, {"subject": "Copy and ac", "content": "Hi,\n\nWhen you copy a resource that have an aAccess Control List (for example, that denies write for all users), does its copy have the same ACL ?\n\nThanx\n\n\n\n", "id": "lists-007-0196066"}, {"subject": "RE: Copy and ac", "content": "This is server defined.  In general,\nthe ACL on a copy can be a combination of the ACL that\na new resource at the Destination would have, with the ACL of the source\non the copy.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Elodie Tasia [mailto:e.tasia@ever-team.com]\nSent: Friday, April 12, 2002 5:46 AM\nTo: IETF DAV\nSubject: Copy and acl\n\n\nHi,\n\nWhen you copy a resource that have an aAccess Control List (for example,\nthat denies write for all users), does its copy have the same ACL ?\n\nThanx\n\n\n\n", "id": "lists-007-0202852"}, {"subject": "RE: Re[2]: Semantic of MOVE between working collection", "content": "Geoff,\nIf I understand this correct, then a PROPFIND with DEPTH=1 on the working\ncollection /repo/wr/wr1 would return the URL:\n/repo/vh/vh1\n\nHowever, in another thread (\"Relative URLs, Multiple Bindings\") you replied\nthat URLs returned must be relative to the parent. To quote:\n\n\"My reading of 2518 is that it MUST return URLs that are relative to\nthe parent (e.g. A/B/x and A/B/y).\"\n\nDo we have a contradiction here or am I missing out something.\n\nGirish\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Montag, 8. April 2002 21:24\nTo: ietf-dav-versioning@w3.org\nSubject: RE: Re[2]: Semantic of MOVE between working collections\n\n\n   From: Konstantin Knizhnik [mailto:KKnizhnik@togetherlab.com]\n\n   So, PROPFIND with DEPTH=1 for working collection will return set of\n   version histories, not VCR, right?\n\nRight.\n\n\n\n", "id": "lists-007-0210121"}, {"subject": "RE: Re[2]: Semantic of MOVE between working collection", "content": "   From: B H, Girish [mailto:g.b.h@sap.com]\n\n From: Konstantin Knizhnik [mailto:KKnizhnik@togetherlab.com]\n So, PROPFIND with DEPTH=1 for working collection will return\n set of version histories, not VCR, right?\n\n      From: Clemm, Geoff [mailto:gclemm@rational.com]\n      Right.\n\n   If I understand this correct, then a PROPFIND with DEPTH=1 on the\n   working collection /repo/wr/wr1 would return the URL: /repo/vh/vh1\n\nNo, it would return \"/repo/wr/wr1/xxx (where xxx is the binding name\nfrom the DAV:versioned-binding-set for /repo/vh/vh1 in the collection\nversion that was checked out).  Both /repo/wr/wr1/xxx and /repo/vh/vh1\nidentify the same resource, but the PROPFIND on /repo/wr/wr1 must\nreturn the first URL.\n\n   However, in another thread (\"Relative URLs, Multiple Bindings\") you\nreplied\n   that URLs returned must be relative to the parent. To quote:\n\n   \"My reading of 2518 is that it MUST return URLs that are relative to\n   the parent (e.g. A/B/x and A/B/y).\"\n\n   Do we have a contradiction here or am I missing out something.\n\nThe latter (:-).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-0219279"}, {"subject": "Is version history a collection", "content": "Hi,\nIs the version history resource a webdav collection? I could not find out\nRFC 3253 specifically mentioning this. \nHowever, in most of the examples in the RFC, resource paths are specified in\nsuch a way as to indicate that the version history resource as a collection.\n\nExample: http://repo.webdav.org/his/23/ver/32\n\nHere it looks like \"ver\" is a member of the collection /his/73\n\nIf version history is a collection, then why do we need the DAV:version-set\nproperty? Because, we can still achieve the same by a PROPFIND with depth 1\non the version history (or rather on /his/23/ver in the above example).\n\nIf its not so, then it means that we are returning a URL to which we cannot\nbrowse to i.e., the version URL is not a webdav-compliant URL?\n\nGirish\n\n\n\n", "id": "lists-007-0228261"}, {"subject": "RE: Is version history a collection", "content": "   From: B H, Girish [mailto:g.b.h@sap.com]\n\n   Is the version history resource a webdav collection?\n\nNot necessarily (a server could make it be one though).\n\n   I could not find out RFC 3253 specifically mentioning this.\n\nThat is correct.  It is a server implementation decision.\n\n   However, in most of the examples in the RFC, resource paths are specified\nin\n   such a way as to indicate that the version history resource as a\ncollection.\n\n   Example: http://repo.webdav.org/his/23/ver/32\n\n   Here it looks like \"ver\" is a member of the collection /his/73\n\nThere are three possibilities in this case:\n-1- \"ver\" is a member of /his/23\n-2- /his/23 is not a WebDAV compliant resource\n-3- /his/23/ver is not a WebDAV compliant resource\nIt is up to the server which one to pick.  The most likely choices are\neither -3- or -1-.  (The reason I expect -2- to be less likely is that\nwould mean the version history resource is not a WebDAV compliant resource,\nwhich is certainly legal, but a bit strange).\n\n   If version history is a collection, then why do we need the\nDAV:version-set\n   property? Because, we can still achieve the same by a PROPFIND with depth\n1\n   on the version history (or rather on /his/23/ver in the above example).\n\nYes, but that wouldn't provide an interoperable solution, unless we\nalso required that the versions are the *only* members of the version\nhistory resource.  A server might want to give a version history other\nmembers beyond the \"ver\" member.\n\n   If its not so, then it means that we are returning a URL to which we\ncannot\n   browse to i.e., the version URL is not a webdav-compliant URL?\n\nI consider that unlikely (that is choice -2-), but it is possible.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-0236102"}, {"subject": "[ietf-dav-versioning] &lt;none&gt", "content": "Hi,\n\nin RFC3253, A.18 Checked-Out Version-Controlled Configuration the\nsupported methods are defined as:\n\n-  all version-controlled configuration methods.\n\nIn this case it looks like, for example, CHECKIN method is not supported\nby a checked-out versin-controlled configuration.\n\nI think that what is missing here is:\n-  all checked-out version controlled resource methods.\n\nRegards\nSasha\n\n\n\n", "id": "lists-007-0244889"}, {"subject": "RE: [ietf-dav-versioning] &lt;none&gt", "content": "I agree, this is a bug.\n\nI'll start an errata page and post it on the delta-v website.\n\nThanks\nTim\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Zivkov, Sasa\n> Sent: 15 April 2002 14:25\n> To: ietf-dav-versioning@w3.org\n> Subject: [ietf-dav-versioning] <none>\n> \n> \n> Hi,\n> \n> in RFC3253, A.18 Checked-Out Version-Controlled Configuration the\n> supported methods are defined as:\n> \n> -  all version-controlled configuration methods.\n> \n> In this case it looks like, for example, CHECKIN method is not supported\n> by a checked-out versin-controlled configuration.\n> \n> I think that what is missing here is:\n> -  all checked-out version controlled resource methods.\n> \n> Regards\n> Sasha\n\n\n\n", "id": "lists-007-0252460"}, {"subject": "DeltaV FA", "content": "May I encourage everyone who has read the spec to contribute to the Delta-V\nFAQ.  The aim is to capture the answers that you found counter-intuitive,\nrequired further explanation, or were simply not covered in the\nspecification.\n\nThe FAQ is at http://www.webdav.org/deltav/faq  -- and anyone can\ncontribute.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0260994"}, {"subject": "Creation time of a version", "content": "Hi,\nmy repository keeps information on the time when a version of a resource\nwas created.\nBut I didn't find a matching property in the spec. So I plan to use eg.\n'creation-time'.\nOr did I overlook something ?\n\nRegards, Edgar\n\n\n\n", "id": "lists-007-0267846"}, {"subject": "RE: Creation time of a version", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Edgar Schwarz\n> Sent: Thursday, April 18, 2002 2:49 PM\n> To: Deltav WG\n> Subject: Creation time of a version.\n> \n> \n> Hi,\n> my repository keeps information on the time when a version of a resource\n> was created.\n> But I didn't find a matching property in the spec. So I plan to use eg.\n> 'creation-time'.\n> Or did I overlook something ?\n\nWouldn't that always be identical to DAV:getlastmodified?\n\n\n\n", "id": "lists-007-0275010"}, {"subject": "RE: Creation time of a version", "content": "It is expected to be the RFC2518 defined property 'DAV:creationdate'.\n\nRegards,\nTim\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Edgar Schwarz\n> Sent: 18 April 2002 13:49\n> To: Deltav WG\n> Subject: Creation time of a version.\n> \n> \n> Hi,\n> my repository keeps information on the time when a version of a resource\n> was created.\n> But I didn't find a matching property in the spec. So I plan to use eg.\n> 'creation-time'.\n> Or did I overlook something ?\n> \n> Regards, Edgar\n\n\n\n", "id": "lists-007-0283710"}, {"subject": "RE: Creation time of a version", "content": "Interesting.\n\nWe are just discussing what a server should store as the version's creation\ndate... A copy of the VCR's creation date? The time of creation of the\nversion itself?\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Thursday, April 18, 2002 2:55 PM\n> To: Deltav WG\n> Subject: RE: Creation time of a version.\n>\n>\n> It is expected to be the RFC2518 defined property 'DAV:creationdate'.\n>\n> Regards,\n> Tim\n>\n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Edgar Schwarz\n> > Sent: 18 April 2002 13:49\n> > To: Deltav WG\n> > Subject: Creation time of a version.\n> >\n> >\n> > Hi,\n> > my repository keeps information on the time when a version of a resource\n> > was created.\n> > But I didn't find a matching property in the spec. So I plan to use eg.\n> > 'creation-time'.\n> > Or did I overlook something ?\n> >\n> > Regards, Edgar\n>\n>\n\n\n\n", "id": "lists-007-0291953"}, {"subject": "RE: Creation time of a version", "content": "> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Julian Reschke\n> Sent: 18 April 2002 13:50\n> To: Edgar Schwarz; Deltav WG\n> Subject: RE: Creation time of a version.\n>\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Edgar Schwarz\n> > Sent: Thursday, April 18, 2002 2:49 PM\n> > To: Deltav WG\n> > Subject: Creation time of a version.\n> >\n> >\n> > Hi,\n> > my repository keeps information on the time when a version of a resource\n> > was created.\n> > But I didn't find a matching property in the spec. So I plan to use eg.\n> > 'creation-time'.\n> > Or did I overlook something ?\n>\n> Wouldn't that always be identical to DAV:getlastmodified?\n>\n\nDepends on your interpretation of last modified (namely whether it includes\nproperty value modifications).  A version's (live) properties may be\nmodified, so the timestamps may differ.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0301829"}, {"subject": "RE: Creation time of a version", "content": "I think the time of creation of the version itself would be more useful.\n\nRegards,\nTim\n\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: 18 April 2002 14:02\n> To: tim@ellison.name; Deltav WG\n> Subject: RE: Creation time of a version.\n> \n> \n> Interesting.\n> \n> We are just discussing what a server should store as the \n> version's creation\n> date... A copy of the VCR's creation date? The time of creation of the\n> version itself?\n> \n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> > Sent: Thursday, April 18, 2002 2:55 PM\n> > To: Deltav WG\n> > Subject: RE: Creation time of a version.\n> >\n> >\n> > It is expected to be the RFC2518 defined property 'DAV:creationdate'.\n> >\n> > Regards,\n> > Tim\n> >\n> > > -----Original Message-----\n> > > From: ietf-dav-versioning-request@w3.org\n> > > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Edgar Schwarz\n> > > Sent: 18 April 2002 13:49\n> > > To: Deltav WG\n> > > Subject: Creation time of a version.\n> > >\n> > >\n> > > Hi,\n> > > my repository keeps information on the time when a version of \n> a resource\n> > > was created.\n> > > But I didn't find a matching property in the spec. So I plan \n> to use eg.\n> > > 'creation-time'.\n> > > Or did I overlook something ?\n> > >\n> > > Regards, Edgar\n> >\n> >\n> \n\n\n\n", "id": "lists-007-0311095"}, {"subject": "RE: Creation time of a version", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Thursday, April 18, 2002 3:13 PM\n> To: Deltav WG\n> Subject: RE: Creation time of a version.\n> ..\n>\n> > Wouldn't that always be identical to DAV:getlastmodified?\n> >\n>\n> Depends on your interpretation of last modified (namely whether\n> it includes\n> property value modifications).  A version's (live) properties may be\n> modified, so the timestamps may differ.\n\nGood point.\n\nSo from Edgar's point of view, DAV:creationdate would make more sense. Alas,\ncan a client rely on that?\n\n\n\n", "id": "lists-007-0321225"}, {"subject": "Properties registr", "content": "Now that there are a number of commercial products available that use\nWebDAV, I'd like to think that we can gain a higher level of\ninteroperability by sharing information about resource properties.\n\nI'm open to suggestions about the form this should take, but to get the ball\nrolling I've added a category to the Delta-V FAQ to capture the properties'\nsyntax and semantics (http://www.webdav.org/deltav/faq/serve/cache/34.html).\n\nThe format is simple, but has the advantage that anyone can add definitions,\nor append further information about an existing property.  I've added the\nRFC2518 properties in there to give you the idea -- clearly these publicly\nspecified properties probably don't need to be in the registry since that\ninformation is merely duplicating the RFCs.\n\nSo send me you thoughts on whether you think that such a registry is useful;\nand we'll see whether the list grows with people's additions (which is going\nto be the real measure of interest).\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0329996"}, {"subject": "RE: Creation time of a version", "content": "> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: 18 April 2002 14:26\n> To: tim@ellison.name; Deltav WG\n> Subject: RE: Creation time of a version.\n>\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> > Sent: Thursday, April 18, 2002 3:13 PM\n> > To: Deltav WG\n> > Subject: RE: Creation time of a version.\n> > ..\n> >\n> > > Wouldn't that always be identical to DAV:getlastmodified?\n> > >\n> >\n> > Depends on your interpretation of last modified (namely whether\n> > it includes\n> > property value modifications).  A version's (live) properties may be\n> > modified, so the timestamps may differ.\n>\n> Good point.\n>\n> So from Edgar's point of view, DAV:creationdate would make more\n> sense.\n\nYes.\n\n> Alas, can a client rely on that?\n\nI think so, the spec. for DAV:creationdate says that it is time time when\nthe resource was initially created (has a non-null state).  In Edgar's\nscenario, that is the time that the version was captured.  So I think\nclients should rely on that.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0337770"}, {"subject": "Typo in RFC 2518", "content": "Hi,\n\nI think I've found a couple of typos in RFC 2518.\n\nSpecifically:\n\nPage 24, Section 8.1.1, RFC 2518:\n\n----\n\n >>Response\n\n   HTTP/1.1 207 Multi-Status\n   Content-Type: text/xml; charset=\"utf-8\"\n   Content-Length: xxxx\n\n   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n <D:multistatus xmlns:D=\"DAV:\">\n<D:response>\n<D:href>http://www.foo.bar/file</D:href>\n<D:propstat>\n<D:prop xmlns:R=\"http://www.foo.bar/boxschema/\">\n<R:bigbox>\n<R:BoxType>Box type A</R:BoxType>\n</R:bigbox>\n<R:author>\n<R:Name>J.J. Johnson</R:Name>\n</R:author>\n</D:prop>\n<D:status>HTTP/1.1 200 OK</D:status>\n</D:propstat>\n<D:propstat>\n<D:prop><R:DingALing/><R:Random/></D:prop>\n[snip]\n----------\n\nHere, this should read:\n\n   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n <D:multistatus xmlns:D=\"DAV:\">\n<D:response xmlns:R=\"http://www.foo.bar/boxschema/\">\n<D:href>http://www.foo.bar/file</D:href>\n<D:propstat>\n<D:prop>\n<R:bigbox>\n<R:BoxType>Box type A</R:BoxType>\n</R:bigbox>\n<R:author>\n<R:Name>J.J. Johnson</R:Name>\n</R:author>\n</D:prop>\n<D:status>HTTP/1.1 200 OK</D:status>\n</D:propstat>\n<D:propstat>\n<D:prop><R:DingALing/><R:Random/></D:prop>\n...\n-----\n\nas otherwise, the namespace definition of R: will be out of scope by\nthe time the <R:DingALing/> tag is encountered.\n\nAnd, on page 91:\n\n-------\n[snip]\n\n23.4.2 Meaning of Qualified Names\n\n   [Note to the reader: This section does not appear in\n   [REC-XML-NAMES],\n   but is necessary to avoid ambiguity for WebDAV XML processors.]\n\n   WebDAV compliant XML processors MUST interpret a qualified name as\n   a\n   URI constructed by appending the LocalPart to the namespace name\n   URI.\n\n   Example\n\n   <del:glider xmlns:del=\"http://www.del.jensen.org/\">\n<del:glidername>\nJohnny Updraft\n     </del:glidername>\n<del:glideraccidents/>\n</del:glider>\n\nIn this example, the qualified element name \"del:glider\" is\n   interpreted as the URL \"http://www.del.jensen.org/glider\".\n\n   <bar:glider xmlns:del=\"http://www.del.jensen.org/\">\n<bar:glidername>\nJohnny Updraft\n     </bar:glidername>\n<bar:glideraccidents/>\n</bar:glider>\n\n[snip]\n\n----------------\n\nIn the second example, the line:\n\n<bar:glider xmlns:del=\"http://www.del.jensen.org/\">\n\nshould read:\n\n<bar:glider xmlns:bar=\"http://www.del.jensen.org/\">\n\nas otherwise the XML namespace bar is undefined, and a namespace\nvalidating parser will barf.\n\nCan someone shed some light on these. Are they typos or have I\nmissed something?\n\nBen\n\n\n\n", "id": "lists-007-0346868"}, {"subject": "Re: Typo in RFC 2518", "content": "Ben,\n\nThese are already known issues (the first is \"MISSING_NS_SPEC\" and the\nsecond is \"NS_BOOBOO\") in the RFC2518 issues list\n(http://www.webdav.org/wg/rfcdev/issues.htm).\n\nAll RFC2518 readers should (and, I suggest, all implementers 'must') read\nthe list of issues and their resolutions.\n\nRegards,\nTim\n\n\n                                                                                                                                                \n                      Ben Evans                                                                                                                 \n                      <ben.evans@parasolsolut        To:       Deltav WG <ietf-dav-versioning@w3.org>                                           \n                      ions.com>                      cc:       w3c-dist-auth@w3.org                                                             \n                      Sent by:                       Subject:  Typo in RFC 2518?                                                                \n                      ietf-dav-versioning-req                                                                                                   \n                      uest@w3.org                                                                                                               \n                                                                                                                                                \n                                                                                                                                                \n                      18/04/2002 16:41                                                                                                          \n                      Please respond to Ben                                                                                                     \n                      Evans                                                                                                                     \n                                                                                                                                                \n                                                                                                                                                \n\n\n\n\nHi,\n\nI think I've found a couple of typos in RFC 2518.\n\nSpecifically:\n\nPage 24, Section 8.1.1, RFC 2518:\n\n----\n\n >>Response\n\n   HTTP/1.1 207 Multi-Status\n   Content-Type: text/xml; charset=\"utf-8\"\n   Content-Length: xxxx\n\n   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n              <D:multistatus xmlns:D=\"DAV:\">\n                         <D:response>\n\n<D:href>http://www.foo.bar/file</D:href>\n                                     <D:propstat>\n                                                 <D:prop xmlns:R=\"\nhttp://www.foo.bar/boxschema/\">\n                                                             <R:bigbox>\n\n<R:BoxType>Box type A</R:BoxType>\n                                                             </R:bigbox>\n                                                             <R:author>\n\n<R:Name>J.J. Johnson</R:Name>\n                                                             </R:author>\n                                                 </D:prop>\n                                                 <D:status>HTTP/1.1 200\nOK</D:status>\n                                     </D:propstat>\n                                     <D:propstat>\n\n<D:prop><R:DingALing/><R:Random/></D:prop>\n[snip]\n----------\n\nHere, this should read:\n\n   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n              <D:multistatus xmlns:D=\"DAV:\">\n                         <D:response xmlns:R=\"http://www.foo.bar/boxschema/\n\">\n\n<D:href>http://www.foo.bar/file</D:href>\n                                     <D:propstat>\n                                                 <D:prop>\n                                                             <R:bigbox>\n\n<R:BoxType>Box type A</R:BoxType>\n                                                             </R:bigbox>\n                                                             <R:author>\n\n<R:Name>J.J. Johnson</R:Name>\n                                                             </R:author>\n                                                 </D:prop>\n                                                 <D:status>HTTP/1.1 200\nOK</D:status>\n                                     </D:propstat>\n                                     <D:propstat>\n\n<D:prop><R:DingALing/><R:Random/></D:prop>\n...\n-----\n\nas otherwise, the namespace definition of R: will be out of scope by\nthe time the <R:DingALing/> tag is encountered.\n\nAnd, on page 91:\n\n-------\n[snip]\n\n23.4.2 Meaning of Qualified Names\n\n   [Note to the reader: This section does not appear in\n   [REC-XML-NAMES],\n   but is necessary to avoid ambiguity for WebDAV XML processors.]\n\n   WebDAV compliant XML processors MUST interpret a qualified name as\n   a\n   URI constructed by appending the LocalPart to the namespace name\n   URI.\n\n   Example\n\n   <del:glider xmlns:del=\"http://www.del.jensen.org/\">\n<del:glidername>\nJohnny Updraft\n     </del:glidername>\n<del:glideraccidents/>\n</del:glider>\n\nIn this example, the qualified element name \"del:glider\" is\n   interpreted as the URL \"http://www.del.jensen.org/glider\".\n\n   <bar:glider xmlns:del=\"http://www.del.jensen.org/\">\n<bar:glidername>\nJohnny Updraft\n     </bar:glidername>\n<bar:glideraccidents/>\n</bar:glider>\n\n[snip]\n\n----------------\n\nIn the second example, the line:\n\n<bar:glider xmlns:del=\"http://www.del.jensen.org/\">\n\nshould read:\n\n<bar:glider xmlns:bar=\"http://www.del.jensen.org/\">\n\nas otherwise the XML namespace bar is undefined, and a namespace\nvalidating parser will barf.\n\nCan someone shed some light on these. Are they typos or have I\nmissed something?\n\nBen\n\n\n\n", "id": "lists-007-0357382"}, {"subject": "Re: Typo in RFC 2518", "content": "Tim,\n\nOn Fri, Apr 19, 2002 at 09:00:12AM +0100, Tim Ellison wrote:\n> \n> These are already known issues (the first is \"MISSING_NS_SPEC\" and the\n> second is \"NS_BOOBOO\") in the RFC2518 issues list\n> (http://www.webdav.org/wg/rfcdev/issues.htm).\n> \n> All RFC2518 readers should (and, I suggest, all implementers 'must') read\n> the list of issues and their resolutions.\n\nThanks for pointing me at the issues page. I was just working from the\nRFC as given at ietf.org, and it doesn't have any corrections listed\nfor 2518.\n\nI've notified the editors of that site, so hopefully they'll add some\nrelevant errata entries and no-one else'll get caught by that.\n\n(goes to read rest of issues...)\n\nBen\n\n\n\n", "id": "lists-007-0372336"}, {"subject": "Re: Typo in RFC 2518", "content": "> On Fri, Apr 19, 2002 at 09:00:12AM +0100, Tim Ellison wrote:\n> >\n> > These are already known issues (the first is \"MISSING_NS_SPEC\" and the\n> > second is \"NS_BOOBOO\") in the RFC2518 issues list\n> > (http://www.webdav.org/wg/rfcdev/issues.htm).\n> >\n> > All RFC2518 readers should (and, I suggest, all implementers 'must')\nread\n> > the list of issues and their resolutions.\n>\n> Thanks for pointing me at the issues page. I was just working from the\n> RFC as given at ietf.org, and it doesn't have any corrections listed\n> for 2518.\n>\n> I've notified the editors of that site, so hopefully they'll add some\n> relevant errata entries and no-one else'll get caught by that.\n>\n> (goes to read rest of issues...)\n\nI've also started a Delta-V issues list at\n  http://www.webdav.org/deltav/protocol/rfc3253-issues-list.htm\n\nlet me know if there is anything to add.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0380453"}, {"subject": "RE: checked-out version-controlled configuratio", "content": "I agree it is a bug, but I believe the bug is\nhaving checked-out version-controlled resource\nand checked-out version-controlled configuration\ncategories.\n\nWe should have just defined version-controlled\nresource to inherit from checked-out resource\nand directly introduce the checked-in properties\nand methods to version-controlled resource,\nand deleted the checked-out vcr and checked-out vcc\ncategories.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Tim Ellison [mailto:tim@ellison.name]\nSent: Tuesday, April 16, 2002 12:24 PM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: [ietf-dav-versioning] <none>\n\n\nI agree, this is a bug.\n\nI'll start an errata page and post it on the delta-v website.\n\nThanks\nTim\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Zivkov, Sasa\n> Sent: 15 April 2002 14:25\n> To: ietf-dav-versioning@w3.org\n> Subject: [ietf-dav-versioning] <none>\n> \n> \n> Hi,\n> \n> in RFC3253, A.18 Checked-Out Version-Controlled Configuration the\n> supported methods are defined as:\n> \n> -  all version-controlled configuration methods.\n> \n> In this case it looks like, for example, CHECKIN method is not supported\n> by a checked-out versin-controlled configuration.\n> \n> I think that what is missing here is:\n> -  all checked-out version controlled resource methods.\n> \n> Regards\n> Sasha\n\n\n\n", "id": "lists-007-0388597"}, {"subject": "RE: Creation time of a version", "content": "I agree with Tim.  The DAV:creationdate for a version should be the time\nthat\nthe version was created (the version captures the dead properties of\nthe VCR, not the live properties ... a version has its own live properties).\n\nSimilarly, the DAV:creationdate for a VCR is the date that VCR was\ncreated, and the DAV:creationdate for a version history is the date\nthat version history was created.\n\nJust keep repeating the mantra: \"A VCR is not a version, a version is\nnot a version history, a version history is not a VCR\" (:-).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Tim Ellison [mailto:tim@ellison.name]\n\n... the spec. for DAV:creationdate says that it is time time when\nthe resource was initially created (has a non-null state).  In Edgar's\nscenario, that is the time that the version was captured.  So I think\nclients should rely on that.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0397984"}, {"subject": "Creation time of a version, Baseline-control stuff, divers", "content": "Geoff wrote:\n> I agree with Tim.  The DAV:creationdate for a version should be the time\n> that\n> the version was created (the version captures the dead properties of\n> the VCR, not the live properties ... a version has its own live properties).\nOkay, so it seems to be okay to request the following (D: and <> dropped\n:-) :\n\nREPORT\nversion-tree\nprop\nversion-name\ncreator-displayname\ncreationdate\ncomment\n\nIn 12.6.1 we see:\nBASELINE-CONTROL\nbaseline-control\nhref\n\nShouldn't this be (See 12.6) ?\nBASELINE-CONTROL\nbaseline-control\nbaseline\nhref\n\n\nThen I'm looking for some reports. \nFirst I would like to have information on a baseline. How can I get the\nlist of\nversions and subbaselines ?\nSecond I want to have information on a configuration. This means state\n(checked-out,\nchecked-in) and a list of VCRs, VCCs and their states.\n\nBTW, after a recent post I had a first look at our FAQ and was surprised\nto see that it's\na faq-o-matiq. That's very nice. I recently also installed a faq-o-matic\nat work.\nI also don't mind having 2518 properties listed. It's more compact than\nin 2518 itself I guess.\n\nI also twice read negative things on WebDAV recently. It was considered\na security risk.\nBut it wasn't clear whether WebDAV itself was the target or faulty\nimplementations.\nI hope ACL (which I didn't have the time to follow) will cure these\nproblems.\n\nCheers, Edgar\n\n\n\n", "id": "lists-007-0405808"}, {"subject": "RE: Creation time of a version, Baseline-control stuff, divers", "content": "   From: Edgar Schwarz [mailto:edgar@edgarschwarz.de]\n\n   In 12.6.1 we see:\n   BASELINE-CONTROL\n   baseline-control\n   href\n\n   Shouldn't this be (See 12.6) ?\n   BASELINE-CONTROL\n   baseline-control\n   baseline\n   href\n\n\nEgads!  It certainly should be.  I'll add that to the Errata.\n\n   Then I'm looking for some reports.  First I would like to have\n   information on a baseline. How can I get the list of versions and\n   subbaselines ?\n\nTo get the list of versions, do a PROPFIND Depth:Infinity on the\nDAV:baseline-collection of the baseline.  To get the subbaselines, get\nthe DAV:subbaseline-set property of the baseline.\n\n   Second I want to have information on a configuration. This means\n   state (checked-out, checked-in) and a list of VCRs, VCCs and their\n   states.\n\nTo get the DAV:checked-in and DAV:checked-out properties of the\nconfiguration, just PROPFIND the DAV:version-controlled-configuration\nof any member of the configuration for those two properties.\n\nWhat list of VCR's did you have in mind?  If it is all the VCR's that\nare the member of the configuration, just PROPFIND Depth:Infinity\nthe root collection of the configuration for DAV:checked-in and\nDAV:checked-out (any resource that has these properties is a VCR\nthat is a member of the configuration).  By VCC, did you mean\nVCCn or VCCl?\n\n   I also twice read negative things on WebDAV recently. It was\n   considered a security risk.  But it wasn't clear whether WebDAV\n   itself was the target or faulty implementations.  I hope ACL (which\n   I didn't have the time to follow) will cure these problems.\n\nThese were negative comments about WebDAV appear to be derived from a\nbasic misunderstanding of the WebDAV design.  In particular, they\nappear to assume WebDAV suffers from the same security problems as\nprotocols like SOAP that tunnel through POST.  WebDAV was specifically\ndesigned to not have these problems (at non-trivial cost, since the\nsecure approach adopted by WebDAV creates problems with non-HTTP/1.1\ncompliant proxies), so it is rather frustrating for WebDAV to be\nincorrectly singled out, instead of the protocols (like SOAP) that in\nfact do have these problems.  Several of us have sent messages to the\nauthors of these incorrect statements, and hopefully they will be\nretracted.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-0414651"}, {"subject": "Label header vs PROPFIND depth ", "content": "Hi,\n\ngiven a collection \"/a\" and a VCR \"/a/b\", where \"/a/b\" has a version\n\"/versions/b/1\" with a label \"labeltest\", what would I expect from a\n\nPROPFIND /a\nDepth: 1\nLabel: labeltest\n\n?\n\nAccording to section 8, the label header should only be applied when the\nrequest URL is a VCR (which isn't the case here). However, a\n\nPROPFIND /a/b\nDepth: 0\nLabel: labeltest\n\n*would* take the label header into account.\n\nThis would make the PROPFIND results for /a/b depend on which is the request\nURL for the PROPFIND, which definitively doesn't seem to be desirable.\n\n(A similar problem applies to COPY with depth > 0).\n\nJulian\n\n\n\n", "id": "lists-007-0425113"}, {"subject": "Re: Label header vs PROPFIND depth ", "content": "\"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n\n> given a collection \"/a\" and a VCR \"/a/b\", where \"/a/b\" has a version\n> \"/versions/b/1\" with a label \"labeltest\", what would I expect from a\n>\n> PROPFIND /a\n> Depth: 1\n> Label: labeltest\n>\n> ?\n>\n> According to section 8, the label header should only be applied when the\n> request URL is a VCR (which isn't the case here). However, a\n>\n> PROPFIND /a/b\n> Depth: 0\n> Label: labeltest\n>\n> *would* take the label header into account.\n>\n> This would make the PROPFIND results for /a/b depend on which is the\nrequest\n> URL for the PROPFIND, which definitively doesn't seem to be desirable.\n>\n> (A similar problem applies to COPY with depth > 0).\n\nYour interpretation is correct.  The label: header is only applied to the\nrequest-URL.  Why is this undesirable?\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0435150"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "I think it breaks a very basic assumption about PROPFIND's depth handling:\nfor a given collection member, you will get the same response element for\ndepth:1 on it's parent and depth:0 for a PROPFIND on itself.\n\nWhat's the motivation for this change? Currently I can't think of a reason,\nand it certainly makes it harder to come up for consistent variant handling\nin WebDAV.\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Monday, April 22, 2002 2:49 PM\n> To: Deltav WG\n> Subject: Re: Label header vs PROPFIND depth 1\n>\n>\n>\n> \"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n>\n> > given a collection \"/a\" and a VCR \"/a/b\", where \"/a/b\" has a version\n> > \"/versions/b/1\" with a label \"labeltest\", what would I expect from a\n> >\n> > PROPFIND /a\n> > Depth: 1\n> > Label: labeltest\n> >\n> > ?\n> >\n> > According to section 8, the label header should only be applied when the\n> > request URL is a VCR (which isn't the case here). However, a\n> >\n> > PROPFIND /a/b\n> > Depth: 0\n> > Label: labeltest\n> >\n> > *would* take the label header into account.\n> >\n> > This would make the PROPFIND results for /a/b depend on which is the\n> request\n> > URL for the PROPFIND, which definitively doesn't seem to be desirable.\n> >\n> > (A similar problem applies to COPY with depth > 0).\n>\n> Your interpretation is correct.  The label: header is only applied to the\n> request-URL.  Why is this undesirable?\n>\n> Regards,\n> Tim\n>\n>\n\n\n\n", "id": "lists-007-0443798"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "\"Julian Reschke\" <julian.reschke@greenbytes.de>\n\n> I think it breaks a very basic assumption about PROPFIND's depth\nhandling:\n> for a given collection member, you will get the same response element for\n> depth:1 on it's parent and depth:0 for a PROPFIND on itself.\n\nWait, maybe I didn't make it clear.  The label: header applies to the\nversion-controlled resource identified by the request-URL; and then the\ndepth operation proceeds on the labelled *version*.  The only version with\nmembers is a versioned collection, whose members are version histories.\n\n> What's the motivation for this change? Currently I can't think of a\nreason,\n> and it certainly makes it harder to come up for consistent variant\nhandling\n> in WebDAV.\n\nIt is a short-hand for referencing the version associated with a\nversion-controlled resource.\n\nRegards,\nTim\n\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Monday, April 22, 2002 2:49 PM\n> To: Deltav WG\n> Subject: Re: Label header vs PROPFIND depth 1\n>\n>\n>\n> \"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n>\n> > given a collection \"/a\" and a VCR \"/a/b\", where \"/a/b\" has a version\n> > \"/versions/b/1\" with a label \"labeltest\", what would I expect from a\n> >\n> > PROPFIND /a\n> > Depth: 1\n> > Label: labeltest\n> >\n> > ?\n> >\n> > According to section 8, the label header should only be applied when\nthe\n> > request URL is a VCR (which isn't the case here). However, a\n> >\n> > PROPFIND /a/b\n> > Depth: 0\n> > Label: labeltest\n> >\n> > *would* take the label header into account.\n> >\n> > This would make the PROPFIND results for /a/b depend on which is the\n> request\n> > URL for the PROPFIND, which definitively doesn't seem to be desirable.\n> >\n> > (A similar problem applies to COPY with depth > 0).\n>\n> Your interpretation is correct.  The label: header is only applied to the\n> request-URL.  Why is this undesirable?\n>\n> Regards,\n> Tim\n>\n>\n\n\n\n", "id": "lists-007-0453954"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Monday, April 22, 2002 3:10 PM\n> To: Deltav WG\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n>\n> \"Julian Reschke\" <julian.reschke@greenbytes.de>\n>\n> > I think it breaks a very basic assumption about PROPFIND's depth\n> handling:\n> > for a given collection member, you will get the same response\n> element for\n> > depth:1 on it's parent and depth:0 for a PROPFIND on itself.\n>\n> Wait, maybe I didn't make it clear.  The label: header applies to the\n\nSeems so.\n\n> version-controlled resource identified by the request-URL; and then the\n> depth operation proceeds on the labelled *version*.  The only version with\n> members is a versioned collection, whose members are version histories.\n\nThis seems to apply to the case where I have version controlled resources in\na version controlled collection. But what happens if the collection itself\nisn't version-controlled?\n\n> > What's the motivation for this change? Currently I can't think of a\n> reason,\n> > and it certainly makes it harder to come up for consistent variant\n> handling\n> > in WebDAV.\n>\n> It is a short-hand for referencing the version associated with a\n> version-controlled resource.\n\nMisunderstanding :-)\n\nI wasn't asking for the motivation for this *feature*, I was asking for the\nmotivation for changing a basic feature about how PROPFIND works on\ncollections...\n\n\n\n", "id": "lists-007-0464804"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "\"Julian Reschke\" <julian.reschke@greenbytes.de>\n\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> > Sent: Monday, April 22, 2002 3:10 PM\n> > To: Deltav WG\n> > Subject: RE: Label header vs PROPFIND depth 1\n> >\n> > \"Julian Reschke\" <julian.reschke@greenbytes.de>\n> >\n> > > I think it breaks a very basic assumption about PROPFIND's depth\n> > handling:\n> > > for a given collection member, you will get the same response\n> > element for\n> > > depth:1 on it's parent and depth:0 for a PROPFIND on itself.\n> >\n> > Wait, maybe I didn't make it clear.  The label: header applies to the\n>\n> Seems so.\n>\n> > version-controlled resource identified by the request-URL; and then the\n> > depth operation proceeds on the labelled *version*.  The only version\nwith\n> > members is a versioned collection, whose members are version histories.\n>\n> This seems to apply to the case where I have version controlled resources\nin\n> a version controlled collection. But what happens if the collection\nitself\n> isn't version-controlled?\n\nAs written in section 8.3, the label: header only applies if the\nrequest-URI identifies a version-controlled resource.\n\n> > > What's the motivation for this change? Currently I can't think of a\n> > reason,\n> > > and it certainly makes it harder to come up for consistent variant\n> > handling\n> > > in WebDAV.\n> >\n> > It is a short-hand for referencing the version associated with a\n> > version-controlled resource.\n>\n> Misunderstanding :-)\n>\n> I wasn't asking for the motivation for this *feature*, I was asking for\nthe\n> motivation for changing a basic feature about how PROPFIND works on\n> collections...\n\n...and do we agree that it doesn't?  It just changes the resource that the\nmethod is applied to.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0474748"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Monday, April 22, 2002 3:28 PM\n> To: Deltav WG\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n> ...\n>\n> > This seems to apply to the case where I have version controlled\n> resources\n> in\n> > a version controlled collection. But what happens if the collection\n> itself\n> > isn't version-controlled?\n>\n> As written in section 8.3, the label: header only applies if the\n> request-URI identifies a version-controlled resource.\n\nWell, exactly that *is* my problem.\n\nI have a non-version-controlled collection with a versioned member resource.\nA PROPFIND with label header and depth:1 will (or may) return a different\nresponse element for the versioned resource than a PROPFIND with depth:0 on\nthe member resource itself.\n\nSo I'd like to clarify/correct RFC3253 that the Label header is handled just\nlike any other HTTP header which causes variant handling -- it applies to\nthe collection members as well.\n\nOtherwise variant handling would differ between -- for instance -- \"Label\"\nand \"Accept-Language\" -- and that doesn't make any sense at all.\n\n> > > It is a short-hand for referencing the version associated with a\n> > > version-controlled resource.\n> >\n> > Misunderstanding :-)\n> >\n> > I wasn't asking for the motivation for this *feature*, I was asking for\n> the\n> > motivation for changing a basic feature about how PROPFIND works on\n> > collections...\n>\n> ...and do we agree that it doesn't?  It just changes the resource that the\n> method is applied to.\n\nYes. But if the collection isn't versioned (does not vary on the Label\nheader), the Label header just should be *ignored* (for the collection), and\nthen *apply* to the indivual versioned members of the collection.\n\n\n\n", "id": "lists-007-0485375"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "\"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n\n> > As written in section 8.3, the label: header only applies if the\n> > request-URI identifies a version-controlled resource.\n>\n> Well, exactly that *is* my problem.\n>\n> I have a non-version-controlled collection with a versioned member\nresource.\n> A PROPFIND with label header and depth:1 will (or may) return a different\n> response element for the versioned resource than a PROPFIND with depth:0\non\n> the member resource itself.\n>\n> So I'd like to clarify/correct RFC3253 that the Label header is handled\njust\n> like any other HTTP header which causes variant handling -- it applies to\n> the collection members as well.\n>\n> Otherwise variant handling would differ between -- for instance --\n\"Label\"\n> and \"Accept-Language\" -- and that doesn't make any sense at all.\n\nNo, the label: header does not apply to the members of the collection, just\nthe request-URI resource.  It behaves the same way as the Depth: header of\nRFC2518, i.e. Depth: 1 only applies to the method at the request-URI\nresource and not recursively to the members.\n\n> > ...and do we agree that it doesn't?  It just changes the resource that\nthe\n> > method is applied to.\n>\n> Yes. But if the collection isn't versioned (does not vary on the Label\n> header), the Label header just should be *ignored* (for the collection),\nand\n> then *apply* to the indivual versioned members of the collection.\n\nNo, it will be ignored for the target of the method, and ignored for the\nmembers of the collection.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0495408"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Monday, April 22, 2002 4:06 PM\n> To: Deltav WG\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n> ...\n> >\n> > Otherwise variant handling would differ between -- for instance --\n> \"Label\"\n> > and \"Accept-Language\" -- and that doesn't make any sense at all.\n>\n> No, the label: header does not apply to the members of the\n> collection, just\n> the request-URI resource.  It behaves the same way as the Depth: header of\n> RFC2518, i.e. Depth: 1 only applies to the method at the request-URI\n> resource and not recursively to the members.\n\nWell, again I think that this is a major problem. It makes handling of the\n\"Label\" header different from handling of other headers that selection\nvariants of a resource. What is the *benefit* of this special handling?\n\n> > > ...and do we agree that it doesn't?  It just changes the resource that\n> the\n> > > method is applied to.\n> >\n> > Yes. But if the collection isn't versioned (does not vary on the Label\n> > header), the Label header just should be *ignored* (for the collection),\n> and\n> > then *apply* to the indivual versioned members of the collection.\n>\n> No, it will be ignored for the target of the method, and ignored for the\n> members of the collection.\n\nSo this is different from for instance handling of the \"accept-language\"\nheader. Can you give a reason why this would be desirable?\n\n\n\n", "id": "lists-007-0504753"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   given a collection \"/a\" and a VCR \"/a/b\", where \"/a/b\" has a version\n   \"/versions/b/1\" with a label \"labeltest\", what would I expect from a\n\n   PROPFIND /a\n   Depth: 1\n   Label: labeltest\n\n   ?\n\nA PROPFIND request applied to a collection with a Depth header is\napplied to the collection every member of the collection that\nsatisfies that Depth header.\n\nSo it is applied to /a and /a/b.\n\nAssuming /a is not version-controlled, then the effect of the Label\nheader is undefined, so your implementation could just ignore the\nLabel header and return the properties of /a, or it could indicate\nthat it is an error for /a.\n\nSince /a/b is version-controlled, the effect is defined by section\n8.6, and you would return the properties of the version labeled\n\"labeltest\".\n\n   According to section 8, the label header should only be applied when the\n   request URL is a VCR (which isn't the case here).\n\nSection 8 just gives you the *additional* semantics for PROPFIND when\na Label header is present.  It doesn't change anything about the\nexisting semantics of PROPFIND, i.e. that any header in the request\nis applied to each of the nested applications of PROPFIND.\n\n   However, a\n\n   PROPFIND /a/b\n   Depth: 0\n   Label: labeltest\n\n   *would* take the label header into account.\n\nA PROPFIND always takes all of its headers into account when it\nis applied to each of the members that it applies to.\n\n   This would make the PROPFIND results for /a/b depend on which is the\nrequest\n   URL for the PROPFIND, which definitively doesn't seem to be desirable.\n\n   (A similar problem applies to COPY with depth > 0).\n\nSimilar answer for COPY ... COPY has all of its normal semantics when\nthe Label header is present, i.e. all headers are applied to each of\nthe \"nested\" copies that result from a Depth copy.\n\nSo, bottom line is, it does what you want (:-).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-0514462"}, {"subject": "Typo in RFC3253, section 3.1.", "content": "Says:\n\n<!ELEMENT supported-live-property-set (supported-live-property*)>\n<!ELEMENT supported-live-property name>\n<!ELEMENT prop ANY>\nANY value: a property element type\n\nSo looking at the last (submitted draft), this should be:\n\n<!ELEMENT supported-live-property-set (supported-live-property*)>\n<!ELEMENT supported-live-property prop>\n<!ELEMENT prop ANY>\nANY value: a property element type\n\nCorrect?\n\n\n\n", "id": "lists-007-0524151"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Monday, April 22, 2002 4:36 PM\n> To: Deltav WG\n> Subject: RE: Label header vs PROPFIND depth 1\n> \n> ...\n> \n> So, bottom line is, it does what you want (:-).\n\nOK. Great. Probably worth adding to the FAQ.\n\n\n\n", "id": "lists-007-0532266"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "\"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n\n> > No, the label: header does not apply to the members of the\n> > collection, just\n> > the request-URI resource.  It behaves the same way as the Depth: header\nof\n> > RFC2518, i.e. Depth: 1 only applies to the method at the request-URI\n> > resource and not recursively to the members.\n>\n> Well, again I think that this is a major problem. It makes handling of\nthe\n> \"Label\" header different from handling of other headers that selection\n> variants of a resource.\n\nHow is it different to the Depth: header?  Ignoring the fact that Depth: 0\nand Depth: infinity degenerate into the 'right thing'.\n\n> What is the *benefit* of this special handling?\n\nSee below.\n\n> > > Yes. But if the collection isn't versioned (does not vary on the\nLabel\n> > > header), the Label header just should be *ignored* (for the\ncollection),\n> > and\n> > > then *apply* to the indivual versioned members of the collection.\n> >\n> > No, it will be ignored for the target of the method, and ignored for\nthe\n> > members of the collection.\n>\n> So this is different from for instance handling of the \"accept-language\"\n> header. Can you give a reason why this would be desirable?\n\nRather than decide whether it should be different from the handling of a\n\"accept-*\" header, we should agree on what is the most useful definition.\nUnless you are suggesting that this difference makes it\nimpossible/difficult to implement, and I don't think that it does.\n\nSo, I think the reason it is the way it is, is so that the results of the\ndepth operation conform to the definition of multistatus, i.e. that the\nresults are related by collection membership.\n\n\"the multistatus XML element for a collection resource with member URIs\nMUST include a response XML element for each member URI of the collection,\nto whatever depth was requested\"\n\nIf the label: applied to each member of the version-controlled collection,\nthen the results would be a set of versions that were not related by\nmembership.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0540697"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Monday, April 22, 2002 4:51 PM\n> To: Deltav WG\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n>\n> \"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n>\n> > > No, the label: header does not apply to the members of the\n> > > collection, just\n> > > the request-URI resource.  It behaves the same way as the\n> Depth: header\n> of\n> > > RFC2518, i.e. Depth: 1 only applies to the method at the request-URI\n> > > resource and not recursively to the members.\n> >\n> > Well, again I think that this is a major problem. It makes handling of\n> the\n> > \"Label\" header different from handling of other headers that selection\n> > variants of a resource.\n>\n> How is it different to the Depth: header?  Ignoring the fact that Depth: 0\n> and Depth: infinity degenerate into the 'right thing'.\n\nThe semantics of the depth header is explicitly defined for PROPFIND. So you\ncan think of it as a parameter to PROPFIND. Headers that select variants\nsimply are different.\n\n> ..\n>\n> > So this is different from for instance handling of the \"accept-language\"\n> > header. Can you give a reason why this would be desirable?\n>\n> Rather than decide whether it should be different from the handling of a\n> \"accept-*\" header, we should agree on what is the most useful definition.\n\nWell, it should also be consistent with the handling of other headers,\nright?\n\n> Unless you are suggesting that this difference makes it\n> impossible/difficult to implement, and I don't think that it does.\n>\n> So, I think the reason it is the way it is, is so that the results of the\n> depth operation conform to the definition of multistatus, i.e. that the\n> results are related by collection membership.\n\nThey are -- keep in mind that *I* am discussing the case where the target\ncollection resource is *not* version-controlled.\n\n> \"the multistatus XML element for a collection resource with member URIs\n> MUST include a response XML element for each member URI of the collection,\n> to whatever depth was requested\"\n>\n> If the label: applied to each member of the version-controlled collection,\n> then the results would be a set of versions that were not related by\n> membership.\n\nNo, the result isn't a set of versions anyway. It is a set of *variants* of\nthe member VCRs. You will not see the version URIs in the response body.\n\n\n\n", "id": "lists-007-0550572"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> The semantics of the depth header is explicitly defined for PROPFIND. So\nyou\n> can think of it as a parameter to PROPFIND. Headers that select variants\n> simply are different.\n\nThe label: header causes the method to be applied to the version -- a\nversion is not a variant of a version-controlled resource, that is, a\nversion is not another representation of the version-controlled resource,\nit is a whole new resource.\n\n> > ..\n> >\n> > > So this is different from for instance handling of the\n\"accept-language\"\n> > > header. Can you give a reason why this would be desirable?\n> >\n> > Rather than decide whether it should be different from the handling of\na\n> > \"accept-*\" header, we should agree on what is the most useful\ndefinition.\n>\n> Well, it should also be consistent with the handling of other headers,\n> right?\n\nWell as you pointed out, we can define headers to have whatever semantics;\nbut consistency is good.\n\n>...\n> They are -- keep in mind that *I* am discussing the case where the target\n> collection resource is *not* version-controlled.\n\nOk.\n\n> > \"the multistatus XML element for a collection resource with member URIs\n> > MUST include a response XML element for each member URI of the\ncollection,\n> > to whatever depth was requested\"\n> >\n> > If the label: applied to each member of the version-controlled\ncollection,\n> > then the results would be a set of versions that were not related by\n> > membership.\n>\n> No, the result isn't a set of versions anyway. It is a set of *variants*\nof\n> the member VCRs. You will not see the version URIs in the response body.\n\nWhat do you mean by the _variants_ of a version-controlled resource?  My\nunderstanding is that a variant is an alternate representation of a\nresource, and that is not the case here.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0561596"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Monday, April 22, 2002 5:16 PM\n> To: Deltav WG\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n>\n> > The semantics of the depth header is explicitly defined for PROPFIND. So\n> you\n> > can think of it as a parameter to PROPFIND. Headers that select variants\n> > simply are different.\n>\n> The label: header causes the method to be applied to the version -- a\n> version is not a variant of a version-controlled resource, that is, a\n> version is not another representation of the version-controlled resource,\n> it is a whole new resource.\n\nIn absence of the LABEL header feature I would agree.\n\nHowever, the label header exactly does what HTTP 1.1 defines a selecting a\nvariant. So if you use it to get a version rather than a VCR, you *make* the\nversion a variant of the VCR (like it or not).\n\n> > > \"the multistatus XML element for a collection resource with\n> member URIs\n> > > MUST include a response XML element for each member URI of the\n> collection,\n> > > to whatever depth was requested\"\n> > >\n> > > If the label: applied to each member of the version-controlled\n> collection,\n> > > then the results would be a set of versions that were not related by\n> > > membership.\n> >\n> > No, the result isn't a set of versions anyway. It is a set of *variants*\n> of\n> > the member VCRs. You will not see the version URIs in the response body.\n>\n> What do you mean by the _variants_ of a version-controlled resource?  My\n> understanding is that a variant is an alternate representation of a\n> resource, and that is not the case here.\n\nYes, it is.\n\nThe label header is a variant selector as defined per RFC2616. If this\nwouldn't be the case, including \"label\" in the \"vary\" header would be wrong.\n\n\n\n", "id": "lists-007-0570935"}, {"subject": "Re: Typo in RFC3253, section 3.1.", "content": "\"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n\n> Says:\n>\n> <!ELEMENT supported-live-property-set (supported-live-property*)>\n> <!ELEMENT supported-live-property name>\n> <!ELEMENT prop ANY>\n> ANY value: a property element type\n>\n> So looking at the last (submitted draft), this should be:\n>\n> <!ELEMENT supported-live-property-set (supported-live-property*)>\n> <!ELEMENT supported-live-property prop>\n> <!ELEMENT prop ANY>\n> ANY value: a property element type\n>\n> Correct?\n\nYes -- looks like that may have been introduced during the final editing\npass.\nI'll add it to the errata document\n(http://www.webdav.org/deltav/protocol/rfc3253-issues-list.htm).\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0581032"}, {"subject": "RE: Typo in RFC3253, section 3.1.", "content": "Argh.  Correct.  Added to Errata.  Thanks!\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Monday, April 22, 2002 10:44 AM\nTo: Deltav WG\nSubject: Typo in RFC3253, section 3.1.4\n\n\nSays:\n\n<!ELEMENT supported-live-property-set (supported-live-property*)>\n<!ELEMENT supported-live-property name>\n<!ELEMENT prop ANY>\nANY value: a property element type\n\nSo looking at the last (submitted draft), this should be:\n\n<!ELEMENT supported-live-property-set (supported-live-property*)>\n<!ELEMENT supported-live-property prop>\n<!ELEMENT prop ANY>\nANY value: a property element type\n\nCorrect?\n\n\n\n", "id": "lists-007-0589303"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "\"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n\n> > What do you mean by the _variants_ of a version-controlled resource?\nMy\n> > understanding is that a variant is an alternate representation of a\n> > resource, and that is not the case here.\n>\n> Yes, it is.\n\n...oh no it isn't   [[ a British vaudeville joke, that probably looses a\nlot in translation<g> ]]\n\n> The label header is a variant selector as defined per RFC2616. If this\n> wouldn't be the case, including \"label\" in the \"vary\" header would be\nwrong.\n\nWell I've read the definition of a variant, and a version is certainly not\na variant of a version-controlled resource.   And I've read the definition\nof the vary: header and it talks about the cache-ability of the result.\nWhat am I missing?\n\nIf DeltaV implies that a version is a variant of a version-controlled\nresource then that must be fixed.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0597270"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Monday, April 22, 2002 5:57 PM\n> To: Deltav WG\n> Subject: RE: Label header vs PROPFIND depth 1\n> ..\n> > The label header is a variant selector as defined per RFC2616. If this\n> > wouldn't be the case, including \"label\" in the \"vary\" header would be\n> wrong.\n>\n> Well I've read the definition of a variant, and a version is certainly not\n> a variant of a version-controlled resource.   And I've read the definition\n> of the vary: header and it talks about the cache-ability of the result.\n> What am I missing?\n\nLet's see:\n\nsection 1.3 (terminology):\n\n\"variant\nA resource may have one, or more than one, representation(s) associated with\nit at any given instant. Each of\nthese representations is termed a 'variant.' Use of the term 'variant' does\nnot necessarily imply that the resource\nis subject to content negotiation.\"\n\nSo any representation you can GET on a URI is a variant of this resource.\n\n> If DeltaV implies that a version is a variant of a version-controlled\n> resource then that must be fixed.\n\nI'd turn it around: if you strongly believe that a version should not be\nconsidered a variant of a resource, then at least the label header semantics\nmust be removed from the spec.\n\n\n\n", "id": "lists-007-0605909"}, {"subject": "RE: Typo in RFC3253, section 3.1.", "content": "And since the errata document is being maintained on a WebDAV\nsite, and since WebDAV provides locking support, Tim and I did\nnot waste our time updating the same document twice ... isn't\nit great to have a protocol that supports distributed authoring? (:-).\n\nCheers,\nGeoff \n\n-----Original Message-----\nFrom: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n\nYes -- looks like that may have been introduced during the final editing\npass.\nI'll add it to the errata document\n(http://www.webdav.org/deltav/protocol/rfc3253-issues-list.htm).\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0615612"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "   From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n\n   \"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n\n   > So this is different from for instance handling of the\n\"accept-language\"\n   > header. Can you give a reason why this would be desirable?\n\n   So, I think the reason it is the way it is, is so that the results of the\n   depth operation conform to the definition of multistatus, i.e. that the\n   results are related by collection membership.\n\n   \"the multistatus XML element for a collection resource with member URIs\n   MUST include a response XML element for each member URI of the\ncollection,\n   to whatever depth was requested\"\n\n   If the label: applied to each member of the version-controlled\ncollection,\n   then the results would be a set of versions that were not related by\n   membership.\n\nThe difference between my interpretation and Tim's interpretation is\nthat I am assuming that only the method is affected by the Label,\nwhile Tim is assuming that the Label affects both the method\nand the recursion itself.\n\nIn other words, by my interpretation, the recursion is:\n\n method ( resource, label, depth )\n {\n    method (resource, label, 0);\n    if (depth != 0) {\n       foreach_internalmember(member, resource) {\n  method ( resource, label, depth-1 ) } } }\n\nwhile by Tim's interpretation, the recursion would be:\n\n method ( resource, label, depth )\n {\n    method (resource, label, 0);\n    if (depth != 0) {\n       foreach_internalmember(member, resource, label) {\n  method ( resource, label, depth-1 ) } } }\n\nI believe my interpretation is more straightforward,\nand produces more predictable results.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-0623435"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "   From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n\n   Geoff said:\n   >    PROPFIND /a\n   >    Depth: 1\n   >    Label: labeltest\n   > Assuming /a is not version-controlled, then the effect of the Label\n   > header is undefined, so your implementation could just ignore the\n   > Label header and return the properties of /a, or it could indicate\n   > that it is an error for /a.\n   >\n   > Since /a/b is version-controlled, the effect is defined by section\n   > 8.6, and you would return the properties of the version labeled\n   > \"labeltest\".\n\n   This is interesting -- I thought that the RFC said that the label\n   header must be ignored if the resource is not version-controlled.\n   Thus, it would be *wrong* to return an error for /a.\n\nLisa is of course correct.  Section 8.3 covers this case.\nSo yes, it must be ignored for a non-version-controlled resource,\nso it would be wrong to return an error for /a.\n\nBoy, nothing like a little jet lag to short-circuit the ol' brain cells\n(:-).\n\n   I don't see any definition of what should happen, BTW, if the \"labeltest\"\n   label does not exist on /a/b -- however the resource is\nversion-controlled.\n   Is that an error?   How is the client supposed to be able to tell the\n   difference between a version-controlled resource for which the label\nexists,\n   and a version-controlled resource for which the label doesn't exist?\n\nSee section 8.6, the DAV:must-select-version-in-history precondition.\nIt is an error if you request a label that does not exist on a given VCR.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-0632833"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "Julian wrote:\n\n> \"variant\n> A resource may have one, or more than one, representation(s)\n> associated with it at any given instant. Each of\n> these representations is termed a 'variant.' Use of the term\n> 'variant' does not necessarily imply that the resource\n> is subject to content negotiation.\"\n>\n> So any representation you can GET on a URI is a variant of this resource.\n\nDon't see how that follows.\nIf you delete a version-controlled resource it does not delete the version\nresource -- they are different resources.\n\n> > If DeltaV implies that a version is a variant of a version-controlled\n> > resource then that must be fixed.\n>\n> I'd turn it around: if you strongly believe that a version should not be\n> considered a variant of a resource, then at least the label\n> header semantics must be removed from the spec.\n\nI see no reason why the label: header cannot be defined to 'redirect' the\nmethod to another resource.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0641983"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: 22 April 2002 19:02\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n>    From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n>\n>    Geoff said:\n>    >    PROPFIND /a\n>    >    Depth: 1\n>    >    Label: labeltest\n>    > Assuming /a is not version-controlled, then the effect of the Label\n>    > header is undefined, so your implementation could just ignore the\n>    > Label header and return the properties of /a, or it could indicate\n>    > that it is an error for /a.\n>    >\n>    > Since /a/b is version-controlled, the effect is defined by section\n>    > 8.6, and you would return the properties of the version labeled\n>    > \"labeltest\".\n>\n>    This is interesting -- I thought that the RFC said that the label\n>    header must be ignored if the resource is not version-controlled.\n>    Thus, it would be *wrong* to return an error for /a.\n>\n> Lisa is of course correct.  Section 8.3 covers this case.\n> So yes, it must be ignored for a non-version-controlled resource,\n> so it would be wrong to return an error for /a.\n\nRight, so imagine what kind of answer you would get back in the\nmultistatus -- some would be from the unversioned resource propfinds and\nsome from version propfinds, and you wouldn't know which were versioned\n(without explictly looking for a live property to distinguishe them), _and_\nit would contravene the 2518 depth result requirement I mentioned earlier.\n\n> Boy, nothing like a little jet lag to short-circuit the ol' brain cells\n> (:-).\n>\n>    I don't see any definition of what should happen, BTW, if the\n> \"labeltest\"\n>    label does not exist on /a/b -- however the resource is\n> version-controlled.\n>    Is that an error?   How is the client supposed to be able to tell the\n>    difference between a version-controlled resource for which the label\n> exists,\n>    and a version-controlled resource for which the label doesn't exist?\n>\n> See section 8.6, the DAV:must-select-version-in-history precondition.\n> It is an error if you request a label that does not exist on a given VCR.\n\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0650220"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> while by Tim's interpretation, the recursion would be:\n>\n>  method ( resource, label, depth )\n>  {\n>     method (resource, label, 0);\n>     if (depth != 0) {\n>        foreach_internalmember(member, resource, label) {\n>   method ( resource, label, depth-1 ) } } }\n\nIn fact I wouldn't consider the label header at all on member resources...\n\n method ( resource, label, depth )\n {\n    method (resource, label, 0);\n    if (depth != 0) {\n       foreach_internalmember(member, resource) {\n  method ( resource, null, depth-1 ) } } }\n\n> I believe my interpretation is more straightforward,\n> and produces more predictable results.\n\nNo, no, _mine_ is more straight forward (one label look-up) -- is just as\npredictable -- and returns a multistatus that can be easily groked.<g>\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0660626"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: 22 April 2002 19:02\n> > To: 'Deltav WG'\n> > Subject: RE: Label header vs PROPFIND depth 1\n> >\n> >\n> >    From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> >\n> >    Geoff said:\n> >    >    PROPFIND /a\n> >    >    Depth: 1\n> >    >    Label: labeltest\n> >    > Assuming /a is not version-controlled, then the effect of the Label\n> >    > header is undefined, so your implementation could just ignore the\n> >    > Label header and return the properties of /a, or it could indicate\n> >    > that it is an error for /a.\n> >    >\n> >    > Since /a/b is version-controlled, the effect is defined by section\n> >    > 8.6, and you would return the properties of the version labeled\n> >    > \"labeltest\".\n> >\n> >    This is interesting -- I thought that the RFC said that the label\n> >    header must be ignored if the resource is not version-controlled.\n> >    Thus, it would be *wrong* to return an error for /a.\n> >\n> > Lisa is of course correct.  Section 8.3 covers this case.\n> > So yes, it must be ignored for a non-version-controlled resource,\n> > so it would be wrong to return an error for /a.\n>\n> Right, so imagine what kind of answer you would get back in the\n> multistatus -- some would be from the unversioned resource propfinds and\n> some from version propfinds, and you wouldn't know which were versioned\n> (without explictly looking for a live property to distinguishe\n> them), _and_\n\nYes -- I think this is what RFC3253 says.\n\n> it would contravene the 2518 depth result requirement I mentioned earlier.\n\nI don't think so.\n\n> a version-controlled resource for which the label doesn't exist?\n> >\n> > See section 8.6, the DAV:must-select-version-in-history precondition.\n> > It is an error if you request a label that does not exist on a\n> given VCR.\n\nSo assume we have /a (collection, not-versioned), /a/b (not-versioned), /a/c\n(versioned, having a version labeled \"x\") and /a/d (versioned, without that\nlabel).\n\nI think we all agree that\n\nGET /a/c\nLabel: x\n\nShould return the content of the version selected by the label x (including\na vary header and probably a content-location header).\n\nGET /a/d\nLabel: x\n\nwill return 403 or 409 with an error element (precondition\nDAV:must-select-version-in-history failed).\n\nGET /a/b\nLabel: x\n\nwill just return b's content, and the vary header when present will NOT\ninclude \"Label\".\n\nSimilarily, similar results will be returned for a PROPFIND/depth 0 on these\nresources. Note that the response element will be \"/a/c\" in the first case,\neven if the properties of a version with a different URI were reported.\n\nFinally, we have PROPFIND/depth 1 on /a:\n\n- as /a isn't version-controlled, the label header is ignored for *this*\nresource\n\n- Geoff and I claim that it *should* apply to the members then, so we'd get:\n\n<multistatus xmlns=\"DAV:\">\n\n  <response>\n    <href>/a</href>\n    <propstat>\n      <prop>...</prop>\n      <status>HTTP/1.1 200 OK</status>\n    </propstat>\n  <response>\n\n  <response>\n    <href>/a/b</href>\n    <propstat>\n      <prop>properties of resource /a/b</prop>\n      <status>HTTP/1.1 200 OK</status>\n    </propstat>\n  <response>\n\n  <response>\n    <href>/a/c</href>\n    <propstat>\n      <prop>properties of selected version</prop>\n      <status>HTTP/1.1 200 OK</status>\n    </propstat>\n  <response>\n\n  <response>\n    <href>/a/d</href>\n    <status>HTTP/1.1 409 Conflict</status>\n\n<responsedescription><error>must-select-version-in-history/></error></respon\nsedescription>\n  <response>\n\n</multistatus>\n\n\n\n", "id": "lists-007-0668460"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Monday, April 22, 2002 8:12 PM\n> To: Deltav WG\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> Julian wrote:\n>\n> > \"variant\n> > A resource may have one, or more than one, representation(s)\n> > associated with it at any given instant. Each of\n> > these representations is termed a 'variant.' Use of the term\n> > 'variant' does not necessarily imply that the resource\n> > is subject to content negotiation.\"\n> >\n> > So any representation you can GET on a URI is a variant of this\n> resource.\n>\n> Don't see how that follows.\n> If you delete a version-controlled resource it does not delete the version\n> resource -- they are different resources.\n\nInteresting point, but does RFC2616 say that deleting a resource must delete\nall it's variants if those have separate URIs (returned as\ncontent-location)?\n\nIf this would be the case, I would conclude that using the Label header so\nselect a version upon GET is a violation of RFC2616.\n\n> > > If DeltaV implies that a version is a variant of a version-controlled\n> > > resource then that must be fixed.\n> >\n> > I'd turn it around: if you strongly believe that a version should not be\n> > considered a variant of a resource, then at least the label\n> > header semantics must be removed from the spec.\n>\n> I see no reason why the label: header cannot be defined to 'redirect' the\n> method to another resource.\n\nWell, that's not supported by RFC2616. Either it *selects* the version (then\nit is a variant by definition), or it causes an HTTP redirect. I don't think\nyou can have both.\n\n\n\n", "id": "lists-007-0681160"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "Juliam wrote:\n\n> > Right, so imagine what kind of answer you would get back in the\n> > multistatus -- some would be from the unversioned resource propfinds and\n> > some from version propfinds, and you wouldn't know which were versioned\n> > (without explictly looking for a live property to distinguishe\n> > them), _and_\n>\n> Yes -- I think this is what RFC3253 says.\n>\n> > it would contravene the 2518 depth result requirement I\n> mentioned earlier.\n>\n> I don't think so.\n\nFrom your example below I see that you envisage the hrefs being those of the\nversion-controlled resource (even though the properties come from the\nlabelled version).\n\nThis is too confusing.  Al the existing code that people write to associate\nthe href with the properties would have to be re-written as the reported\nproperties are from a different resource to the href.\n\n> > a version-controlled resource for which the label doesn't exist?\n> > >\n> > > See section 8.6, the DAV:must-select-version-in-history precondition.\n> > > It is an error if you request a label that does not exist on a\n> > given VCR.\n>\n> So assume we have /a (collection, not-versioned), /a/b\n> (not-versioned), /a/c\n> (versioned, having a version labeled \"x\") and /a/d (versioned,\n> without that\n> label).\n>\n> I think we all agree that\n>\n> GET /a/c\n> Label: x\n>\n> Should return the content of the version selected by the label x\n> (including\n> a vary header and probably a content-location header).\n\nAgreed -- I think we specify a Location: header, but whatever (i.e. resource\nlocation, not content location).\n\n> GET /a/d\n> Label: x\n>\n> will return 403 or 409 with an error element (precondition\n> DAV:must-select-version-in-history failed).\n\nAgreed.\n\n> GET /a/b\n> Label: x\n>\n> will just return b's content, and the vary header when present will NOT\n> include \"Label\".\n\nCan I hedge on the vary: header in the response?  Given that the GET cache\nmay be invalidated by the resource /a/b coming under version control, and\nacquiring a label, I may be inclined to believe that we should return a vary\nheader for every label: request for a version-controlled or versionable\nresource.\n\n> Similarily, similar results will be returned for a PROPFIND/depth\n> 0 on these\n> resources. Note that the response element will be \"/a/c\" in the\n> first case, even if the properties of a version with a different\n> URI were reported.\n\nNo.  I think the href must be for the version resource selected by the\nlabel, not the version-control resource at the request-URI.\n\n> Finally, we have PROPFIND/depth 1 on /a:\n>\n> - as /a isn't version-controlled, the label header is ignored for *this*\n> resource\n>\n> - Geoff and I claim that it *should* apply to the members then,\n> so we'd get:\n\n...and I say it shouldn't apply to members, otherwise the result will\ncontain properties from resources that are not in the same collection\nmembership hierarchy, and thereby contravene 2518 (as well as complicate the\nresult enourmously).\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0691010"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "Tim,\n\nbefore going into details, I'd like to repeat that the way the label header\nis defined makes the selected revision a variant of the VCR. That's what\nRFC2616 says, and IMHO there's no way to avoid that.\n\nIf you strongly feel that this is a problem (I may agree), than the label\nheader should be removed from the spec (deprecated in the issues list), and\nwe should go back looking at the original requirements it's supposed to\nhandle.\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Tuesday, April 23, 2002 10:58 AM\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> Juliam wrote:\n>\n> > > Right, so imagine what kind of answer you would get back in the\n> > > multistatus -- some would be from the unversioned resource\n> propfinds and\n> > > some from version propfinds, and you wouldn't know which were\n> versioned\n> > > (without explictly looking for a live property to distinguishe\n> > > them), _and_\n> >\n> > Yes -- I think this is what RFC3253 says.\n> >\n> > > it would contravene the 2518 depth result requirement I\n> > mentioned earlier.\n> >\n> > I don't think so.\n>\n> From your example below I see that you envisage the hrefs being\n> those of the\n> version-controlled resource (even though the properties come from the\n> labelled version).\n>\n> This is too confusing.  Al the existing code that people write to\n> associate\n> the href with the properties would have to be re-written as the reported\n> properties are from a different resource to the href.\n\nNo, they aren't. They are from a specific variant of the VCR (as defined by\nHTTP).\n\n> > > a version-controlled resource for which the label doesn't exist?\n> > > >\n> > > > See section 8.6, the DAV:must-select-version-in-history\n> precondition.\n> > > > It is an error if you request a label that does not exist on a\n> > > given VCR.\n> >\n> > So assume we have /a (collection, not-versioned), /a/b\n> > (not-versioned), /a/c\n> > (versioned, having a version labeled \"x\") and /a/d (versioned,\n> > without that\n> > label).\n> >\n> > I think we all agree that\n> >\n> > GET /a/c\n> > Label: x\n> >\n> > Should return the content of the version selected by the label x\n> > (including\n> > a vary header and probably a content-location header).\n>\n> Agreed -- I think we specify a Location: header, but whatever\n> (i.e. resource\n> location, not content location).\n\nI think content-location is correct:\n\n\"The Content-Location entity-header field MAY be used to supply the resource\nlocation for the entity enclosed\nin the message when that entity is accessible from a location separate from\nthe requested resource?s URI. A server\nSHOULD provide a Content-Location for the variant corresponding to the\nresponse entity; especially in the\ncase where a resource has multiple entities associated with it, and those\nentities actually have separate locations by\nwhich they might be individually accessed, the server SHOULD provide a\nContent-Location for the particular\nvariant which is returned.\"\n\nwhile the RFC says for location:\n\n\"The Location response-header field is used to redirect the recipient to a\nlocation other than the Request-URI\nfor completion of the request or identification of a new resource. For 201\n(Created) responses, the Location is that\nof the new resource which was created by the request. For 3xx responses, the\nlocation SHOULD indicate the server?s\npreferred URI for automatic redirection to the resource. The field value\nconsists of a single absolute URI.\"\n\n> > GET /a/d\n> > Label: x\n> >\n> > will return 403 or 409 with an error element (precondition\n> > DAV:must-select-version-in-history failed).\n>\n> Agreed.\n>\n> > GET /a/b\n> > Label: x\n> >\n> > will just return b's content, and the vary header when present will NOT\n> > include \"Label\".\n>\n> Can I hedge on the vary: header in the response?  Given that the GET cache\n> may be invalidated by the resource /a/b coming under version control, and\n> acquiring a label, I may be inclined to believe that we should\n> return a vary\n> header for every label: request for a version-controlled or versionable\n> resource.\n\nI think this is right. Which means that vary: label must be set upon GET on\n*any* resource that is versionable (on a server supporting the LABEL\nfeature).\n\n> > Similarily, similar results will be returned for a PROPFIND/depth\n> > 0 on these\n> > resources. Note that the response element will be \"/a/c\" in the\n> > first case, even if the properties of a version with a different\n> > URI were reported.\n>\n> No.  I think the href must be for the version resource selected by the\n> label, not the version-control resource at the request-URI.\n\nNope. You can't do that. This breaks PROPFIND. HTTP offers you:\n\n- variants (representations) of the resource, which will have the same URI,\nor\n\n- redirects (where the request is redirected to a different URI).\n\nYou can't have both.\n\n> > Finally, we have PROPFIND/depth 1 on /a:\n> >\n> > - as /a isn't version-controlled, the label header is ignored for *this*\n> > resource\n> >\n> > - Geoff and I claim that it *should* apply to the members then,\n> > so we'd get:\n>\n> ...and I say it shouldn't apply to members, otherwise the result will\n> contain properties from resources that are not in the same collection\n> membership hierarchy, and thereby contravene 2518 (as well as\n> complicate the\n> result enourmously).\n\nRFC2518:\n\n\"Consequently, the multistatus XML element for a collection resource with\nmember URIs MUST include a response XML element for each member URI of the\ncollection, to whatever depth was requested. Each response XML element MUST\ncontain an href XML element that gives the URI of the resource on which the\nproperties in the prop XML element are defined. Results for a PROPFIND on a\ncollection resource with internal member URIs are returned as a flat list\nwhose order of entries is not significant. \"\n\n\n\n", "id": "lists-007-0701608"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "I agree that there is no point in getting into the details unless we agree\nwhether a version is a variant of a checked-in version-controlled resource.\nOnce we get agreement on that we can go through the remainder of the issues\nand use that as a guidepost.\n\nSo, you think it is a variant, and I think it isn't.\n\nAnybody else like to chip-in?  (anybody else following this or has everyone\nelse gone home<g>?)\n\nRegards,\nTim\n\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: 23 April 2002 10:42\n> To: tim@ellison.name; 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> Tim,\n>\n> before going into details, I'd like to repeat that the way the\n> label header\n> is defined makes the selected revision a variant of the VCR. That's what\n> RFC2616 says, and IMHO there's no way to avoid that.\n>\n> If you strongly feel that this is a problem (I may agree), than the label\n> header should be removed from the spec (deprecated in the issues\n> list), and\n> we should go back looking at the original requirements it's supposed to\n> handle.\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> > Sent: Tuesday, April 23, 2002 10:58 AM\n> > To: 'Deltav WG'\n> > Subject: RE: Label header vs PROPFIND depth 1\n> >\n> >\n> > Juliam wrote:\n> >\n> > > > Right, so imagine what kind of answer you would get back in the\n> > > > multistatus -- some would be from the unversioned resource\n> > propfinds and\n> > > > some from version propfinds, and you wouldn't know which were\n> > versioned\n> > > > (without explictly looking for a live property to distinguishe\n> > > > them), _and_\n> > >\n> > > Yes -- I think this is what RFC3253 says.\n> > >\n> > > > it would contravene the 2518 depth result requirement I\n> > > mentioned earlier.\n> > >\n> > > I don't think so.\n> >\n> > From your example below I see that you envisage the hrefs being\n> > those of the\n> > version-controlled resource (even though the properties come from the\n> > labelled version).\n> >\n> > This is too confusing.  Al the existing code that people write to\n> > associate\n> > the href with the properties would have to be re-written as the reported\n> > properties are from a different resource to the href.\n>\n> No, they aren't. They are from a specific variant of the VCR (as\n> defined by\n> HTTP).\n>\n> > > > a version-controlled resource for which the label doesn't exist?\n> > > > >\n> > > > > See section 8.6, the DAV:must-select-version-in-history\n> > precondition.\n> > > > > It is an error if you request a label that does not exist on a\n> > > > given VCR.\n> > >\n> > > So assume we have /a (collection, not-versioned), /a/b\n> > > (not-versioned), /a/c\n> > > (versioned, having a version labeled \"x\") and /a/d (versioned,\n> > > without that\n> > > label).\n> > >\n> > > I think we all agree that\n> > >\n> > > GET /a/c\n> > > Label: x\n> > >\n> > > Should return the content of the version selected by the label x\n> > > (including\n> > > a vary header and probably a content-location header).\n> >\n> > Agreed -- I think we specify a Location: header, but whatever\n> > (i.e. resource\n> > location, not content location).\n>\n> I think content-location is correct:\n>\n> \"The Content-Location entity-header field MAY be used to supply\n> the resource\n> location for the entity enclosed\n> in the message when that entity is accessible from a location\n> separate from\n> the requested resource?s URI. A server\n> SHOULD provide a Content-Location for the variant corresponding to the\n> response entity; especially in the\n> case where a resource has multiple entities associated with it, and those\n> entities actually have separate locations by\n> which they might be individually accessed, the server SHOULD provide a\n> Content-Location for the particular\n> variant which is returned.\"\n>\n> while the RFC says for location:\n>\n> \"The Location response-header field is used to redirect the recipient to a\n> location other than the Request-URI\n> for completion of the request or identification of a new resource. For 201\n> (Created) responses, the Location is that\n> of the new resource which was created by the request. For 3xx\n> responses, the\n> location SHOULD indicate the server?s\n> preferred URI for automatic redirection to the resource. The field value\n> consists of a single absolute URI.\"\n>\n> > > GET /a/d\n> > > Label: x\n> > >\n> > > will return 403 or 409 with an error element (precondition\n> > > DAV:must-select-version-in-history failed).\n> >\n> > Agreed.\n> >\n> > > GET /a/b\n> > > Label: x\n> > >\n> > > will just return b's content, and the vary header when\n> present will NOT\n> > > include \"Label\".\n> >\n> > Can I hedge on the vary: header in the response?  Given that\n> the GET cache\n> > may be invalidated by the resource /a/b coming under version\n> control, and\n> > acquiring a label, I may be inclined to believe that we should\n> > return a vary\n> > header for every label: request for a version-controlled or versionable\n> > resource.\n>\n> I think this is right. Which means that vary: label must be set\n> upon GET on\n> *any* resource that is versionable (on a server supporting the LABEL\n> feature).\n>\n> > > Similarily, similar results will be returned for a PROPFIND/depth\n> > > 0 on these\n> > > resources. Note that the response element will be \"/a/c\" in the\n> > > first case, even if the properties of a version with a different\n> > > URI were reported.\n> >\n> > No.  I think the href must be for the version resource selected by the\n> > label, not the version-control resource at the request-URI.\n>\n> Nope. You can't do that. This breaks PROPFIND. HTTP offers you:\n>\n> - variants (representations) of the resource, which will have the\n> same URI,\n> or\n>\n> - redirects (where the request is redirected to a different URI).\n>\n> You can't have both.\n>\n> > > Finally, we have PROPFIND/depth 1 on /a:\n> > >\n> > > - as /a isn't version-controlled, the label header is ignored\n> for *this*\n> > > resource\n> > >\n> > > - Geoff and I claim that it *should* apply to the members then,\n> > > so we'd get:\n> >\n> > ...and I say it shouldn't apply to members, otherwise the result will\n> > contain properties from resources that are not in the same collection\n> > membership hierarchy, and thereby contravene 2518 (as well as\n> > complicate the\n> > result enourmously).\n>\n> RFC2518:\n>\n> \"Consequently, the multistatus XML element for a collection resource with\n> member URIs MUST include a response XML element for each member URI of the\n> collection, to whatever depth was requested. Each response XML\n> element MUST\n> contain an href XML element that gives the URI of the resource on\n> which the\n> properties in the prop XML element are defined. Results for a\n> PROPFIND on a\n> collection resource with internal member URIs are returned as a flat list\n> whose order of entries is not significant. \"\n>\n\n\n\n", "id": "lists-007-0716523"}, {"subject": "Label: and Depth: header combination (was: RE: Label header vs PROPFIND depth 1", "content": "RFC2518 Section 9.2 \"Depth header\":\n\n\"Any headers on a method that has a defined interaction with the Depth\nheader MUST be applied to all resources in the scope of the method except\nwhere alternative behavior is explicitly defined. For example, an If-Match\nheader will have its value applied against every resource in the method's\nscope and will cause the method to fail if the header fails to match.\"\n\n\nSo that means that the Label: header MUST be applied to all resources in the\nscope of a PROPFIND, contrary to my argument.  I think there are problems\nwith both our interpretations, DeltaV needs fixing.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0733039"}, {"subject": "Problems with Windows XP &quot;redirector&quot; and Mac OS X WebDAVFS", "content": "Hi,\n\nWe've been testing Merant versioning WebDAV server with Windows XP\n\"redirector\" and Mac OS X WebDAVFS. The behavior of our versioning WebDAV\nserver is equivalent to the behavior of the DeltaV server with auto\nversioning.\n\nOn the surface things seems to be working but if you look closer the\nsituation is really bad. Both clients behave like a file system and perform\nwhat is called a \"safe save\". This means that the new changes are saved in a\ntemporary file on the WebDAV server, the old file is deleted and then the\ntemp file is renamed. This means that when a file is being saved we lose the\nprevious versions, a new version history is created. Both clients also\ncreate a few versions that seem to contain some temporary values making the\nversion history unacceptably polluted.\n\nWe are quite concerned since both Windows XP \"redirector\" and Mac OS\nWebDAVFS would enable access to WebDAV server from any application on those\nplatforms. With this behavior the only solution for us or a DeltaV server\nwould be to deny the write access to these agents so that the user data is\nnot destroyed and polluted. This is quite a change from our expectations on\nwhat DeltaV would do for us and we are hoping that some solutions can be\nstill found.\n\nDid anybody test these clients with a DeltaV server implementation? Any\ncomments, suggestions, explanations?\n\nKasia\n\n\n\n", "id": "lists-007-0741184"}, {"subject": "Re: Label header vs PROPFIND depth ", "content": "As one more voice, I support Tim's position:\n\n* the Label is applied against the Request-URI\n* a version resource results from that operation\n* the PROPFIND(Depth=N) is applied to that *resource*\n\nThe basic problem that we're arguing is \"precedence\". What applies first?\nDepth or Label?\n\nI believe Label applies first. It is part of the lookup process for the\nresource to operate on. Then you start your operation, in this case\nPROPFIND, which is defined to use the Depth: header.\n\nI'll also note that mod_dav applies the Label first, which means that\nSubversion and ClearCase do the label first :-)\n\nCheers,\n-g\n\n-- \nGreg Stein, http://www.lyra.org/\n\n\n\n", "id": "lists-007-0750936"}, {"subject": "Configuration/baseline report", "content": "Hi Geoff (or any other XML experts),\n\nI have a client and a server on a single machine which do the reporting\nI describe\nbelow. \nBut if I want to distribute them to different machines they must speak\nWebDAV-XML\nwith each other. That's a language I'm not fluent yet :-).\nSo perhaps somebody could give XML lessons to my client and server ?\nI would like to get a XML example for that before I implement something\nwrong.\nBTW, wouldn't it be nice to add a scenario section to our faq-o-matic\nFAQ ?\nI would add the examples there if I get them.\n\nGeoff wrote:\n> Edgar schrieb:\n>    Then I'm looking for some reports.  First I would like to have\n>    information on a baseline. How can I get the list of versions and\n>    subbaselines ?\n> \n> To get the list of versions, do a PROPFIND Depth:Infinity on the\n> DAV:baseline-collection of the baseline.  To get the subbaselines, get\n> the DAV:subbaseline-set property of the baseline.\nMy starting point would be the baseline-controlled collection.\nAt first I guess I must find e.g\n bcc.version-controlled-configuration.checked-in.baseline-collection\nThen I suppose I must do a PROPFIND on the baseline-collection (Forget\nsubbaselines\nfor the moment. I think I can figure that out by myself if I know the\nother stuff)\nAs a result the client would like to be able to extract the following\ninformation:\n1{<path relative to bcc> <version url>} \nI hope I don't need too many requests for that.\n\nGeoff wrote:\n> Edgar schrieb:\n>    Second I want to have information on a configuration. This means\n>    state (checked-out, checked-in) and a list of VCRs, VCCs and their\n>    states.\n> \n> To get the DAV:checked-in and DAV:checked-out properties of the\n> configuration, just PROPFIND the DAV:version-controlled-configuration\n> of any member of the configuration for those two properties.\n> \n> What list of VCR's did you have in mind?  If it is all the VCR's that\n> are the member of the configuration, just PROPFIND Depth:Infinity\n> the root collection of the configuration for DAV:checked-in and\n> DAV:checked-out (any resource that has these properties is a VCR\n> that is a member of the configuration).\nCould you give me an example beginning with a root collection perhaps\nwith\na checked-out version-controlled-configuration with two VCRs. One\nchecked-in,\none checked-out. And again my client would like to be able to learn\nsomething: \n{<path relative to bcc> <version url> (checked-out | checked-in)}\n\nAnd then I want my client to do a 'compare-baseline-with-configuration'\nto tell\nme what I already changed in my workspace in comparison to a baseline.\nBut that's\nmy problem to solve. Even if it would be nice to delegate this to a\n'compare-baseline-with-configuration-report' :-)\n\n> By VCC, did you mean VCCn or VCCl?\nBy VCC I meant VCCn. I don't care about VCCls at the moment:-) I hope I\nwill\nremember next time to avoid writing VCC.\n\n\nThen a remark to the label header discussion. Once upon at time I\nthought labels\n(Kowing RCS, ClearCase, ...) were a simple concept.\nBut in an HTTP header together with Depth they seem to make problems. By\nthis I mean\nthat they loose the property to be easily understood.\nSo perhaps it would be better to drop the Label header for PROPFIND and\nrequire\nan UPDATE(label) + PROPFIND instead ?\n\nI think we must be careful to introduce functionality that's difficult\nto grok.\nSo perhaps it's better to drop a clever shortcut when it's not obvious\nwhat it\nwill do. But perhaps it's just a matter of learning the DeltaV mindset.\n\nCheers, Edgar\n\n\n\n", "id": "lists-007-0758711"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Greg Stein\n> Sent: Tuesday, April 23, 2002 11:16 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: Re: Label header vs PROPFIND depth 1\n>\n>\n> As one more voice, I support Tim's position:\n>\n> * the Label is applied against the Request-URI\n> * a version resource results from that operation\n> * the PROPFIND(Depth=N) is applied to that *resource*\n>\n> The basic problem that we're arguing is \"precedence\". What applies first?\n> Depth or Label?\n\nThat's not the only problem we're discussing. Some more:\n\n- what happens if the collection isn't versioned?\n\n- is the entity returned upon GET/Label on a VCR a variant of the VCR? HTTP\nsays: yes, by definition.\n\n> I believe Label applies first. It is part of the lookup process for the\n> resource to operate on. Then you start your operation, in this case\n> PROPFIND, which is defined to use the Depth: header.\n>\n> I'll also note that mod_dav applies the Label first, which means that\n> Subversion and ClearCase do the label first :-)\n\nI don't have any problem with this, as long as we can agree on consistent\nbehaviour for the case where the request URI is a non-version-controlled\ncollection.\n\n\n\n", "id": "lists-007-0768535"}, {"subject": "RE: Problems with Windows XP &quot;redirector&quot; and Mac OS X WebDAVFS", "content": "One workaround that comes to mind is to interpret a MOVE from a\nnon-version-controlled resource to a checked-out VCR as a COPY/DELETE.\n\nUnless someone comes up with a better idea, I'll add this to the 3253\n\"errata\" sheet as an interoperability suggestion for the MOVE request.\n\nCheers,\nGeoff\n\n\n   From: Kasia Jonca [mailto:Kasia.Jonca@merant.com]\n\n   We've been testing Merant versioning WebDAV server with Windows XP\n   \"redirector\" and Mac OS X WebDAVFS. The behavior of our versioning\n   WebDAV server is equivalent to the behavior of the DeltaV server\n   with auto versioning.  On the surface things seems to be working\n   but if you look closer the situation is really bad. Both clients\n   behave like a file system and perform what is called a \"safe\n   save\". This means that the new changes are saved in a temporary\n   file on the WebDAV server, the old file is deleted and then the\n   temp file is renamed. This means that when a file is being saved we\n   lose the previous versions, a new version history is created. Both\n   clients also create a few versions that seem to contain some\n   temporary values making the version history unacceptably polluted.\n   We are quite concerned since both Windows XP \"redirector\" and Mac\n   OS WebDAVFS would enable access to WebDAV server from any\n   application on those platforms. With this behavior the only\n   solution for us or a DeltaV server would be to deny the write\n   access to these agents so that the user data is not destroyed and\n   polluted. This is quite a change from our expectations on what\n   DeltaV would do for us and we are hoping that some solutions can be\n   still found.  Did anybody test these clients with a DeltaV server\n   implementation? Any comments, suggestions, explanations?\n\n\n\n", "id": "lists-007-0778217"}, {"subject": "Re: Problems with Windows XP &quot;redirector&quot; and Mac OS X WebDAVFS", "content": "Am Mittwoch den, 24. April 2002, um 14:49, schrieb Clemm, Geoff:\n\n> One workaround that comes to mind is to interpret a MOVE from a\n> non-version-controlled resource to a checked-out VCR as a COPY/DELETE.\n\nFirst the good news: if you have a shell on OSX and do a\ncp test.txt to /Volumes/dav/test.txt\nwhere \"dav\" is a WebDAV mounted volumes, the webdav code\nin OSX does basically a LOCK/PUT/UNLOCK on an existing\ntest.txt. So (auto)versioning will do the job.\n\nHowever if you use the Finder or any Carbon/Cocoa Application,\nsome library code will do (on save in the GUI):\n1) MOVE /Volumes/dav/test.txt /Volumes/dav/test~.txt\n2) PUT  /Volumes/dav/data1234.txt\n3) MOVE /Volumes/dav/data1234.txt /Volumes/dav/test.txt\n4) DELETE /Volumes/dav/test~.txt\n\n(modulo LOCK/UNLOCK)\n\nI see no chance to keep any versioning on text.txt.\n\n//Stefan\n\n> Unless someone comes up with a better idea, I'll add this to the 3253\n> \"errata\" sheet as an interoperability suggestion for the MOVE request.\n>\n> Cheers,\n> Geoff\n>\n>\n>    From: Kasia Jonca [mailto:Kasia.Jonca@merant.com]\n>\n>    We've been testing Merant versioning WebDAV server with Windows XP\n>    \"redirector\" and Mac OS X WebDAVFS. The behavior of our versioning\n>    WebDAV server is equivalent to the behavior of the DeltaV server\n>    with auto versioning.  On the surface things seems to be working\n>    but if you look closer the situation is really bad. Both clients\n>    behave like a file system and perform what is called a \"safe\n>    save\". This means that the new changes are saved in a temporary\n>    file on the WebDAV server, the old file is deleted and then the\n>    temp file is renamed. This means that when a file is being saved we\n>    lose the previous versions, a new version history is created. Both\n>    clients also create a few versions that seem to contain some\n>    temporary values making the version history unacceptably polluted.\n>    We are quite concerned since both Windows XP \"redirector\" and Mac\n>    OS WebDAVFS would enable access to WebDAV server from any\n>    application on those platforms. With this behavior the only\n>    solution for us or a DeltaV server would be to deny the write\n>    access to these agents so that the user data is not destroyed and\n>    polluted. This is quite a change from our expectations on what\n>    DeltaV would do for us and we are hoping that some solutions can be\n>    still found.  Did anybody test these clients with a DeltaV server\n>    implementation? Any comments, suggestions, explanations?\n>\n\n\n\n", "id": "lists-007-0788662"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "Tim,\n\ngreat.\n\nMy position is that if you don't consider the version selected by the LABEL\nheader to be a variant (representation) of the VCR, then it MUST NOT be\nreturned by a GET on the VCR URI.\n\nRFC2616, section 1.3:\n\nvariant\n\nA resource may have one, or more than one, representation(s) associated with\nit at any given instant. Each of these representations is termed a\n`varriant'. Use of the term `variant' does not necessarily imply that the\nresource is subject to content negotiation.\n\n\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Tuesday, April 23, 2002 12:16 PM\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> I agree that there is no point in getting into the details unless we agree\n> whether a version is a variant of a checked-in version-controlled\n> resource.\n> Once we get agreement on that we can go through the remainder of\n> the issues\n> and use that as a guidepost.\n>\n> So, you think it is a variant, and I think it isn't.\n>\n> Anybody else like to chip-in?  (anybody else following this or\n> has everyone\n> else gone home<g>?)\n>\n> Regards,\n> Tim\n>\n> > -----Original Message-----\n> > From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> > Sent: 23 April 2002 10:42\n> > To: tim@ellison.name; 'Deltav WG'\n> > Subject: RE: Label header vs PROPFIND depth 1\n> >\n> >\n> > Tim,\n> >\n> > before going into details, I'd like to repeat that the way the\n> > label header\n> > is defined makes the selected revision a variant of the VCR. That's what\n> > RFC2616 says, and IMHO there's no way to avoid that.\n> >\n> > If you strongly feel that this is a problem (I may agree), than\n> the label\n> > header should be removed from the spec (deprecated in the issues\n> > list), and\n> > we should go back looking at the original requirements it's supposed to\n> > handle.\n> >\n> > > From: ietf-dav-versioning-request@w3.org\n> > > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> > > Sent: Tuesday, April 23, 2002 10:58 AM\n> > > To: 'Deltav WG'\n> > > Subject: RE: Label header vs PROPFIND depth 1\n> > >\n> > >\n> > > Juliam wrote:\n> > >\n> > > > > Right, so imagine what kind of answer you would get back in the\n> > > > > multistatus -- some would be from the unversioned resource\n> > > propfinds and\n> > > > > some from version propfinds, and you wouldn't know which were\n> > > versioned\n> > > > > (without explictly looking for a live property to distinguishe\n> > > > > them), _and_\n> > > >\n> > > > Yes -- I think this is what RFC3253 says.\n> > > >\n> > > > > it would contravene the 2518 depth result requirement I\n> > > > mentioned earlier.\n> > > >\n> > > > I don't think so.\n> > >\n> > > From your example below I see that you envisage the hrefs being\n> > > those of the\n> > > version-controlled resource (even though the properties come from the\n> > > labelled version).\n> > >\n> > > This is too confusing.  Al the existing code that people write to\n> > > associate\n> > > the href with the properties would have to be re-written as\n> the reported\n> > > properties are from a different resource to the href.\n> >\n> > No, they aren't. They are from a specific variant of the VCR (as\n> > defined by\n> > HTTP).\n> >\n> > > > > a version-controlled resource for which the label doesn't exist?\n> > > > > >\n> > > > > > See section 8.6, the DAV:must-select-version-in-history\n> > > precondition.\n> > > > > > It is an error if you request a label that does not exist on a\n> > > > > given VCR.\n> > > >\n> > > > So assume we have /a (collection, not-versioned), /a/b\n> > > > (not-versioned), /a/c\n> > > > (versioned, having a version labeled \"x\") and /a/d (versioned,\n> > > > without that\n> > > > label).\n> > > >\n> > > > I think we all agree that\n> > > >\n> > > > GET /a/c\n> > > > Label: x\n> > > >\n> > > > Should return the content of the version selected by the label x\n> > > > (including\n> > > > a vary header and probably a content-location header).\n> > >\n> > > Agreed -- I think we specify a Location: header, but whatever\n> > > (i.e. resource\n> > > location, not content location).\n> >\n> > I think content-location is correct:\n> >\n> > \"The Content-Location entity-header field MAY be used to supply\n> > the resource\n> > location for the entity enclosed\n> > in the message when that entity is accessible from a location\n> > separate from\n> > the requested resource?s URI. A server\n> > SHOULD provide a Content-Location for the variant corresponding to the\n> > response entity; especially in the\n> > case where a resource has multiple entities associated with it,\n> and those\n> > entities actually have separate locations by\n> > which they might be individually accessed, the server SHOULD provide a\n> > Content-Location for the particular\n> > variant which is returned.\"\n> >\n> > while the RFC says for location:\n> >\n> > \"The Location response-header field is used to redirect the\n> recipient to a\n> > location other than the Request-URI\n> > for completion of the request or identification of a new\n> resource. For 201\n> > (Created) responses, the Location is that\n> > of the new resource which was created by the request. For 3xx\n> > responses, the\n> > location SHOULD indicate the server?s\n> > preferred URI for automatic redirection to the resource. The field value\n> > consists of a single absolute URI.\"\n> >\n> > > > GET /a/d\n> > > > Label: x\n> > > >\n> > > > will return 403 or 409 with an error element (precondition\n> > > > DAV:must-select-version-in-history failed).\n> > >\n> > > Agreed.\n> > >\n> > > > GET /a/b\n> > > > Label: x\n> > > >\n> > > > will just return b's content, and the vary header when\n> > present will NOT\n> > > > include \"Label\".\n> > >\n> > > Can I hedge on the vary: header in the response?  Given that\n> > the GET cache\n> > > may be invalidated by the resource /a/b coming under version\n> > control, and\n> > > acquiring a label, I may be inclined to believe that we should\n> > > return a vary\n> > > header for every label: request for a version-controlled or\n> versionable\n> > > resource.\n> >\n> > I think this is right. Which means that vary: label must be set\n> > upon GET on\n> > *any* resource that is versionable (on a server supporting the LABEL\n> > feature).\n> >\n> > > > Similarily, similar results will be returned for a PROPFIND/depth\n> > > > 0 on these\n> > > > resources. Note that the response element will be \"/a/c\" in the\n> > > > first case, even if the properties of a version with a different\n> > > > URI were reported.\n> > >\n> > > No.  I think the href must be for the version resource selected by the\n> > > label, not the version-control resource at the request-URI.\n> >\n> > Nope. You can't do that. This breaks PROPFIND. HTTP offers you:\n> >\n> > - variants (representations) of the resource, which will have the\n> > same URI,\n> > or\n> >\n> > - redirects (where the request is redirected to a different URI).\n> >\n> > You can't have both.\n> >\n> > > > Finally, we have PROPFIND/depth 1 on /a:\n> > > >\n> > > > - as /a isn't version-controlled, the label header is ignored\n> > for *this*\n> > > > resource\n> > > >\n> > > > - Geoff and I claim that it *should* apply to the members then,\n> > > > so we'd get:\n> > >\n> > > ...and I say it shouldn't apply to members, otherwise the result will\n> > > contain properties from resources that are not in the same collection\n> > > membership hierarchy, and thereby contravene 2518 (as well as\n> > > complicate the\n> > > result enourmously).\n> >\n> > RFC2518:\n> >\n> > \"Consequently, the multistatus XML element for a collection\n> resource with\n> > member URIs MUST include a response XML element for each member\n> URI of the\n> > collection, to whatever depth was requested. Each response XML\n> > element MUST\n> > contain an href XML element that gives the URI of the resource on\n> > which the\n> > properties in the prop XML element are defined. Results for a\n> > PROPFIND on a\n> > collection resource with internal member URIs are returned as a\n> flat list\n> > whose order of entries is not significant. \"\n> >\n>\n>\n\n\n\n", "id": "lists-007-0800106"}, {"subject": "Re: Label header vs PROPFIND depth ", "content": "Am Dienstag den, 23. April 2002, um 12:16, schrieb Tim Ellison:\n\n> I agree that there is no point in getting into the details unless \n> we agree\n> whether a version is a variant of a checked-in version-controlled \n> resource.\n> Once we get agreement on that we can go through the remainder of \n> the issues\n> and use that as a guidepost.\n>\n> So, you think it is a variant, and I think it isn't.\n\nThe result of a GET has to be cacheable by HTTP proxies. For the\nLABEL header to be compliant with GET, it has to select a variant\n(as variant in rfc2616) of the resource and declare so in the Vary\nheader.\n\nI think there is no way around it without breaking GET and I hear\nthat Roy Fielding has got a big knife and is after the SOAP guys for\nrelated matters...\n\nI think LABEL has to be rethought.\n\n//Stefan\n\n> Anybody else like to chip-in?  (anybody else following this or has \n> everyone\n> else gone home<g>?)\n>\n> Regards,\n> Tim\n>\n>> -----Original Message-----\n>> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>> Sent: 23 April 2002 10:42\n>> To: tim@ellison.name; 'Deltav WG'\n>> Subject: RE: Label header vs PROPFIND depth 1\n>>\n>>\n>> Tim,\n>>\n>> before going into details, I'd like to repeat that the way the\n>> label header\n>> is defined makes the selected revision a variant of the VCR. \n>> That's what\n>> RFC2616 says, and IMHO there's no way to avoid that.\n>>\n>> If you strongly feel that this is a problem (I may agree), than \n>> the label\n>> header should be removed from the spec (deprecated in the issues\n>> list), and\n>> we should go back looking at the original requirements it's \n>> supposed to\n>> handle.\n>>\n>>> From: ietf-dav-versioning-request@w3.org\n>>> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n>>> Sent: Tuesday, April 23, 2002 10:58 AM\n>>> To: 'Deltav WG'\n>>> Subject: RE: Label header vs PROPFIND depth 1\n>>>\n>>>\n>>> Juliam wrote:\n>>>\n>>>>> Right, so imagine what kind of answer you would get back in the\n>>>>> multistatus -- some would be from the unversioned resource\n>>> propfinds and\n>>>>> some from version propfinds, and you wouldn't know which were\n>>> versioned\n>>>>> (without explictly looking for a live property to distinguishe\n>>>>> them), _and_\n>>>>\n>>>> Yes -- I think this is what RFC3253 says.\n>>>>\n>>>>> it would contravene the 2518 depth result requirement I\n>>>> mentioned earlier.\n>>>>\n>>>> I don't think so.\n>>>\n>>> From your example below I see that you envisage the hrefs being\n>>> those of the\n>>> version-controlled resource (even though the properties come from the\n>>> labelled version).\n>>>\n>>> This is too confusing.  Al the existing code that people write to\n>>> associate\n>>> the href with the properties would have to be re-written as the \n>>> reported\n>>> properties are from a different resource to the href.\n>>\n>> No, they aren't. They are from a specific variant of the VCR (as\n>> defined by\n>> HTTP).\n>>\n>>>>> a version-controlled resource for which the label doesn't exist?\n>>>>>>\n>>>>>> See section 8.6, the DAV:must-select-version-in-history\n>>> precondition.\n>>>>>> It is an error if you request a label that does not exist on a\n>>>>> given VCR.\n>>>>\n>>>> So assume we have /a (collection, not-versioned), /a/b\n>>>> (not-versioned), /a/c\n>>>> (versioned, having a version labeled \"x\") and /a/d (versioned,\n>>>> without that\n>>>> label).\n>>>>\n>>>> I think we all agree that\n>>>>\n>>>> GET /a/c\n>>>> Label: x\n>>>>\n>>>> Should return the content of the version selected by the label x\n>>>> (including\n>>>> a vary header and probably a content-location header).\n>>>\n>>> Agreed -- I think we specify a Location: header, but whatever\n>>> (i.e. resource\n>>> location, not content location).\n>>\n>> I think content-location is correct:\n>>\n>> \"The Content-Location entity-header field MAY be used to supply\n>> the resource\n>> location for the entity enclosed\n>> in the message when that entity is accessible from a location\n>> separate from\n>> the requested resource?s URI. A server\n>> SHOULD provide a Content-Location for the variant corresponding to the\n>> response entity; especially in the\n>> case where a resource has multiple entities associated with it, \n>> and those\n>> entities actually have separate locations by\n>> which they might be individually accessed, the server SHOULD provide a\n>> Content-Location for the particular\n>> variant which is returned.\"\n>>\n>> while the RFC says for location:\n>>\n>> \"The Location response-header field is used to redirect the \n>> recipient to a\n>> location other than the Request-URI\n>> for completion of the request or identification of a new \n>> resource. For 201\n>> (Created) responses, the Location is that\n>> of the new resource which was created by the request. For 3xx\n>> responses, the\n>> location SHOULD indicate the server?s\n>> preferred URI for automatic redirection to the resource. The \n>> field value\n>> consists of a single absolute URI.\"\n>>\n>>>> GET /a/d\n>>>> Label: x\n>>>>\n>>>> will return 403 or 409 with an error element (precondition\n>>>> DAV:must-select-version-in-history failed).\n>>>\n>>> Agreed.\n>>>\n>>>> GET /a/b\n>>>> Label: x\n>>>>\n>>>> will just return b's content, and the vary header when\n>> present will NOT\n>>>> include \"Label\".\n>>>\n>>> Can I hedge on the vary: header in the response?  Given that\n>> the GET cache\n>>> may be invalidated by the resource /a/b coming under version\n>> control, and\n>>> acquiring a label, I may be inclined to believe that we should\n>>> return a vary\n>>> header for every label: request for a version-controlled or \n>>> versionable\n>>> resource.\n>>\n>> I think this is right. Which means that vary: label must be set\n>> upon GET on\n>> *any* resource that is versionable (on a server supporting the LABEL\n>> feature).\n>>\n>>>> Similarily, similar results will be returned for a PROPFIND/depth\n>>>> 0 on these\n>>>> resources. Note that the response element will be \"/a/c\" in the\n>>>> first case, even if the properties of a version with a different\n>>>> URI were reported.\n>>>\n>>> No.  I think the href must be for the version resource selected \n>>> by the\n>>> label, not the version-control resource at the request-URI.\n>>\n>> Nope. You can't do that. This breaks PROPFIND. HTTP offers you:\n>>\n>> - variants (representations) of the resource, which will have the\n>> same URI,\n>> or\n>>\n>> - redirects (where the request is redirected to a different URI).\n>>\n>> You can't have both.\n>>\n>>>> Finally, we have PROPFIND/depth 1 on /a:\n>>>>\n>>>> - as /a isn't version-controlled, the label header is ignored\n>> for *this*\n>>>> resource\n>>>>\n>>>> - Geoff and I claim that it *should* apply to the members then,\n>>>> so we'd get:\n>>>\n>>> ...and I say it shouldn't apply to members, otherwise the result will\n>>> contain properties from resources that are not in the same collection\n>>> membership hierarchy, and thereby contravene 2518 (as well as\n>>> complicate the\n>>> result enourmously).\n>>\n>> RFC2518:\n>>\n>> \"Consequently, the multistatus XML element for a collection \n>> resource with\n>> member URIs MUST include a response XML element for each member \n>> URI of the\n>> collection, to whatever depth was requested. Each response XML\n>> element MUST\n>> contain an href XML element that gives the URI of the resource on\n>> which the\n>> properties in the prop XML element are defined. Results for a\n>> PROPFIND on a\n>> collection resource with internal member URIs are returned as a \n>> flat list\n>> whose order of entries is not significant. \"\n>>\n>\n\n\n\n", "id": "lists-007-0819429"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "Julian wrote:\n\n> My position is that if you don't consider the version selected by\n> the LABEL header to be a variant (representation) of the VCR,\n\nwhich, as I stated, I don't.\n\n> then it MUST NOT be returned by a GET on the VCR URI.\n\nI assume this is because of the definition of GET, and not ...\n\n> RFC2616, section 1.3:\n>\n> variant\n>\n> A resource may have one, or more than one, representation(s)\n> associated with it at any given instant. Each of these\n> representations is termed a `varriant'. Use of the term\n> `variant' does not necessarily imply that the resource is\n> subject to content negotiation.\n\nThis definition is fine for a variant -- and has nothing to do with the\nsituation we are discussing, which is two different resources (a\nversion-controlled resource and a version resource).\n\nThis is the definition of the vary: header (RFC2616 section 14.44):\n\n\"The Vary field value indicates the set of request-header fields that fully\ndetermines, while the response is fresh, whether a cache is permitted to use\nthe response to reply to a subsequent request without revalidation. For\nuncacheable or stale responses, the Vary field value advises the user agent\nabout the criteria that were used to select the representation. A Vary field\nvalue of \"*\" implies that a cache cannot determine from the request headers\nof a subsequent request whether this response is the appropriate\nrepresentation. See section 13.6 for use of the Vary header field by caches.\n\n       Vary  = \"Vary\" \":\" ( \"*\" | 1#field-name )\"\n\n\nIt is therefore reasonable to include 'label' in the vary header to indicate\nthat a cache should consider the value of the label header when determining\nthe correct response.  Indeed, from the same section:\n\n\"The field-names given are not limited to the set of standard request-header\nfields defined by this specification.\"\n\nI cannot see anything that says a 'variant' is defined by the 'vary' header.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0837433"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "Stefan Eissing wrote:\n\n> The result of a GET has to be cacheable by HTTP proxies.\n\nI see nothing to prevent the response from a GET including a 'Cache-Control:\nno-cache' header.  Why do you say that?\n\n> For the LABEL header to be compliant with GET, it has to\n> select a variant (as variant in rfc2616) of the resource\n\nI disagree that it has to select a variant (or at least I haven't been shown\nwhy yet).\n\n>  and declare so in the Vary header.\n\nThe Vary: header doesn't state the result is a variant, or otherwise.\n\n> I think there is no way around it without breaking GET and I hear\n> that Roy Fielding has got a big knife and is after the SOAP guys for\n> related matters...\n\nHow does it break GET?  (This discussion is drifting all over the map!)\n\n> I think LABEL has to be rethought.\n\nClearly it has to be clarified.  We had a number of working group review\nperiods, and all the authors signed it off in it's current form; so I hope\nit isn't too far away from sanity.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-0846717"}, {"subject": "RE: Problems with Windows XP &quot;redirector&quot; and Mac OS X WebDAVFS", "content": "Hi,\n\nI am not sure how your suggestion would help us Geoff.\nLet me give a bit more detail on the problem...\n\nLet's imagine you have a VCR at /dav/foo.c, it has a VHR at /dav/vhr/foo1\nand a checked-in version /dav/vhr/foo1/v1.\n\nThe user connects to this DeltaV server using the Windows XP WebDAV\nredirector or MacOS X.\nThese clients are not DeltaV clients so they don't do an explicit CHECKOUT\nbut lets imagine \nthe server is an auto-versioning server (as ours is):\n\n* The user opens foo.c (the client maybe does a LOCK but basically does a\nGET on /dav/foo.c).  \n\n* The user changes the file content and saves...\n\n* So the client does the \"safe save\" and creates a temporary file so will do\nPUT /dav/foo.c.tmp \n  (for example), this will create a new resource (VCR because it is\nauto-versioning), \n  a new VHR, version etc.\n\n* The client issues DELETE on /dav/foo.c (we don't delete the VHR and the\nversion at this point, \n  so /dav/foo1 and /dav/foo1/v1 will still exist and maybe VCRs in other\nworkspaces will still point \n  to them or maybe they will be dangling).\n\n* The client issues a MOVE to rename /dav/foo.c.tmp to /dav/foo.c.\n\nThe net result of this is that EVERY resource on the server has only one\nversion \nand there are many VHRs and Versions lying around the system some possibly\ndangling.\nWe also noticed that some clients do several PUTs to both the temporary\nresource and\nthe original VCR (resulting in some spurious versions).\n\nI dread to think what would happen with an auto-versioning server with\nversion controlled\ncollections...do the clients do the same temporary resource and move trick\nwith folders?\n\nI understand this is due to the fact that the filesystem redirectors are\nbeing called\nby applications which are expecting a filesystem :-) So it's not necessarily\nthe redirector\nwhich is at fault, the applications are doing this multiple save and move\nbehaviour and\nthe redirector is honouring the applications request by doing WebDAV\nmethods.\nBut it does seem like a fairly serious problem that will probably be\nencountered by and\nWebDAV servers being used by these redirector clients.\n\nAny ideas what we can do to protect data from being deleted and from the\nproliferation\nof unnecessary versions and VCRs in the system?\n\nOur current strategy is to make these clients \"read-only\" but that seems to\ndevalue the\nusefulness of having filesystem redirectors.\n\nRegards,\n--\nPeter Raymond - MERANT\nPrincipal Architect (PVCS)\nTel: +44 (0)1727 813362\nFax: +44 (0)1727 869804\nmailto:Peter.Raymond@merant.com\nWWW: http://www.merant.com\n\n\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: 24 April 2002 13:49\nTo: 'ietf-dav-versioning@w3.org'\nSubject: RE: Problems with Windows XP \"redirector\" and Mac OS X\nWebDAVFS.\n\n\nOne workaround that comes to mind is to interpret a MOVE from a\nnon-version-controlled resource to a checked-out VCR as a COPY/DELETE.\n\nUnless someone comes up with a better idea, I'll add this to the 3253\n\"errata\" sheet as an interoperability suggestion for the MOVE request.\n\nCheers,\nGeoff\n\n\n   From: Kasia Jonca [mailto:Kasia.Jonca@merant.com]\n\n   We've been testing Merant versioning WebDAV server with Windows XP\n   \"redirector\" and Mac OS X WebDAVFS. The behavior of our versioning\n   WebDAV server is equivalent to the behavior of the DeltaV server\n   with auto versioning.  On the surface things seems to be working\n   but if you look closer the situation is really bad. Both clients\n   behave like a file system and perform what is called a \"safe\n   save\". This means that the new changes are saved in a temporary\n   file on the WebDAV server, the old file is deleted and then the\n   temp file is renamed. This means that when a file is being saved we\n   lose the previous versions, a new version history is created. Both\n   clients also create a few versions that seem to contain some\n   temporary values making the version history unacceptably polluted.\n   We are quite concerned since both Windows XP \"redirector\" and Mac\n   OS WebDAVFS would enable access to WebDAV server from any\n   application on those platforms. With this behavior the only\n   solution for us or a DeltaV server would be to deny the write\n   access to these agents so that the user data is not destroyed and\n   polluted. This is quite a change from our expectations on what\n   DeltaV would do for us and we are hoping that some solutions can be\n   still found.  Did anybody test these clients with a DeltaV server\n   implementation? Any comments, suggestions, explanations?\n\n\n\n", "id": "lists-007-0855205"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Wednesday, April 24, 2002 5:50 PM\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> Stefan Eissing wrote:\n>\n> > The result of a GET has to be cacheable by HTTP proxies.\n>\n> I see nothing to prevent the response from a GET including a\n> 'Cache-Control:\n> no-cache' header.  Why do you say that?\n>\n> > For the LABEL header to be compliant with GET, it has to\n> > select a variant (as variant in rfc2616) of the resource\n>\n> I disagree that it has to select a variant (or at least I haven't\n> been shown\n> why yet).\n\nI think the situation is as follows: regarding the label header, RFC3253\ndefines a behaviour for GET that clearly makes the selected version a\nvariant of the VCR (according to RFC2616). No matter what RFC3253 says, GET\nis defined by RFC2616. If a server exposes behaviour for GET that makes a\nresource a variant according to the text of RFC2616, it *is* a variant (no\nmatter what another RFC says). If \"the other\" RFC says it isn't a variant,\nit clearly breaks the HTTP protocol.\n\nThat aside, why are you so opposed to this interpretation?\n\n\n\n", "id": "lists-007-0869733"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Wednesday, April 24, 2002 5:40 PM\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> Julian wrote:\n>\n> > My position is that if you don't consider the version selected by\n> > the LABEL header to be a variant (representation) of the VCR,\n>\n> which, as I stated, I don't.\n>\n> > then it MUST NOT be returned by a GET on the VCR URI.\n>\n> I assume this is because of the definition of GET, and not ...\n>\n> > RFC2616, section 1.3:\n> >\n> > variant\n> >\n> > A resource may have one, or more than one, representation(s)\n> > associated with it at any given instant. Each of these\n> > representations is termed a `varriant'. Use of the term\n> > `variant' does not necessarily imply that the resource is\n> > subject to content negotiation.\n>\n> This definition is fine for a variant -- and has nothing to do with the\n> situation we are discussing, which is two different resources (a\n> version-controlled resource and a version resource).\n\nNo, it isn't.\n\nWe are doing a GET against a single URI. GET never returns resources, it\nreturns *representations* (== variants) of resources. If you don't specify\nthe Label header, you get a representation (variant) of the VCR. If you do,\nyou get a representation (variant) of the version. This -- by definition --\nmakes the version a representation (variant) of the VCR.\n\nIf you don't like that, don't allow GET on the VCR URI to return it.\n\n> This is the definition of the vary: header (RFC2616 section 14.44):\n>\n> \"The Vary field value indicates the set of request-header fields\n> that fully\n> determines, while the response is fresh, whether a cache is\n> permitted to use\n> the response to reply to a subsequent request without revalidation. For\n> uncacheable or stale responses, the Vary field value advises the\n> user agent\n> about the criteria that were used to select the representation. A\n> Vary field\n> value of \"*\" implies that a cache cannot determine from the\n> request headers\n> of a subsequent request whether this response is the appropriate\n> representation. See section 13.6 for use of the Vary header field\n> by caches.\n>\n>        Vary  = \"Vary\" \":\" ( \"*\" | 1#field-name )\"\n>\n>\n> It is therefore reasonable to include 'label' in the vary header\n> to indicate\n> that a cache should consider the value of the label header when\n> determining\n> the correct response.  Indeed, from the same section:\n>\n> \"The field-names given are not limited to the set of standard\n> request-header\n> fields defined by this specification.\"\n>\n> I cannot see anything that says a 'variant' is defined by the\n> 'vary' header.\n\nIt doesn't *need* to say that.\n\nGET returns representations (== variants) of resources. By making GET on the\n*same* URI returning the VCR in one case and a version in another case, you\n*make* the version a variant of the VCR.\n\n\n\n", "id": "lists-007-0879160"}, {"subject": "Re: Label header vs PROPFIND depth ", "content": "Am Mittwoch den, 24. April 2002, um 17:50, schrieb Tim Ellison:\n\n> Stefan Eissing wrote:\n>\n>> The result of a GET has to be cacheable by HTTP proxies.\n>\n> I see nothing to prevent the response from a GET including a \n> 'Cache-Control:\n> no-cache' header.  Why do you say that?\n\nThen 3253 must require that DeltaV servers send no-cache on resonse\nto *all* GETs on VCRs. Otherwise it breaks proxies.\n\n>> For the LABEL header to be compliant with GET, it has to\n>> select a variant (as variant in rfc2616) of the resource\n>\n> I disagree that it has to select a variant (or at least I haven't \n> been shown\n> why yet).\n\nI think we do not share a common definition of \"variant\" and that\nis causing all the confusion.\n\nIn my thinking a variant is what is returned by GET on a URI.\nA lot of HTTP resources just have one variant at one point in\ntime. The cacheability of that is mainly influences by the Expires\nHTTP header.\nSome resources however have more than one variant at one point\nin time. For example \"Accept-Language\" might influence which\nvariant is returned by GET. A server then should indicate in\nthe Vary response header which *request* header influences\nthe response. Caches will then only return cached results when\nthose request headers match.\n\nOf course, DeltaV could disable all caching by requiring servers\nto return \"Cache-Control: no-cache\" on all GET responses for VCRs.\n\nI personally think this should be avoided.\n\n//Stefan\n\n>\n>>  and declare so in the Vary header.\n>\n> The Vary: header doesn't state the result is a variant, or otherwise.\n>\n>> I think there is no way around it without breaking GET and I hear\n>> that Roy Fielding has got a big knife and is after the SOAP guys for\n>> related matters...\n>\n> How does it break GET?  (This discussion is drifting all over the map!)\n>\n>> I think LABEL has to be rethought.\n>\n> Clearly it has to be clarified.  We had a number of working group \n> review\n> periods, and all the authors signed it off in it's current form; \n> so I hope\n> it isn't too far away from sanity.\n>\n> Regards,\n> Tim\n>\n\n\n\n", "id": "lists-007-0890430"}, {"subject": "RE: Problems with Windows XP &quot;redirector&quot; and Mac OS X WebDAVFS", "content": "If the client first does a MOVE, then I agree there's not\nmuch an auto-versioning server could reasonably do.\n\nJust for interests sake, what is the motivation for\nthose libraries to do a <MOVE-to-temp1, PUT-to-temp2,\nMOVE-to-real, DELETE-temp1> instead of the simpler\n<PUT-to-temp, MOVE-temp-to-actual> ?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\n\nAm Mittwoch den, 24. April 2002, um 14:49, schrieb Clemm, Geoff:\n\n> One workaround that comes to mind is to interpret a MOVE from a\n> non-version-controlled resource to a checked-out VCR as a COPY/DELETE.\n\nFirst the good news: if you have a shell on OSX and do a\ncp test.txt to /Volumes/dav/test.txt\nwhere \"dav\" is a WebDAV mounted volumes, the webdav code\nin OSX does basically a LOCK/PUT/UNLOCK on an existing\ntest.txt. So (auto)versioning will do the job.\n\nHowever if you use the Finder or any Carbon/Cocoa Application,\nsome library code will do (on save in the GUI):\n1) MOVE /Volumes/dav/test.txt /Volumes/dav/test~.txt\n2) PUT  /Volumes/dav/data1234.txt\n3) MOVE /Volumes/dav/data1234.txt /Volumes/dav/test.txt\n4) DELETE /Volumes/dav/test~.txt\n\n(modulo LOCK/UNLOCK)\n\nI see no chance to keep any versioning on text.txt.\n\n//Stefan\n\n> Unless someone comes up with a better idea, I'll add this to the 3253\n> \"errata\" sheet as an interoperability suggestion for the MOVE request.\n>\n> Cheers,\n> Geoff\n>\n>\n>    From: Kasia Jonca [mailto:Kasia.Jonca@merant.com]\n>\n>    We've been testing Merant versioning WebDAV server with Windows XP\n>    \"redirector\" and Mac OS X WebDAVFS. The behavior of our versioning\n>    WebDAV server is equivalent to the behavior of the DeltaV server\n>    with auto versioning.  On the surface things seems to be working\n>    but if you look closer the situation is really bad. Both clients\n>    behave like a file system and perform what is called a \"safe\n>    save\". This means that the new changes are saved in a temporary\n>    file on the WebDAV server, the old file is deleted and then the\n>    temp file is renamed. This means that when a file is being saved we\n>    lose the previous versions, a new version history is created. Both\n>    clients also create a few versions that seem to contain some\n>    temporary values making the version history unacceptably polluted.\n>    We are quite concerned since both Windows XP \"redirector\" and Mac\n>    OS WebDAVFS would enable access to WebDAV server from any\n>    application on those platforms. With this behavior the only\n>    solution for us or a DeltaV server would be to deny the write\n>    access to these agents so that the user data is not destroyed and\n>    polluted. This is quite a change from our expectations on what\n>    DeltaV would do for us and we are hoping that some solutions can be\n>    still found.  Did anybody test these clients with a DeltaV server\n>    implementation? Any comments, suggestions, explanations?\n>\n\n\n\n", "id": "lists-007-0900242"}, {"subject": "RE: Problems with Windows XP &quot;redirector&quot; and Mac OS X WebDAVFS", "content": "Do XP and OS X really do the same thing`?\n\n1) Regarding Mac OS X, the problem may be caused by the Mac OS File System\nCalls that allow \"exchanging\" file contents [1], which AFAIK is used for\nSave operations in traditional Mac applications. Maybe we just need to wait\nfor the Apple programmers to add limited RFC3253 support to fix this\nproblem.\n\n2) Regarding the XP redirector: well, it's full of bugs anyway, and\nMicrosoft doesn't seem to consider this an issue.\n\nJulian\n\n[1]\n<http://developer.apple.com/techpubs/macosx/Carbon/Files/FileManager/File_Ma\nnager/index.html>\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, April 26, 2002 5:01 AM\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: RE: Problems with Windows XP \"redirector\" and Mac OS X\n> WebDAVFS.\n>\n>\n> If the client first does a MOVE, then I agree there's not\n> much an auto-versioning server could reasonably do.\n>\n> Just for interests sake, what is the motivation for\n> those libraries to do a <MOVE-to-temp1, PUT-to-temp2,\n> MOVE-to-real, DELETE-temp1> instead of the simpler\n> <PUT-to-temp, MOVE-temp-to-actual> ?\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\n>\n> Am Mittwoch den, 24. April 2002, um 14:49, schrieb Clemm, Geoff:\n>\n> > One workaround that comes to mind is to interpret a MOVE from a\n> > non-version-controlled resource to a checked-out VCR as a COPY/DELETE.\n>\n> First the good news: if you have a shell on OSX and do a\n> cp test.txt to /Volumes/dav/test.txt\n> where \"dav\" is a WebDAV mounted volumes, the webdav code\n> in OSX does basically a LOCK/PUT/UNLOCK on an existing\n> test.txt. So (auto)versioning will do the job.\n>\n> However if you use the Finder or any Carbon/Cocoa Application,\n> some library code will do (on save in the GUI):\n> 1) MOVE /Volumes/dav/test.txt /Volumes/dav/test~.txt\n> 2) PUT  /Volumes/dav/data1234.txt\n> 3) MOVE /Volumes/dav/data1234.txt /Volumes/dav/test.txt\n> 4) DELETE /Volumes/dav/test~.txt\n>\n> (modulo LOCK/UNLOCK)\n>\n> I see no chance to keep any versioning on text.txt.\n>\n> //Stefan\n>\n> > Unless someone comes up with a better idea, I'll add this to the 3253\n> > \"errata\" sheet as an interoperability suggestion for the MOVE request.\n> >\n> > Cheers,\n> > Geoff\n> >\n> >\n> >    From: Kasia Jonca [mailto:Kasia.Jonca@merant.com]\n> >\n> >    We've been testing Merant versioning WebDAV server with Windows XP\n> >    \"redirector\" and Mac OS X WebDAVFS. The behavior of our versioning\n> >    WebDAV server is equivalent to the behavior of the DeltaV server\n> >    with auto versioning.  On the surface things seems to be working\n> >    but if you look closer the situation is really bad. Both clients\n> >    behave like a file system and perform what is called a \"safe\n> >    save\". This means that the new changes are saved in a temporary\n> >    file on the WebDAV server, the old file is deleted and then the\n> >    temp file is renamed. This means that when a file is being saved we\n> >    lose the previous versions, a new version history is created. Both\n> >    clients also create a few versions that seem to contain some\n> >    temporary values making the version history unacceptably polluted.\n> >    We are quite concerned since both Windows XP \"redirector\" and Mac\n> >    OS WebDAVFS would enable access to WebDAV server from any\n> >    application on those platforms. With this behavior the only\n> >    solution for us or a DeltaV server would be to deny the write\n> >    access to these agents so that the user data is not destroyed and\n> >    polluted. This is quite a change from our expectations on what\n> >    DeltaV would do for us and we are hoping that some solutions can be\n> >    still found.  Did anybody test these clients with a DeltaV server\n> >    implementation? Any comments, suggestions, explanations?\n> >\n>\n>\n\n\n\n", "id": "lists-007-0912381"}, {"subject": "Re: Problems with Windows XP &quot;redirector&quot; and Mac OS X WebDAVFS", "content": "Am Freitag den, 26. April 2002, um 05:00, schrieb Clemm, Geoff:\n\n> If the client first does a MOVE, then I agree there's not\n> much an auto-versioning server could reasonably do.\n>\n> Just for interests sake, what is the motivation for\n> those libraries to do a <MOVE-to-temp1, PUT-to-temp2,\n> MOVE-to-real, DELETE-temp1> instead of the simpler\n> <PUT-to-temp, MOVE-temp-to-actual> ?\n\nI had a closer look and it's seems to be rather application\nspecific. What role the frameworks play in this, maybe someone\nfrom apple can elaborate.\n\nThe example I gave comes from TextEdit application on OSX.\nTextEdit always creates a backup file (test~.txt), but the\ndefault setting is that this backup is deleted. That explains\nthe strange MOVE/DELETE on that.\n\nI tested with Internet Explorer. IE, if asked to replace an\nexisting file, will first DELETE the file and then create\na new one.\n\nThen I tested Apple's Mail application. That app will first\ncreate a temp file and then MOVE the temp file to replace\nthe existing one.\n\nSo the answer is: it depends. Which is rather unfortunate.\n\n//Stefan\n\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\n>\n> Am Mittwoch den, 24. April 2002, um 14:49, schrieb Clemm, Geoff:\n>\n>> One workaround that comes to mind is to interpret a MOVE from a\n>> non-version-controlled resource to a checked-out VCR as a COPY/DELETE.\n>\n> First the good news: if you have a shell on OSX and do a\n> cp test.txt to /Volumes/dav/test.txt\n> where \"dav\" is a WebDAV mounted volumes, the webdav code\n> in OSX does basically a LOCK/PUT/UNLOCK on an existing\n> test.txt. So (auto)versioning will do the job.\n>\n> However if you use the Finder or any Carbon/Cocoa Application,\n> some library code will do (on save in the GUI):\n> 1) MOVE /Volumes/dav/test.txt /Volumes/dav/test~.txt\n> 2) PUT  /Volumes/dav/data1234.txt\n> 3) MOVE /Volumes/dav/data1234.txt /Volumes/dav/test.txt\n> 4) DELETE /Volumes/dav/test~.txt\n>\n> (modulo LOCK/UNLOCK)\n>\n> I see no chance to keep any versioning on text.txt.\n>\n> //Stefan\n>\n>> Unless someone comes up with a better idea, I'll add this to the 3253\n>> \"errata\" sheet as an interoperability suggestion for the MOVE request.\n>>\n>> Cheers,\n>> Geoff\n>>\n>>\n>>    From: Kasia Jonca [mailto:Kasia.Jonca@merant.com]\n>>\n>>    We've been testing Merant versioning WebDAV server with Windows XP\n>>    \"redirector\" and Mac OS X WebDAVFS. The behavior of our versioning\n>>    WebDAV server is equivalent to the behavior of the DeltaV server\n>>    with auto versioning.  On the surface things seems to be working\n>>    but if you look closer the situation is really bad. Both clients\n>>    behave like a file system and perform what is called a \"safe\n>>    save\". This means that the new changes are saved in a temporary\n>>    file on the WebDAV server, the old file is deleted and then the\n>>    temp file is renamed. This means that when a file is being saved we\n>>    lose the previous versions, a new version history is created. Both\n>>    clients also create a few versions that seem to contain some\n>>    temporary values making the version history unacceptably polluted.\n>>    We are quite concerned since both Windows XP \"redirector\" and Mac\n>>    OS WebDAVFS would enable access to WebDAV server from any\n>>    application on those platforms. With this behavior the only\n>>    solution for us or a DeltaV server would be to deny the write\n>>    access to these agents so that the user data is not destroyed and\n>>    polluted. This is quite a change from our expectations on what\n>>    DeltaV would do for us and we are hoping that some solutions can be\n>>    still found.  Did anybody test these clients with a DeltaV server\n>>    implementation? Any comments, suggestions, explanations?\n>>\n>\n\n\n\n", "id": "lists-007-0926734"}, {"subject": "Antwort: RE: Problems with Windows XP &quot;redirector&quot; and Mac OS X WebDAVFS", "content": "Hi Stefan,\nwhy are you so pessimistic ?\nI would assume that most \"safe save\" algorithms will have a recognizable\npattern\nlike MOVE a -> b, PUT a, DELETE b.\nSo a clever autoversioning server could assume that b was a temporary file\nwhich\ncan be thrown away (Also deleting the autoversioned history) and\nautoversion a.\nOr is this assuming too much and the behaviour can also be expected in the\nwild\nby a DeltaV client ?\n\nMit freundlichen Gr??en / Best regards\n\nEdgar Schwarz\n\n--\nEdgar.Schwarz@marconi.com, Postf. 1920, D-71509 Backnang,+49 7191 13 3382,\nMarconi Communications, Access Division, Quality and Process Improvement\nPrivat kann jeder soviel C programmieren oder Videos ansehen wie er mag\n(Niklaus Wirth). Make it as simple as possible, but not simpler\n(A.Einstein)\n\n\n\n\n                                                                                                                                 \n                          \"Clemm, Geoff\"                                                                                         \n                          <gclemm@rational.c        An:    \"'ietf-dav-versioning@w3.org'\" <ietf-dav-versioning@w3.org>           \n                          om>                       Kopie:                                                                       \n                          Gesendet von:             Blindkopie:                                                                  \n                          ietf-dav-versionin        Thema: RE: Problems with Windows XP \"redirector\" and Mac OS X WebDAVFS.      \n                          g-request@w3.org                                                                                       \n                                                                                                                                 \n                                                                                                                                 \n                          26.04.2002 05:00                                                                                       \n                                                                                                                                 \n                                                                                                                                 \n\n\n\n\nIf the client first does a MOVE, then I agree there's not\nmuch an auto-versioning server could reasonably do.\n\nJust for interests sake, what is the motivation for\nthose libraries to do a <MOVE-to-temp1, PUT-to-temp2,\nMOVE-to-real, DELETE-temp1> instead of the simpler\n<PUT-to-temp, MOVE-temp-to-actual> ?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\n\nAm Mittwoch den, 24. April 2002, um 14:49, schrieb Clemm, Geoff:\n\n> One workaround that comes to mind is to interpret a MOVE from a\n> non-version-controlled resource to a checked-out VCR as a COPY/DELETE.\n\nFirst the good news: if you have a shell on OSX and do a\ncp test.txt to /Volumes/dav/test.txt\nwhere \"dav\" is a WebDAV mounted volumes, the webdav code\nin OSX does basically a LOCK/PUT/UNLOCK on an existing\ntest.txt. So (auto)versioning will do the job.\n\nHowever if you use the Finder or any Carbon/Cocoa Application,\nsome library code will do (on save in the GUI):\n1) MOVE /Volumes/dav/test.txt /Volumes/dav/test~.txt\n2) PUT  /Volumes/dav/data1234.txt\n3) MOVE /Volumes/dav/data1234.txt /Volumes/dav/test.txt\n4) DELETE /Volumes/dav/test~.txt\n\n(modulo LOCK/UNLOCK)\n\nI see no chance to keep any versioning on text.txt.\n\n\n\n", "id": "lists-007-0939731"}, {"subject": "Re: Antwort: RE: Problems with Windows XP &quot;redirector&quot; and Mac OS X WebDAVFS", "content": "Edgar,\n\nAm Freitag den, 26. April 2002, um 13:06, schrieb Edgar Schwarz:\n>\n> Hi Stefan,\n> why are you so pessimistic ?\n> I would assume that most \"safe save\" algorithms will have a \n> recognizable\n> pattern\n> like MOVE a -> b, PUT a, DELETE b.\n\nthis sequence of operations has an outcome which is defined\nby the RFCs 2518 and 3253. That definition makes sense if a\nclient wants to safely replace a *without* autoversioning.\n\nA client which wants to do autversioning should do\nPUT b, COPY b -> a, DELETE b.\n\n> So a clever autoversioning server could assume that b was a \n> temporary file\n> which\n> can be thrown away (Also deleting the autoversioned history) and\n> autoversion a.\n\nThe problems with this are:\n- the servers is guessing on the intention of the client - this\n   could be wrong\n- Only after DELETE b, the server could guess that the new a is the next\n   version of the former a (now b).\n- Before DELETE b, the new a is either a unversioned resource or a\n   VCR with its own, new version history.\n- The situation gets easily messy if someone does a PROPPATCH a\n   before DELETE b. If a is a VCR at that time, autoversioning strikes\n   again and a has 2 versions. Both versions need to be applied\n   to the version history of the \"old\" a...\n- How long should a server monitor for a DELETE after the PUT a?\n  etc.\n\n> Or is this assuming too much and the behaviour can also be \n> expected in the\n> wild by a DeltaV client ?\n\n> Mit freundlichen Gr??en / Best regards\n>\n> Edgar Schwarz\n>\n> --\n> Edgar.Schwarz@marconi.com, Postf. 1920, D-71509 Backnang,+49 7191 \n> 13 3382,\n> Marconi Communications, Access Division, Quality and Process \n> Improvement\n> Privat kann jeder soviel C programmieren oder Videos ansehen wie er mag\n> (Niklaus Wirth). Make it as simple as possible, but not simpler\n> (A.Einstein)\n>\n>\n>\n>\n>\n>                           \"Clemm, Geoff\"\n>                           <gclemm@rational.c        An:    \n> \"'ietf-dav-versioning@w3.org'\" <ietf-dav-versioning@w3.org>\n>                           om>                       Kopie:\n>                           Gesendet von:             Blindkopie:\n>                           ietf-dav-versionin        Thema: RE: \n> Problems with Windows XP \"redirector\" and Mac OS X WebDAVFS.\n>                           g-request@w3.org\n>\n>\n>                           26.04.2002 05:00\n>\n>\n>\n>\n>\n>\n> If the client first does a MOVE, then I agree there's not\n> much an auto-versioning server could reasonably do.\n>\n> Just for interests sake, what is the motivation for\n> those libraries to do a <MOVE-to-temp1, PUT-to-temp2,\n> MOVE-to-real, DELETE-temp1> instead of the simpler\n> <PUT-to-temp, MOVE-temp-to-actual> ?\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\n>\n> Am Mittwoch den, 24. April 2002, um 14:49, schrieb Clemm, Geoff:\n>\n>> One workaround that comes to mind is to interpret a MOVE from a\n>> non-version-controlled resource to a checked-out VCR as a COPY/DELETE.\n>\n> First the good news: if you have a shell on OSX and do a\n> cp test.txt to /Volumes/dav/test.txt\n> where \"dav\" is a WebDAV mounted volumes, the webdav code\n> in OSX does basically a LOCK/PUT/UNLOCK on an existing\n> test.txt. So (auto)versioning will do the job.\n>\n> However if you use the Finder or any Carbon/Cocoa Application,\n> some library code will do (on save in the GUI):\n> 1) MOVE /Volumes/dav/test.txt /Volumes/dav/test~.txt\n> 2) PUT  /Volumes/dav/data1234.txt\n> 3) MOVE /Volumes/dav/data1234.txt /Volumes/dav/test.txt\n> 4) DELETE /Volumes/dav/test~.txt\n>\n> (modulo LOCK/UNLOCK)\n>\n> I see no chance to keep any versioning on text.txt.\n>\n\n\n\n", "id": "lists-007-0953011"}, {"subject": "Antwort: Re: Antwort: RE: Problems with Windows XP &quot;redirector&quot; and Mac OS  X WebDAVFS", "content": "Hallo Stefan,\n\nStefan Eissing schrieb:\n> Am Freitag den, 26. April 2002, um 13:06, schrieb Edgar Schwarz:\n> > So a clever autoversioning server could assume that b was a\n> > temporary file which\n> > can be thrown away (Also deleting the autoversioned history) and\n> > autoversion a.\nI forgot to state a precondition: The client is telling who it is in the\nHTTP request.\nIf this is wrong please stop reading :-)\n\n> The problems with this are:\n> - the server is guessing on the intention of the client - this\n>   could be wrong\nIf you know the client you probably can make a very educated guess.\n\n> - Only after DELETE b, the server could guess that the new a is the next\n>   version of the former a (now b).\nNaturally, this just would mean that you have to delete the version history\nyou just created.\n\n> - Before DELETE b, the new a is either a unversioned resource or a\n>    VCR with its own, new version history.\n> - The situation gets easily messy if someone does a PROPPATCH a\n>    before DELETE b. If a is a VCR at that time, autoversioning strikes\n>    again and a has 2 versions. Both versions need to be applied\n>    to the version history of the \"old\" a...\nI agree that the situation can become messy. What I just want to say is:\nIF the client which is causing the problem with an autoversioning server\ndoesn't hide it's identity\nAND IF the solution to forbid this client write access isn't acceptable\nTHEN it could be possible to give it some special treatment by recognizing\ncertain request patterns.\n\nMit freundlichen Gr??en / Best regards\n\nEdgar Schwarz\n\n--\nEdgar.Schwarz@marconi.com, Postf. 1920, D-71509 Backnang,+49 7191 13 3382,\nMarconi Communications, Access Division, Quality and Process Improvement\nPrivat kann jeder soviel C programmieren oder Videos ansehen wie er mag\n(Niklaus Wirth). Make it as simple as possible, but not simpler\n(A.Einstein)\n\n\n\n", "id": "lists-007-0966746"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "I am not surprised the Label header is proving to be problematic.\nThe last time I tried to get rid of it (obviously unsuccessfully)\nwas about a year ago.\n\nMy first choice would be to deprecate the Label header altogether, and\nto instead define a DAV:labeled-version report on a VCR, whose\nparameters were a label and a list of property names.  The result of\nthis report would be the values of the specified properties on the\nversion selected by the specified label from the VCR identified by the\nrequest-URL.\n\nAn alternative approach would be to deprecate the use of the Label\nheader with a non-zero Depth request (either because of an explicit\nnon-zero Depth header, or because a request is non-zero Depth by\ndefault).\n\nI'd be interested in responses on the following three questions:\n\n(1) Do these approaches address the issues raised?\n(2) Is there another approach that could be considered?\n(3) Which approach do you prefer?\n\nIf we can get consensus on an approach, I'll add it to the RFC 3253\nErrata document.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-0976317"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "Geoff,\n\n- I'd like to see the label *header* deprecated\n- I'm happy with the LABEL method and the label-name-set property\n- I think that PROPFIND/label should be replaced by a specific REPORT\n- I'm unsure about other methods that are currently affected by the\nheader -- what were the requirements...?\n- Servers that decide to implement LABEL and DAV:label-name-set, but no not\nsupport the label header should *not* report the LABEL feature in OPTIONS.\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, April 26, 2002 4:54 PM\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> I am not surprised the Label header is proving to be problematic.\n> The last time I tried to get rid of it (obviously unsuccessfully)\n> was about a year ago.\n>\n> My first choice would be to deprecate the Label header altogether, and\n> to instead define a DAV:labeled-version report on a VCR, whose\n> parameters were a label and a list of property names.  The result of\n> this report would be the values of the specified properties on the\n> version selected by the specified label from the VCR identified by the\n> request-URL.\n>\n> An alternative approach would be to deprecate the use of the Label\n> header with a non-zero Depth request (either because of an explicit\n> non-zero Depth header, or because a request is non-zero Depth by\n> default).\n>\n> I'd be interested in responses on the following three questions:\n>\n> (1) Do these approaches address the issues raised?\n> (2) Is there another approach that could be considered?\n> (3) Which approach do you prefer?\n>\n> If we can get consensus on an approach, I'll add it to the RFC 3253\n> Errata document.\n>\n> Cheers,\n> Geoff\n>\n>\n\n\n\n", "id": "lists-007-0984678"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   - I'd like to see the label *header* deprecated\n   - I'm happy with the LABEL method and the label-name-set property\n   - I think that PROPFIND/label should be replaced by a specific REPORT\n\nIs the proposed DAV:labeled-version report OK with you?\n\n   - I'm unsure about other methods that are currently affected by the\n   header -- what were the requirements...?\n\nThe other methods are LABEL, CHECKOUT, GET, and COPY.  \nFor Depth:0 variants of these operations, the Label header\njust provided an optimization to save one roundtrip\n(i.e. first getting the version URL via the DAV:labeled-version report).\nI believe we can easily do without that Depth:0 optimization.\n\nFor Depth:infinity (only relevant for LABEL and COPY), the savings\nwould be more significant, but unfortunately the semantics is broken\n(since if the namespace is being versioned, you'll get the wrong\nresources if you simply do a Depth operation on the current namespace).\n\nThe Depth:infinity Label header operations are really just a way of\ntrying to have the client fake workspaces and baselines, instead of\nhaving the server support them directly.  Since it is much more\nefficient and reliable to have the server layer these constructs\nabove a labeling infrastructure, rather than having the client do\nso, I believe the cost of maintaining these Depth:infinity Label\nheader operations in the protocol is not warranted.\n\nNote though that (depth:0) labeling and baselining go very well\ntogether.  Instead of doing a Depth:infinity LABEL, you can create a\nbaseline (which under the hood the server may well implement with\nreserved labels, but maybe not), and then LABEL that baseline.  Then\nwhen you want to do a Depth:infinity COPY, you retrieve the\nDAV:baseline-collection of the labeled baseline (using the\nDAV:labeled-version report), and copy that to wherever you want.\n\nAlternatively, if you want a \"modifiable\" selection, you can create a\nworkspace (which under the hood the server may well implement with\nreserved labels, but maybe not).  When you want to adjust the versions\nbeing selected, you just use UPDATE.  Then when you want to do a\nDepth:infinity COPY, you just copy from that workspace to wherever you\nwant.\n\n   - Servers that decide to implement LABEL and DAV:label-name-set,\n   but no not support the label header should *not* report the LABEL\n   feature in OPTIONS.\n\nThat's probably right.  A client can find out if the LABEL operation\nis supported by querying the DAV:supported-method-set property values\nof a VCR.\n\nCheers,\nGeoff\n\n   > From: Clemm, Geoff\n   >\n   > I am not surprised the Label header is proving to be problematic.\n   > The last time I tried to get rid of it (obviously unsuccessfully)\n   > was about a year ago.\n   >\n   > My first choice would be to deprecate the Label header altogether, and\n   > to instead define a DAV:labeled-version report on a VCR, whose\n   > parameters were a label and a list of property names.  The result of\n   > this report would be the values of the specified properties on the\n   > version selected by the specified label from the VCR identified by the\n   > request-URL.\n   >\n   > An alternative approach would be to deprecate the use of the Label\n   > header with a non-zero Depth request (either because of an explicit\n   > non-zero Depth header, or because a request is non-zero Depth by\n   > default).\n   >\n   > I'd be interested in responses on the following three questions:\n   >\n   > (1) Do these approaches address the issues raised?\n   > (2) Is there another approach that could be considered?\n   > (3) Which approach do you prefer?\n   >\n   > If we can get consensus on an approach, I'll add it to the RFC 3253\n   > Errata document.\n\n\n\n", "id": "lists-007-0994680"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "At 09:48 12/28/98 -0800, Ted Hardie wrote:\n\n>Thanks for your reply to my comments; I believe, however, that\n>some inexactness on my part may have led you astray, as we still seem\n>to be talking at cross-purposes on some issues.  I will endeavor below\n>to clarify those areas.\n\nSorry for the delay - on my part, I hope my response is more precise this\ntime...\n\n>Before going into the details, however, I want to make clear\n>that I was not proposing that the HTTP *minor* version number be\n>revved, but its *major* version number.  This document seems to me to\n>propose a framework that will encompass changes sufficiently great to\n>warrant that change--the landscape of the web will be changed\n>completely if this is adopted, and that calls to me for some pretty\n>clear signposts.  \n>\n>I will repeat that I would not see the need for the rev if the\n>document did not allow responses to contain extensions based on \"a\n>priori\" knowledge.  Without that \"a priori\" extension, HEAD, OPTIONS,\n>or the other methods you describe would suffice.  Without a very clear\n>specification of very specific cases where those \"a priori\" extensions\n>are allowed, they will be used in many, many cases that we cannot now\n>foresee.  That means a big, big flag needs to be raised.\n\nAccording to your reasoning here, HTTP/1.1 would have to called HTTP/2.0.\nThink of the Vary header field. The server may select a representation\nbased not only on any request header field but also on factors completely\noutside of the request itself (indicated by using the \"*\" value in the Vary\nheader field). In other words, the server may base the selection on apriori\nknowledge about what the client can handle. It is impossible to describe\nthe open ended set of ways this information is passed to the server.\n\n>> Furthermore, there is no reason why an application MUST read the\n>> declaration first - the ns prefixed header fields are just unknown\n>> extension header fields until the extension declaration has been\n>> interpreted. This kind of \"two-pass\" header field parsing is not new to\n>> HTTP - the same is the case for the connection header field and the\n>> cache-control header field, for example.\n>\n>\n>I did not say it must *read* the declaration first; I said it must\n>*process* it first.  Whether that is a one pass or a two pass header\n>field parsing makes no difference to the requirement.  As written, if\n>a Man: or an Opt: header exists, it must be processed with its\n>namespace headers first, as the meanings of the other headers may\n>change based on the extensions.\n\nThe change is actually not a *may* but a *will* - the header fields are by\ndefinition *undefined* until they have been defined by the extension\ndeclaration.\n\nThis is in fact a very fundamental point, not only about the extension\nmechanism but about HTTP itself: a header field doesn't mean anything\nunless it has been defined somewhere. That a header field may have an\nEnglish sounding name is really just a coincidence, it could as well be a\nnumber instead. In your example, it doesn't matter that you know what\n\"warm\" means - unless it has been defined as a property of beer and weather\nthen you can not talk about warm beer and warm weather.\n\nPrecisely because of this, the situation you are referring to can only\noccur if two individual extensions define the header field \"Warm\" to mean\ntwo different things - a situation that the extension framework explicitly\nprevents by using name spaces.\n\nThe major problem wrt extensibility in HTTP right now is that the only way\nto define a header field is to write a standards track RFC which we all\nknow takes a lot of time and leaves no way of gracefully deploying the\nfeature in the mean time.\n\nThe extension framework in fact allows for this and (if deployed) can make\nit easier for future extensions to be deployed in a step by step manner -\nnot only by defining what the extension means but also by specifying which\nparameters are associated with these extensions.\n\n>This is, in fact, a point I don't feel I am making well, and I'd like\n>Larry to speak to it if he can.  During the CONNEG meetings in Orlando,\n>he expressed very well the principle that the meaning of a feature must\n>not depend semantically on the values of *other* features (so \"Warm\" must\n>mean the same thing whether we are talking about beer or the weather).  \n\nI am not sure what Larry said, but having warm mean the same for both beer\nand weather is exactly having the meaning of one feature depend\nsemantically on more than one feature, right?\n\n>>   3.  If 2) did not result in a 510 (Not Extended) status code, then\n>>       strip the \"M-\" prefix from the method name and process the\n>>       remainder of the request according to the semantics of the\n>>       extensions and of the existing HTTP/1.1 method name as defined in\n>>       [5].\n>> \n>\n>Again, I don't seem to be getting my point across here.  The example I\n>gave was possibly too local.  I was trying to imply that the apparent\n>method for extending a method might seem to imply constraints which\n>aren't there.  In the M-GET example, you may have the base semantics\n>of GET, but you also have the possibility of secondary effects (like\n>the M-GET popping a stack and causing a new value to be present at the\n>URL) which substantially change the original semantics and cause\n>previously expected characteristics of GET (like idempotence) to\n>change.  The implication of this is that anyone examining a method for\n>security reasons (like a firewall administrator) cannot rely on the\n>method to the right of the M- for any real expectations of the\n>method's semantics.\n\nAs Yaron points out - this is a feature and not a bug. M- defines a new\nmethod which can only be considered a subclass of an existing method if the\nextension declaration is understood by the recipient.\n\n>> I can think of plenty of examples where this is not the case - for\n>> example published papers, released software packages etc. However, you\n>> are right that this is an issue and extension designers have to be\n>> careful (as should everybody else) when selecting a spot in the URI name\n>> space. This is also the reason for the careful wording in [2] section \n>> 8:\n>> \n>> \n>> <paraindent><param>left</param>It is strongly recommended that the\n>> integrity and persistence of the extension identifier be maintained and\n>> kept unquestioned throughout the lifetime of the extension. Care should\n>> be taken not to distribute conflicting specifications that reference the\n>> same name. Even when an extension specification is made available at the\n>> address of the URI, care must be taken that the specification made\n>> available at that address does not change over time. One agent may\n>> associate the identifier with the old semantics, and another might\n>> associate it with the new semantics.\n>> \n>> </paraindent>\n>\n>The fact that people get identifiers right in other contexts doesn't\n>really change the fact that this a major change to how URLs are used\n>in the current web context.  Given that current context, I am afraid I\n>find \"strongly recommended\" to be weakly worded.  It's not even a\n>SHOULD requirement, and I believe that it ought to be the most\n>strongly worded MUST we can design.  Without that strong requirement,\n>interoperability is based on the good will of the market players, some\n>of whom will have strong disincentives to admit some kinds of changes.\n\nWhy don't you consider paper publishing and software release to be part of\nthe current Web? In any case, putting a timeline on URIs identifying\nextensions is for our purposes a social and not really a technical problem\n- I believe this has been discussed at length (say, the last 5 years) in\nthe URN community. Note that this in fact can happen with a central\nregistry just as well - some MIME header fields are defined differently by\ndifferent protocols.\n\nIt is not the task of specification writers to prevent people from shooting\nthemselves in the foot - I for one would not take on this responsibility!\n\n>> >4) The content negotiation implied by the document is also not\n>> >workable within the current CONNEG framework, because the set\n>> >intersection model CONNEG uses presumes that the resource is intended\n>> >for a single purpose; it has no provision for a resource that is a\n>> >token, a description, and machine-usable code.  In the current\n>> >framework, a device selects among multiple values in a set\n>> >intersection by q-value, not purpose.  It can't really select \"one for\n>> >this and one for that\" in the same operation.\n>> \n>> Unless this is different from HTTP then the q values describe the value\n>> on the axis and not the dimension of the axis. q values can be applied to\n>> any dimension be it type or some other property. In fact, the negotiation\n>> hinted at here only spans the media type.\n>>\n>> As metadata is moving on the Web and the ways of describing capabilities\n>> get more powerful, so is content negotiation likely to get more powerful.\n>> The extension framework doesn't depend on any particular content\n>> negotiation mechanism (including no mechanism at all) and can actually be\n>> used to introduce improved content negotiation schemes as they evolve.\n>\n>Your first point is exactly what I am trying to get across: q values\n>describe the value on the axis and not *which* axis is being given the\n>value.  For a content negotiation mechanism to handle the problem you\n>propose, it would have to be able to designate the axis and the value.\n>I am not aware of any content negotiation mechanism, current or\n>proposed, that can handle that at the level of complexity your\n>document implies.  The correct operation of content negotiation for a\n>single-URI resource which potentially has everything from\n>machine-executable code to multi-lingual, multi-character set\n>descriptions is not an easy problem.  If you must imply that you want\n>it, please be very sure that you describe it as an unsolved problem\n>requiring further work.\n\nSorry, I wasn't clear - there is no way that you can define globally\napplicable parameters that can be applied to arbitrary or even unknown\nheader fields. Parameters can be applied only if that header field has been\ndefined to support those parameters.\n\nIn fact, the example of q-values is a good example - it actually doesn't\nwork the same way for all accept* header fields. Some really only define\nq-values as binary values, others define them as a value [0,1]. Look for\nexample closely at TE and accept-encoding - because of the default values\nof certain values, anything but 0 or 1 doesn't make sense.\n\nI see now where you are coming from - however, MIME doesn't work this way,\nand if CONNEG assumes this to be the case then you have made me worried\nabout its feasibility.\n\n>To be brutally honest, I believe that those who ought to be giving this\n>framework the very careful review it deserves are simply too tired to\n>go over it with the fine-toothed comb it needs.  We must be careful\n>to get that review and those problems worked at before it is released,\n>though, as the work required to fix this post facto would be enormous.\n\nI think this in fact is a very bad excuse for not moving forward. The draft\n(almost in its current state) has been around for a long time, there has\nbeen a \"last call\" on the mailing list [1] Augsut 18, the comments that\ncame back have been integrated into the latest 01 draft [2] which was\nreleased Nov 18. Furthermore, there is an extensive set of scenarios\navailable [3]. This is not moving at the speed of light - this is crawling\nat the pace of a mole under ground.\n\nThe main reason for attempting to moving HTTP extensions forward on this\nlist and not only the HTTP community is precisely to get feedback from a\nlarger community of which many are attempting to use HTTP as a base\ntransport for various extensions. Remember that HTTP is not owned by the\nHTTP WG - as much as we may like that idea.\n\nThanks for your comments!\n\nHenrik\n\n[1] http://lists.w3.org/Archives/Public/ietf-http-ext/1998JulSep/0028.html\n[2]\nhttp://info.internet.isi.edu/in-drafts/files/draft-frystyk-http-extensions-0\n1.txt\n[3] http://www.w3.org/Protocols/HTTP/ietf-http-ext/Scenarios.html\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10011205"}, {"subject": "RE: Looking for comments on the HTTP Extension draf", "content": "At 13:10 12/28/98 -0800, Yaron Goland wrote:\n><Defining the Problem>\n>I suspect we all at least agree that there is a need for a mandatory\n>extension mechanism. The functionality for this header being something on\n>the order of \"If you don't understand the header names specified in this\n>header then you MUST fail this method.\"\n>\n>One could make the argument that if one needs to add a header with semantics\n>that can't be ignored then one should change the method name and require\n>that the new method not ignore this header. However the management\n>complexities of this solution are exponential, thus this proposal is not\n>acceptable.\n\nActually I think this is just as valid for XML namespaces although I don't\nthink this discussion belongs here.\n\n<... deleted otherwise nice sales pitch for why HTTP extensions are needed\n...>\n\n><Henrik, put down that knife!>\n>However, given the previous pointed out sub-optimalities, I'm not sure that\n>the cure is all that much better than the disease. As such, I would like to\n>propose an alternative design.\n>\n>1) The creation of a hierarchical namespace encoding for methods and headers\n>ala what is being discussed in the URLREG WG. For example V!MS!FOO where V\n>is a stand in for vnd or vendor.\n>\n>2) The creation of a standardized encoding mechanism to allow for the use of\n>a fully qualified URIs as a method of header name. Because both use the\n>token production, standard URI characters such as : and / can not be used\n>without encoding.\n>\n>These two mechanisms will allow for decentralized extension without fear of\n>collision, exactly as is being attempted now in the URLREG WG. The cost,\n>however, of this mechanism is byte bloat. Mandatory's use of prefixing\n>allows short names to be used with short prefixes which are then translated\n>to their full names. In essence, mandatory has created relative URIs.\n>However the cost is double processing the headers. Thus every mandatory\n>aware proxy/firewall/server must process each request twice. There is a\n>trade off to be made here. My proposal leverages the existing HTTP\n>infrastructure as the cost of byte bloat. Henrik's proposal solves the byte\n>bloat problem but at the cost of causing us to have to completely re-write\n>our parsers to do double parsing. I suspect maintaining the current\n>infrastructure is probably the better goal.\n\nI have two religious and one practical objection to this proposal (I will\ntry and be polite as only a Dane can be). First the practical reason:\n\nI don't understand the underlying logic behind this proposal. The proposal\nseems to be an attempt of working around the problem that already deployed\nservers throw away header fields as soon as they are parsed if they are\nknown to be unknown or at least not useful to the server in order to\ngenerate the response.\n\nFor firewalls and proxies, this can not be the case. By definition all\nunknown header fields are end-to-end header fields - that is, they must be\npassed through to the other side regardless of the proxy acting as a client\nor a server. However, this changes if the header field is mentioned in the\nconnection header field in which case the proxy will have to find the\nheader field again and zap it. That is, it must maintain at least a\nreference to the header field while parsing the complete message.\n\nIn the case of an origin server there are already at least two scenarios in\nHTTP/1.1 where the server must parse the complete request before being able\nto determine whether the header field can be ignored or not. Granted, both\nthese cases are optional features that the server can ignore but more about\nthis later - first the two cases:\n\na) The If-Range only works if there also is a Range header field present\nand must be ignored if this is not the case. That is, the If-Range can not\nbe thrown away before the full message has been parsed.\n\nb) The interactions between the If-Modified-Since and If-None-Match\nrequires both to be used before the server can determine whether it can\ngenerate a 304 response or not. This has been discussed on the HTTP mailing\nlist [1] - that I think the solution is rather complex is another question.\n\nThat is, a moderately advanced HTTP/1.1 server is likely to have at least\nthe hooks for returning to and handling already parsed header fields while\nthe request is still being parsed.\n\nTherefore a more correct assessment is probably that \"Some origin servers\nwill have to have extra hooks put in to their header parsers.\" Note here\nthat it is not required to maintain pointers to anything but header fields\nstarting with a digit.\n\nIs this a big thing? As always, an absolute answer to this question is\nimpossible but relative to the additional work of encoding/decoding URIs\nwith a (new?) encoding, it doesn't seem so. Actually, it seems rather\nlightweight compared to having to parse all header fields to see if it\nlooks like a URI in disguise.\n\nOn the religious side, here are my main points against your proposal:\n\nb) Assuming that a central registry can be the authoritative source of\ninformation for an open-ended set of extensions deployed on the Internet at\nlarge is in my mind rather unrealistic. Sure, it may contain\nunauthoritative information about vendor specific features but only that\nvendor has the final information. HTTP Extension URI point directly at this\nalready hence avoiding multiple lookups.\n\nb) The breakdown of independence between URIs and MIME headers. The\nencoding of URIs must by definition be a function of the way we transport\nthem - in this case the MIME framework. This means that we forever tie\nextension identifiers and MIME together. I don't like that feeling.\n\n>The downside of my simplification proposal is that it doesn't provide a\n>generic mechanism to say \"The functionality represented by this URI is now\n>associated with this method.\" Instead you have to use a header hack. You\n>have to add a header with the specified URI and then include its name in\n>Mandatory. I can live with this. How about you?\n></Henrik, put down that knife!>\n\nSo, in summary, I am happy that you agree on the problem statement but I\ndon't think your proposal is any simpler than what we already have on the\ntable - in fact it is likely to be rather more complex.\n\nHenrik (who is trying to imagine himself hunting chickens with a knife and\nbear hands)\n\n[1] http://www.egroups.com/list/http-wg/7416.html\n\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10032536"}, {"subject": "HTTP Extension draf", "content": "Hi folks,\n\nI was asked to comment on Henrik's HTTP Extensions Draft as someone who's\nlooked at this problem in the past.  When we were working on the RTSP draft\n(now RFC 2326), we contemplated baking in PEP support, but then backed down\nand came up with a drastically simplified extension mechanism which you can\nfind in RFC 2326 by looking at the \"Require:\" and \"Proxy-Require:\" fields. \n\nCurrent experience on the RTSP extension mechanisms is still sparse, and so\nI can't offer a lot of anecdotal evidence on that front.  However, we\nhaven't yet run into anything that suggests that we screwed up too terribly.\n\nHowever, I can speak from the perspective of a vendor of an HTTP system who\nmay be confronted with implementing this one day.  I think it solves the\nproblems it tries to solve well, but that it bites off more than it should\nchew.\n\nHere's the three problems that I see this solving:\n1.  Ability to add mandatory extensions\n2.  Ability to send extension metadata\n3.  Ability to add vendor-specific extensions free from namespace collisions\n\nI think #1 is very interesting and useful.  #2 and #3 are of limited\nutility in my opinion (I can go further on the inevitable prompting, but\nI'm tired of typing right now :)\n\nSo, in the best possible of worlds, I would prefer to see proposals that\ndecouple the three, and solve them semi-independently (though #2 and #3\ncould certainly build on #1).  I'd be very supportive of a proposal that\nsolves #1 as simply as possible, and tests the limits of that model.  #2\nand #3 could be saved for HTTP-NG, or could be added if the #1 solution was\nproven insufficient.\n\nRob\n\n\n\n", "id": "lists-007-10048198"}, {"subject": "Re: HTTP Extension draf", "content": "At 00:06 1/4/99 -0800, Rob Lanphier wrote:\n\nHi Rob,\n\n>However, I can speak from the perspective of a vendor of an HTTP system who\n>may be confronted with implementing this one day.  I think it solves the\n>problems it tries to solve well, but that it bites off more than it should\n>chew.\n>\n>Here's the three problems that I see this solving:\n>1.  Ability to add mandatory extensions\n>2.  Ability to send extension metadata\n>3.  Ability to add vendor-specific extensions free from namespace collisions\n\nThanks for your review - first I have a meta question: In #2 what kind of\nmetadata do you mean? In case you mean the old feature discovery exchange\nmechanism defined in PEP then I fully agree with you. If you mean the\nextension instance parameters then I would not consider that metadata but\ncall parameters of a particular instance.\n\nWith respect to #3, is it that you consider a central registry sufficient\nor is it the name space prefix model you are referring to? Note, however,\nthat as a policy neutral specification, there is nothing that prevents an\nextension from being open or to be the design of multiple organizations\nand/or commercial companies. This is fully up to the designers of that\nparticular extension.\n\nThe main purpose is to define a mechanism that allows for graceful\ndeployment of new extensions locally as well as globally without requiring\nthat two peers have complete knowledge about each others capabilities.\n\n>So, in the best possible of worlds, I would prefer to see proposals that\n>decouple the three, and solve them semi-independently (though #2 and #3\n>could certainly build on #1).  I'd be very supportive of a proposal that\n>solves #1 as simply as possible, and tests the limits of that model.  #2\n>and #3 could be saved for HTTP-NG, or could be added if the #1 solution was\n>proven insufficient.\n\nThe HTTP extension draft in fact does separate instance data from metadata\n- it simply doesn't define a mechanism for handling the latter\nindependently of instance data.\n\nThanks!\n\nHenrik\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10056847"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, April 26, 2002 6:06 PM\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    - I'd like to see the label *header* deprecated\n>    - I'm happy with the LABEL method and the label-name-set property\n>    - I think that PROPFIND/label should be replaced by a specific REPORT\n>\n> Is the proposed DAV:labeled-version report OK with you?\n\nYes. But I think it's Tim's turn to say whether this would work for him or\nnot...\n\n>    - I'm unsure about other methods that are currently affected by the\n>    header -- what were the requirements...?\n>\n> The other methods are LABEL, CHECKOUT, GET, and COPY.\n> For Depth:0 variants of these operations, the Label header\n> just provided an optimization to save one roundtrip\n> (i.e. first getting the version URL via the DAV:labeled-version report).\n> I believe we can easily do without that Depth:0 optimization.\n\nAs stated before, I think that's not the single problem. Having GET return a\n(representation of a) version rather than (a representation of) the VCR\nmakes the version *by definition* a variant (representation) of the VCR --\nand it seems that most of us want to avoid that interpretation.\n\n> For Depth:infinity (only relevant for LABEL and COPY), the savings\n> would be more significant, but unfortunately the semantics is broken\n> (since if the namespace is being versioned, you'll get the wrong\n> resources if you simply do a Depth operation on the current namespace).\n>\n> The Depth:infinity Label header operations are really just a way of\n> trying to have the client fake workspaces and baselines, instead of\n> having the server support them directly.  Since it is much more\n> efficient and reliable to have the server layer these constructs\n> above a labeling infrastructure, rather than having the client do\n> so, I believe the cost of maintaining these Depth:infinity Label\n> header operations in the protocol is not warranted.\n>\n> Note though that (depth:0) labeling and baselining go very well\n> together.  Instead of doing a Depth:infinity LABEL, you can create a\n> baseline (which under the hood the server may well implement with\n> reserved labels, but maybe not), and then LABEL that baseline.  Then\n> when you want to do a Depth:infinity COPY, you retrieve the\n> DAV:baseline-collection of the labeled baseline (using the\n> DAV:labeled-version report), and copy that to wherever you want.\n>\n> Alternatively, if you want a \"modifiable\" selection, you can create a\n> workspace (which under the hood the server may well implement with\n> reserved labels, but maybe not).  When you want to adjust the versions\n> being selected, you just use UPDATE.  Then when you want to do a\n> Depth:infinity COPY, you just copy from that workspace to wherever you\n> want.\n>\n>    - Servers that decide to implement LABEL and DAV:label-name-set,\n>    but no not support the label header should *not* report the LABEL\n>    feature in OPTIONS.\n>\n> That's probably right.  A client can find out if the LABEL operation\n> is supported by querying the DAV:supported-method-set property values\n> of a VCR.\n\n...and also use DAV:supported-live-property-set to discover the\nDAV:label-name-set property.\n\n\n\n", "id": "lists-007-1006106"}, {"subject": "Re: Archive of this list", "content": "At 15:07 12/17/98 -0500, Paul Hoffman / IMC wrote:\n>Greetings. I said last week that I would start an \"applicaitons using XML\"\n>mailing list, but wanted to be know what had been said on this mailing list\n>before I did. Has anyone been keeping a complete archive?\n\nDid we ever get this sorted out? I think it is crucial that we have an\narchive - otherwise we are likely to go around in circles in our discussions.\n\nThanks,\n\nHenrik\n\n\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10066177"}, {"subject": "Re: Message threading in e-mail softwar", "content": "Jacob,\n\nJacob Palme wrote:\n> \n> I have written a paper which describes how e-mail software\n> handles message threads. The paper can be found at URL:\n\nThe two additional headers, Original-Message-Id and\nOriginal-Envelope-Id, from part 2 of the multipart/report (if available)\nthat should be used to thread received DSN/MDNs.  Netscape does add\nReferences to MDNs it produces and threads received ones if they contain\nit but is no good for reports without it.  \n\nRgds\n-- \nAntony Bowesman\nadb@to.sel.fujitsu.co.jp\n\n\n\n", "id": "lists-007-10073271"}, {"subject": "RE: Looking for comments on the HTTP Extension draf", "content": "Can we please just pass the damn thing?\n\n> -----Original Message-----\n> From: Henrik Frystyk Nielsen [mailto:frystyk@w3.org]\n> Sent: Sunday, January 03, 1999 4:21 PM\n> To: Yaron Goland; 'Ted Hardie'\n> Cc: masinter@parc.xerox.com; Chris.Newman@INNOSOFT.COM;\n> discuss@apps.ietf.org; Josh Cohen; Yaron Goland\n> Subject: RE: Looking for comments on the HTTP Extension draft\n> \n> \n> At 13:10 12/28/98 -0800, Yaron Goland wrote:\n> ><Defining the Problem>\n> >I suspect we all at least agree that there is a need for a mandatory\n> >extension mechanism. The functionality for this header being \n> something on\n> >the order of \"If you don't understand the header names \n> specified in this\n> >header then you MUST fail this method.\"\n> >\n> >One could make the argument that if one needs to add a \n> header with semantics\n> >that can't be ignored then one should change the method name \n> and require\n> >that the new method not ignore this header. However the management\n> >complexities of this solution are exponential, thus this \n> proposal is not\n> >acceptable.\n> \n> Actually I think this is just as valid for XML namespaces \n> although I don't\n> think this discussion belongs here.\n> \n> <... deleted otherwise nice sales pitch for why HTTP \n> extensions are needed\n> ...>\n> \n> ><Henrik, put down that knife!>\n> >However, given the previous pointed out sub-optimalities, \n> I'm not sure that\n> >the cure is all that much better than the disease. As such, \n> I would like to\n> >propose an alternative design.\n> >\n> >1) The creation of a hierarchical namespace encoding for \n> methods and headers\n> >ala what is being discussed in the URLREG WG. For example \n> V!MS!FOO where V\n> >is a stand in for vnd or vendor.\n> >\n> >2) The creation of a standardized encoding mechanism to \n> allow for the use of\n> >a fully qualified URIs as a method of header name. Because \n> both use the\n> >token production, standard URI characters such as : and / \n> can not be used\n> >without encoding.\n> >\n> >These two mechanisms will allow for decentralized extension \n> without fear of\n> >collision, exactly as is being attempted now in the URLREG \n> WG. The cost,\n> >however, of this mechanism is byte bloat. Mandatory's use of \n> prefixing\n> >allows short names to be used with short prefixes which are \n> then translated\n> >to their full names. In essence, mandatory has created relative URIs.\n> >However the cost is double processing the headers. Thus \n> every mandatory\n> >aware proxy/firewall/server must process each request twice. \n> There is a\n> >trade off to be made here. My proposal leverages the existing HTTP\n> >infrastructure as the cost of byte bloat. Henrik's proposal \n> solves the byte\n> >bloat problem but at the cost of causing us to have to \n> completely re-write\n> >our parsers to do double parsing. I suspect maintaining the current\n> >infrastructure is probably the better goal.\n> \n> I have two religious and one practical objection to this \n> proposal (I will\n> try and be polite as only a Dane can be). First the practical reason:\n> \n> I don't understand the underlying logic behind this proposal. \n> The proposal\n> seems to be an attempt of working around the problem that \n> already deployed\n> servers throw away header fields as soon as they are parsed \n> if they are\n> known to be unknown or at least not useful to the server in order to\n> generate the response.\n> \n> For firewalls and proxies, this can not be the case. By definition all\n> unknown header fields are end-to-end header fields - that is, \n> they must be\n> passed through to the other side regardless of the proxy \n> acting as a client\n> or a server. However, this changes if the header field is \n> mentioned in the\n> connection header field in which case the proxy will have to find the\n> header field again and zap it. That is, it must maintain at least a\n> reference to the header field while parsing the complete message.\n> \n> In the case of an origin server there are already at least \n> two scenarios in\n> HTTP/1.1 where the server must parse the complete request \n> before being able\n> to determine whether the header field can be ignored or not. \n> Granted, both\n> these cases are optional features that the server can ignore \n> but more about\n> this later - first the two cases:\n> \n> a) The If-Range only works if there also is a Range header \n> field present\n> and must be ignored if this is not the case. That is, the \n> If-Range can not\n> be thrown away before the full message has been parsed.\n> \n> b) The interactions between the If-Modified-Since and If-None-Match\n> requires both to be used before the server can determine \n> whether it can\n> generate a 304 response or not. This has been discussed on \n> the HTTP mailing\n> list [1] - that I think the solution is rather complex is \n> another question.\n> \n> That is, a moderately advanced HTTP/1.1 server is likely to \n> have at least\n> the hooks for returning to and handling already parsed header \n> fields while\n> the request is still being parsed.\n> \n> Therefore a more correct assessment is probably that \"Some \n> origin servers\n> will have to have extra hooks put in to their header \n> parsers.\" Note here\n> that it is not required to maintain pointers to anything but \n> header fields\n> starting with a digit.\n> \n> Is this a big thing? As always, an absolute answer to this question is\n> impossible but relative to the additional work of \n> encoding/decoding URIs\n> with a (new?) encoding, it doesn't seem so. Actually, it seems rather\n> lightweight compared to having to parse all header fields to see if it\n> looks like a URI in disguise.\n> \n> On the religious side, here are my main points against your proposal:\n> \n> b) Assuming that a central registry can be the authoritative source of\n> information for an open-ended set of extensions deployed on \n> the Internet at\n> large is in my mind rather unrealistic. Sure, it may contain\n> unauthoritative information about vendor specific features \n> but only that\n> vendor has the final information. HTTP Extension URI point \n> directly at this\n> already hence avoiding multiple lookups.\n> \n> b) The breakdown of independence between URIs and MIME headers. The\n> encoding of URIs must by definition be a function of the way \n> we transport\n> them - in this case the MIME framework. This means that we forever tie\n> extension identifiers and MIME together. I don't like that feeling.\n> \n> >The downside of my simplification proposal is that it \n> doesn't provide a\n> >generic mechanism to say \"The functionality represented by \n> this URI is now\n> >associated with this method.\" Instead you have to use a \n> header hack. You\n> >have to add a header with the specified URI and then include \n> its name in\n> >Mandatory. I can live with this. How about you?\n> ></Henrik, put down that knife!>\n> \n> So, in summary, I am happy that you agree on the problem \n> statement but I\n> don't think your proposal is any simpler than what we already \n> have on the\n> table - in fact it is likely to be rather more complex.\n> \n> Henrik (who is trying to imagine himself hunting chickens \n> with a knife and\n> bear hands)\n> \n> [1] http://www.egroups.com/list/http-wg/7416.html\n> \n> --\n> Henrik Frystyk Nielsen,\n> World Wide Web Consortium\n> http://www.w3.org/People/Frystyk\n> \n\n\n\n", "id": "lists-007-10081265"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "Henrik Frystyk Nielsen:\n>\n>At 14:53 12/18/98 +0100, Koen Holtman wrote:\n>\n>>There could be some more discussion of caching related considerations, in\n>>particular\n>>\n>>  - I would like to see and example of correct use of the Vary header\n>>    (hinted at in 3.1)\n>\n>It works exactly as for accept* headers with q-values in case you are using\n>ns and without q-values if not.\n\nI am not sure what you are saying here, I don't see the connection\nwith the presence or absence of q values.  Anyway, the type of example\nI want to see is\n\n request:\n  M-GET /p/q HTTP/1.1\n  Man: \"http://www.x.y/transform\"; ns=16-\n  16-use-transform: xyzzy\n  ....\n\n response:\n  HTTP/1.1 200 OK\n  Ext:\n  Vary: man, 16-use-transform\n  Date: Sun, 25 Oct 1998 08:12:31 GMT\n  Expires: Sun, 25 Oct 1998 08:12:31 GMT\n  Cache-Control: no-cache=\"Ext\", max-age=100000\n  ....\n\n\n[....]\n>>  - I would like explicit mention of the fact that things can break\n>>    horribly if extensions are added to a 304 response.  See\n>>    http://lists.w3.org/Archives/Public/ietf-http-ext/1998JanMar/0105.html\n>>    for a discussion of the problem. \n>\n>I don't think the situation you describe is any different than what can\n>happen if any header field is tagged onto a 304 response. This is the\n>reason for the restrictions on what a 304 response can contain, see\n>\n>http://www.ietf.org/internet-drafts/draft-ietf-http-v11-spec-rev-06.txt\n>\n>section \"10.3.5 304 Not Modified\", where it says:\n\nI know about that restriction on 304 responses in HTTP/1.1.  But it is\nnot clear from your http-ext spec whether http-ext servers and proxies\nmay violate that restriction.  http-ext proxies violate 1.1 in other\nways too, for example proxies will sometimes change the request\nmethod, which is not allowed under plain 1.1.  You need to be more\nexplicit on the matter of 304 responses.  It is true that one could\nconclude, after careful analysis of caching scenarios, that this 304\nrestriction in HTTP needs to be retained, but it is far too easy to\nwrongly infer from the text that the piggybacking mechanism is safe\nfor any response code.\n\n\nI guess there is a common theme in my Vary and 304 comments and your\nresponses: I want things to be more obvious, and you are saying that\nthings are obvious enough already.  I believe that the current draft,\nif used as a basis for implementations, will quite likely lead to\nimplementations which have subtle caching related problems.  You may\nsay that this is a fault in the implementers, who should have known\nthe pitfalls in HTTP caching better, but I say this is a fault in the\ndraft.\n\nI would be far happier if the draft dropped the examples with cachable\nresponses and replaced it with a discussion of one fail-safe method of\nmaking sure that interference from caches is avoided.  I would not\ncare if the method was not very cache-friendly, expert implementers\ncould figure out more cache-friendly methods for themselves.\n\n\n>>  Also, if the user\n>>agent would send a subsequent M-GET+Man request, it probably wants the Man\n>>header to reach the origin server, so it would have to include a\n>>Cache-Control: no-cache in its request.  The only case where the cached\n>>response could do some good is if a proxy along the chain transforms a GET\n>>request into an M-GET+C-opt request, but this subtle benefit is not clear\n>>from the example. \n>\n>Nope - by default, an HTTP client is interested in the nearest fresh\n>response it can get for that method. It is no different with a client\n>issuing a M-GET request - by default it is interested in the nearest fresh\n>response for that method.\n\nI disagree.  If the client includes a Man header, it wants some\naction, specified by the extension in the header, to be performed by\nthe origin server.  Isn't that what mandatory stands for?  If it did\nnot really want the action, but would settle for a fresh response\ninstead, it would have put the action in an Opt header.\n\nIf mandatory means 'this request must result in an action by the\norigin server but a fresh response from a cache is OK too' then we\nare talking about a different type of extension mechanism I think.\n\n>> - The header field prefixes stuff is just unnecessary complexity in\n>>   my opinion.  It would be easier for everyone to put all extension\n>>   related data as decl-extensions in the Man or Opt header.\n>\n>This proposal was voted down after discussion on the <ietf-http-ext>\n>mailing list:\n>\n>http://lists.w3.org/Archives/Public/ietf-http-ext/1998AprJun/0029.html\n\nHmm, I did not recall that this issue was completely resolved, but I\nthink I was wrong.  The above URL points to the minutes of a phone\nconference I did not participate in, but looking a bit further in the\nlist archives I guess the issue did get resolved on the list, by lack\nof comments to the last call.  So I apologise for having brought it up\nagain.\n\n[...]\n\n>Henrik\n\nKoen.\n\n\n\n", "id": "lists-007-10099003"}, {"subject": "Re: request for review: http extension", "content": ">Sorry for the late review (I hope its not too late). Hope its useful.\n>\n>-Jonathan R.\n>\n>Philipp Hoschka wrote:\n>> \n>> Jonathan,\n>> could you review Henrik's http extensions proposal ?\n>> ftp://ftp.ietf.org/internet-drafts/draft-frystyk-http-extensions-01.txt\n>> \n>> and send your review to\n>> discuss@apps.ietf.org\n>> \n>> This is a prerequisite to move this to Proposed Standard level\n>> at the IETF.\n>> \n>> Your review would be greatly appreciated\n>> \n>> Happy Holidays\n>> \n>> -Philipp\n>\n>-- \n>Jonathan D. Rosenberg                       Lucent Technologies\n>Member of Technical Staff                   101 Crawfords Corner Rd.\n>High Speed Networks Research                Holmdel, NJ 07733\n>FAX: (732) 834-5379                         Rm. 4C-526\n>EMAIL: jdrosen@bell-labs.com\n>URL: http://www.cs.columbia.edu/~jdrosen\n>1.  o Some party designs and specifies an extension; the party assigns\n>    the extension a globally unique address (URI)\n>\n>This would seem to imply that a URI = a globally unique address, which\n>it does not (it may not contain an address). Rather, what this means\n>to say is that a globally unique identifer is assigned, and that the\n>identifer also specifies a resource which is the definition of the\n>extension itself.\n>\n>2. The usage of the - as part of the BNF for header prefix seems\n>uneccesary. Rather, the BNF need only define the numeric value of the\n>namespace. An implementation then takes this number, appends the dash,\n>and then adds the actual header name when placing extension headers in\n>the message. In the BNF, it serves neither as a conveyer of\n>information nor as a separator between elements.\n>\n>3. THe usage of the field-name for ext-decl seems odd. The ext-decl\n>must be a globally unique identifier which points to a definition of\n>the extension. If this extension is documented in an RFC, then really\n>it is also a URI, probably a urn like urn:ietf:rfc:2141 (see\n>draft-ietf-urn-ietf). Why add this extra field-name parameter when a\n>URN will suffice?\n>\n>4. The spec allows for declaration extension parameters, but none are\n>defined and there is no guidelines regarding what they might actually\n>be useful for. What is their purpose?\n>\n>5. The spec says unrecognized decl-ext parameters SHOULD be\n>ignored. What else can it do? Shouldn't this be a MUST?\n>\n>6. \"The header-prefix are dynamically generated header field prefix strings\n>that can be used to indicate that all header fields in the message\n>matching the header-prefix value using string prefix-matching are\n>introduced by this extension instance.\" \n>\n>This sentence is a run on and is confusing, but it conveys some really\n>important information. Cleanup would be useful.\n>\n>7. The spec should probably say something specific about requirements for the\n>prefix strings; something like \"prefix strings for different\n>extensions, or for different instances of the same extension, MUST be\n>different, but SHOULD otherwise be the same from request to request\"\n>\n>8. The term \"ultimate recipient\" is used a lot, but I didn't find a\n>definition of who it is. I think that for hop by hop, its the next\n>proxy that receives the message, and for end to end, its the origin\n>server or cache. Not sure if this is right, though. You should define\n>this term more clearly.\n>\n>9. THe appendices start numbering at 14, essentially as continuations\n>of section numbers. They should probably start over at 1 or A.\n>\n>10. (See section 4.1 and 4.2, and appendix 14\n>for a table of interactions with origin servers and proxies.)\n>\n>This is gramatically incorrect. Should be:\n>\n>(See sections 4.1 and 4.2; also see appendix 14 which has a table\n>of....)\n>\n>11. \"Mandatory declarations MUST be applied to a\n>request message as described in section 5 and to a response message as\n>described in section 6.\"\n>\n>Mandatory declarations MUST be applied only when a mandatory extension\n>has been applied. This sentence just says that you must always apply\n>mandatory declarations to requests and responses.\n>\n>12. \"The ultimate recipient of a mandatory end-to-end extension declaration\n>\n>MUST handle that extension declaration as described in section 5 and\n>6.\"\n>\n>Extra carriage return in the middle of the sentence.\n>\n>13. \"That is, the header fields are\n>to be included as Connection header field directives (see [5], section\n>14.10).\"\n>\n>are to be included -> MUST be included. Also, MUST the header fields\n>declared in the extension also be protected by a COnnection header?\n>\n>14. Its not clear why you need the Ext and M-Ext headers. According to\n>section 5, a request is responded to with a 510 if any mandatory\n>extension is not understood. So, if a client or proxy receives a\n>response that is not 510, it knows that every mandatory and hop by hop\n>was understood, so the Ext and M-Ext headers convey no useful\n>information. If a 510 is received, the request was not fulfilled and\n>neither the end to end or hop by hop mandatory extensions were\n>fulfilled.\n>\n>15. \"The Ext and the C-Ext header fields are not mutually exclusive, they can\n>both occur within the same message as described in section 5.1.\"\n>\n>The comma should be a semicolon.\n>\n>16. Why does the method name need to be prefixed with an M? Is this\n>for compatibility with HTTP implementations which don't understand\n>this extension mechanism?\n>\n>17. \"It is strongly recommended that the integrity and persistence of the\n>extension identifier be maintained and kept unquestioned\"\n>\n>RECOMMENDED\n>\n>18. The examples in appendix 15 would be more useful if they were more\n>complete. In particular, if the C-Opt, C-Man, Opt, and Man header\n>fields were formulated properly.\n>\n>19. You might want to consider a header called Unsupported for 510\n>responses (its used in SIP. It could be used to list those mandatory\n>extensions which were not understood:\n>\n>GET <address>\n>Man: ext1, ext2, ext3\n>\n>510 Not Extended\n>Unsupported: ext1, ext3\n>\n>This would allow a client to reformulate the request without the\n>extension, if possible. Besides this, the draft seems to be a\n>reasonably complete solution for extensions.\n>\n>\n>\n>\n>\n\n\n\n", "id": "lists-007-10113234"}, {"subject": "Re: HTTP Extension draf", "content": "At 09:19 AM 1/4/99 -0500, Henrik Frystyk Nielsen wrote:\n>At 00:06 1/4/99 -0800, Rob Lanphier wrote:\n>>Here's the three problems that I see this solving:\n>>1.  Ability to add mandatory extensions\n>>2.  Ability to send extension metadata\n>>3.  Ability to add vendor-specific extensions free from namespace collisions\n>\n>Thanks for your review - first I have a meta question: In #2 what kind of\n>metadata do you mean? In case you mean the old feature discovery exchange\n>mechanism defined in PEP then I fully agree with you. If you mean the\n>extension instance parameters then I would not consider that metadata but\n>call parameters of a particular instance.\n\nOn second reading, I realize that \"metadata\" is too strong a word (I have\nto admit reading it with PEP tinted glasses the first time) :), and that\nyou're probably right that the rest is necessary to solve the namspace\nclashing problem (#3).  Now, whether #1 and #3 should be solved in the same\ndraft is another discussion....\n\n>With respect to #3, is it that you consider a central registry sufficient\n>or is it the name space prefix model you are referring to? Note, however,\n>that as a policy neutral specification, there is nothing that prevents an\n>extension from being open or to be the design of multiple organizations\n>and/or commercial companies. This is fully up to the designers of that\n>particular extension.\n\nI can see the benefits of trying to extend the XML model to HTTP.  However,\nI'd like to see how things pan out with XML namespaces before retrofitting\nthat model into HTTP.\n\nA side question:  if this becomes a proposed recommendation, what do you\nthink will be the first application that uses this?  I ask this because I'm\nwondering if there's something waiting in the wings for the completion of\nthis spec, and to get a good feel for a good application of this.\n\nRob\n\n\n\n", "id": "lists-007-10128127"}, {"subject": "Re: HTTP Extension draf", "content": "At 09:50 1/6/99 -0800, Rob Lanphier wrote:\n\n>I can see the benefits of trying to extend the XML model to HTTP.  However,\n>I'd like to see how things pan out with XML namespaces before retrofitting\n>that model into HTTP.\n\nActually, the HTTP extension framework namespace model has been there for\nquite some time - remember that the basic idea of this proposal goes back a\nwhile.\n\n>A side question:  if this becomes a proposed recommendation, what do you\n>think will be the first application that uses this?  I ask this because I'm\n>wondering if there's something waiting in the wings for the completion of\n>this spec, and to get a good feel for a good application of this.\n\nThere are several applications that are waiting/potential candidates for\nHTTP extensions (no endorsement from my side on whether these extensions\nare good or not).\n\n* Integrating TIP in HTTP - Yaron wrote up a draft some time ago regarding\nthis. It has expired now but you can find it at [3].\n\n* The W3C P3P [1] intends to use it for sending privacy agreements over the\nwire\n\n* The work going on in the conneg area with respect to CCPP [2]\n\n* The WIRE draft [4] (although a highly revised version is soon to be sent\nout this is still valid), which is a mechanism for exchanging generic\nmetadata in HTTP\n\n* Negotiating new transport filters like TLS, compression, etc. would be an\nobvious use of the extension framework. Rohit wrote a draft on how to use\nthe upgrade header but the extension framework is really a superset of the\nupgrade header. [5]\n\nAnd then of course there is Larry Masinter's infamous HTCPCP [6].\n\nI am aware of others but will leave it to the extension designers to\nannounce this. This has nothing to do with W3C work, it's just that I don't\nknow how and when they prefer to announce their work.\n\nHenrik\n\n[1] http://www.w3.org/P3P/\n[2] http://www.w3.org/TR/NOTE-CCPP/\n[3] http://www.ics.uci.edu/pub/ietf/http/draft-ietf-tip-usehttp-01.txt\n[4] http://www.ics.uci.edu/pub/ietf/http/draft-girod-w3-id-res-ext-00.txt\n[5] http://www.ics.uci.edu/pub/ietf/http/draft-ietf-tls-http-upgrade-00.txt\n[6] http://info.internet.isi.edu:80/in-notes/rfc/files/rfc2324.txt\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10137247"}, {"subject": "Re: request for review: http extension", "content": "At 02:09 1/6/99 -0500, Jonathan Rosenberg wrote:\n>Sorry for the late review (I hope its not too late). Hope its useful.\n\nVery useful - thanks for a very detailed review! Too bad that you haven't\nbeen in on the mailing list discussions [1] as many of your questions have\nbeen discussed there at length.\n\n>1.  o Some party designs and specifies an extension; the party assigns\n>    the extension a globally unique address (URI)\n>\n>This would seem to imply that a URI = a globally unique address, which\n>it does not (it may not contain an address). Rather, what this means\n>to say is that a globally unique identifer is assigned, and that the\n>identifer also specifies a resource which is the definition of the\n>extension itself.\n\nNo, what is meant is that only URIs that in fact are globally unique\nidentifiers can be used. I will change the wording to \"globally unique URI\".\n\n>2. The usage of the - as part of the BNF for header prefix seems\n>uneccesary. Rather, the BNF need only define the numeric value of the\n>namespace. An implementation then takes this number, appends the dash,\n>and then adds the actual header name when placing extension headers in\n>the message. In the BNF, it serves neither as a conveyer of\n>information nor as a separator between elements.\n\nIt must be there as a separator (in fact any non-digit character would do).\nOtherwise an application can potentially block the whole prefix name space.\nThis was discussed on the list [2].\n\n>3. THe usage of the field-name for ext-decl seems odd. The ext-decl\n>must be a globally unique identifier which points to a definition of\n>the extension. If this extension is documented in an RFC, then really\n>it is also a URI, probably a urn like urn:ietf:rfc:2141 (see\n>draft-ietf-urn-ietf). Why add this extra field-name parameter when a\n>URN will suffice?\n\nThe problem is exactly the \"probably\". There is no current resolution for\nwhat the name space for RFCs and the like should be. And in case it should\nbe based on URNs then they themselves are not yet resolved. Whether that\nwill happen is another discussion altogether. \n\nTed Hardie checked on the current status of the header field registration\nwork in the drums working group and came up with this:\n\nJacob Palme on this and he tells me that DRUMs decided\nat it's last meeting to delay working on this until the\n821bis and 822bis documents are ready. I personally believe\nthat this means we cannot count on this registry existing\nin the form specified by draft-ietf-drums-MHregistry-03.txt\nany time soon.\n\nThis is the reason we went with the current solution which allows for a\nsmooth transition from local extension to standards track RFC without\nhaving to resolve the problem of defining the URI space for IANA registered\ntokens and documents.\n\n>4. The spec allows for declaration extension parameters, but none are\n>defined and there is no guidelines regarding what they might actually\n>be useful for. What is their purpose?\n\nWhat do you mean \"none are defined\" - they are intended for extending the\nextension declarations with (by definition) optional parameters. I am not\nsure what you mean?\n\n>5. The spec says unrecognized decl-ext parameters SHOULD be\n>ignored. What else can it do? Shouldn't this be a MUST?\n\nThe SHOULD is really more a guideline for what to do with unknown\nparameters. The only strict requirement is that it must not be removed if\nforwarded. I will here refer to Larry Masinter's thoughts on\nMAY/SHOULD/MUST [7]. \n\n>6. \"The header-prefix are dynamically generated header field prefix strings\n>that can be used to indicate that all header fields in the message\n>matching the header-prefix value using string prefix-matching are\n>introduced by this extension instance.\" \n>\n>This sentence is a run on and is confusing, but it conveys some really\n>important information. Cleanup would be useful.\n\nWhat about:\n\nThe header-prefix is a dynamically generated string\nindicating that all header fields in the message matching the\nheader-prefix string using string prefix-matching belong to\nthat extension declaration.\n\n>7. The spec should probably say something specific about requirements for the\n>prefix strings; something like \"prefix strings for different\n>extensions, or for different instances of the same extension, MUST be\n>different, but SHOULD otherwise be the same from request to request\"\n\nYou don't think this is expressed in\n\nAgents MUST NOT reuse header-prefix values in the same\nmessage unless explicitly allowed by the extension\n(see section 4.1 for a discussion of the ultimate\nrecipient of an extension declaration).\n\nClients SHOULD be as consistent as possible when generating\nheader-prefix values as this facilitates use of the Vary\nheader field in responses that vary as a function of the\nrequest extension declaration(s) (see [5], section 13.6).\n\n>8. The term \"ultimate recipient\" is used a lot, but I didn't find a\n>definition of who it is. I think that for hop by hop, its the next\n>proxy that receives the message, and for end to end, its the origin\n>server or cache. Not sure if this is right, though. You should define\n>this term more clearly.\n\nSigh - this has been discussed more times than I care (or can) to keep\ntrack of.  The term \"ultimate recipient\" is introduced in the introduction:\n\no The HTTP application which the extension declaration is intended for\n(hereafter called the ultimate recipient) can deduce how to properly\ninterpret the extended message based on the extension declaration.\n\nIt has been a constant source of confusion that the ultimate recipient in\nHTTP in general (not only HTTP extensions) can be a proxy in the middle and\nnot necessarily has to be the user agent or origin server, see [5], section\n13.5.1:\n\nEnd-to-end headers, which are transmitted to the ultimate\nrecipient of a request or response. End-to-end headers in\nresponses MUST be stored as part of a cache entry and MUST\nbe transmitted in any response formed from a cache entry.\n\nThe reason being that proxies can change the content on the fly (if not\nexplicitly prohibited by a cache-control directive). Examples are image\nconverting proxies, PICS proxies, anonymizing proxies, etc. I had an\nexplanation of this property of HTTP but this caused more confusion than\nclarity so it was decided to take it out [6].\n\n>9. THe appendices start numbering at 14, essentially as continuations\n>of section numbers. They should probably start over at 1 or A.\n\nok\n\n>10. (See section 4.1 and 4.2, and appendix 14\n>for a table of interactions with origin servers and proxies.)\n>\n>This is gramatically incorrect. Should be:\n>\n>(See sections 4.1 and 4.2; also see appendix 14 which has a table\n>of....)\n\nok\n\n>11. \"Mandatory declarations MUST be applied to a\n>request message as described in section 5 and to a response message as\n>described in section 6.\"\n>\n>Mandatory declarations MUST be applied only when a mandatory extension\n>has been applied. This sentence just says that you must always apply\n>mandatory declarations to requests and responses.\n\nWhat about:\n\n(see section 5 for how to apply mandatory extension\ndeclarations to requests and section 6 for how to apply\nthem to responses)\n\n>12. \"The ultimate recipient of a mandatory end-to-end extension declaration\n>\n>MUST handle that extension declaration as described in section 5 and\n>6.\"\n>\n>Extra carriage return in the middle of the sentence.\n\nHmm, I wonder where that came from - could be a formatting problem while\nprinting the test only version.\n\n>13. \"That is, the header fields are\n>to be included as Connection header field directives (see [5], section\n>14.10).\"\n>\n>are to be included -> MUST be included.\n\nThis is really just an explanation of how the requirement expressed in the\npreceding sentence is fulfilled in HTTP/1.1:\n\nIn HTTP/1.1, the C-Man and the C-Opt header field MUST be\nprotected by a Connection header field. That is, the header\nfields are to be included as Connection header field directives\n(see [5], section 14.10)\n\nI am reluctant to add a MUST here as the mechanism is defined by HTTP/1.1\nand should not be redefined by this spec.\n\n> Also, MUST the header fields declared in the extension also be protected\nby a COnnection header?\n\nGood point - what about:\n\nHop-by-hop extension declarations are meaningful only for a single HTTP\nconnection. In HTTP/1.1, C-Man, C-Opt and all header fields with matching\nheader-prefix values defined by C-Man and C-Opt MUST be protected by a\nConnection header field. That is, these header fields are to be included as\nConnection header field directives (see [5], section 14.10). The two header\nfields have the following grammar:\n\n>14. Its not clear why you need the Ext and M-Ext headers. According to\n>section 5, a request is responded to with a 510 if any mandatory\n>extension is not understood. So, if a client or proxy receives a\n>response that is not 510, it knows that every mandatory and hop by hop\n>was understood, so the Ext and M-Ext headers convey no useful\n>information. If a 510 is received, the request was not fulfilled and\n>neither the end to end or hop by hop mandatory extensions were\n>fulfilled.\n\nThat would be true if it wasn't for the problem that some existing\napplications in some situations ignore the M- method name prefix and send\nback a 200 OK regardless. This is particularly the case for many resources\nservices by CGI scripts. 99.9% (my rough estimate) of all CGI scripts don't\nlook at the method name handed to them by the server and returns a normal\nresponse regardless of the method. This has been discussed in [4].\n\n>15. \"The Ext and the C-Ext header fields are not mutually exclusive, they can\n>both occur within the same message as described in section 5.1.\"\n>\n>The comma should be a semicolon.\n\nok\n\n>16. Why does the method name need to be prefixed with an M? Is this\n>for compatibility with HTTP implementations which don't understand\n>this extension mechanism?\n\nyes, exactly\n\n>17. \"It is strongly recommended that the integrity and persistence of the\n>extension identifier be maintained and kept unquestioned\"\n>\n>RECOMMENDED\n\nI don't think this will change anything\n\n>18. The examples in appendix 15 would be more useful if they were more\n>complete. In particular, if the C-Opt, C-Man, Opt, and Man header\n>fields were formulated properly.\n\nI agree that putting in complete URIs would be a help but I don't think\nadding more \"normal HTTP stuff\" will help understanding the scenarios.\n\n>19. You might want to consider a header called Unsupported for 510\n>responses (its used in SIP. It could be used to list those mandatory\n>extensions which were not understood:\n\nThe problem with this is that there may be other reasons why extensions are\nnot accepted which can not be expressed by such a header field (they can\nhave the wrong parameters, be combined in unacceptable ways, etc.). As this\nis really a function of the extensions, this is better expressed by them\nthan by the extension protocol.\n\n>Besides this, the draft seems to be a\n>reasonably complete solution for extensions.\n\nThanks!\n\nHenrik\n\n[1] http://lists.w3.org/Archives/Public/ietf-http-ext/\n[2] http://lists.w3.org/Archives/Public/ietf-http-ext/1998AprJun/0003.html\n[3] http://www.egroups.com/list/http-wg/mg601080931.html\n[4] http://lists.w3.org/Archives/Public/ietf-http-ext/1998JulSep/0004.html\n[5] http://lists.w3.org/Archives/Public/ietf-http-ext/1998AprJun/0029.html\n[6] http://lists.w3.org/Archives/Public/ietf-http-ext/1998AprJun/0027.html\n[7] http://www.egroups.com/list/http-wg/mg752462118.html\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10146991"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "At 13:42 1/5/99 +0100, Koen Holtman wrote:\n\n>I am not sure what you are saying here, I don't see the connection\n>with the presence or absence of q values.  Anyway, the type of example\n>I want to see is\n\nI will add a vary example.\n\n>>I don't think the situation you describe is any different than what can\n>>happen if any header field is tagged onto a 304 response. This is the\n>>reason for the restrictions on what a 304 response can contain, see\n>>\n>>http://www.ietf.org/internet-drafts/draft-ietf-http-v11-spec-rev-06.txt\n>>\n>>section \"10.3.5 304 Not Modified\", where it says:\n>\n>I know about that restriction on 304 responses in HTTP/1.1.  But it is\n>not clear from your http-ext spec whether http-ext servers and proxies\n>may violate that restriction.  http-ext proxies violate 1.1 in other\n>ways too, for example proxies will sometimes change the request\n>method, which is not allowed under plain 1.1.\n\nHTTP Extensions don't break HTTP - HTTP doesn't say anything about whether\na proxy can or cannot change the method. However, it is very specific on\nthe use of 304 and hence the rules are clear. The reason why I don't want\nto define the  semantics of what can happen with a 304 message is that\nHTTP/1.1 is and should be the authoritative on this issue.\n\n>I guess there is a common theme in my Vary and 304 comments and your\n>responses: I want things to be more obvious, and you are saying that\n>things are obvious enough already.  I believe that the current draft,\n>if used as a basis for implementations, will quite likely lead to\n>implementations which have subtle caching related problems.  You may\n>say that this is a fault in the implementers, who should have known\n>the pitfalls in HTTP caching better, but I say this is a fault in the\n>draft.\n\nIt's actually more a question of specification independence. Anybody can\nextend HTTP/1.1 - and while doing that they may run into the problem of how\nto handle 304 messages. This is not unique to the extensions draft. The\nimportant thing to note is that the extension draft doesn't invalidate\nexisting HTTP/1.1 behavior and so if you follow HTTP/1.1 rules, you should\nbe safe.\n\n>I would be far happier if the draft dropped the examples with cachable\n>responses and replaced it with a discussion of one fail-safe method of\n>making sure that interference from caches is avoided.  I would not\n>care if the method was not very cache-friendly, expert implementers\n>could figure out more cache-friendly methods for themselves.\n\nBefore doing that I would like to understand what you think is wrong with\nthe current model and how that affects caching. Sorry for being slow but I\nreally don't think this belongs in the extension draft.\n\n>I disagree.  If the client includes a Man header, it wants some\n>action, specified by the extension in the header, to be performed by\n>the origin server.  Isn't that what mandatory stands for?  If it did\n>not really want the action, but would settle for a fresh response\n>instead, it would have put the action in an Opt header.\n>\n>If mandatory means 'this request must result in an action by the\n>origin server but a fresh response from a cache is OK too' then we\n>are talking about a different type of extension mechanism I think.\n\nNope, it wants some action to be performed by a server which is authorized\nto and capable of handling the request. The opening statement in section 5\nclearly defines this:\n\nA server MUST NOT claim to have fulfilled a mandatory request\nunless it understood and obeyed all the mandatory extension\ndeclarations in the request. This section defines a\nmechanism for conveying this information to the client in\nsuch a way that it interoperates with existing HTTP\napplications.\n\nNote that it doesn't say \"origin server\" but any server.\n\nHenrik\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10167445"}, {"subject": "Re: request for review: http extension", "content": "Henrik Frystyk Nielsen wrote:\n> \n> >1.  o Some party designs and specifies an extension; the party assigns\n> >    the extension a globally unique address (URI)\n> >\n> >This would seem to imply that a URI = a globally unique address, which\n> >it does not (it may not contain an address). Rather, what this means\n> >to say is that a globally unique identifer is assigned, and that the\n> >identifer also specifies a resource which is the definition of the\n> >extension itself.\n> \n> No, what is meant is that only URIs that in fact are globally unique\n> identifiers can be used. I will change the wording to \"globally unique URI\".\n\nOK.\n\n> \n> >2. The usage of the - as part of the BNF for header prefix seems\n> >uneccesary. Rather, the BNF need only define the numeric value of the\n> >namespace. An implementation then takes this number, appends the dash,\n> >and then adds the actual header name when placing extension headers in\n> >the message. In the BNF, it serves neither as a conveyer of\n> >information nor as a separator between elements.\n> \n> It must be there as a separator (in fact any non-digit character would do).\n> Otherwise an application can potentially block the whole prefix name space.\n> This was discussed on the list [2].\n\nI read this message and followed the thread a bit; I agree with Dave\nKristol here and still don't see your point. I am assuming your\ndefinition of hogging the space is something like:\n\nMan: \"myextension\";ns=00-,\"myextension\";ns=01-,\"myextension\";ns=02-\n\nand so on.\n\nNow, with or without the dash, its impossible to hog the space since the\nnumber of digits is unbounded. Or, do you have some other definition of\nhogging? Even if the BNF was 1*2DIGIT followed by a dash, there would be\n100 possible extensions in a message, and this would be the same if it\nwas 1*2DIGIT without the dash, so it doesn't seem to do much.\n\n> \n> >3. THe usage of the field-name for ext-decl seems odd. The ext-decl\n> >must be a globally unique identifier which points to a definition of\n> >the extension. If this extension is documented in an RFC, then really\n> >it is also a URI, probably a urn like urn:ietf:rfc:2141 (see\n> >draft-ietf-urn-ietf). Why add this extra field-name parameter when a\n> >URN will suffice?\n> \n> The problem is exactly the \"probably\". There is no current resolution for\n> what the name space for RFCs and the like should be. And in case it should\n> be based on URNs then they themselves are not yet resolved. Whether that\n> will happen is another discussion altogether.\n> \n> Ted Hardie checked on the current status of the header field registration\n> work in the drums working group and came up with this:\n> \n>         Jacob Palme on this and he tells me that DRUMs decided\n>         at it's last meeting to delay working on this until the\n>         821bis and 822bis documents are ready. I personally believe\n>         that this means we cannot count on this registry existing\n>         in the form specified by draft-ietf-drums-MHregistry-03.txt\n>         any time soon.\n> \n> This is the reason we went with the current solution which allows for a\n> smooth transition from local extension to standards track RFC without\n> having to resolve the problem of defining the URI space for IANA registered\n> tokens and documents.\n\nUnderstandable. In that case, an implementors note saying that the URI\nspace for RFC's would be preferrable, once available, would be useful.\n\n> \n> >4. The spec allows for declaration extension parameters, but none are\n> >defined and there is no guidelines regarding what they might actually\n> >be useful for. What is their purpose?\n> \n> What do you mean \"none are defined\" - they are intended for extending the\n> extension declarations with (by definition) optional parameters. I am not\n> sure what you mean?\n\nI mean, what would be an example of an optional parameter that someone\nmight try to use in the future? \n\n> \n> >5. The spec says unrecognized decl-ext parameters SHOULD be\n> >ignored. What else can it do? Shouldn't this be a MUST?\n> \n> The SHOULD is really more a guideline for what to do with unknown\n> parameters. The only strict requirement is that it must not be removed if\n> forwarded. I will here refer to Larry Masinter's thoughts on\n> MAY/SHOULD/MUST [7].\n\nOn more thought, its sort of strange that the only possibility is for\nunknown decl-ext parameters to be ignored (i.e., the declaration\nextension is optional). What happens if the declaration extension must\nbe understood in order to process the request? \n\nOn a related note, the extension mechanism really only allows you to\ndefine new header extensions. However, extensions could also include new\nvalues for existing headers or new parameters, and so on. Might be\nuseful to extend the concept to cover these cases as well. For example:\n\nMan: \"my-extension\"; ns=11-\nCache-Control: 11-new-cache-mechanism\n\n> \n> >6. \"The header-prefix are dynamically generated header field prefix strings\n> >that can be used to indicate that all header fields in the message\n> >matching the header-prefix value using string prefix-matching are\n> >introduced by this extension instance.\"\n> >\n> >This sentence is a run on and is confusing, but it conveys some really\n> >important information. Cleanup would be useful.\n> \n> What about:\n> \n>         The header-prefix is a dynamically generated string\n>         indicating that all header fields in the message matching the\n>         header-prefix string using string prefix-matching belong to\n>         that extension declaration.\n\nOr better:\n\nThe header-prefix is a dynamically generated string. All header fields\nin the message that match this string, using string prefix-matching,\nbelong to that extension declaration.\n\n\n> \n> >7. The spec should probably say something specific about requirements for the\n> >prefix strings; something like \"prefix strings for different\n> >extensions, or for different instances of the same extension, MUST be\n> >different, but SHOULD otherwise be the same from request to request\"\n> \n> You don't think this is expressed in\n> \n>         Agents MUST NOT reuse header-prefix values in the same\n>         message unless explicitly allowed by the extension\n>         (see section 4.1 for a discussion of the ultimate\n>         recipient of an extension declaration).\n> \n>         Clients SHOULD be as consistent as possible when generating\n>         header-prefix values as this facilitates use of the Vary\n>         header field in responses that vary as a function of the\n>         request extension declaration(s) (see [5], section 13.6).\n\nMust have been confused when reading it; this seems fine.\n\n> \n> >8. The term \"ultimate recipient\" is used a lot, but I didn't find a\n> >definition of who it is. I think that for hop by hop, its the next\n> >proxy that receives the message, and for end to end, its the origin\n> >server or cache. Not sure if this is right, though. You should define\n> >this term more clearly.\n> \n> Sigh - this has been discussed more times than I care (or can) to keep\n> track of.  The term \"ultimate recipient\" is introduced in the introduction:\n> \n> o The HTTP application which the extension declaration is intended for\n> (hereafter called the ultimate recipient) can deduce how to properly\n> interpret the extended message based on the extension declaration.\n> \n> It has been a constant source of confusion that the ultimate recipient in\n> HTTP in general (not only HTTP extensions) can be a proxy in the middle and\n> not necessarily has to be the user agent or origin server, see [5], section\n> 13.5.1:\n> \n>         End-to-end headers, which are transmitted to the ultimate\n>         recipient of a request or response. End-to-end headers in\n>         responses MUST be stored as part of a cache entry and MUST\n>         be transmitted in any response formed from a cache entry.\n> \n> The reason being that proxies can change the content on the fly (if not\n> explicitly prohibited by a cache-control directive). Examples are image\n> converting proxies, PICS proxies, anonymizing proxies, etc. I had an\n> explanation of this property of HTTP but this caused more confusion than\n> clarity so it was decided to take it out [6].\n\nOK.\n\n\n> >11. \"Mandatory declarations MUST be applied to a\n> >request message as described in section 5 and to a response message as\n> >described in section 6.\"\n> >\n> >Mandatory declarations MUST be applied only when a mandatory extension\n> >has been applied. This sentence just says that you must always apply\n> >mandatory declarations to requests and responses.\n> \n> What about:\n> \n>         (see section 5 for how to apply mandatory extension\n>         declarations to requests and section 6 for how to apply\n>         them to responses)\n\nOK.\n\n\n> >13. \"That is, the header fields are\n> >to be included as Connection header field directives (see [5], section\n> >14.10).\"\n> >\n> >are to be included -> MUST be included.\n> \n> This is really just an explanation of how the requirement expressed in the\n> preceding sentence is fulfilled in HTTP/1.1:\n> \n>         In HTTP/1.1, the C-Man and the C-Opt header field MUST be\n>         protected by a Connection header field. That is, the header\n>         fields are to be included as Connection header field directives\n>         (see [5], section 14.10)\n> \n> I am reluctant to add a MUST here as the mechanism is defined by HTTP/1.1\n> and should not be redefined by this spec.\n\nOK.\n\n> \n> > Also, MUST the header fields declared in the extension also be protected\n> by a COnnection header?\n> \n> Good point - what about:\n> \n> Hop-by-hop extension declarations are meaningful only for a single HTTP\n> connection. In HTTP/1.1, C-Man, C-Opt and all header fields with matching\n> header-prefix values defined by C-Man and C-Opt MUST be protected by a\n> Connection header field. That is, these header fields are to be included as\n> Connection header field directives (see [5], section 14.10). The two header\n> fields have the following grammar:\n\nSounds good.\n\n> \n> >14. Its not clear why you need the Ext and M-Ext headers. According to\n> >section 5, a request is responded to with a 510 if any mandatory\n> >extension is not understood. So, if a client or proxy receives a\n> >response that is not 510, it knows that every mandatory and hop by hop\n> >was understood, so the Ext and M-Ext headers convey no useful\n> >information. If a 510 is received, the request was not fulfilled and\n> >neither the end to end or hop by hop mandatory extensions were\n> >fulfilled.\n> \n> That would be true if it wasn't for the problem that some existing\n> applications in some situations ignore the M- method name prefix and send\n> back a 200 OK regardless. This is particularly the case for many resources\n> services by CGI scripts. 99.9% (my rough estimate) of all CGI scripts don't\n> look at the method name handed to them by the server and returns a normal\n> response regardless of the method. This has been discussed in [4].\n\nI see. Thats kind of scary, though.. I'm assuming then that the CGI\nscripts treat all methods as GET? In that case, its a broader problem\nsince you might send a PUT method with no extensions and get a 200 OK\neven though it wasn't really fulfilled properly. You'd think that the\nserver would only pass GET requests to CGI scripts.\n\nIn any case, a bit of motivation about why this header is needed,\nbasically what you mention above, would be useful in the document.\n\n\n\n> >17. \"It is strongly recommended that the integrity and persistence of the\n> >extension identifier be maintained and kept unquestioned\"\n> >\n> >RECOMMENDED\n> \n> I don't think this will change anything\n\nI guess since its not a protocol issue but a process issue thats fine.\n\n> \n> >18. The examples in appendix 15 would be more useful if they were more\n> >complete. In particular, if the C-Opt, C-Man, Opt, and Man header\n> >fields were formulated properly.\n> \n> I agree that putting in complete URIs would be a help but I don't think\n> adding more \"normal HTTP stuff\" will help understanding the scenarios.\n\nAgreed.\n\n> \n> >19. You might want to consider a header called Unsupported for 510\n> >responses (its used in SIP. It could be used to list those mandatory\n> >extensions which were not understood:\n> \n> The problem with this is that there may be other reasons why extensions are\n> not accepted which can not be expressed by such a header field (they can\n> have the wrong parameters, be combined in unacceptable ways, etc.). As this\n> is really a function of the extensions, this is better expressed by them\n> than by the extension protocol.\n\nThis seem more an argument for a different response code than anything\nelse; in other words, 510 is sent ONLY when the problem was that a\nmandatory extension was not understood since its not implemented (along\nwith the Unsupported header). If it was understood (i.e., the server\nknows and implements it) but the values or parameters malformed, a\ndifferent response code would be used (perhaps a 400).\n\nThanks,\nJonathan R.\n-- \nJonathan D. Rosenberg                       Lucent Technologies\nMember of Technical Staff                   101 Crawfords Corner Rd.\nHigh Speed Networks Research                Holmdel, NJ 07733\nFAX: (732) 834-5379                         Rm. 4C-526\nEMAIL: jdrosen@bell-labs.com\nURL: http://www.cs.columbia.edu/~jdrosen\n\n\n\n", "id": "lists-007-10180422"}, {"subject": "Replacing the Label header with a DAV:labeled-version repor", "content": "Since this is a fairly significant change, I'd like to\nhear from a few more folks before adding this to the 3253 Errata.\n\nThanks,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Saturday, April 27, 2002 5:09 AM\nTo: Clemm, Geoff; 'Deltav WG'\nSubject: RE: Label header vs PROPFIND depth 1\n\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, April 26, 2002 6:06 PM\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    - I'd like to see the label *header* deprecated\n>    - I'm happy with the LABEL method and the label-name-set property\n>    - I think that PROPFIND/label should be replaced by a specific REPORT\n>\n> Is the proposed DAV:labeled-version report OK with you?\n\nYes. But I think it's Tim's turn to say whether this would work for him or\nnot...\n\n>    - I'm unsure about other methods that are currently affected by the\n>    header -- what were the requirements...?\n>\n> The other methods are LABEL, CHECKOUT, GET, and COPY.\n> For Depth:0 variants of these operations, the Label header\n> just provided an optimization to save one roundtrip\n> (i.e. first getting the version URL via the DAV:labeled-version report).\n> I believe we can easily do without that Depth:0 optimization.\n\nAs stated before, I think that's not the single problem. Having GET return a\n(representation of a) version rather than (a representation of) the VCR\nmakes the version *by definition* a variant (representation) of the VCR --\nand it seems that most of us want to avoid that interpretation.\n\n> For Depth:infinity (only relevant for LABEL and COPY), the savings\n> would be more significant, but unfortunately the semantics is broken\n> (since if the namespace is being versioned, you'll get the wrong\n> resources if you simply do a Depth operation on the current namespace).\n>\n> The Depth:infinity Label header operations are really just a way of\n> trying to have the client fake workspaces and baselines, instead of\n> having the server support them directly.  Since it is much more\n> efficient and reliable to have the server layer these constructs\n> above a labeling infrastructure, rather than having the client do\n> so, I believe the cost of maintaining these Depth:infinity Label\n> header operations in the protocol is not warranted.\n>\n> Note though that (depth:0) labeling and baselining go very well\n> together.  Instead of doing a Depth:infinity LABEL, you can create a\n> baseline (which under the hood the server may well implement with\n> reserved labels, but maybe not), and then LABEL that baseline.  Then\n> when you want to do a Depth:infinity COPY, you retrieve the\n> DAV:baseline-collection of the labeled baseline (using the\n> DAV:labeled-version report), and copy that to wherever you want.\n>\n> Alternatively, if you want a \"modifiable\" selection, you can create a\n> workspace (which under the hood the server may well implement with\n> reserved labels, but maybe not).  When you want to adjust the versions\n> being selected, you just use UPDATE.  Then when you want to do a\n> Depth:infinity COPY, you just copy from that workspace to wherever you\n> want.\n>\n>    - Servers that decide to implement LABEL and DAV:label-name-set,\n>    but no not support the label header should *not* report the LABEL\n>    feature in OPTIONS.\n>\n> That's probably right.  A client can find out if the LABEL operation\n> is supported by querying the DAV:supported-method-set property values\n> of a VCR.\n\n...and also use DAV:supported-live-property-set to discover the\nDAV:label-name-set property.\n\n\n\n", "id": "lists-007-1018063"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "Henrik Frystyk Nielsen:\n>\n>At 13:42 1/5/99 +0100, Koen Holtman wrote:\n[...]\n>>I guess there is a common theme in my Vary and 304 comments and your\n>>responses: I want things to be more obvious, and you are saying that\n>>things are obvious enough already.  I believe that the current draft,\n>>if used as a basis for implementations, will quite likely lead to\n>>implementations which have subtle caching related problems.  You may\n>>say that this is a fault in the implementers, who should have known\n>>the pitfalls in HTTP caching better, but I say this is a fault in the\n>>draft.\n>\n>It's actually more a question of specification independence.\n\nNo, it is a question of whether your spec is clear enough.\n\n> Anybody can\n>extend HTTP/1.1 - and while doing that they may run into the problem of how\n>to handle 304 messages. This is not unique to the extensions draft. The\n>important thing to note is that the extension draft doesn't invalidate\n>existing HTTP/1.1 behavior and so if you follow HTTP/1.1 rules, you should\n>be safe.\n\nYes, the special status of 304 will be a problem in many HTTP\nextensions implementations, but that does not mean that you can just\nremain silent about it in your particular extension spec.  If we had\nsome generic document which discussed the problem in a generic way,\nyou could get away with just referencing that document in your spec,\nbut there is no such document.\n\n>>I would be far happier if the draft dropped the examples with cachable\n>>responses and replaced it with a discussion of one fail-safe method of\n>>making sure that interference from caches is avoided.  I would not\n>>care if the method was not very cache-friendly, expert implementers\n>>could figure out more cache-friendly methods for themselves.\n>\n>Before doing that I would like to understand what you think is wrong with\n>the current model and how that affects caching. \n\nI don't think there is anything wrong with the extension mechanism\nitself, I just think that the current examples are not very good.\nThey steer implementers in a certain direction (making responses\ncachable) without mentioning the pitfalls along the way.  I'd rather\nsee clear instructions on how to follow a safe path.\n\n>Sorry for being slow but I\n>really don't think this belongs in the extension draft.\n\n\n[...]\n>>If mandatory means 'this request must result in an action by the\n>>origin server but a fresh response from a cache is OK too' then we\n>>are talking about a different type of extension mechanism I think.\n>\n>Nope, it wants some action to be performed by a server which is authorized\n>to and capable of handling the request.\n\nThe trouble is that if the client sends the request from table 3 a\nsecond time before the previous response has expired:\n\n Client issues a     M-GET <some-address> HTTP/1.1\n request with one    Opt: <ext-1>\n optional and one    Man: <ext-2>\n mandatory           ...\n extension\n\nthen an intermediate cache may return the fresh response \n\n HTTP/1.1 200 OK\n Cache-Control: max-age=120, no-cache=\"Ext\"\n Age: 123\n ...\n [Note no Ext: in the response!]\n\nin which case *no* mandatory action has been performed by an\nauthorised and capable server.  If it wanted to make sure that such an\naction would be performed, the client would have to send\n\n M-GET <some-address> HTTP/1.1\n Opt: <ext-1>\n Man: <ext-2>\n Cache-Control: no-cache\n\nbut this is not apparent from your examples.  So either the client in\nthe example is not really interested in having the action performed,\nor the example shows a broken way of controlling the caches.\n\n> The opening statement in section 5\n>clearly defines this:\n>\n>        A server MUST NOT claim to have fulfilled a mandatory request\n>        unless it understood and obeyed all the mandatory extension\n>        declarations in the request. This section defines a\n>        mechanism for conveying this information to the client in\n>        such a way that it interoperates with existing HTTP\n>        applications.\n>\n>Note that it doesn't say \"origin server\" but any server.\n\nSo the second 'end' in the man 'end-to-end' declaration does not mean\nthe origin server?  This is not at all clear to me from reading your\nspec.  In HTTP/1.1 'end to end revalidation' means revalidation which\ngoes through to the origin server, so I was assuming that an\n'end-to-end' declaration also goes through to the origin server.  The\nabove quote talks about both end-to-end and hop-to-hop, so it does not\ncontradict the assumption that end-to-end always means to the origin\nserver.\n\n\n>Henrik\n\nKoen.\n\n\n\n", "id": "lists-007-10202817"}, {"subject": "Re: request for review: http extension", "content": "At 01:42 1/12/99 -0500, Jonathan Rosenberg wrote:\n\n>I read this message and followed the thread a bit; I agree with Dave\n>Kristol here and still don't see your point. I am assuming your\n>definition of hogging the space is something like:\n>\n>Man: \"myextension\";ns=00-,\"myextension\";ns=01-,\"myextension\";ns=02-\n>\n>and so on.\n>\n>Now, with or without the dash, its impossible to hog the space since the\n>number of digits is unbounded.\n\nNope, it is still possible: 11 will match not only 11- but also 111,\n111mynewheader, etc. That is, without the non digit separator, you can hog\nthe space using 100 prefixes.\n\n>> This is the reason we went with the current solution which allows for a\n>> smooth transition from local extension to standards track RFC without\n>> having to resolve the problem of defining the URI space for IANA registered\n>> tokens and documents.\n>\n>Understandable. In that case, an implementors note saying that the URI\n>space for RFC's would be preferrable, once available, would be useful.\n\nok - it now says:\n\nThe support for header field names as extension identifiers\nprovides a transition strategy from decentralized extensions\nto extensions defined by IETF Standards Track RFCs until a\npersistent mapping has been defined between the globally unique\nURI space and features defined in IETF Standards Track RFCs.\n\n>> >4. The spec allows for declaration extension parameters, but none are\n>> >defined and there is no guidelines regarding what they might actually\n>> >be useful for. What is their purpose?\n>> \n>> What do you mean \"none are defined\" - they are intended for extending the\n>> extension declarations with (by definition) optional parameters. I am not\n>> sure what you mean?\n>\n>I mean, what would be an example of an optional parameter that someone\n>might try to use in the future? \n>\n>> >5. The spec says unrecognized decl-ext parameters SHOULD be\n>> >ignored. What else can it do? Shouldn't this be a MUST?\n>> \n>> The SHOULD is really more a guideline for what to do with unknown\n>> parameters. The only strict requirement is that it must not be removed if\n>> forwarded. I will here refer to Larry Masinter's thoughts on\n>> MAY/SHOULD/MUST [7].\n>\n>On more thought, its sort of strange that the only possibility is for\n>unknown decl-ext parameters to be ignored (i.e., the declaration\n>extension is optional). What happens if the declaration extension must\n>be understood in order to process the request? \n\nThe decl-ext extensions are only intended to extend the extension framework\nitself (the declaration) and not any of the extensions that it is used to\ndeclare. If you want an mandatory extension to the extension framework, you\nuse the extension itself to introduce the new extension. Only one mandatory\nbit is sufficient.\n\nMaybe this is not clear from the context so I have added:\n\nAn agent MAY use the decl-extensions mechanism to include\noptional extension declaration parameters but cannot assume\nthese parameters to be recognized by the recipient. This\nmechanism MUST NOT be used to pass extension instance data,\nwhich MAY be passed using header field prefix values\n(see section 3.1). Unrecognized decl-ext parameters SHOULD\nbe ignored and MUST NOT be removed by proxies when\nforwarding the extension declaration.\n\n>On a related note, the extension mechanism really only allows you to\n>define new header extensions. However, extensions could also include new\n>values for existing headers or new parameters, and so on. Might be\n>useful to extend the concept to cover these cases as well. For example:\n>\n>Man: \"my-extension\"; ns=11-\n>Cache-Control: 11-new-cache-mechanism\n\nThis is intentional - otherwise it would require that every HTTP extension\napplication knows how to parse all existing (as well as any new) header\nfields which is not possible. Because of the way MIME works, the unit of an\nextension must be a header field and not a header field parameter.\n\n>Or better:\n>\n>The header-prefix is a dynamically generated string. All header fields\n>in the message that match this string, using string prefix-matching,\n>belong to that extension declaration.\n\nok\n\n>> That would be true if it wasn't for the problem that some existing\n>> applications in some situations ignore the M- method name prefix and send\n>> back a 200 OK regardless. This is particularly the case for many resources\n>> services by CGI scripts. 99.9% (my rough estimate) of all CGI scripts don't\n>> look at the method name handed to them by the server and returns a normal\n>> response regardless of the method. This has been discussed in [4].\n>\n>I see. Thats kind of scary, though.. I'm assuming then that the CGI\n>scripts treat all methods as GET? In that case, its a broader problem\n>since you might send a PUT method with no extensions and get a 200 OK\n>even though it wasn't really fulfilled properly. You'd think that the\n>server would only pass GET requests to CGI scripts.\n>\n>In any case, a bit of motivation about why this header is needed,\n>basically what you mention above, would be useful in the document.\n\nok\n\n>> >19. You might want to consider a header called Unsupported for 510\n>> >responses (its used in SIP. It could be used to list those mandatory\n>> >extensions which were not understood:\n>> \n>> The problem with this is that there may be other reasons why extensions are\n>> not accepted which can not be expressed by such a header field (they can\n>> have the wrong parameters, be combined in unacceptable ways, etc.). As this\n>> is really a function of the extensions, this is better expressed by them\n>> than by the extension protocol.\n>\n>This seem more an argument for a different response code than anything\n>else; in other words, 510 is sent ONLY when the problem was that a\n>mandatory extension was not understood since its not implemented (along\n>with the Unsupported header). If it was understood (i.e., the server\n>knows and implements it) but the values or parameters malformed, a\n>different response code would be used (perhaps a 400).\n\nBut then you have all the combinations of the two - imagine two extensions\nwhere one wasn't fulfilled because of lack of credentials and the other was\nnot understood. I still think leaving the whole thing to the extensions is\nbetter.\n\nHenrik\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10216130"}, {"subject": "Re: request for review: http extension", "content": "Henrik Frystyk Nielsen wrote:\n> \n> At 01:42 1/12/99 -0500, Jonathan Rosenberg wrote:\n> \n> >I read this message and followed the thread a bit; I agree with Dave\n> >Kristol here and still don't see your point. I am assuming your\n> >definition of hogging the space is something like:\n> >\n> >Man: \"myextension\";ns=00-,\"myextension\";ns=01-,\"myextension\";ns=02-\n> >\n> >and so on.\n> >\n> >Now, with or without the dash, its impossible to hog the space since the\n> >number of digits is unbounded.\n> \n> Nope, it is still possible: 11 will match not only 11- but also 111,\n> 111mynewheader, etc. That is, without the non digit separator, you can hog\n> the space using 100 prefixes.\n\nI see; the problem though again is not in the BNF for the extension\ndelcaration. What you are trying to say is that a header that belongs to\nan extension MUST have a dash after its extension number. Then, a header\nmatches an extension if the extension number, with a dash appended to\nit, are a prefix of the header. This rule does not require the dash\nitself to be present in the BNF for the extension declaration. \n\nIn other words:\n\nMan: \"my-extension\";ns=00\n00-Header1: value\n000-Header1: value2\n\nBased on the rules, a dash is appended to the header extension number\nfor my-extension, yielding 00-, and then a prefix search is done on the\nheader fields. Only the first one matches, so this one belongs to the\nmy-extension extension. \n\n> \n> >> This is the reason we went with the current solution which allows for a\n> >> smooth transition from local extension to standards track RFC without\n> >> having to resolve the problem of defining the URI space for IANA registered\n> >> tokens and documents.\n> >\n> >Understandable. In that case, an implementors note saying that the URI\n> >space for RFC's would be preferrable, once available, would be useful.\n> \n> ok - it now says:\n> \n>         The support for header field names as extension identifiers\n>         provides a transition strategy from decentralized extensions\n>         to extensions defined by IETF Standards Track RFCs until a\n>         persistent mapping has been defined between the globally unique\n>         URI space and features defined in IETF Standards Track RFCs.\n\nSounds good.\n\n> \n> >> >4. The spec allows for declaration extension parameters, but none are\n> >> >defined and there is no guidelines regarding what they might actually\n> >> >be useful for. What is their purpose?\n> >>\n> >> What do you mean \"none are defined\" - they are intended for extending the\n> >> extension declarations with (by definition) optional parameters. I am not\n> >> sure what you mean?\n> >\n> >I mean, what would be an example of an optional parameter that someone\n> >might try to use in the future?\n> >\n> >> >5. The spec says unrecognized decl-ext parameters SHOULD be\n> >> >ignored. What else can it do? Shouldn't this be a MUST?\n> >>\n> >> The SHOULD is really more a guideline for what to do with unknown\n> >> parameters. The only strict requirement is that it must not be removed if\n> >> forwarded. I will here refer to Larry Masinter's thoughts on\n> >> MAY/SHOULD/MUST [7].\n> >\n> >On more thought, its sort of strange that the only possibility is for\n> >unknown decl-ext parameters to be ignored (i.e., the declaration\n> >extension is optional). What happens if the declaration extension must\n> >be understood in order to process the request?\n> \n> The decl-ext extensions are only intended to extend the extension framework\n> itself (the declaration) and not any of the extensions that it is used to\n> declare. If you want an mandatory extension to the extension framework, you\n> use the extension itself to introduce the new extension. Only one mandatory\n> bit is sufficient.\n> \n> Maybe this is not clear from the context so I have added:\n> \n>         An agent MAY use the decl-extensions mechanism to include\n>         optional extension declaration parameters but cannot assume\n>         these parameters to be recognized by the recipient. This\n>         mechanism MUST NOT be used to pass extension instance data,\n>         which MAY be passed using header field prefix values\n>         (see section 3.1). Unrecognized decl-ext parameters SHOULD\n>         be ignored and MUST NOT be removed by proxies when\n>         forwarding the extension declaration.\n\nOK.\n\n> \n> >On a related note, the extension mechanism really only allows you to\n> >define new header extensions. However, extensions could also include new\n> >values for existing headers or new parameters, and so on. Might be\n> >useful to extend the concept to cover these cases as well. For example:\n> >\n> >Man: \"my-extension\"; ns=11-\n> >Cache-Control: 11-new-cache-mechanism\n> \n> This is intentional - otherwise it would require that every HTTP extension\n> application knows how to parse all existing (as well as any new) header\n> fields which is not possible. Because of the way MIME works, the unit of an\n> extension must be a header field and not a header field parameter.\n\nI think this works so long as the application can parse the header\nfields to which the extension applies. If an extension is listed as\nmandatory, and a client doesn't know the extension, it just returns an\nerror response. If it is mandatory, and the client does understand the\nextension, than presumably it knows how to parse the header to which the\nextension applies, using the new parameters. I guess the problem is with\noptional extensions, and that an application would still try to parse\nthe extended header, not noticing its extended since the header looks\nthe same. \n\n\n> >> >19. You might want to consider a header called Unsupported for 510\n> >> >responses (its used in SIP. It could be used to list those mandatory\n> >> >extensions which were not understood:\n> >>\n> >> The problem with this is that there may be other reasons why extensions are\n> >> not accepted which can not be expressed by such a header field (they can\n> >> have the wrong parameters, be combined in unacceptable ways, etc.). As this\n> >> is really a function of the extensions, this is better expressed by them\n> >> than by the extension protocol.\n> >\n> >This seem more an argument for a different response code than anything\n> >else; in other words, 510 is sent ONLY when the problem was that a\n> >mandatory extension was not understood since its not implemented (along\n> >with the Unsupported header). If it was understood (i.e., the server\n> >knows and implements it) but the values or parameters malformed, a\n> >different response code would be used (perhaps a 400).\n> \n> But then you have all the combinations of the two - imagine two extensions\n> where one wasn't fulfilled because of lack of credentials and the other was\n> not understood. I still think leaving the whole thing to the extensions is\n> better.\n\nI think extensions not being understood always takes precedence, since\nthe extension could be defining a feature which is \"ignore the lack of\ncredentials for any other extensions\", in which case if the extension\nwas understood there would be no error for the other. If a mandatory\nextension is not understood, no other aspect of a request can be\nreliably parsed, so I still think it makes sense to report a 510 and\nlist the extension that wasn't understood. But, I don't feel terribly\nstrongly here, and if the group doesn't consider this an issue thats\nfine.\n\n-Jonathan R.\n\n-- \nJonathan D. Rosenberg                       Lucent Technologies\nMember of Technical Staff                   101 Crawfords Corner Rd.\nHigh Speed Networks Research                Holmdel, NJ 07733\nFAX: (732) 834-5379                         Rm. 4C-526\nEMAIL: jdrosen@bell-labs.com\nURL: http://www.cs.columbia.edu/~jdrosen\n\n\n\n", "id": "lists-007-10230786"}, {"subject": "Some comments on draft-frystyk-http-extensions-01.tx", "content": "Had opportunity to read the draft, and had the following comments and\nquestions :\n\n\n\nSection 3 (Extension declarations)\n\nI found it somewhat confusing and a little premature to be talking about\nthe grammar for an extension declaration here. What I am saying is that\nthe reader hasn't been told that these declarations are actually made\ninside of a special header that is not yet discussed. May be a good idea\nto do it the other way around - ie. talk about the new headers first and\nthen the extension declaration grammar. Likewise with 3.1.\nAlternatively, one could just add some text in the beginning of the\nsection 3 that the declarations and prefixes are placed in special\nheaders defined in section 4.\n\nAlso felt that the choice of name \"decl-ext\"(for an extended extension)\nis dubious, given that we call the extension \"ext-decl\"\nSection 3, but this is a nit.\n\n\nSection 3\n\nIn a mandatory extension request , are the decl-ext parameters mandatory\nas well ? What happens if a server supports the extension but not the\ndecl-ext ?\n\nSection 4.2 Hop-by-Hop extensions\n\n\"the C-Man and the C-Opt header field MUST be protected...\"\nshould be \n\"the C-Man and the C-Opt header fields MUST  be protected...\" ?\n\n\nSection 6\nIf a client is the ultimate recipient of a mandatory HTTP response\ncontaining mandatory extension declarations that either the client does\nnot understand or does not want to use, then it SHOULD discard the\ncomplete response as if it were a 500 (Internal Server Error) response.\n\nShouldn't this be \"MUST\".\n\nSection 7\nThis is a pretty basic question :\nThis status code seems to convey that \"the client did not access the\nresource with the required extension\". Could it not also convey \"the\nserver does not support the extension requested by the client\"  ? One\ncould argue that many extensions would be applicable to any resource.\n\nIf a client request declares 2 mandatory extensions, and the server\nsupports only 1, unless I misunderstood something, there does not seem\nto be a way of conveying which one was not supported. \nThis will be necessary in practice. Ideally it should be conveyed in the\n510 or another 5xx response.\n\n-Anup.\n\n\n\n", "id": "lists-007-10247229"}, {"subject": "Re: request for review: http extension", "content": "At 22:57 1/17/99 -0500, Jonathan Rosenberg wrote:\n\n>I see; the problem though again is not in the BNF for the extension\n>delcaration. What you are trying to say is that a header that belongs to\n>an extension MUST have a dash after its extension number. Then, a header\n>matches an extension if the extension number, with a dash appended to\n>it, are a prefix of the header. This rule does not require the dash\n>itself to be present in the BNF for the extension declaration. \n\nI think we are saying the same thing but represent it in two different\nways: should the \"-\" be part of the ns production or a part of the prefix\nstring matching algorithm. Either way is fine with me - one may argue that\nnot using the \"-\" in the BNF production is closer to the XML NS spec.\n\n>I think this works so long as the application can parse the header\n>fields to which the extension applies. If an extension is listed as\n>mandatory, and a client doesn't know the extension, it just returns an\n>error response. If it is mandatory, and the client does understand the\n>extension, than presumably it knows how to parse the header to which the\n>extension applies, using the new parameters. I guess the problem is with\n>optional extensions, and that an application would still try to parse\n>the extended header, not noticing its extended since the header looks\n>the same. \n\nThere is no guarantee that an application who knows the extension also\nknows all header fields that it may be added to in the form of attributes.\nCombined with the overhead of having to parse the whole message to find\nthese parameters, I would rather leave this out.\n\n>I think extensions not being understood always takes precedence, since\n>the extension could be defining a feature which is \"ignore the lack of\n>credentials for any other extensions\", in which case if the extension\n>was understood there would be no error for the other. If a mandatory\n>extension is not understood, no other aspect of a request can be\n>reliably parsed, so I still think it makes sense to report a 510 and\n>list the extension that wasn't understood. But, I don't feel terribly\n>strongly here, and if the group doesn't consider this an issue thats\n>fine.\n\nI think this better belong in another spec (OPTIONS, for example?) which\ncan define a schema for passing metainformation about capabilities.\n\nThanks!\n\nHenrik\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10256809"}, {"subject": "Re: Some comments on draft-frystyk-http-extensions-01.tx", "content": "At 19:57 1/19/99 -0800, Anup Rao wrote:\n>Had opportunity to read the draft, and had the following comments and\n>questions :\n\nHi Anup,\n\nThanks for the comments - I am just about wrapping up a new revision which\nI hope to submit today.\n\n>Section 3 (Extension declarations)\n>\n>Alternatively, one could just add some text in the beginning of the\n>section 3 that the declarations and prefixes are placed in special\n>headers defined in section 4.\n\nI have just done exactly this!\n\n>Also felt that the choice of name \"decl-ext\"(for an extended extension)\n>is dubious, given that we call the extension \"ext-decl\"\n>Section 3, but this is a nit.\n\nIt's for extending the declaration, not for passing extension instance\ndata. This has been made clear in the new revision.\n\n>\n>Section 3\n>\n>In a mandatory extension request , are the decl-ext parameters mandatory\n>as well ? What happens if a server supports the extension but not the\n>decl-ext ?\n\nThey are by definition optional which makes sense when you know that they\nare not part of the extension itself but of the extension declaration. This\nhas also been  clarified.\n\n>Section 4.2 Hop-by-Hop extensions\n>\n>\"the C-Man and the C-Opt header field MUST be protected...\"\n>should be \n>\"the C-Man and the C-Opt header fields MUST  be protected...\" ?\n\nok.\n\n>Section 6\n>If a client is the ultimate recipient of a mandatory HTTP response\n>containing mandatory extension declarations that either the client does\n>not understand or does not want to use, then it SHOULD discard the\n>complete response as if it were a 500 (Internal Server Error) response.\n>\n>Shouldn't this be \"MUST\".\n\nDepends on what you mean by \"discard\" - it is OK for the client to save it\nas long as it doesn't try to interpret the response. I don't think it\nmatters here really.\n\n>Section 7\n>This is a pretty basic question :\n>This status code seems to convey that \"the client did not access the\n>resource with the required extension\". Could it not also convey \"the\n>server does not support the extension requested by the client\"  ? One\n>could argue that many extensions would be applicable to any resource.\n>\n>If a client request declares 2 mandatory extensions, and the server\n>supports only 1, unless I misunderstood something, there does not seem\n>to be a way of conveying which one was not supported. \n>This will be necessary in practice. Ideally it should be conveyed in the\n>510 or another 5xx response.\n\nAll it says is that the request could not be fulfilled but it doesn't\nprovide any information to as why. However, the requirement is that the\nserver sends back enough information so that the client at least has a\nmechanism for trying again. However, as has been discussed, it is hard for\nthe extension framework to know extensions are to be used and it is\ntherefore left to the extensions and the server to describe what is needed\nin order to access the resource.\n\nThanks!\n\nHenrik\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10267300"}, {"subject": "Re: request for review: http extension", "content": "Henrik Frystyk Nielsen wrote:\n> \n> At 22:57 1/17/99 -0500, Jonathan Rosenberg wrote:\n> \n> >I see; the problem though again is not in the BNF for the extension\n> >delcaration. What you are trying to say is that a header that belongs to\n> >an extension MUST have a dash after its extension number. Then, a header\n> >matches an extension if the extension number, with a dash appended to\n> >it, are a prefix of the header. This rule does not require the dash\n> >itself to be present in the BNF for the extension declaration.\n> \n> I think we are saying the same thing but represent it in two different\n> ways: should the \"-\" be part of the ns production or a part of the prefix\n> string matching algorithm. Either way is fine with me - one may argue that\n> not using the \"-\" in the BNF production is closer to the XML NS spec.\n\nI don't feel too strongly here, preferring slightly to leave the - out\nof the BNF. \n \n> \n> >I think this works so long as the application can parse the header\n> >fields to which the extension applies. If an extension is listed as\n> >mandatory, and a client doesn't know the extension, it just returns an\n> >error response. If it is mandatory, and the client does understand the\n> >extension, than presumably it knows how to parse the header to which the\n> >extension applies, using the new parameters. I guess the problem is with\n> >optional extensions, and that an application would still try to parse\n> >the extended header, not noticing its extended since the header looks\n> >the same.\n> \n> There is no guarantee that an application who knows the extension also\n> knows all header fields that it may be added to in the form of attributes.\n> Combined with the overhead of having to parse the whole message to find\n> these parameters, I would rather leave this out.\n\nFine.\n\n> \n> >I think extensions not being understood always takes precedence, since\n> >the extension could be defining a feature which is \"ignore the lack of\n> >credentials for any other extensions\", in which case if the extension\n> >was understood there would be no error for the other. If a mandatory\n> >extension is not understood, no other aspect of a request can be\n> >reliably parsed, so I still think it makes sense to report a 510 and\n> >list the extension that wasn't understood. But, I don't feel terribly\n> >strongly here, and if the group doesn't consider this an issue thats\n> >fine.\n> \n> I think this better belong in another spec (OPTIONS, for example?) which\n> can define a schema for passing metainformation about capabilities.\n\nFine.\n\n-Jonathan R.\n\n-- \nJonathan D. Rosenberg                       Lucent Technologies\nMember of Technical Staff                   101 Crawfords Corner Rd.\nHigh Speed Networks Research                Holmdel, NJ 07733\nFAX: (732) 834-5379                         Rm. 4C-526\nEMAIL: jdrosen@bell-labs.com\nURL: http://www.cs.columbia.edu/~jdrosen\n\n\n\n", "id": "lists-007-10277931"}, {"subject": "Submitted draft-frystyk-http-extensions-02.tx", "content": "I have now submitted a new revision of the HTTP extension draft. You can\nget it from\n\nhttp://www.w3.org/Protocols/HTTP/ietf-http-ext/\n\nand of course from IETF ID listing when it has gone through.\n\n>From the page above, you can also find a diff version (PS) from the\nprevious version.\n\nThanks to all of you who have commented - I definitely think the draft has\nimproved!\n\nComments are welcome!\n\nHenrik\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-10288670"}, {"subject": "Extending IETF meetings to two weeks", "content": "The IETF meetings tend to become too large, creating\nlogistics and planning problems. I suggest that future\nmeetings are held for two weeks, with applications and user\nservices issues the first week, and all other issues the\nsecond week. Those who so wish could attend both weeks, and\nother people could attend only one week. Those who choose\nto attend both weeks would be able to cover more groups and\ndo better liaisons between the different areas. The Friday\nof the first week could discuss applications issues which\nmight be of special interest to the other areas, and the\nMonday of the second week would schedule other groups which\nmight be of special interest to applications people, so\nsome people could attend Monday-Monday or Friday-Friday.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10295629"}, {"subject": "subscrib", "content": "subscribe\n\n\n\n", "id": "lists-007-10303070"}, {"subject": "Archive of this lis", "content": "On Mon, Jan 25, 1999 at 04:22:55PM -0500, someone wrote:\n> subscribe\n\nThat was my fault, sorry.\n\nThere is now an archive of this list at:\n\n    http://lists.w3.org/Archives/Public/ietf-discuss/\n\nIf anyone has traffic from before Dec 5 1998 or other messages\nwhich aren't in our archive, please get in touch with me.\n\n-- \nGerald Oskoboiny       <gerald@w3.org>  +1 617 253 2920\nSystem Administrator   http://www.w3.org/People/Gerald/\nWorld Wide Web Consortium (W3C)      http://www.w3.org/\n\n\n\n", "id": "lists-007-10309165"}, {"subject": "Re: Replacing the Label header with a DAV:labeled-version repor", "content": "Am Sonntag den, 28. April 2002, um 15:53, schrieb Clemm, Geoff:\n\n> Since this is a fairly significant change, I'd like to\n> hear from a few more folks before adding this to the 3253 Errata.\n\nMaybe Greg could comment from subversion's point of view?\n\n//Stefan\n\n> Thanks,\n> Geoff\n>\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Saturday, April 27, 2002 5:09 AM\n> To: Clemm, Geoff; 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n>> From: ietf-dav-versioning-request@w3.org\n>> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n>> Sent: Friday, April 26, 2002 6:06 PM\n>> To: 'Deltav WG'\n>> Subject: RE: Label header vs PROPFIND depth 1\n>>\n>>\n>>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>>\n>>    - I'd like to see the label *header* deprecated\n>>    - I'm happy with the LABEL method and the label-name-set property\n>>    - I think that PROPFIND/label should be replaced by a specific \n>> REPORT\n>>\n>> Is the proposed DAV:labeled-version report OK with you?\n>\n> Yes. But I think it's Tim's turn to say whether this would work \n> for him or\n> not...\n>\n>>    - I'm unsure about other methods that are currently affected by the\n>>    header -- what were the requirements...?\n>>\n>> The other methods are LABEL, CHECKOUT, GET, and COPY.\n>> For Depth:0 variants of these operations, the Label header\n>> just provided an optimization to save one roundtrip\n>> (i.e. first getting the version URL via the DAV:labeled-version \n>> report).\n>> I believe we can easily do without that Depth:0 optimization.\n>\n> As stated before, I think that's not the single problem. Having \n> GET return a\n> (representation of a) version rather than (a representation of) the VCR\n> makes the version *by definition* a variant (representation) of \n> the VCR --\n> and it seems that most of us want to avoid that interpretation.\n>\n>> For Depth:infinity (only relevant for LABEL and COPY), the savings\n>> would be more significant, but unfortunately the semantics is broken\n>> (since if the namespace is being versioned, you'll get the wrong\n>> resources if you simply do a Depth operation on the current \n>> namespace).\n>>\n>> The Depth:infinity Label header operations are really just a way of\n>> trying to have the client fake workspaces and baselines, instead of\n>> having the server support them directly.  Since it is much more\n>> efficient and reliable to have the server layer these constructs\n>> above a labeling infrastructure, rather than having the client do\n>> so, I believe the cost of maintaining these Depth:infinity Label\n>> header operations in the protocol is not warranted.\n>>\n>> Note though that (depth:0) labeling and baselining go very well\n>> together.  Instead of doing a Depth:infinity LABEL, you can create a\n>> baseline (which under the hood the server may well implement with\n>> reserved labels, but maybe not), and then LABEL that baseline.  Then\n>> when you want to do a Depth:infinity COPY, you retrieve the\n>> DAV:baseline-collection of the labeled baseline (using the\n>> DAV:labeled-version report), and copy that to wherever you want.\n>>\n>> Alternatively, if you want a \"modifiable\" selection, you can create a\n>> workspace (which under the hood the server may well implement with\n>> reserved labels, but maybe not).  When you want to adjust the versions\n>> being selected, you just use UPDATE.  Then when you want to do a\n>> Depth:infinity COPY, you just copy from that workspace to wherever you\n>> want.\n>>\n>>    - Servers that decide to implement LABEL and DAV:label-name-set,\n>>    but no not support the label header should *not* report the LABEL\n>>    feature in OPTIONS.\n>>\n>> That's probably right.  A client can find out if the LABEL operation\n>> is supported by querying the DAV:supported-method-set property values\n>> of a VCR.\n>\n> ....and also use DAV:supported-live-property-set to discover the\n> DAV:label-name-set property.\n>\n\n\n\n", "id": "lists-007-1031069"}, {"subject": "Application &quot;core protocol&quot; BOF/WG ide", "content": "I'm interested in feedback on the following BOF/WG idea.  Do you think\nthis is a good/bad idea?  Any suggestions to improve the proposed charter?\nAnyone interested in being a document editor of either of the two\nproposed documents or interested in WG chair/co-chair position?\n\n- Chris\n------\nThe APPLCORE BOF will discuss the following proposed charter:\n\nApplication core protocol WG  (APPLCORE)\n\nThe IETF has traditionally developed application protocols directly on top\nof a raw TCP stream.  However, there is a growing set of problems which\nmany application protocols have to solve regardless of what the protocols\ndo.  This WG will identify these problems, identify the successes and\nfailures that deployed IETF protocols made when addressing these problems\nand design a simple core protocol to address these problems.  This core\nprotocol may then be used by future application protocols to simplify both\nthe process of protocol design and the complexity of implementing\nmulti-protocol servers.\n\nIn order to keep the WG in focus, the following items are explicitly\nout-of-scope:\n\n* Backwards compatibility with existing application protocols\n  Backwards compatibility often compromises correct design.  If this\n  WG is successful it will impact a great number of future protocols,\n  and thus the design errors which backwards compatibility might\n  dictate must be avoided.\n\n* Transport layers other than TCP/IP\n  This has been a rathole in too many other WGs.\n\n* New features\n  If a problem hasn't been solved in at least two deployed IETF\n  application protocols, then it doesn't need to be addressed in the\n  core protocol spec.  This does not preclude individuals or other\n  groups from doing extensions to the core protocol which might be\n  used by multiple future application protocols; it just limits the\n  scope of the core spec.\n\n* Normative references to other application protocols\n  The core protocol has to stand by itself.  It may reference protocol\n  building blocks that have been used by several other application\n  protocols such as ABNF, language tags, UTF-8, domain names, URLs,\n  MIME, SASL, GSSAPI and TLS.  It must avoid normative references to\n  full application protocols such as ACAP, HTTP, IMAP, LDAP, and SMTP.\n\nThe WG will produce the following output:\n\n* An Informational RFC documenting the problems identified to solve,\n  and giving examples of existing deployed IETF protocols which\n  succeeded or made mistakes when solving those problems.  A starting\n  list of problems for the WG to discuss (the WG may choose not to\n  address some of these) follows:\n\n  * connection user authentication and privacy (e.g., SASL and STARTTLS)\n  * server capability/extension announcement (e.g., SMTP EHLO)\n  * extensible command/response syntax and structure\n  * error status tokens and human readable error text issues\n  * syntax for transfer of large (multi-line) objects (e.g., dot-stuffing,\n    length counting, chunking)\n  * multiple commands in progress at the same time (command ids or tags)\n  * unsolicited server messages\n  * command pipelining (sending multiple commands without waiting for\n    responses)\n  * Structured data representation (e.g., RFC 822-style AV pairs, IMAP\n    s-expressions, LDAP ASN.1, XDR, etc) in command/response syntax.\n  * low bandwidth support (e.g., compression layer or packed binary\n    protocol encoding)\n  * connection shutdown (QUIT/LOGOUT command)\n\n* A simplicity litmus test to determine if a proposal is acceptably\n  simple.  The initial litmus test will be: core protocol spec is less\n  than 25 pages.\n\n* A standards track core application protocol specification which uses\n  the lessons learned from the informational document and fits the\n  litmus test above.  An open source implementation of the complete\n  core protocol must exist prior to IETF last call.\n\nThe WG may solicit strawmen for the core application protocol from\nmultiple document editors and select the one which is technically\nbest and fits this charter.\n\nThe WG may choose to do additional standards track documents which\nextend the core protocol as long as they are not new features by the\nabove definition.\n\nThe WG may choose to do one or more APIs for using the core protocol\nand adding commands/extensions to it.  These might be informational\nor standards track as deemed appropriate.\n\n\n\n", "id": "lists-007-10316246"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "Chris,\nI think a BOF on the topic is a good idea.  My first take is\nthat simply identifying all of the common problems that application\nprotocols need to solve would be a big win and a big enough task that\na short-lived working group on just that would be great.  I don't have\nenough of a sense of what problems future protocols will be solving to\nknow whether the best approach is to create a \"generic\" protocol or to\nprovide framework elements for solving the usual problems (like the\nmandatory-to-implement authentication issue).  I know that the W3C\ngroup which is doing the \"HTTP-NG\" work has the view that a new common\nprotocol would have advantages.  Like you, they have also explictly\nruled out backwards compatibility as a design requirement (which means\ntheir work actually doesn't have a lot to do with the current HTTP\n1.1).  You might want to talk to them about participating in this\neffort.  Jim Gettys would probably be the best contact there.\nregards,\nTed Hardie\n\n\n\n\n\n\n\n> I'm interested in feedback on the following BOF/WG idea.  Do you think\n> this is a good/bad idea?  Any suggestions to improve the proposed charter?\n> Anyone interested in being a document editor of either of the two\n> proposed documents or interested in WG chair/co-chair position?\n> \n> - Chris\n> ------\n> The APPLCORE BOF will discuss the following proposed charter:\n> \n> Application core protocol WG  (APPLCORE)\n> \n> The IETF has traditionally developed application protocols directly on top\n> of a raw TCP stream.  However, there is a growing set of problems which\n> many application protocols have to solve regardless of what the protocols\n> do.  This WG will identify these problems, identify the successes and\n> failures that deployed IETF protocols made when addressing these problems\n> and design a simple core protocol to address these problems.  This core\n> protocol may then be used by future application protocols to simplify both\n> the process of protocol design and the complexity of implementing\n> multi-protocol servers.\n> \n> In order to keep the WG in focus, the following items are explicitly\n> out-of-scope:\n> \n> * Backwards compatibility with existing application protocols\n>   Backwards compatibility often compromises correct design.  If this\n>   WG is successful it will impact a great number of future protocols,\n>   and thus the design errors which backwards compatibility might\n>   dictate must be avoided.\n> \n> * Transport layers other than TCP/IP\n>   This has been a rathole in too many other WGs.\n> \n> * New features\n>   If a problem hasn't been solved in at least two deployed IETF\n>   application protocols, then it doesn't need to be addressed in the\n>   core protocol spec.  This does not preclude individuals or other\n>   groups from doing extensions to the core protocol which might be\n>   used by multiple future application protocols; it just limits the\n>   scope of the core spec.\n> \n> * Normative references to other application protocols\n>   The core protocol has to stand by itself.  It may reference protocol\n>   building blocks that have been used by several other application\n>   protocols such as ABNF, language tags, UTF-8, domain names, URLs,\n>   MIME, SASL, GSSAPI and TLS.  It must avoid normative references to\n>   full application protocols such as ACAP, HTTP, IMAP, LDAP, and SMTP.\n> \n> The WG will produce the following output:\n> \n> * An Informational RFC documenting the problems identified to solve,\n>   and giving examples of existing deployed IETF protocols which\n>   succeeded or made mistakes when solving those problems.  A starting\n>   list of problems for the WG to discuss (the WG may choose not to\n>   address some of these) follows:\n> \n>   * connection user authentication and privacy (e.g., SASL and STARTTLS)\n>   * server capability/extension announcement (e.g., SMTP EHLO)\n>   * extensible command/response syntax and structure\n>   * error status tokens and human readable error text issues\n>   * syntax for transfer of large (multi-line) objects (e.g., dot-stuffing,\n>     length counting, chunking)\n>   * multiple commands in progress at the same time (command ids or tags)\n>   * unsolicited server messages\n>   * command pipelining (sending multiple commands without waiting for\n>     responses)\n>   * Structured data representation (e.g., RFC 822-style AV pairs, IMAP\n>     s-expressions, LDAP ASN.1, XDR, etc) in command/response syntax.\n>   * low bandwidth support (e.g., compression layer or packed binary\n>     protocol encoding)\n>   * connection shutdown (QUIT/LOGOUT command)\n> \n> * A simplicity litmus test to determine if a proposal is acceptably\n>   simple.  The initial litmus test will be: core protocol spec is less\n>   than 25 pages.\n> \n> * A standards track core application protocol specification which uses\n>   the lessons learned from the informational document and fits the\n>   litmus test above.  An open source implementation of the complete\n>   core protocol must exist prior to IETF last call.\n> \n> The WG may solicit strawmen for the core application protocol from\n> multiple document editors and select the one which is technically\n> best and fits this charter.\n> \n> The WG may choose to do additional standards track documents which\n> extend the core protocol as long as they are not new features by the\n> above definition.\n> \n> The WG may choose to do one or more APIs for using the core protocol\n> and adding commands/extensions to it.  These might be informational\n> or standards track as deemed appropriate.\n> \n> \n\n\n\n", "id": "lists-007-10328772"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "Ted Hardie said this:\n> I think a BOF on the topic is a good idea.  My first take is\n> that simply identifying all of the common problems that application\n> protocols need to solve would be a big win and a big enough task that\n> a short-lived working group on just that would be great.  \n\nI have to agree with this one. If there were a document I could point to\nand say that the recommended way of doing error codes can be found here\nit would save me huge amounts of time with in house one shot protocols\nin terms of educating people about what works and what doesn't work.\n\nA good example is the constant re-use of RFC821's response codes. If\nthat itself were brought up to date and re-released on its own it would\ndo alot to help new protocol writers....\n\n-MM\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | www.rwhois.net/michael\nSr. Research Engineer   |   www.ga.lp.org/gwinnett     | ICQ#:         14198821\nNetwork Solutions|          www.lp.org          |  michaelm@netsol.com\n\n\n\n", "id": "lists-007-10342353"}, {"subject": "RE: Application &quot;core protocol&quot; BOF/WG ide", "content": "Even with Chris's excellent charter which I think does a great job of\nrestricting rat holes a core protocol WG would still be more appropriate for\nthe IRTF than the IETF. In my opinion the IETF's job is to clean up the mess\nleft behind by the innovators. That means we follow, we do not lead. As such\nI strongly encourage outside efforts like HTTP-NG who will blaze a trail\nthat the IETF can later follow and standardize.\n\nHowever, a WG to identify common issues and equally common solutions would\nprovide crucial guidance for application protocol standards writers and be\nvery much in line with the IETF's work. For example, such a \"common issues\"\nWG might produce a document which made it mandatory for all new application\nprotocols to explicitly address issues such as: Extensibility (Provide clear\nrules on what to do with unrecognized protocol elements - ignore or fail?),\nNAT/Proxy/Firewall support, caching, connection oriented vs. non-connection\noriented, TCP vs. UDP, reliable vs. unreliable multicast, etc. These\nrequirements would be in line with current requirements regarding support\nfor Y2k friendly dates, internationalization and general security. Just\nproducing a list of the most common issues would be a great accomplishment.\nIt would be a valuable guide for reviewers and ADs to use when evaluating\nnew protocols.\n\nYaron\n\n> -----Original Message-----\n> From: Michael Mealling [mailto:michael@bailey.dscga.com]\n> Sent: Thursday, January 28, 1999 10:38 AM\n> To: hardie@equinix.com\n> Cc: Chris.Newman@INNOSOFT.COM; discuss@apps.ietf.org\n> Subject: Re: Application \"core protocol\" BOF/WG idea\n> \n> \n> Ted Hardie said this:\n> > I think a BOF on the topic is a good idea.  My first take is\n> > that simply identifying all of the common problems that application\n> > protocols need to solve would be a big win and a big enough \n> task that\n> > a short-lived working group on just that would be great.  \n> \n> I have to agree with this one. If there were a document I \n> could point to\n> and say that the recommended way of doing error codes can be \n> found here\n> it would save me huge amounts of time with in house one shot protocols\n> in terms of educating people about what works and what doesn't work.\n> \n> A good example is the constant re-use of RFC821's response codes. If\n> that itself were brought up to date and re-released on its \n> own it would\n> do alot to help new protocol writers....\n> \n> -MM\n> \n> -- \n> --------------------------------------------------------------\n> ------------------\n> Michael Mealling|      Vote Libertarian!       | \nwww.rwhois.net/michael\nSr. Research Engineer   |   www.ga.lp.org/gwinnett     | ICQ#:\n14198821\nNetwork Solutions|          www.lp.org          |\nmichaelm@netsol.com\n\n\n\n", "id": "lists-007-10351479"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "At 9:31 AM -0800 1/28/99, Chris Newman wrote:\n\n\n> I'm interested in feedback on the following BOF/WG idea.  Do you think\n> this is a good/bad idea?  Any suggestions to improve the proposed charter?\n> Anyone interested in being a document editor of either of the two\n> proposed documents or interested in WG chair/co-chair position?\n\n\nI think it would be a good idea.  A quick read of the straw charter \nshows it contains those things that I can think of off the top of my \nhead.  I also think that, while this could be very useful effort, it \ncould also degenerate and thus needs a tight reign on scope.  The \nwork should definitely be done in steps:\n\n\n    1.  Identify common problems\n    2.  Identify solutions used in various protocols\n    3.  Analyze solutions: what elements worked, what didn't\n    4.  Publish informational document\n    5.  Identify core set of problems for new skeleton protocol\n\n\n\n\nI'd be willing to be a document editor or chair/co-chair.\n\n\n\n", "id": "lists-007-10364257"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "Rough concensus appears to be heading in the direction of liking part or\nall of this proposal (including three voluteers for WG chair or document\neditor positions) and I have yet to hear a compelling negative response. \nBut rough concensus is not yet sufficiently clear, so please continue to\nexpress your opinions.  Here are responses to the general concerns\nexpressed so far: \n\n> The task is too big and should be constrained to the\n> problem-identification and history document.\n\nIf it's useful identifying the problem, then it's also useful to propose a\nsolution.  Futhermore, if you constrain the working group to the point\nthat it doesn't have a product which is sufficiently compelling to\nmotivate participants to work, then the effort will die.  While the\nhistory/problem-statement document would be interesting and useful, I\ndoubt it is sufficient by itself to motivate active participation.\n\nMy motivation stems from my realization that the IETF usually can't say\n\"no\"; it can only say \"use this instead\", \"take your proposal elsewhere\"\nor \"fix this problem in your proposal\".  There are people who wish to\nlayer unrelated new protocol services on top of a 167 page HTTP protocol\nbecause they think it gives security and MIME labelling \"for free.\"  I\ncan't argue with an honest desire to simplify the task of specifying new\nprotocols, so I want to see a significantly simpler \"use this instead\"\ncandidate.  The engineer in me is willing to expend a lot of energy so\nthat future IETF protocols are simpler and cleaner.  Remove the \"core\nprotocol\" task and you remove my motivation and probably that of several\nothers.\n\n> Isn't this what HTTP-NG is doing?\n\nNo.  HTTP-NG has a much larger scope than this proposal.  On the high-end,\nthe HTTP-NG name implies it's a replacement for a high-level hypertext\ntransfer application, and is thus out-of-scope for this proposal.  On the\nlow-end, HTTP-NG met as an IETF \"transport area\" WG, which indicates a\nfocus at a much lower level than this proposal permits.  This proposal is\nvery narrow so it only addresses those problems we (in the applications\narea) have solved before and have operational experience with.\n\n> Isn't this a research project?\n\nNo.  The proposed charter explicitly rules out-of-scope anything that\nhasn't already been done in a deployed IETF protocol.  The fact that\npeople think this might be a research project or as broad as the HTTP-NG\nwork suggests the proposed charter needs to be tightened up further, so I\nhave clarified the initial paragraph to reflect.\n\n> Let's do this in a strict sequence of steps\n\nI have revised the proposed charter so the \"core protocol\" proposal can't\ngo to IETF last call until the \"history/problem statement\" document has\nbeen completed.  However, I think it's a bad idea to attempt to do a\nproblem statement and requirements without doing a prototype solution in\nparallel -- otherwise the problem statement and requirements may not be \ngrounded in reality.\n\n\nI have also added a couple other constraints to the proposed charter to\naddress other concerns which were expressed. \n\n- Chris\n\n------APPLCORE proposed charter V2\n\nThe APPLCORE BOF will discuss the following proposed charter:\n\nApplication core protocol WG  (APPLCORE)\n\nThe IETF has traditionally developed application protocols directly on\ntop of a raw TCP stream.  However, there is a growing set of problems\nwhich many application protocols have to solve regardless of what the\nprotocols do.  This WG will identify the common problems that deployed\nIETF protocols have solved, identify the successes and failures that\ndeployed IETF protocols made when addressing these problems and design\na simple core protocol to address these problems.  This core protocol\nmay then be used by future application protocols to simplify both the\nprocess of protocol design and the complexity of implementing\nmulti-protocol servers.\n\nIn order to keep the WG in focus, the following items are explicitly\nout-of-scope:\n\n* Backwards compatibility with existing application protocols\n  Backwards compatibility often compromises correct design.  If this\n  WG is successful it will impact a great number of future protocols,\n  and thus the design errors which backwards compatibility might\n  dictate must be avoided.\n\n* Transport layers other than TCP/IP\n  This has been a rathole in too many other WGs.\n\n* Protocol models outside the traditional IETF client-server TCP\n  application protocol model.\n  The IETF doesn't have sufficient past experience in these areas.\n\n* New features\n  If a problem hasn't been solved in at least two deployed IETF\n  application protocols, then it is out-of-scope for the base core\n  protocol spec.  This does not preclude individuals or other groups\n  from doing extensions to the core protocol which might be used by\n  multiple future application protocols; it just limits the scope of\n  the core spec.\n\n* Normative references to other application protocols or non-public specs\n  The core protocol has to stand by itself.  It may reference protocol\n  building blocks that have been used by several other application\n  protocols such as ABNF, language tags, UTF-8, domain names, URLs,\n  MIME, SASL, GSSAPI and TLS.  It must avoid normative references to\n  full application protocols such as ACAP, HTTP, IMAP, LDAP, and SMTP.\n  It must avoid normative references to any document which is not\n  freely and publicly available on the Internet.\n\nThe WG will produce the following output:\n\n* An Informational RFC documenting the problems identified to solve,\n  and giving examples of existing deployed IETF protocols which\n  succeeded or made mistakes when solving those problems.  A starting\n  list of problems for the WG to discuss (the WG may choose not to\n  address some of these) follows:\n\n  * connection user authentication and privacy (e.g., SASL and STARTTLS)\n  * server capability/extension announcement (e.g., SMTP EHLO)\n  * extensible command/response syntax and structure\n  * error status tokens and human readable error text issues\n  * syntax for transfer of large (multi-line) objects (e.g., dot-stuffing,\n    length counting, chunking)\n  * multiple commands in progress at the same time (command ids or tags)\n  * unsolicited server messages\n  * command pipelining (sending multiple commands without waiting for\n    responses)\n  * Structured data representation (e.g., RFC 822-style AV pairs, IMAP\n    s-expressions, LDAP ASN.1, XDR, etc) in command/response syntax.\n  * low bandwidth support (e.g., compression layer or packed binary\n    protocol encoding)\n  * connection shutdown (QUIT/LOGOUT command)\n\n* A simplicity litmus test to determine if a proposal is acceptably\n  simple.  The initial litmus test will be: core protocol spec is less\n  than 25 pages.\n\n* A standards track core application protocol specification which uses\n  the lessons learned from the informational document and fits the\n  litmus test above.  An open source implementation of the complete\n  core protocol must exist prior to IETF last call.  The problem\n  identification draft (above) must be completed prior to IETF last\n  call.\n\nThe WG may solicit strawmen for the core application protocol from\nmultiple document editors and select the one which is technically\nbest and fits this charter.\n\nThe WG may choose to do additional standards track documents which\nextend the core protocol as long as they are not new features by the\nabove definition.\n\nThe WG may choose to do one or more APIs for using the core protocol\nand adding commands/extensions to it.  These might be informational\nor standards track as deemed appropriate.\n\n\n\n", "id": "lists-007-10372899"}, {"subject": "RE: Application &quot;core protocol&quot; BOF/WG ide", "content": "All,\n\nI think we should also look into why earlier attempts have failed.\n\nRFC 1831 defines a working RPC mechanism, which could potentially have \nbeen used by multiple application protocols but wasn't.\n\nThe IPP WG looked at this as an alternative to using HTTP, but came to\nthe conclusion that there were few if any implementations of RFC 1831,\nand it was certainly not \"on everybody's desktop\" like HTTP.\n\nDo we know why RFC 1831 was never picked up by the market place, and\nhow we can avoid making yet another generic application protocol,\nthat does not get implemented?\n\n(I expect to hear complaints from all of you who actually have \nimplemented RFC 1831 :-)\n\nCarl-Uno\n\n> -----Original Message-----\n> From: Chris Newman [mailto:Chris.Newman@INNOSOFT.COM]\n> Sent: Thursday, January 28, 1999 5:03 PM\n> To: discuss@apps.ietf.org\n> Subject: Re: Application \"core protocol\" BOF/WG idea\n> \n> \n> Rough concensus appears to be heading in the direction of \n> liking part or\n> all of this proposal (including three voluteers for WG chair \n> or document\n> editor positions) and I have yet to hear a compelling \n> negative response. \n> But rough concensus is not yet sufficiently clear, so please \n> continue to\n> express your opinions.  Here are responses to the general concerns\n> expressed so far: \n> \n> > The task is too big and should be constrained to the\n> > problem-identification and history document.\n> \n> If it's useful identifying the problem, then it's also useful \n> to propose a\n> solution.  Futhermore, if you constrain the working group to the point\n> that it doesn't have a product which is sufficiently compelling to\n> motivate participants to work, then the effort will die.  While the\n> history/problem-statement document would be interesting and useful, I\n> doubt it is sufficient by itself to motivate active participation.\n> \n> My motivation stems from my realization that the IETF usually \n> can't say\n> \"no\"; it can only say \"use this instead\", \"take your proposal \n> elsewhere\"\n> or \"fix this problem in your proposal\".  There are people who wish to\n> layer unrelated new protocol services on top of a 167 page \n> HTTP protocol\n> because they think it gives security and MIME labelling \"for free.\"  I\n> can't argue with an honest desire to simplify the task of \n> specifying new\n> protocols, so I want to see a significantly simpler \"use this instead\"\n> candidate.  The engineer in me is willing to expend a lot of energy so\n> that future IETF protocols are simpler and cleaner.  Remove the \"core\n> protocol\" task and you remove my motivation and probably that \n> of several\n> others.\n> \n> > Isn't this what HTTP-NG is doing?\n> \n> No.  HTTP-NG has a much larger scope than this proposal.  On \n> the high-end,\n> the HTTP-NG name implies it's a replacement for a high-level hypertext\n> transfer application, and is thus out-of-scope for this \n> proposal.  On the\n> low-end, HTTP-NG met as an IETF \"transport area\" WG, which indicates a\n> focus at a much lower level than this proposal permits.  This \n> proposal is\n> very narrow so it only addresses those problems we (in the \n> applications\n> area) have solved before and have operational experience with.\n> \n> > Isn't this a research project?\n> \n> No.  The proposed charter explicitly rules out-of-scope anything that\n> hasn't already been done in a deployed IETF protocol.  The fact that\n> people think this might be a research project or as broad as \n> the HTTP-NG\n> work suggests the proposed charter needs to be tightened up \n> further, so I\n> have clarified the initial paragraph to reflect.\n> \n> > Let's do this in a strict sequence of steps\n> \n> I have revised the proposed charter so the \"core protocol\" \n> proposal can't\n> go to IETF last call until the \"history/problem statement\" \n> document has\n> been completed.  However, I think it's a bad idea to attempt to do a\n> problem statement and requirements without doing a prototype \n> solution in\n> parallel -- otherwise the problem statement and requirements \n> may not be \n> grounded in reality.\n> \n> \n> I have also added a couple other constraints to the proposed \n> charter to\n> address other concerns which were expressed. \n> \n> - Chris\n> \n> ------APPLCORE proposed charter V2\n> \n> The APPLCORE BOF will discuss the following proposed charter:\n> \n> Application core protocol WG  (APPLCORE)\n> \n> The IETF has traditionally developed application protocols directly on\n> top of a raw TCP stream.  However, there is a growing set of problems\n> which many application protocols have to solve regardless of what the\n> protocols do.  This WG will identify the common problems that deployed\n> IETF protocols have solved, identify the successes and failures that\n> deployed IETF protocols made when addressing these problems and design\n> a simple core protocol to address these problems.  This core protocol\n> may then be used by future application protocols to simplify both the\n> process of protocol design and the complexity of implementing\n> multi-protocol servers.\n> \n> In order to keep the WG in focus, the following items are explicitly\n> out-of-scope:\n> \n> * Backwards compatibility with existing application protocols\n>   Backwards compatibility often compromises correct design.  If this\n>   WG is successful it will impact a great number of future protocols,\n>   and thus the design errors which backwards compatibility might\n>   dictate must be avoided.\n> \n> * Transport layers other than TCP/IP\n>   This has been a rathole in too many other WGs.\n> \n> * Protocol models outside the traditional IETF client-server TCP\n>   application protocol model.\n>   The IETF doesn't have sufficient past experience in these areas.\n> \n> * New features\n>   If a problem hasn't been solved in at least two deployed IETF\n>   application protocols, then it is out-of-scope for the base core\n>   protocol spec.  This does not preclude individuals or other groups\n>   from doing extensions to the core protocol which might be used by\n>   multiple future application protocols; it just limits the scope of\n>   the core spec.\n> \n> * Normative references to other application protocols or \n> non-public specs\n>   The core protocol has to stand by itself.  It may reference protocol\n>   building blocks that have been used by several other application\n>   protocols such as ABNF, language tags, UTF-8, domain names, URLs,\n>   MIME, SASL, GSSAPI and TLS.  It must avoid normative references to\n>   full application protocols such as ACAP, HTTP, IMAP, LDAP, and SMTP.\n>   It must avoid normative references to any document which is not\n>   freely and publicly available on the Internet.\n> \n> The WG will produce the following output:\n> \n> * An Informational RFC documenting the problems identified to solve,\n>   and giving examples of existing deployed IETF protocols which\n>   succeeded or made mistakes when solving those problems.  A starting\n>   list of problems for the WG to discuss (the WG may choose not to\n>   address some of these) follows:\n> \n>   * connection user authentication and privacy (e.g., SASL \n> and STARTTLS)\n>   * server capability/extension announcement (e.g., SMTP EHLO)\n>   * extensible command/response syntax and structure\n>   * error status tokens and human readable error text issues\n>   * syntax for transfer of large (multi-line) objects (e.g., \n> dot-stuffing,\n>     length counting, chunking)\n>   * multiple commands in progress at the same time (command \n> ids or tags)\n>   * unsolicited server messages\n>   * command pipelining (sending multiple commands without waiting for\n>     responses)\n>   * Structured data representation (e.g., RFC 822-style AV pairs, IMAP\n>     s-expressions, LDAP ASN.1, XDR, etc) in command/response syntax.\n>   * low bandwidth support (e.g., compression layer or packed binary\n>     protocol encoding)\n>   * connection shutdown (QUIT/LOGOUT command)\n> \n> * A simplicity litmus test to determine if a proposal is acceptably\n>   simple.  The initial litmus test will be: core protocol spec is less\n>   than 25 pages.\n> \n> * A standards track core application protocol specification which uses\n>   the lessons learned from the informational document and fits the\n>   litmus test above.  An open source implementation of the complete\n>   core protocol must exist prior to IETF last call.  The problem\n>   identification draft (above) must be completed prior to IETF last\n>   call.\n> \n> The WG may solicit strawmen for the core application protocol from\n> multiple document editors and select the one which is technically\n> best and fits this charter.\n> \n> The WG may choose to do additional standards track documents which\n> extend the core protocol as long as they are not new features by the\n> above definition.\n> \n> The WG may choose to do one or more APIs for using the core protocol\n> and adding commands/extensions to it.  These might be informational\n> or standards track as deemed appropriate.\n> \n\n\n\n", "id": "lists-007-10388248"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "Chris,\n\nI think that this is a great idea and has been sorely needed for a\nwhile now. I also empathize with Michael's comments. I'm a bit\noverloaded at the moment, but I would like to lend whatever support I\ncan.\n\nregards,\nJohn\n\n-----Original Message-----\nFrom: Randall Gellens <randy@qualcomm.com>\nTo: Chris Newman <Chris.Newman@innosoft.com>; discuss@apps.ietf.org\n<discuss@apps.ietf.org>\nDate: Thursday, January 28, 1999 3:17 PM\nSubject: Re: Application \"core protocol\" BOF/WG idea\n\n\n>At 9:31 AM -0800 1/28/99, Chris Newman wrote:\n>\n>\n>> I'm interested in feedback on the following BOF/WG idea.  Do you\nthink\n>> this is a good/bad idea?  Any suggestions to improve the proposed\ncharter?\n>> Anyone interested in being a document editor of either of the two\n>> proposed documents or interested in WG chair/co-chair position?\n>\n>\n>I think it would be a good idea.  A quick read of the straw charter\n>shows it contains those things that I can think of off the top of my\n>head.  I also think that, while this could be very useful effort, it\n>could also degenerate and thus needs a tight reign on scope.  The\n>work should definitely be done in steps:\n>\n>\n>    1.  Identify common problems\n>    2.  Identify solutions used in various protocols\n>    3.  Analyze solutions: what elements worked, what didn't\n>    4.  Publish informational document\n>    5.  Identify core set of problems for new skeleton protocol\n>\n>\n>\n>\n>I'd be willing to be a document editor or chair/co-chair.\n>\n\n\n\n", "id": "lists-007-10407135"}, {"subject": "Coding method for group communication protoco", "content": "I am involved in two EU-funded research projects,\nSeniorOnline (http://cmc.dsv.su.se/sol) and SELECT\n(http://cmc.dsv.su.se/select) which both are planning to\ndevelop distributed protocols which might in the future be\ncandidates for standardisation. We have a problem in\nchoosing a coding method for the distributed operations we\nare planning to specify. Example of operations might be in\nSeniorOnline:\n\n- Subscribe to a forum in another server\n- Replicate a message to another server\n- List the members of a forum in another server\n\nCoding method which we are considering are:\n\n- XML (sent via HTTP). Advantage: Powerful, general-purpose,\n  a current fad.\n- multipart/formdata (RFC 2388, RFC 1867). Advantage:\n  MIME-based, easy to produce test data since an ordinary\n  HTML form can be used.\n- A variant of the DSN format (RFC 1894)\n- CORBA\n- A variant of LDAP, since some of the operations\n  we will define will be directory-type operations\n\nIn the first three cases, HTTP would probably be used for\ntransport. I do not know enough about CORBA, but it may\nhave its own transport protocol.\n\nCan I get advice on which of the above protocol encoding\nmethods would be best for us to use?\n\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10417860"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "At 09:31 28/01/99 -0800, Chris Newman wrote:\n>I'm interested in feedback on the following BOF/WG idea.  Do you think\n>this is a good/bad idea?  Any suggestions to improve the proposed charter?\n>Anyone interested in being a document editor of either of the two\n>proposed documents or interested in WG chair/co-chair position?\n>\n>- Chris\n>------\n>The APPLCORE BOF will discuss the following proposed charter:\n>\n>Application core protocol WG  (APPLCORE)\n>\n>The IETF has traditionally developed application protocols directly on top\n>of a raw TCP stream.  However, there is a growing set of problems which\n>many application protocols have to solve regardless of what the protocols\n>do.  This WG will identify these problems, identify the successes and\n>failures that deployed IETF protocols made when addressing these problems\n>and design a simple core protocol to address these problems.  This core\n>protocol may then be used by future application protocols to simplify both\n>the process of protocol design and the complexity of implementing\n>multi-protocol servers.\n\nWhile I applaud the general intent, I echo other concerns that the goal is\ntoo ambitious.\n\nSpecifically, I find the idea that we can \"design a simple core protocol to\naddress these problems\" is something of a tall order.  What I do think may\nbe achievable is to identify a range of problems, and then make\nrecommendations about solutions to these.\n\nYour reference a number of areas that may be considered:\n\n>  * connection user authentication and privacy (e.g., SASL and STARTTLS)\n>  * server capability/extension announcement (e.g., SMTP EHLO)\n>  * extensible command/response syntax and structure\n>  * error status tokens and human readable error text issues\n>  * syntax for transfer of large (multi-line) objects (e.g., dot-stuffing,\n>    length counting, chunking)\n>  * multiple commands in progress at the same time (command ids or tags)\n>  * unsolicited server messages\n>  * command pipelining (sending multiple commands without waiting for\n>    responses)\n>  * Structured data representation (e.g., RFC 822-style AV pairs, IMAP\n>    s-expressions, LDAP ASN.1, XDR, etc) in command/response syntax.\n>  * low bandwidth support (e.g., compression layer or packed binary\n>    protocol encoding)\n>  * connection shutdown (QUIT/LOGOUT command)\n\nI would add object security (e.g. S/MIME, openPGP),\n\nFor each of these there may be one or more preferred solutions.  I think\nthe detailed specification of technical solutions should be separated from\na document that makes recommendations about how these may be effectively\nused together to create new application protocol.\n\nTo the maximum extent possible, existing protocols should be used.  With\nfew exceptions, what remains is, I think, a statement of how these are\ncombined to create a new application protocol.\n\nSo, instead of \"core protocol\", how about \"core protocols\"?\n\n#g\n\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-10427197"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "I think your proposal is a great idea and we should move forward with\nit.\n\nJim\n\n--\nJames M. Galvin                       Director, EC Technologies\nCommerceNet Consortium                +1 410.549.5545\nhttp://www.commerce.net               +1 410.549.5546 FAX\n\nAll the world's a stage and most of us are desperately unrehearsed.\n                -- Sean O'Casey\n\n\n\n", "id": "lists-007-10438542"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "I'd be happy with deprecating non-0 depth header. There are better ways to \nget related versions of resources. This would seem to solve the problem \nwith minimal effect on the spec, and provide one-trip access to a specific \nversion of a resource (for diff purposes, etc.).\n\n\n\n\nGeoff,\n\n- I'd like to see the label *header* deprecated\n- I'm happy with the LABEL method and the label-name-set property\n- I think that PROPFIND/label should be replaced by a specific REPORT\n- I'm unsure about other methods that are currently affected by the\nheader -- what were the requirements...?\n- Servers that decide to implement LABEL and DAV:label-name-set, but no \nnot\nsupport the label header should *not* report the LABEL feature in OPTIONS.\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, April 26, 2002 4:54 PM\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> I am not surprised the Label header is proving to be problematic.\n> The last time I tried to get rid of it (obviously unsuccessfully)\n> was about a year ago.\n>\n> My first choice would be to deprecate the Label header altogether, and\n> to instead define a DAV:labeled-version report on a VCR, whose\n> parameters were a label and a list of property names.  The result of\n> this report would be the values of the specified properties on the\n> version selected by the specified label from the VCR identified by the\n> request-URL.\n>\n> An alternative approach would be to deprecate the use of the Label\n> header with a non-zero Depth request (either because of an explicit\n> non-zero Depth header, or because a request is non-zero Depth by\n> default).\n>\n> I'd be interested in responses on the following three questions:\n>\n> (1) Do these approaches address the issues raised?\n> (2) Is there another approach that could be considered?\n> (3) Which approach do you prefer?\n>\n> If we can get consensus on an approach, I'll add it to the RFC 3253\n> Errata document.\n>\n> Cheers,\n> Geoff\n>\n>\n\n\n\n", "id": "lists-007-1044192"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "While I am supportive of the need for an object security proposal, I do\nwant to observe that the IETF has not officially endorsed an object\nframework.  MIME is certainly a contender but it has never been formally\nsanctioned in that way.\n\nInsofar as MIME is the object framework of choice, Security Multiparts\nis the object security framework of choice.  That leaves choosing the\nsecurity protocol itself, be it S/MIME or OpenPGP.  Frankly, that's a\ndebate we don't need and I hope we don't have.\n\nMy worst fear is that the recently proposed \"mailcap\" will go there.\nI'd prefer we just have a way of knowing which protocol is supported by\na recipient and let it go at that.  We've already seen how well the\nmarket and our process handles choosing secure email protocols.\n\nSo, I don't think this working group should include this action item.\n\nJim\n\n--\nJames M. Galvin                       Director, EC Technologies\nCommerceNet Consortium                +1 410.549.5545\nhttp://www.commerce.net               +1 410.549.5546 FAX\n\nAll the world's a stage and most of us are desperately unrehearsed.\n                -- Sean O'Casey\n\n\n\nattached mail follows:\nAt 09:31 28/01/99 -0800, Chris Newman wrote:\n>I'm interested in feedback on the following BOF/WG idea.  Do you think\n>this is a good/bad idea?  Any suggestions to improve the proposed charter?\n>Anyone interested in being a document editor of either of the two\n>proposed documents or interested in WG chair/co-chair position?\n>\n>- Chris\n>------\n>The APPLCORE BOF will discuss the following proposed charter:\n>\n>Application core protocol WG  (APPLCORE)\n>\n>The IETF has traditionally developed application protocols directly on top\n>of a raw TCP stream.  However, there is a growing set of problems which\n>many application protocols have to solve regardless of what the protocols\n>do.  This WG will identify these problems, identify the successes and\n>failures that deployed IETF protocols made when addressing these problems\n>and design a simple core protocol to address these problems.  This core\n>protocol may then be used by future application protocols to simplify both\n>the process of protocol design and the complexity of implementing\n>multi-protocol servers.\n\nWhile I applaud the general intent, I echo other concerns that the goal is\ntoo ambitious.\n\nSpecifically, I find the idea that we can \"design a simple core protocol to\naddress these problems\" is something of a tall order.  What I do think may\nbe achievable is to identify a range of problems, and then make\nrecommendations about solutions to these.\n\nYour reference a number of areas that may be considered:\n\n>  * connection user authentication and privacy (e.g., SASL and STARTTLS)\n>  * server capability/extension announcement (e.g., SMTP EHLO)\n>  * extensible command/response syntax and structure\n>  * error status tokens and human readable error text issues\n>  * syntax for transfer of large (multi-line) objects (e.g., dot-stuffing,\n>    length counting, chunking)\n>  * multiple commands in progress at the same time (command ids or tags)\n>  * unsolicited server messages\n>  * command pipelining (sending multiple commands without waiting for\n>    responses)\n>  * Structured data representation (e.g., RFC 822-style AV pairs, IMAP\n>    s-expressions, LDAP ASN.1, XDR, etc) in command/response syntax.\n>  * low bandwidth support (e.g., compression layer or packed binary\n>    protocol encoding)\n>  * connection shutdown (QUIT/LOGOUT command)\n\nI would add object security (e.g. S/MIME, openPGP),\n\nFor each of these there may be one or more preferred solutions.  I think\nthe detailed specification of technical solutions should be separated from\na document that makes recommendations about how these may be effectively\nused together to create new application protocol.\n\nTo the maximum extent possible, existing protocols should be used.  With\nfew exceptions, what remains is, I think, a statement of how these are\ncombined to create a new application protocol.\n\nSo, instead of \"core protocol\", how about \"core protocols\"?\n\n#g\n\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-10446394"}, {"subject": "Re: Coding method for group communication protoco", "content": "I'm very opinionated on the subject, so I'll gladly comment:\n\nOn Fri, 29 Jan 1999, Jacob Palme wrote:\n> Coding method which we are considering are:\n> \n> - XML (sent via HTTP). Advantage: Powerful, general-purpose,\n>   a current fad.\n\nIf you're working on structured documents, I would recommend using XML and\nDOM.  While each of these two pieces is mediocre by itself, I suspect the\ncombination of the two in a standards arena will be very valuable.\n\nFor general metadata, XML is just a mediocre syntax (it'd be good if there\nweren't 6 ways to encode a character and junk like Processing Instructions\nand CDATA were cut).  If simple A-V pairs will suffice, I'd go with RFC\n822 style headers since they're more readable, but if nested structures\nare needed XML syntax isn't a bad choice.\n\n> - multipart/formdata (RFC 2388, RFC 1867). Advantage:\n>   MIME-based, easy to produce test data since an ordinary\n>   HTML form can be used.\n\nIt tends to be hard to treat multipart MIME objects as single entities\nwith current infrastructure.  While I consider this a flaw in the current\ndeployed infrastructure it would influence my choice.  When passing around\na collection of structured data, it's important to be able to treat that\ncollection as a single independent entity at times.\n\n> - A variant of the DSN format (RFC 1894)\n\nThis is a simplified version of RFC 822 style headers.  A good choice if\nA-V pairs is all you need.\n\n> - CORBA\n\nI know almost nothing about it.  My first impression is that it's trendy\njunk, but I could be wrong.\n\n> - A variant of LDAP, since some of the operations\n>   we will define will be directory-type operations\n\nI'm not fond of ASN.1 binary encodings -- they're at least as hard as text\n(in programmer time) to marshal and unmarshal correctly, and require\nadditional programmer time to build a debugging and testing\ninfrastructure.\n\nIf your data is very directory-oriented and likely to gateway to LDAP\noperations at times, I'd look at LDIF and/or text/directory.  Most\ndeployed LDAP servers have LDIF support for import/export. \n\n- Chris\n\n\n\n", "id": "lists-007-10458356"}, {"subject": "The marketplace, RPC and IPP (was RE: Application &quot;core protocol&quot; ,  BOF/WG idea", "content": "On Thu, 28 Jan 1999, Manros, Carl-Uno B wrote:\n> I think we should also look into why earlier attempts have failed.\n\nIt's often hard and sometimes impossible to identify why a protocol didn't\nget deployed or used.  It may have nothing to do with technical merit. \nI'd rather focus on operational problems or successes with deployed\nprotocols, which can be documented in a mostly objective fashion.\n\n> RFC 1831 defines a working RPC mechanism, which could potentially have \n> been used by multiple application protocols but wasn't.\n\nMy speculation, which I can't back up with research, is that RPC\nmechanisms are a poor choice in general for standards-based protocols.\nIt's much harder to design an extensible and simple API than it is to\ndesign an extensible and simple wire protocol.  In addition, APIs by their\nnature tend to have significant biases in the direction of programming\nlanguage or operating system.  Finally, RPCs are designed to \"hide\" the\nnetwork -- I think the network and network latency in particular needs to\nbe explicitly factored into the design at several levels.  Non-RPC\nprotocols tend to force that to happen in practice.\n\n> The IPP WG looked at this as an alternative to using HTTP, but came to\n> the conclusion that there were few if any implementations of RFC 1831,\n> and it was certainly not \"on everybody's desktop\" like HTTP.\n\nIt seems really strange to think of a general purpose RPC mechanism and a\nhypertext/MIME transfer application protocol as similar beasts... Which\nbrings me to a question I've been wondering about: TCP is on more desktops\nthan HTTP and has a significantly smaller code footprint, so why didn't\nyou just build IPP on TCP?\n\n> Do we know why RFC 1831 was never picked up by the market place, and\n> how we can avoid making yet another generic application protocol,\n> that does not get implemented?\n\nThe marketplace is fickle so there's no way to be assured of success.  The\nbest chance is to design for technical excellence, as illuminated by our\npast successes and operational problems.  I'll note that IMAP was around\nfor 10 years before the marketplace really picked it up.  Was IMAP ahead\nof it's time, too complex, not properly publicised or was the marketplace\njust being stupid?  I couldn't guess the relative influence of those\nfactors, and I don't think it's feasible to study.\n\n- Chris\n\n\n\n", "id": "lists-007-10468621"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "Chris:\n\nThere are two reasons to do what you suggest, only one of which will\nfly.\n\n[1]To provide guidance on not having to repeat the same mistakes made\nby\nothers.  This is a good thing.\n\n[2]To provide mechanisms that keep us from existing using\nprotocols inappropriately.\n\nI think [1] can be accomplished with a BCP, stating those BCPs (make a\nstronger statement than Informational).  I do not think [2] can\nrealistically be accomplished, given the motivations of application\ndevelopers in using protocols such as HTTP.  HTTP offers no real\nintrinsic benefit over TCP, other than that it gets through many\nfirewalls in a nearly unrestricted fashion.\n\nFurther, it's not clear that developing an APPLCORE protocol is\nreasonable to attempt, since it will force you into too many LCD\nsituations with lots of options.  This is something that we in the IETF\nhave struggled with in the past.  \"We have seen ISO and they are us.\"\n--\nEliot Lear\nelear@cisco.com\n\n\n\n", "id": "lists-007-10479297"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Fri, 29 Jan 1999, Graham Klyne wrote:\n> Specifically, I find the idea that we can \"design a simple core protocol to\n> address these problems\" is something of a tall order.\n\nYou may be right.  But what if we can?  Just because it might be hard does\nthat mean we shouldn't try?  While protocol building blocks like SASL are\nvery useful to new protocol developers and multi-protocol software\nproducts, a successful \"core protocol\" would be much more useful. \n\nI'll note one ad-hoc attempt at such a \"core protocol\" was published as\ndraft-earhart-ap-spec-01.txt (January 1998).  It was heavily based on IMAP\nand ACAP.  Now I happen to think that was too complex and needed to be\nilluminated by other successful IETF protocols and a more careful study of\nthe deployed use of the core protocol facilities in IMAP.  But it did\naddress many (most?) of the problems listed in the proposed charter in 24\npages.  It's at least a good indication that a solution to the \"core\nprotocol\" problem is viable. \n\n> What I do think may\n> be achievable is to identify a range of problems, and then make\n> recommendations about solutions to these.\n\nI see a set of \"protocol building blocks\" as the fallback position if\nrough concensus on a simple core protocol fails.\n\n> So, instead of \"core protocol\", how about \"core protocols\"?\n\nI'd prefer to focus on a single \"core protocol\" based on the\nconnection-based stateful client-server structure that most successful\nIETF application protocols follow.  There are obviously other protocol\nmodels with which we have far less experience, but most of those _are_\nresearch problems and thus out-of-scope. \n\n- Chris\n\n\n\n", "id": "lists-007-10488136"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Fri, 29 Jan 1999, Eliot Lear wrote:\n> There are two reasons to do what you suggest, only one of which will\n> fly.\n> \n> [1]To provide guidance on not having to repeat the same mistakes made\n>       by others.  This is a good thing.\n\nI agree this is a good thing, but I also suspect that by itself it lacks\nsufficient benefit to motivate people to do the hard work.  Anyone could\nhave documented the mistakes of the past at any time.  The closest anyone\ncame to doing so that I'm aware of was my internet draft:\ndraft-newman-protocol-design-01.txt\nBut I found myself lacking sufficient motivation to continue that hard\nwork.  It cost a lot of time and had no visible benefit.\n\n> [2]To provide mechanisms that keep us from existing using\n> protocols inappropriately.\n\nGiven the way you've worded this I'd have to agree.  I don't think the\nIETF can or should forbid people from abusing existing protocols.  That's\nnot something a concensus organization should do.  But we can develop a\nsimple alternative to abusing existing protocols which addresses most of\nmotivations for such abuse.  I consider that the vital motivation for this\neffort.\n\n> I think [1] can be accomplished with a BCP, stating those BCPs (make a\n> stronger statement than Informational). \n\nWhile I wouldn't oppose it being a BCP, I really don't think that's\nnecessary.  If we document past mistakes anywhere, we can always point to\nit and say \"you're repeating this mistake.\"\n\n> Further, it's not clear that developing an APPLCORE protocol is\n> reasonable to attempt, since it will force you into too many LCD\n> situations with lots of options.  This is something that we in the IETF\n> have struggled with in the past.\n\nI believe it's possible to make reasonable decisions to avoid too many LCD\noptions.  But this is an interesting point which I will keep in mind.\n\n> \"We have seen ISO and they are us.\"\n\nFunny, I see APPLCORE as an attempt to counter-act one ISOism that's\ncreeping into the IETF.  ISO tends to require the use of lots of\novercomplex and often unnecessary protocol and encoding layers.  I see\nAPPLCORE as creating a simpler alternative to some really large and\ncomplex protocol layers (with lots of unnecessary complexity) people are\ninsisting on using. \n\n- Chris\n\n\n\n", "id": "lists-007-10497628"}, {"subject": "RE: Label header vs PROPFIND depth ", "content": "Jim,\n\neven of depth operations aren't supported, we still have several issues with\nthe LABEL header. In particular, allowing GET to act on the label makes the\nversion by *definition* a variant of the VCR. I didn't have the impression\nthat anybody is willing to support that design decision...\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Jim Amsden\n> Sent: Friday, May 03, 2002 3:56 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> I'd be happy with deprecating non-0 depth header. There are\n> better ways to\n> get related versions of resources. This would seem to solve the problem\n> with minimal effect on the spec, and provide one-trip access to a\n> specific\n> version of a resource (for diff purposes, etc.).\n>\n>\n>\n>\n> Geoff,\n>\n> - I'd like to see the label *header* deprecated\n> - I'm happy with the LABEL method and the label-name-set property\n> - I think that PROPFIND/label should be replaced by a specific REPORT\n> - I'm unsure about other methods that are currently affected by the\n> header -- what were the requirements...?\n> - Servers that decide to implement LABEL and DAV:label-name-set, but no\n> not\n> support the label header should *not* report the LABEL feature in OPTIONS.\n>\n> Julian\n>\n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Friday, April 26, 2002 4:54 PM\n> > To: 'Deltav WG'\n> > Subject: RE: Label header vs PROPFIND depth 1\n> >\n> >\n> > I am not surprised the Label header is proving to be problematic.\n> > The last time I tried to get rid of it (obviously unsuccessfully)\n> > was about a year ago.\n> >\n> > My first choice would be to deprecate the Label header altogether, and\n> > to instead define a DAV:labeled-version report on a VCR, whose\n> > parameters were a label and a list of property names.  The result of\n> > this report would be the values of the specified properties on the\n> > version selected by the specified label from the VCR identified by the\n> > request-URL.\n> >\n> > An alternative approach would be to deprecate the use of the Label\n> > header with a non-zero Depth request (either because of an explicit\n> > non-zero Depth header, or because a request is non-zero Depth by\n> > default).\n> >\n> > I'd be interested in responses on the following three questions:\n> >\n> > (1) Do these approaches address the issues raised?\n> > (2) Is there another approach that could be considered?\n> > (3) Which approach do you prefer?\n> >\n> > If we can get consensus on an approach, I'll add it to the RFC 3253\n> > Errata document.\n> >\n> > Cheers,\n> > Geoff\n> >\n> >\n>\n>\n>\n>\n>\n>\n>\n\n\n\n", "id": "lists-007-1054296"}, {"subject": "HTTP 1.1 (RFC 2616) in PDF forma", "content": "I have run the HTTP 1.1 (RFC 2616) through the Acrobat\nDistiller (version 3) to obtain a PDF version. The PDF\nversion is available at\n   http://www.dsv.su.se/~jpalme/ietf/rfc2616-HTTP-1-1-draft.pdf\n\nIf, however, there is a more official PDF version\navailable, I will delete the file above. It would of course\nbe more valuable if the PDF version got clickable links in\nthe table of content and index, but I have not done that.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10551319"}, {"subject": "Re: Issues in EU-funded ratings research projec", "content": "At 11.08 +0200 99-05-27, Jacob Palme wrote:\n> The EU-funded research project SELECT\n> ( http://cmc.dsv.su.se/select ) has as its main goal to\n> develop a rating system for web pages. This system will\n> allow people, whenever they see a web page, to give their\n> rating of this web page on a scale from \"very poor\" to\n> \"superior\". The ratings will be stored in a data base, and\n> people will be able to make searches of rated documents,\n> such as \"find all documents whose upper quartile rating is\n> higher than 'good'\" and has the keyword 'SMTP'\" or \"find\n> all documents highly rated by people who often rate\n> documents the same way I rate documents\".\n>\n> We will try to use open standards as much as possible, so\n> that people can re-place one part of our system and\n> continue to use the rest of the system. For example\n> re-placing the user interface, but keep the data base, or\n> the reverse. Since there already is a standard for ratings,\n> PICS, we will with high probability use it, where possible.\n\nI have now been looking more at the encoding needs for\nSELECT. SELECT will need a number of protocol elements\nwith a somewhat complex internal structure. Examples of\nprotocol elements needed:\n\nGet service-           Find out which rating services are handled by\ndescription-list       this server\n\nGet service-           Find out which rating categories are handled by\ndescription            this service\n\nSend-rating            Send a rating on a resource\n\nRegister-rater         Register a rater with a server\n\nLogin                  Establish credentials for a user\n\nLogout                 Waive credtentials for a user\n\nSearch                 Make a search for rated resources\n\nEvaluate               Get the ratings for a list of resources\n\nFind news              Find new resources of special interest to a\n                       particular user\n\nExchange-ratings-data  Mirror ratings data between two SELECT servers\n\nWhen I wrote my previous message to this list, I said that\nwe were going to use PICS as a basis, since PICS is an\nalready existing standard for some of the protocol elements\nwe need. PICS has part of the functionality we need, but\nlacks the \"Send-rating\", \"Search\" and \"Find news\" function,\nand is possibly restricted in the kind of data formats\nallowed for ratings.\n\nWe are now considering another alternative, which is to use\nXML for the encoding of our protocol elements. XML has some\nadvantages compared to PICS:\n\n(1) There is, and will even more in the future be, much\n    software available for various processing of XML-formatted\n    data.\n\n(2) XML is a neater and more readable format than PICS.\n\n(3) XML can be extended in neater ways than PICS.\n\nXML has also disadvantages:\n\n(4) Unless compression is used, somewhat more characters\n    are needed.\n\n(5) When there is an existing standard, like PICS, it is of\n    course an advantage to use it. Because of this, if we chose\n    to use XML, we will try to make the XML encoding equivalent\n    to PICS, so that we may in the future easily provide\n    servers which can provide ratings using either XML and PICS.\n\nOne could of course also consider to use PICS where it\nsuffices, and add what PICS cannot do, using XML. But this\nwould not be very neat.\n\nCan anyone give us any comments on the choice of PICS or XML\nfor our protocols?\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10558283"}, {"subject": "[Fax] Summary of Internet Fax WG - July 9", "content": "To all -  \n\nAttached is the summary for the IETF Fax WG meeting held on July 13, 1999\n\nFax WG Summary\n\nThe meeting began with a status review of the ITU cooperation.   The T.37\nAmendment\n1, which adds support for the \"Full Mode\" by referencing the IETF 2530-2\nseries on extended\nInternet fax, was not passed in April, mainly due to RFC refererence\nissues.  However, a \nrevised T.37 Amend 1 has been prepared and is up for approval in September.\n  The status of progressing the simple mode documents to draft standard\nlevel was also reviewed.   The drafts have been clarified in small ways\nfrom the RFCs and seem to be in good shape.  Interworking efforts are also\nproceeding well for the simple mode, but a call was made for implementors\nthat support RFC 2303-4 on Offramp addressing to contact the chair about\nconducting interworking tests with other vendors.   A cover page draft was\nreviewed and the room feels that this work is important to complete; it was\nnoted that the multipart/fax MIME concept is likely to be replaced by\nsomething else, which will be considered jointly with voice and email\nexperts.  It was confirmed that the WG wants to produce an implementors\nguide targeted to informational status and a design team is forming. Two\ncommunications from the ITU were reviewed.  The first deals with aspects of\nthe extended mode that could benefit from clarification:  1)  Refinements\nto the request/response process for capabilities via DSN/MDN 2)  Extending\nMDN to get Page level granularity 3)  Providing better precision in how MDN\nwill report on the processing results for attachments.    There was some\ndiscussion on each item and directions on how to proceed were established.\n The second communication was on synchronization between T.30 and related\nRFCs; approaches for this were also discussed.   The WG will review the\nitems in the communications and the chair will draft a response.   The\nmeeting concluded with a milestone review, which targets moving simple mode\nto draft std later this summer and concluding the current 3 drafts in\nprocess.   \n\n------ end of summary ---------------\n*------------------------------------------------*\nJames Rafferty\nPresident, Human Communications LLC\n12 Kevin Drive\nDanbury, CT  06811-2901\nUSA\nVoice/Fax:  +1-203-746-4367\nFax to email:  +1-603-925-5753\nEmail/Internet Fax:  JRafferty@worldnet.att.net\n J_Rafferty_HC@csi.com\n     jrafferty@humancomm.com\n\nHC Web Site:  http://www.humancomm.com  \n*---------------------------------------------------\n\n\n\n", "id": "lists-007-10569016"}, {"subject": "Summary of VPIM BOF - July 9", "content": "Folks,\n\nAttached is the summary of the VPIM BOF meetings held July 12 & 13, 1999 at\nIETF 45.  The minutes will be available shortly for your comments.\n\nCheers,\nGlenn.\n\n----------------------------------------------------------\nGlenn Parsons               Internet Application Standards\n                            Nortel Networks\nPhone: +1-613-763-7582      Ottawa, Ontario, CANADA\nG3fax: +1-613-763-4461\nEmail: Glenn.Parsons@NortelNetworks.com\n\n\n\nVPIM (Voice Profile for Internet Mail) BOF\n==========================================\n\nThe proposed charter that describes the VPIM v2 and VPIM v3 work was\ndiscussed.  Several minor changes were suggested -- notably, it was\nclarified that the primary goal of VPIM v3 was to support desktop clients\nand that the work of the Internet Fax group be included.  The charter was\nagreed and will be sent to the list for final comments before forwarding to\nthe ADs.  The VPIM web site and mailing list were problematic during the\nmeeting and will be fixed.\n\nThe VPIM v2 revision was reviewed and it was noted that the posted draft was\nmissing the last few pages -- a complete copy will be posted.  The goal is\nto advance VPIM v2 to Draft Standard.  To achieve this, the references must\nbe evaluated and an interop report created based on the testing.  Most\nproposed changes were non-controversial, however it was pointed out that if\nthe vCard was changed to inline (ie, a protocol change) VPIM v2 would have\nto recycle at Proposed.\n\nThe VPIM v3 discussion quickly bogged down into a codec debate -- the room\ndisagreed with the mandatory 6 or more codecs.  After much discussion, it\nwas proposed that for backwards compatibility the codec must be G.726 and\nfor desktop compatibility it must be MS-GSM.  It was proposed to split VPIM\nv3 into mandatory desktop compatibility and optional backwards\ncompatibility.  The primary content semantic for unified messaging proposed\nfor multipart/voice-message & multipart/fax-message was again rejected in\nfavour of a more general approach.  This might use multipart/related with a\nvoice or fax parameter along with partial MDNs or DSNs.\n\nThe IMAP Voice requirements were discussed and several were discounted as\nbeing not IMAP issues (message length) or already solved (streaming).  The\nbinary requirement was moved to the IMAPext BOF.\n\n\n\n", "id": "lists-007-10579762"}, {"subject": "AD:Family Reunion T Shirts &amp; Mor", "content": "Message sent by:  Kuppler Graphics, 32 West Main Street, Maple Shade, New Jersey, 08052,\n1-800-810-4330.   This list will NOT be sold.  All addresses \nare automatically added to our remove list.\n\nHello.  My name is Bill from Kuppler Graphics.  We do screenprinting on T Shirts, Sweatshirts,\nJackets, Hats, Tote Bags and more!\n\nDo you or someone you know have a Family Reunion coming up?  Kuppler Graphics would like to\nprovide you with some great looking T Shirts for your Reunion.\n\nKuppler Graphics can also provide you with custom T's and promotional items such as imprinted\nmagnets, keychains, pens, mugs, hats, etc. for your business or any fundraising activity\n(church, school, business etc.) We also can provide you with quality embroidery. \n\nWe are a family owned company with over 15 years of experience.  \n\nAll work is done at this location.  No middle man.  Our prices are great!\n\nClick reply to email us or call 1-800-810-4330 for more info\n\n\nBill\nKuppler Graphics\n \n \n \n \n \n \n \n \n \n \n \n \n \n\n\n\n", "id": "lists-007-10589846"}, {"subject": "Personal notes from the IETF meeting in Oslo,  July 199", "content": "My personal notes (not official minutes) from the IETF\nmeeting in Oslo, July 1999, can be found at\n   http://www.dsv.su.se/~jpalme/ietf/ietf-july-99-notes.html\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10596987"}, {"subject": "RE: Personal notes from the IETF meeting in Oslo, July 199", "content": "Jacob,\n\nCould you please change the link to the DESIRE site from the (old)\nSURFnet site to the current site at http://www.desire.org/? Thanks,\n\nTon.\n\n|  My personal notes (not official minutes) from the IETF\n|  meeting in Oslo, July 1999, can be found at\n|     http://www.dsv.su.se/~jpalme/ietf/ietf-july-99-notes.html\n|\n\n\n\n", "id": "lists-007-10604821"}, {"subject": "IAB draft on securit", "content": "This list might be interested in draft-iab-secmech-01.txt. It describes the \napplicability of various IETF security mechanisms to various situations, \nincluding applications. Steve Bellovin says he hasn't gotten much comment \non it and wants to go to last call soon, so you should review it soon and \nlet him know if you have any changes or desired additions.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-10612945"}, {"subject": "Re: IAB draft on securit", "content": "At 20.44 -0700 99-07-21, Paul Hoffman / IMC wrote:\n>This list might be interested in draft-iab-secmech-01.txt. It \n>describes the applicability of various IETF security mechanisms to \n>various situations, including applications. Steve Bellovin says he \n>hasn't gotten much comment on it and wants to go to last call soon, \n>so you should review it soon and let him know if you have any \n>changes or desired additions.\n\nThe document, like many other security documents, tells too much \nabout what will not work, too little on what will work. It seems as \nif security experts are better at telling you that something is \ndangerous or might not be secure, than telling you how to get \nsecurity. I would prefer to get more practical advice with\nrecommendations on how to get the security you want.\n\nThis may be a reason why security techniques have so much trouble \ngetting accepted and used.\n\nI was interested to note the warnings against MD5, since MD5 is so \npopular. But why not tell us what we should use instead of MD5, \ninstead of just saying that MD5 has security risks.\n\nThere was no mention of the export restriction problem with\nencryption tools. Is this not a major problem? How can you\nresolve it?\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10621251"}, {"subject": "Re: IAB draft on securit", "content": "In message <v04210106b3c1d31e6300@[130.237.150.138]>, Jacob Palme writes:\n> At 20.44 -0700 99-07-21, Paul Hoffman / IMC wrote:\n> >This list might be interested in draft-iab-secmech-01.txt. It \n> >describes the applicability of various IETF security mechanisms to \n> >various situations, including applications. Steve Bellovin says he \n> >hasn't gotten much comment on it and wants to go to last call soon, \n> >so you should review it soon and let him know if you have any \n> >changes or desired additions.\n> \n> The document, like many other security documents, tells too much \n> about what will not work, too little on what will work. It seems as \n> if security experts are better at telling you that something is \n> dangerous or might not be secure, than telling you how to get \n> security. I would prefer to get more practical advice with\n> recommendations on how to get the security you want.\n\nHmm -- I thought that it was doing that; its whole purpose was to provide\na list of techniques that could be used in specific niches.  I'll reread it\nfrom that perspective.\n> \n> This may be a reason why security techniques have so much trouble \n> getting accepted and used.\n> \n> I was interested to note the warnings against MD5, since MD5 is so \n> popular. But why not tell us what we should use instead of MD5, \ninstead of just saying that MD5 has security risks.\n\nWill fix.\n> \n> There was no mention of the export restriction problem with\n> encryption tools. Is this not a major problem? How can you\n> resolve it?\n\nThe IETF decided long ago that this was (mostly) a US problem, and that we\nwouldn't let our standards be crippled to accomodate it.\n\n\n\n", "id": "lists-007-10629860"}, {"subject": "RE: IAB draft on securit", "content": "Hello Jacob and Steve,\n\nJacob wrote\n\n\nThe document, like many other security documents, tells too much \nabout what will not work, too little on what will work. It seems as \nif security experts are better at telling you that something is \ndangerous or might not be secure, than telling you how to get \nsecurity. I would prefer to get more practical advice with\nrecommendations on how to get the security you want.\n\nThis may be a reason why security techniques have so much trouble \ngetting accepted and used.\n\n\nIMHO there are 4 reasons why security techniques are not widely used.\nMore or less in order of importance\n1) Mostly much too complicated and time consuming for the average user to set up and use.\n2) Confusion caused by competing standards S/MIME vs PGP.\n3) Confusion caused by US gov interference.\n4) Confusion caused by licencing and patent issues.\n\nNot much can be done about about 2 & 3 but maybe some comments on 1  and  information (patented/not patented) on 4 could be usefully included in the document ??\n\n\nGeoff Marshall\n\n\n\n", "id": "lists-007-10638861"}, {"subject": "Re: IAB draft on securit", "content": "At 11:01 26/07/99 +0200, Jacob Palme wrote:\n\n>The document, like many other security documents, tells too much \n>about what will not work, too little on what will work. It seems as \n>if security experts are better at telling you that something is \n>dangerous or might not be secure, than telling you how to get \n>security. I would prefer to get more practical advice with\n>recommendations on how to get the security you want.\n\nI think this is a fair comment, that may also reflect the very nature of\nsecurity.\n\nI am reminded of a little game that is very prevalent on a certain desktop\noperating system:  Minesweeper.  (The goal is to uncover a number of hidden\nmines by stomping on all the squares that do NOT contain mines:  to stomp\non a mine is sudden death.)\n\nMaking systems secure seems a similar kind of activity:  experts can tell\nus where mines are known to exist, but it is both imperative and very\ndifficult to deduce where mines certainly do not exist.\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-10647979"}, {"subject": "Re: IAB draft on securit", "content": "At 11:01 26/07/99 +0200, Jacob Palme wrote:\n\n>The document, like many other security documents, tells too much \n>about what will not work, too little on what will work. It seems as \n>if security experts are better at telling you that something is \n>dangerous or might not be secure, than telling you how to get \n>security. I would prefer to get more practical advice with\n>recommendations on how to get the security you want.\n\nI think this is a fair comment, that may also reflect the very nature of\nsecurity.\n\nI am reminded of a little game that is very prevalent on a certain desktop\noperating system:  Minesweeper.  (The goal is to uncover a number of hidden\nmines by stomping on all the squares that do NOT contain mines:  to stomp\non a mine is sudden death.)\n\nMaking systems secure seems a similar kind of activity:  experts can tell\nus where mines are known to exist, but it is both imperative and very\ndifficult to deduce where mines certainly do not exist.\n\n#g\n\n\n\n", "id": "lists-007-10656520"}, {"subject": "RE: IAB draft on securit", "content": "(Thanks to Paul, for starting this ver important thread.)\n\nThe current draft is wonderfully concise and readable.  For the non-expert, \nit is an excellent way to learn both about the current range of standard \n(and non-recommended) techniques and some issues about their uses.\n\nI think it needs more, not different, text.\n\n\nAt 06:24 AM 7/26/99 , Geoff wrote:\n>1) Mostly much too complicated and time consuming for the average user to \n>set up and use.\n>2) Confusion caused by competing standards S/MIME vs PGP.\n>3) Confusion caused by US gov interference.\n>4) Confusion caused by licencing and patent issues.\n\n\nNice list of possibilities.  They do not all have the same import.\n\nI think that the complexity of \"valid\" security mechanisms (by which I mean \nmechanisms that have real-world effectiveness, for the level/quality of \nsecurity promised) is very hard to design.  That is a technical limitation, \nwithin the technical community.  It is best demonstrated by the constant \nping-pong IETF process of having applications folk try to design a \nmechanism and having security experts shoot it down.\n\nPossible guidance for Bellovin's paper:\n\nAdd a section 7, with recommendations for entire security \"systems\" to be \nused for particular scenarios.  Yes, this is requesting the cookbook \napproach that the document specifically warns against, but I have long felt \nthat we have no choice.\n\nShow some very common application environments and recommend a specific SET \n(no pun intended) of tools, based on the protections needed.  (Start with \napplication or connection type, move to protection type, then list \ntechniques recommended.)\n\nFrankly I view this as a human factors problem.  We need to make it easier \nto use these technologies.  Use by protocol designers, as well as use by \nsysadmins and end-users.  In other words, I think that the REAL barrier to \nsecurity use is variations on Geoff's #1.  #2-4 affect quality of use and \neffectiveness, but I do not believe they are the real \"market\" barrier.\n\nFor now, it is very difficult for non-experts to design protocol services \nthat the security experts approve.  The cookbook should attack (pun \nintended) that problem directly.\n\nHowever, it is also very difficult to install and run a security \nservice.  The choices made for the document should reflect easier/harder \noperations.\n\nAnd end-users trying to set up their security environment, such as for PGP \nor S/MIME, are usually hit with far, far too much complexity.  (It does not \nhelp that the security module is often an add-on, rather than built-in.)\n\nWe can't do anything about end-user complexity, other than try to raise the \nissue for developers, unless there are specific implementation suggestions \nwe can offer than will make things simpler.\n\nd/\n\n\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\nDave Crocker                                         Tel: +1 408 246 8253\nBrandenburg Consulting                               Fax: +1 408 273 6464\n675 Spruce Drive                             <http://www.brandenburg.com>\nSunnyvale, CA 94086 USA                 <mailto:dcrocker@brandenburg.com>\n\n\n\n", "id": "lists-007-10664787"}, {"subject": "ANN: draft-reschke-deltav-compute-checkin-uri-0", "content": "Hi,\n\na new version of \"draft-reschke-deltav-compute-checkin-uri\" is available\nfrom the IETF ID directory [1] and our WebDAV resources page [2].\n\nFrom the abstract:\n\n\"In many cases, a versioning-aware client might want to display/include the\nURI of the version it's editing while it's being edited. For instance, an\neditor might include this as meta information, or the author of a document\nmight want to know the URI of the version before it's checked in. A\nwell-known example is the W3C way of referring to document versions in\nrecommendations: it contains references to \"the current version\", to \"this\nversion\" and to the \"previous version\". Something like this is currently\nimpossible with WebDAV versioning [RFC3253], as the version URI is\ndetermined at the time of CHECKIN.\"\n\nChanges:\n\n\"Updated abstract not to refer to DeltaV WG anymore. Use \"WebDAV versioning\"\ninstead of \"deltaV\".\nChanged descriptions to use RFC3253's Marshalling/Precondition format.\nChanged name of cu:cannot-assign-expected-version-URI to\ncu:can-assign-expected-version-URI as this is a precondition.\"\n\nNext steps:\n\nWill be probably submitted as informational RFC.\n\n\n[1]\n<http://www.ietf.org/internet-drafts/draft-reschke-deltav-compute-checkin-ur\ni-02.txt>\n[2] <http://greenbytes.de/tech/webdav/>\n\n\n\n", "id": "lists-007-1066916"}, {"subject": "RE: IAB draft on securit", "content": "I think the cookbook is an excellent suggestion.\nAnd as I also believe that for messaging it's time to dump both PGP and S/MIME in favour of something much simpler to implement, maybe the cookbook could outline an alternative.\nGeoff\n\n\n(Thanks to Paul, for starting this ver important thread.)\n\n\nThe current draft is wonderfully concise and readable.  For the non-expert, \nit is an excellent way to learn both about the current range of standard \n(and non-recommended) techniques and some issues about their uses.\n\nI think it needs more, not different, text.\n\n\n\nAt 06:24 AM 7/26/99 , Geoff wrote:\n>1) Mostly much too complicated and time consuming for the average user to \n>set up and use.\n>2) Confusion caused by competing standards S/MIME vs PGP.\n>3) Confusion caused by US gov interference.\n>4) Confusion caused by licencing and patent issues.\n\n\nNice list of possibilities.  They do not all have the same import.\n\nI think that the complexity of \"valid\" security mechanisms (by which I mean \nmechanisms that have real-world effectiveness, for the level/quality of \nsecurity promised) is very hard to design.  That is a technical limitation, \nwithin the technical community.  It is best demonstrated by the constant \nping-pong IETF process of having applications folk try to design a \nmechanism and having security experts shoot it down.\n\n\nPossible guidance for Bellovin's paper:\n\nAdd a section 7, with recommendations for entire security \"systems\" to be \nused for particular scenarios.  Yes, this is requesting the cookbook \napproach that the document specifically warns against, but I have long felt \nthat we have no choice.\n\nShow some very common application environments and recommend a specific SET \n(no pun intended) of tools, based on the protections needed.  (Start with \napplication or connection type, move to protection type, then list \ntechniques recommended.)\n\nFrankly I view this as a human factors problem.  We need to make it easier \nto use these technologies.  Use by protocol designers, as well as use by \nsysadmins and end-users.  In other words, I think that the REAL barrier to \nsecurity use is variations on Geoff's #1.  #2-4 affect quality of use and \neffectiveness, but I do not believe they are the real \"market\" barrier.\n\nFor now, it is very difficult for non-experts to design protocol services \nthat the security experts approve.  The cookbook should attack (pun \nintended) that problem directly.\n\nHowever, it is also very difficult to install and run a security \nservice.  The choices made for the document should reflect easier/harder \noperations.\n\nAnd end-users trying to set up their security environment, such as for PGP \nor S/MIME, are usually hit with far, far too much complexity.  (It does not \nhelp that the security module is often an add-on, rather than built-in.)\n\nWe can't do anything about end-user complexity, other than try to raise the \nissue for developers, unless there are specific implementation suggestions \nwe can offer than will make things simpler.\n\nd/\n\n\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\nDave Crocker                                         Tel: +1 408 246 8253\nBrandenburg Consulting                               Fax: +1 408 273 6464\n675 Spruce Drive                             <http://www.brandenburg.com>\nSunnyvale, CA 94086 USA                 <mailto:dcrocker@brandenburg.com>\n\n\n\n", "id": "lists-007-10675883"}, {"subject": "RE: IAB draft on securit", "content": "At 01:43 AM 7/27/99 , Geoff wrote:\n>I think the cookbook is an excellent suggestion.\n>And as I also believe that for messaging it's time to dump both PGP and \n>S/MIME in favour of something much simpler to implement, maybe the \n>cookbook could outline an alternative.\n\noh, god, please don't tackle that issue in this document.\n\n(On the other hand, if there is a serious technical constituency that could \nput forward a subsetting of one of them, to reduce the entry cost, that \nwould be delightful to see discussed independently.)\n\nd/\n\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\nDave Crocker                                         Tel: +1 408 246 8253\nBrandenburg Consulting                               Fax: +1 408 273 6464\n675 Spruce Drive                             <http://www.brandenburg.com>\nSunnyvale, CA 94086 USA                 <mailto:dcrocker@brandenburg.com>\n\n\n\n", "id": "lists-007-10687176"}, {"subject": "Re: IAB draft on securit", "content": "I am responding to this in what I hope will be seen as a constructive\nspirit.  There seems to be a general feeling that this draft contains good\ninformation, but more is desirable.  I try to suggest some areas that I, as\na non-security-expert, might benefit from additional guidance.\n\nI should add that my comments are made from a perspective of application\nprotocol design, so I may miss many issues that are relevant to lower layer\nprotocol design.\n\n\n>                  Security Mechanisms for the Internet\n>\n>                        draft-iab-secmech-00.txt\n\n[...]\n>3. Introduction\n>\n[...]\n>\n>   Finally, security mechanisms are not magic pixie dust that can be\n>   sprinkled over completed protocols.  It is rare that security can be\n>   bolted on later.  Good designs--that is, secure, clean, and efficient\n>   designs--occur when the security mechanisms are crafted along with\n>   the protocol.\n\nThis idea of \"designed-in\" security is oft-repeated, and I don't think\nanyone seriously disagrees (I don't!).\n\nBut when I think about it, I'm not really clear what it means to \"design\nin\", other than to design the security mechanisms at the same time as the\nprotocol (which is effectively what you say) -- is there more?\n\nFor example, in dealing with messaging-related protocols it is easy to say\nthat some form of object security should be applied to the message content,\nand cite RFC 1847, S/MIME, OpenPGP, etc.  To me, this feels like \"bolt-on\"\nsecurity but it's not clear to me what more can and should be done.  Can\nmore guidance be offered?\n\n\n>4. Decision Factors\n>\n>\n>4.1. Threat Model\n\nI think that a checklist of possible threats might be helpful for\nnon-security-experts:  it might give us something around which to structure\na \"security considerations\" section in a protocol goals document.\n\nLooking through your draft (and adding a few I think of), I can see:\n- theft of static information\n- theft if information in transit (eavesdropping)\n- traffic analysis\n- service spoofing\n- theft of infrastructure use\n- disruption of infrastructure\n- corruption of data\n- spoofing of identity\n- denial of service\n- insider vs outsider attacks\n- social engineering\n\n\n>   The value of a target to an attacker may depend on where it is\n>   located.  A network monitoring station that is physically on a\n>   backbone cable is a major target, since it could easily be turned\n>   into an eavesdropping station.  The same machine, if located on a\n>   stub net and used for word processing, would be at little risk.\n\nThis paragraph suggests a difference between a threat and a vulnerability\nthat is exploited to realize that threat.  In this case, the network\nmonitoring protocols may have vulnerabilities that can be explpoited to\ncause theft/disruption of infrastructure elements.  Thus, the above list\nshould probably be two:  threats and vulnerabilities.\n\nSome kind of structured approach to guide a non-expert may be helpful.\n\nI can imagine a matrix of threat, exploited vulnerability,\nvalue-to-attacket, value-to-victim, cross-referenced to the kind of\nprotocol for which this needs to be considered.   I imagine a kind of\nliving document that can be updated as the threat/vulnerability/usage\nmodels become better understood.\n\n(I'm not trying to suggest a \"cookbook\" here --that's too much like\npixie-dust-- but a distillation of security knowledge that can hep\ndesigners determine if they have considered the things that a security\nexpert would naturally consider.)\n\n\n>4.2. Granularity of Protection\n[...]\n\nI think granularity has two impacts:  the domain from which certain kinds\nof attack can be launched, and the range of resources that are vulnerable\nto an attack -- would these benefit from being separated more clearly?\n\n\n>4.3. Implementation Layer\n>\n>   Security mechanisms can be located at any layer.  In general, putting\n>   a mechanism at a lower layer protects a wider variety of higher-layer\n>   protocols.  The usual tradeoff is reach; lower-layer protocols\n>   terminate sooner.\n[...]\n\nThis is a very interesing characterization, but I am not sure how it helps\na struggling protocol designer.  I seems to me that we have little choice:\neither the mechanisms must already exist, or the scope for additional\nmechanism is very constrained.\n\n\n>5. Standard Security Mechanisms\n>\n>\n>5.1. Plaintext Passowrds\n[...]\n>   Another weakness arises because of common implementation techniques.\n>   It is considered good form [MT79] for the host to store a one-way\n>   hash of the users' passwords, rather than their plaintext form.\n>   However, that may preclude migrating to stronger authentication\n>   mechanisms, such as HMAC-based challenge/response.\n........................^^^^ add forward reference?\n\n>   The strongest attack against passwords, other than eavesdropping, is\n>   password-guessing.  With a suitable program and dictionary (and these\n>   are widely available), 20-30% of passwords can be guessed in most\n>   environments.\n\nA thought:  I think it's perceived wisdom that it's better to have a fine\ngranularity of password protection (one per user, possibly per\nuser/application).  But doesn't this increase the number of passwords in\nuse, hence the chances of a successful guessing attack?  I guess however\nyou cut it, passwords are not great.\n\n\n[...]\n>5.7. DNSSEC\n>\n>   DNSSEC [RFC2065] digitally signs DNS records.  It is an essential\n>   tool for protecting against cache contamination attacks; these in\n>   turn can be used to defeat name-based authentication and to redirect\n>   traffic to or past an attacker.  The latter makes DNSSEC an essential\n>   component of some other security mechanisms, notably IPSEC.\n\nWould it be helpful to clarify the importance of DNSSEC when designing\nother protocols?\n\n\n>5.10. Firewalls and Topology\n[...]\n\nAs guidance for protocol designers, I think it would help to say that\nprotocols should not be designed to sneak or piggyback their way through\nfirewalls.  Rather, a firewall administrator should be able to exercise\nclear and uncluttered control over which services are allowed through, and\nwhich are not.\n\n\n\nAnd a final thought:  some people have noted that human factors are a big\nfactor in the non-deployment and failure of security mechanisms.  Would it\nbe helpful to add a section that discusses human factors, and the kind of\ndesigns that:\n(a) make deployment more likely to be achieved, and\n(b) reduce the chance of security being compromised or subverted by the\nhuman users.\n\nTall order, n'est ce pas?\n\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-10695766"}, {"subject": "Re: IAB draft on securit", "content": "At 08.47 -0400 99-07-26, Steven M. Bellovin wrote:\n>The IETF decided long ago that this was (mostly) a US problem, and that we\n>wouldn't let our standards be crippled to accomodate it.\n\nIt is not a US-only problem. There is an international agreement,\nwhich most of the developed countries have signed, and in which they\npromise to restrict export of encryption. Different countries do, I\nbelieve, interpret this agreement more or less rigorously. I think\nthe agreement has the name Wassenaar Agreement on Export Controls for\nConventional Arms and Dual-use Goods and Technologies, see\n    http://www.techweb.com/wire/story/TWB19990518S0038\n\nI know that in Sweden, a number of companies have had problems with\nnot being allowed to export encryption. France has earlier been very\nstrict on this, but I have heard that they are changing their minds.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10709522"}, {"subject": "RE: IAB draft on securit", "content": "> At 08.47 -0400 99-07-26, Steven M. Bellovin wrote:\n> >The IETF decided long ago that this was (mostly) a US problem, and that we\n> >wouldn't let our standards be crippled to accomodate it.\n\nA document that gives security guidelines for IETF protocols\nshould explain this policy and its impact.\n\nLarry\n\n\n\n", "id": "lists-007-10717892"}, {"subject": "Re: IAB draft on securit", "content": "Jacob,\n\nBut whatever the legal/political situation, the IETF can only\nwork on technology specifications.\n\n  Brian\n\nJacob Palme wrote:\n> \n> At 08.47 -0400 99-07-26, Steven M. Bellovin wrote:\n> >The IETF decided long ago that this was (mostly) a US problem, and that we\n> >wouldn't let our standards be crippled to accomodate it.\n> \n> It is not a US-only problem. There is an international agreement,\n> which most of the developed countries have signed, and in which they\n> promise to restrict export of encryption. Different countries do, I\n> believe, interpret this agreement more or less rigorously. I think\n> the agreement has the name Wassenaar Agreement on Export Controls for\n> Conventional Arms and Dual-use Goods and Technologies, see\n>     http://www.techweb.com/wire/story/TWB19990518S0038\n> \n> I know that in Sweden, a number of companies have had problems with\n> not being allowed to export encryption. France has earlier been very\n> strict on this, but I have heard that they are changing their minds.\n> ------------------------------------------------------------------------\n> Jacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\n> for more info see URL: http://www.dsv.su.se/~jpalme\n\n-- \n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nBrian E Carpenter (IAB Chair)\nProgram Director, Internet Standards & Technology, IBM Internet Div\nOn assignment for IBM at http://www.iCAIR.org \nNon-IBM email: brian@icair.org\n\n\n\n", "id": "lists-007-10725231"}, {"subject": "Re: IAB draft on securit", "content": "Larry Masinter wrote:\n> \n> > At 08.47 -0400 99-07-26, Steven M. Bellovin wrote:\n> > >The IETF decided long ago that this was (mostly) a US problem, and that we\n> > >wouldn't let our standards be crippled to accomodate it.\n> \n> A document that gives security guidelines for IETF protocols\n> should explain this policy and its impact.\n> \n> Larry\n\nNot while I'm in the liability line of fire, thank you.\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nBrian E Carpenter (IAB Chair)\nProgram Director, Internet Standards & Technology, IBM Internet Div\nOn assignment for IBM at http://www.iCAIR.org \nNon-IBM email: brian@icair.org\n\n\n\n", "id": "lists-007-10734414"}, {"subject": "Re: IAB draft on securit", "content": "At 03:10 PM 7/27/99 , Brian E Carpenter wrote:\n> > A document that gives security guidelines for IETF protocols\n> > should explain this policy and its impact.\n>\n>Not while I'm in the liability line of fire, thank you.\n\n\nPermit me to presumptuously re-word Larry's suggestion:\n\nA particular set of security technology and operations constraints are \nbelieved by the expert security technical community to carry a particular \nset of exposures and might also carry a set of mis-perceived comforts.\n\nIt would be entirely reasonable for the IETF/IAB to produce a paper stating \nthose constraints, exposures and mis-comforts.\n\nDone objectively, the fact that the constraints might perfectly align with \na particular group's security policies seems unlikely to create legal \nexposures (though, yes, I would expect the legal mis-comforts to continue.)\n\nd/\n\n\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\nDave Crocker                                         Tel: +1 408 246 8253\nBrandenburg Consulting                               Fax: +1 408 273 6464\n675 Spruce Drive                             <http://www.brandenburg.com>\nSunnyvale, CA 94086 USA                 <mailto:dcrocker@brandenburg.com>\n\n\n\n", "id": "lists-007-10742481"}, {"subject": "Re: IAB draft on securit", "content": "Dave,\n\nWhat is missing in RFC 1984 in this respect?\n\n  Brian\n\nDave Crocker wrote:\n> \n> At 03:10 PM 7/27/99 , Brian E Carpenter wrote:\n> > > A document that gives security guidelines for IETF protocols\n> > > should explain this policy and its impact.\n> >\n> >Not while I'm in the liability line of fire, thank you.\n> \n> Permit me to presumptuously re-word Larry's suggestion:\n> \n> A particular set of security technology and operations constraints are\n> believed by the expert security technical community to carry a particular\n> set of exposures and might also carry a set of mis-perceived comforts.\n> \n> It would be entirely reasonable for the IETF/IAB to produce a paper stating\n> those constraints, exposures and mis-comforts.\n> \n> Done objectively, the fact that the constraints might perfectly align with\n> a particular group's security policies seems unlikely to create legal\n> exposures (though, yes, I would expect the legal mis-comforts to continue.)\n> \n> d/\n> \n> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n> Dave Crocker                                         Tel: +1 408 246 8253\n> Brandenburg Consulting                               Fax: +1 408 273 6464\n> 675 Spruce Drive                             <http://www.brandenburg.com>\n> Sunnyvale, CA 94086 USA                 <mailto:dcrocker@brandenburg.com>\n\n\n\n", "id": "lists-007-10751643"}, {"subject": "Typo in RFC 3253, section 5.4.", "content": "Hi,\n\nin the example request, the XML isn't well-formed:\n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<D:locate-by-history xmlns:D=\"DAV:\">\n <D:version-history-set>\n   <D:href>http://repo.webdav.org/his/23</D:href>\n   <D:href>http://repo.webdav.org/his/84</D:href>\n   <D:href>http://repo.webdav.org/his/129</D:href>\n <D:version-history-set/>\n <D:prop>\n   </D:version-history>\n </D:prop>\n</D:locate-by-history>\n\n\n\n[1] <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.5.4.1>\n\n\n\n", "id": "lists-007-1075664"}, {"subject": "RE: IAB draft on securit", "content": "> > > > A document that gives security guidelines for IETF protocols\n> > > > should explain this policy and its impact.\n\n> What is missing in RFC 1984 in this respect?\n\nA set of thorough cross-references to RFC 1984 would be a fine way\nof satisfying this particular goal.\n\n\n\n", "id": "lists-007-10760751"}, {"subject": "RE: IAB draft on securit", "content": "At 04:05 PM 7/27/99 , Larry Masinter wrote:\n> > > > > A document that gives security guidelines for IETF protocols\n> > > > > should explain this policy and its impact.\n>\n> > What is missing in RFC 1984 in this respect?\n>\n>A set of thorough cross-references to RFC 1984 would be a fine way\n>of satisfying this particular goal.\n\n\nI don't agree.\n\nIn effect, 1984 makes a set of cases about general issues.  It's entirely \ngeneric.\n\nI think that something which analyses current detail would be appropriate.\n\nIronically, this should probably be published as a BCP, noting a particular \nset of details and their particular limitations. For example, noting that \nthe details in the current limitation permit highly reliable breakability \nwith (what is it now?) 72 hours, or somesuch.\n\nJust a thought.\n\nd/\n\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\nDave Crocker                                         Tel: +1 408 246 8253\nBrandenburg Consulting                               Fax: +1 408 273 6464\n675 Spruce Drive                             <http://www.brandenburg.com>\nSunnyvale, CA 94086 USA                 <mailto:dcrocker@brandenburg.com>\n\n\n\n", "id": "lists-007-10768729"}, {"subject": "RE: IAB draft on securit", "content": "At 05:02 PM 7/27/1999 -0700, Dave Crocker wrote:\n>I don't agree.\n>\n>In effect, 1984 makes a set of cases about general issues.  It's entirely \n>generic.\n>\n>I think that something which analyses current detail would be appropriate.\n\nI fully agree with Dave.\n\nThe question of \"what about export rules\" come up so often in various \nsecurity debates that it really should be dealt with in the secmech \ndocument. Two or three paragraphs explaining why the IETF rules were \nadopted, what has transpired since RFC 1984 that have shown the rules to be \ngood ones, and advice to implementors who are faced with legal issues \nimplementing the mechanisms described in secmech would go a long way to \ngetting security actually implemented correctly.\n\nWe're not trying to change the laws here, simply to explain why we are not \npaying attention to some transient local laws when we design protocols with \nsecurity.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-10777917"}, {"subject": "RE: Proposal:  Mailing list archive requirement(s", "content": "Non-simultaneous group communication is done through two different\nkinds of services:\n\n(b) Groupware systems, like Usenet news, where the same user interface\n     is used for reading, searching, filtering, writing.\n\n(a) E-mail mailing lists. Here, reading is done by ordinary mail clients,\n     but these mail clients can use filters, to put each list into a\n     separate folder. The reader will then have the same kind of\n     structured reading as in groupware. Archiving is done by separate\n     archiving systems, which again can provide the same services\n     as groupware systems.\n\nI am not sure that users want it to be this way. Users want to discuss\ntopics, organise their discussions, browse old discussions. Users\nprobably prefer to do this in a unified way.\n\nAt 13.43 -0700 99-07-27, Dan Kohn wrote:\n>To make a specific proposal, I think we're suggesting that BCP 25, RC\n>2418 <http://www.normos.org/ietf/bcp/bcp25.txt> should be updated to add\n>additional requirements to the working group mailing lists in section\n>2.2.\n>\n>I would suggest that working group mailing lists have the following\n>additional requirements:\n>\n>1) The mailing list should support standard -request commands for\n>subscription requests.\n>\n>2) The mailing list should have a web-based archive that supports\n>searching and threading.\n>\n>3) The mailing list should also archive the messages in original rfc822\n>message format or in standard Unix mailbox format.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10785668"}, {"subject": "Re: IAB draft on securit", "content": "At 17.09 -0500 99-07-27, Brian E Carpenter wrote:\n>But whatever the legal/political situation, the IETF can only\n>work on technology specifications.\n\nWe might develop solutions which are both technially sound and\nacceptable to the export control people. For example, we might use\ndifferent algorithms for encryption of content, than for the\nencryption used in identification and authorization services. The\nexport control people may be willing to allow longer key length for\nidentification and authorization than for content encryption.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10794118"}, {"subject": "Re: IAB draft on securit", "content": "> We might develop solutions which are both technially sound and\n> acceptable to the export control people. For example, we might use\n> different algorithms for encryption of content, than for the\n> encryption used in identification and authorization services.\n\nwhat makes you think that this approach is technically sound?\n\n\n\n", "id": "lists-007-10802129"}, {"subject": "Re: IAB draft on securit", "content": "At 11:12 AM 7/29/1999 +0200, Jacob Palme wrote:\n>We might develop solutions which are both technially sound and\n>acceptable to the export control people. For example, we might use\n>different algorithms for encryption of content, than for the\n>encryption used in identification and authorization services. The\n>export control people may be willing to allow longer key length for\n>identification and authorization than for content encryption.\n\n...or they might not. The security folks have gotten used to relying on one \npart of a government saying \"you can do that\" but then having another part \nsay \"you can't do that\". And, remember, we'd have to get buy-in from *all* \ngovernments, or at least all the ones we thought were significant. I think \ntrying to keep the security folks in all governments happy is a classic \nrathole.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-10809497"}, {"subject": "Re: IAB draft on securit", "content": "Keith Moore wrote:\n> \n> > We might develop solutions which are both technially sound and\n> > acceptable to the export control people. For example, we might use\n> > different algorithms for encryption of content, than for the\n> > encryption used in identification and authorization services.\n> \n> what makes you think that this approach is technically sound?\n\nIn any case, why is it more acceptable for someone to read my mail\nthan to forge it? The IETF plenary debate on this topic in Danvers\ngave pretty unambiguous input that we should do what's right\nfrom a security viewpoint, not what suits governments.\n\n  Brian\n\n\n\n", "id": "lists-007-10817376"}, {"subject": "User agent, Service agent, Client, Serve", "content": "Is the terminology below correct?\n\nUser agent (UA)     A module which communicates with a user through\n                     a user interface, and performs network operations,\n                     possibly connecting to one or more servers, to\n                     satisfy user requests.\n\nService agent (SA)  An agent which performs services, either in the\n                     background or at the request of User Agents.\n\nClient              A process which opens connections to servers,\n                     and gives commands to them and gets the results.\n\nServer              A process which accepts connections from clients\n                     and either accepts and performs them, or refuses them.\n\nImportant in the terminology above is the distinction between\n\"client\" and \"user agent\". User agents are usually clients, but all\nclients are not user agents.\n\nIf this is the right terminology, what is then the correct word\nfor an HTTP server which provides interactive services using\nHTML forms? From an HTTP viewpoint, such a server is a server\nand not a client. But from an application viewpoint, it is a\nuser agent. So a user agent can be a server.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10824672"}, {"subject": "Re: User agent, Service agent, Client, Serve", "content": "> Is the terminology below correct?\n\nwords like \"client\" and \"server\" and \"user agent\" are inherently fuzzy,\nand are generally meaningless unless you at least say \"relative to what?\"\nso yes, a user agent can be a client, or a server, or both.\n\nKeith\n\n\n\n", "id": "lists-007-10833319"}, {"subject": "RFC 3253 issue vs. DAV:auto-update and working resource", "content": "Hi,\n\n[1] states that DAV:auto-update is a required property for a working\nresource.\n\nHowever, [2] states that \"The DAV:auto-update property of the working\nresource MUST NOT exist.\" is the CHECKOUT is done on a version.\n\nSo, is it required or not? If not, how can I detect that something is a\nworking resource?\n\nJulian\n\n[1] <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.9.2>\n[2] <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.9.3.p.4>\n\n\n\n", "id": "lists-007-1083952"}, {"subject": "Re: User agent, Service agent, Client, Serve", "content": "At 21:07 29/07/99 +0200, Jacob Palme wrote:\n>Is the terminology below correct?\n>\n>User agent (UA)     A module which communicates with a user through\n>                     a user interface, and performs network operations,\n>                     possibly connecting to one or more servers, to\n>                     satisfy user requests.\n>\n>Service agent (SA)  An agent which performs services, either in the\n>                     background or at the request of User Agents.\n>\n>Client              A process which opens connections to servers,\n>                     and gives commands to them and gets the results.\n>\n>Server              A process which accepts connections from clients\n>                     and either accepts and performs them, or refuses them.\n>\n>Important in the terminology above is the distinction between\n>\"client\" and \"user agent\". User agents are usually clients, but all\n>clients are not user agents.\n>\n>If this is the right terminology, what is then the correct word\n>for an HTTP server which provides interactive services using\n>HTML forms? From an HTTP viewpoint, such a server is a server\n>and not a client. But from an application viewpoint, it is a\n>user agent. So a user agent can be a server.\n\nYour terminology for \"User Agent\" tends to cast it in an active role\n(\"performs network services\"), which I think would also make it a \"client\".\n (Similarly, your definition of \"service\" agent seems to imply a passive\nrole.)\n\nI am reminded of the classic case of the X-window terminal that is also a\n\"server\".  But is it a \"User agent\"?  I'm dubious (based on your\ndefinitions, it seems not).\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-10840798"}, {"subject": "Query form about collaborative filterin", "content": "I am active in an EU-project about collaborative filtering.\nIn this project, we would like different web users to fill\nin a questionnaire about how they want collaborative\nfiltering to work.\n\nYou can fill in the questionnairy, by going to\n   http://www.sztaki.hu/servlets/voting/SELECT\nand click on the link \"You can cast your vote now!\"\n\nTo fill in the form will take 5-10 minutes.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-10886788"}, {"subject": "need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "one of the other ADs ran across this draft, which layers a protocol\non top of HTTP.  we're looking for a few good HTTP experts to\nsanity check this draft, paying special attention to the proposed\nmethods and usage - and perhaps to show up at a BOF in Minneapolis\nand comment on the draft.\n\nif you're willing to look at this before Minneapolis, please send me a note.\n\nKeith\n\np.s. I haven't read it yet myself...\n\n\n\n", "id": "lists-007-10913745"}, {"subject": "[Seventh Heaven] Need help describing APPLCOR", "content": "Any and all editorial thoughts would be appreciated -- but please\nreply to me personally. It seems flabby to me, and I'm too bleary to\ntell if it's too lame or too technical at times... RK\n\nThis column:  http://www.ics.uci.edu/~rohit/IEEE-L7-applcore.html\nFirst column: http://www.ics.uci.edu/~rohit/IEEE-L7-1.html\nGeneral info: http://www.ics.uci.edu/~rohit/\n\nSeventh Heaven appears in each issue of IEEE Internet Computing:\nhttp://computer.org/internet\n\n---\nRohit Khare -- UC Irvine -- 4K Associates -- +1-(626) 806-7574\nhttp://www.ics.uci.edu/~rohit -- http://xent.ics.uci.edu/~FoRK\n\n========================================================================\n\n   Building the Perfect Beast\n   \n   Dreams of a Grand Unified Protocol\n   \n   Rohit Khare // March 5, 1999\n   IEEE Internet Computing // Seventh Heaven\n   \n   Seventh Heaven was inaugurated one year ago to chart the evolution of\n   Internet application protocols. Perched upon the heights of the\n   network stack, we paged back through history to trace the lineage of\n   Telnet, FTP, SMTP, NNTP, Gopher, and HTTP. With Jon Postel's\n   fingerprints to guide us, the arc of thirty years of Transfer Protocol\n   (TP) development brought us to the present day -- where the pages of\n   our history books go blank.\n   \n   Leaving us, gentle reader, with but one option for our second season:\n   to turn from documenting the past to divining the future. After all,\n   unlike designs past, there are infinite number of designs yet-to-be:\n   XML-RPC, HTTP-NG, DIAMETER, IMPP, SIP, ISEN, SWAP, WAP, SDMI, ...\n   and every other acrynomious concoction we can get our hands on(*). And\n   that's to say nothing of how protocols are actually adopted and\n   history actually gets written: the mythical eighth (Economic) and\n   ninth (Political) layers of the stack. These are the kinds of new\n   topics we'll tackle in 1999: new protocols, economic models, and\n   standardization processes.\n   \n   (*) [Footnote: For the record, that's Remote Procedure Calls in\n   Extensible Markup Language, HTTP-Next Generation, an extensible\n   successor to RADIUS (Remote Dial-In USer) authentication, Instant\n   Messaging and Presence Protocol, Session Invitation Protocol,\n   Internet-Scale Event Notification, Simple Workflow Access Protocol,\n   Wireless Access Protocol, and the Secure Digital Music Initiative.]\n   \n   Johnny APPLCORE\n   \n   Conveniently, this raises a very timely topic to the head of our\n   agenda: the IETF Applications Directorate's debate over the\n   possibility and desirability of an Application Core Protocol\n   (APPLCORE). This latest outbreak of an ancient meme bloomed rapidly,\n   from its first mention in January to a Birds-of-a-Feather session at\n   IETF-44 in Minneapolis by March. The proliferation of new applications\n   derived -- or worse, cut-and-pasted by parts -- from SMTP and IMAP\n   (Interactive Mail Access Protocol) has prompted an interest in\n   documenting the common challenges of such extensions, and perhaps in\n   developing an entirely new set of command building-blocks.\n   \n   Another variant of the same infectious hope motivates the HTTP-Next\n   Generation project, sponsored by the World Wide Web Consortium with\n   participation from Xerox and Digital (profiled in detail by Bill\n   Janssen last issue). From their vantage point, the Grail looks like a\n   programmable distributed object protocol, atop an efficient new\n   multiplexing transport. They look ahead to interoperating with Java\n   RMI, CORBA IIOP, and RPC protocols.\n   \n   And of course, HTTP/1.1 itself has proven flexible enough for a host\n   of communities to (ab)use it to their own ends. From distributed\n   authoring and versioning (WebDAV) to the Internet Printing Protocol\n   (IPP), the freedom to define new methods, headers, and Internet Media\n   Types at will has led to at least three schools of thought on\n   extending the hypertext Web to other information transfer problems.\n   Its proposed Mandatory extension mechanism aims to rationalize the\n   patchwork of existing rules.\n   \n   These three camps -- Mail, Web, and Objects -- are each vying to\n   establish a new order for Application Layer Protocol design. The quest\n   for universal applicability, though, crosses several common fault\n   lines in the design space. Each camp tends towards different tradeoffs\n   between human- and machine-readability, command-oriented and stateless\n   transactions, end-to-end and proxiable connections, inspectability and\n   security, and whether to exploit the unique properties of UDP,\n   multicast, broadcast, and anycast transmission.\n   \n   While it may seem quixotic to hope for a Grand Unified Protocol, part\n   of the IETF ethos is that you never know unless you try. However slim\n   the opportunity for clean reengineering, it is still appears\n   worthwhile to each camp to seek out an \"application-layer TCP,\" a\n   second neck in the Internet hourglass.\n   \n   Or, as mail protocol and security maven Chris Newman put it when\n   calling for APPLCORE in the first pace, \"What protocol facilities are\n   common to most of FTP, HTTP, IMAP, LDAP, NNTP, POP, SMTP/ESMTP, Telnet\n   and our other successful protocols? ... I can't predict what a\n   careful study of IETF protocol history and comparison of candidate\n   solutions will suggest.\" Since that's the very mission statement of\n   our column, let's take a shot at evaluating these camps'\n   prospects...\n   \n   Diversity vs. the Melting Pot\n   \n   While \"transport\" protocol merely deliver piles of bits, TPs need to\n   'tag-and-bag' their information, almost invariably using MIME syntax.\n   IETF's eventual success in hammering out a standard for packaging\n   information objects is a powerful inspiration for today's protocol\n   unification.\n   \n   It's not much of a stretch to think of today's TPs as merely different\n   strategies for delivering MIME objects -- real-time vs batch, push vs.\n   pull, end-to-end vs. relayed, reliable vs. unreliable, and so on. Over\n   the past year, this column has fleshed out a model of Transfer\n   Protocols (TPs), as summarized in Table 1. We classify three aspects\n   of TPs: addresses that identify participating nodes; distribution\n   rules controlling transfers; and the message formats on the wire.\n   \n   Before proposing a universal solution by picking winners and losers,\n   it behooves us to investigate the tensions and tradeoffs that\n   motivated such diverse solutions in the first place.\n   \n   Engineering for Humans or Machines?\n   \n   While all of these protocols are executed by machines, they are\n   created by programmers -- two actors with rather different priorities\n   for standardization. Will the messages be binary (and faster for\n   computers to parse) or English text (and easier for humans to debug\n   and extend)? Will the application semantics be precisely defined, a la\n   RPC, or open to extensible interpretation, like HTTP?\n   \n   Syntax. Two archetypal alternatives are RFC822 header fields and X\n   Window System events. Email, news, and web headers from any\n   information service are reasonably easy to understand, at the cost of\n   marshaling complex data structures like dates and numbers as ASCII\n   text and parsing all sorts of variations of case, line folding,\n   comments, character sets and other gremlins to uphold the maxim \"be\n   liberal in what you accept\". X Protocol messages are tightly packed\n   binary data aligned on machine boundaries -- and can be processed\n   several orders of magnitude more efficiently because the control flow\n   through a server is clearly delineated by X Window System semantics\n   and a strict extension mechanism.\n   \n   Furthermore, both alternatives are relatively brittle.\n   Internationalizing header text in various human languages is\n   notoriously difficult because of the number of techniques available\n   (RFC 2277, \"IETF Policy on Character Sets and Languages\"). IETF also\n   has some (exasperating) experience with ISO's Abstract Syntax Notation\n   (ASN.1) self-describing binary marshaling format for SNMP and X.500\n   public-key certificates. The tools for compiling such data structures\n   are expensive and still can't guarantee interoperability amongst all\n   the possible Encoding Rules (Basic, Defined, Text, ...).\n   \n   The silver bullet of the moment is XML. Roll-your-own tagsets offer\n   some hope of jointly guaranteeing machine-readable validity and\n   human-readable message text. As WebDAV encountered, using XML in a\n   wire protocol has its own costs: complex machinery for XML text\n   encoding (\"entities\"), whitespace, namespaces, and bloated message\n   text. And for all that, there's still no standard data-formatting\n   rules yet for basic data types like dates, numbers, arrays, and so on.\n   \n   The ability to simulate a protocol exchange with Telnet is another\n   litmus test whether it's catering to machines or humans. If the\n   application itself expects to be supported by individual users and\n   system administrators, it's useful to experiment and debug the system\n   with a bare-minimum tool available on almost any host. If it's a core\n   OS service supported by the vendor, then it's reasonable to expect\n   libraries for inspecting binary messages and APIs to support it.\n   \n   Semantics. Another way of justifying the \"Telnet test\" is to estimate\n   how many independent implementations are expected. While there are\n   only a few X servers and client libraries -- including definitive\n   editions from the X Consortium -- there are uncountable little\n   HTTP-driven scripts and hacked applications babbling away in pidgin\n   dialects developers learned by imitating other clients and servers.\n   The smaller the community of developers, the greater the likelihood of\n   establishing a common ontology. A system as multilateral as the Web\n   dilutes the semantics of \"GET\" to the point it could be opening a\n   database, running a Turing-complete program, instructing a robot, or\n   any other process that eventually generates a MIME entity.\n   \n   Turn the argument on its head, and it illuminates the tension between\n   APIs and protocols. If there is a suite of clearly defined operations,\n   there's more ease-of-reuse by standardizing programming interfaces\n   (\"the Microsoft way,\" Generic Security Services (GSSAPI, RFC 1508)).\n   If implementations are expected to diverge, just focus on the\n   bytes-on-the-wire and the message sequence (\"the IETF way,\" Simple\n   Authentication and Security Layer (SASL, RFC 2222)).\n   \n   It's the Latency, Stupid!\n   \n   Performance constraints also vary with human-driven or machine-driven\n   transactions. Interactive use must minimize latency, leading to\n   stateless protocols, while batched server-to-server communications can\n   optimize bandwidth utilization with stateful command protocols.\n   \n   In the messaging arena, POP and IMAP provide client-server access,\n   while SMTP and NNTP relay between stores. POP optimizes latency by\n   selectively listing headers and bulk data separately; IMAP further\n   offers concurrent operations. SMTP and NNTP, though, operate in modal\n   lockstep, pipelining transmission and reception of new messages.\n   \n   On the Web, last issue's column suggested that the earliest HTTP/0.9\n   spec was even less powerful than FTP -- but it had a critical\n   advantage of lower latency. While FTP requires separate commands (and\n   round-trips) to login, authenticate, navigate to a path, and request\n   transmission, an HTTP download begins within one round-trip after\n   connection establishment. That's because its request message\n   encapsulates all those commands in a single message (URLs for path and\n   filename; headers for authentication information and media-type) --\n   and each request can be processed on its own, without reference to the\n   state of a connection.\n   \n   As the 'bandwidth-delay product' gets larger and larger for wireless,\n   fiber, and satellite links, stateless protocols become more valuable\n   -- it takes less time to pickle the added state information and\n   transmit it than to wait for a command to complete.\n   \n   Relay Races\n   \n   End-to-end support is another contentious design decision facing our\n   conquering heroes. Stateful command sequences are harder to proxy\n   through firewalls or cache, but can manage concurrency explicitly.\n   Store-and-forward messaging (TPs) typically operate across a chain of\n   relays, in contrast to interactive query and access protocols (APs)\n   directly connecting clients and servers.\n   \n   Consider, then, the Calendaring and Scheduling WG's dilemma. Their\n   requirements included connected and disconnected operation, queries\n   against multiple stores, and low-bandwidth operation\n   (draft-ietf-calsch-capreq-02.txt). There are some arguments for\n   modeling a calendar as a Web resources, and operations upon it as HTTP\n   transactions. In particular, the DAV and DAV Searching and Locating\n   (DASL) extensions cover some of their requirement space. It's unclear,\n   though, if the HTTP caching model is sufficient for nomadic use,\n   though. An access protocol like IMAP has richer support for reflecting\n   local actions immediately, chains of actions, and conflict resolution,\n   but at the expense of custom development (about four years in this\n   case).\n   \n   Concurrency is also represented differently in each school. An AP can\n   tag its requests by ID and thus reshuffle its responses to several\n   outstanding operations in the same session. APs like SMTP and NNTP can\n   also \"turn\" the connection around to make requests in the opposite\n   direction. Stateless TPs typically require synchronous response,\n   tacitly pushing concurrency control -- the timing and priority of\n   responses -- to the transport layer. Thus, Web browsers that open\n   multiple TCP connections; and the Message Multiplexing (MEMUX) effort\n   within HTTP-NG.\n   \n   Unlike end-to-end APs, proxying permits intermediaries to offer\n   sophisticated services, from caching to Japanese translation. While\n   HTTP cannot explicitly model the side-effects of a chain of operations\n   (does the server reply to the outstanding GET or PUT first?), its\n   statelessness does enable a rich caching model (I don't care as long\n   as the reply's no older than five minutes).\n   \n   Checkpoint Charlie\n   \n   Firewalls are another kind of proxy. Network administrators have a\n   right to inspect the contents of Internet connections. Today's\n   baseline is filtering services by TCP port number, but as more and\n   more applications attempt to extend HTTP or other APs, the port number\n   isn't precise enough to enable or disable specific services. It's\n   intellectually dishonest to use an existing, popular protocol as mere\n   transport \"because it gets through firewalls\" -- they're there for a\n   reason.\n   \n   For example, one totally flexible universal protocol is to map remote\n   procedure calls to HTTP, whether in XML or directly coding, say\n   Distributed COM (shipped with NT5, though thankfully off by default).\n   If Web traffic could now conceal information leaking out or hackers\n   coming in...\n   \n   Even multiplexing makes firewalls more resource-intensive. One TCP\n   connection running MEMUX could have several subchannels, each of which\n   must be judged individually.\n   \n   End-to-end encryption of an AP is another tough scenario: while a TP\n   proxy might be able to decrypt and then forward an entire information\n   object, it can be a violation of the standard to interpose a proxy in\n   the middle of a stateful conversation.\n   \n   Security is more than transport-layer encryption alone. There are far\n   too many application-layer Authentication and Authorization schemes.\n   SASL succeeded by providing a simple building block -- a sequence of\n   challenge-response messages and status codes -- that allow developers\n   to mix-and-match authentication algorithms.\n   \n   Making the Medium the Message\n   \n   The layers below also offer application designers unique capabilities\n   often overlooked. Telnet, for example, relied on TCP's urgent data and\n   interrupt facilities, but HTTP serenely floats atop any 8-bit clean\n   channel (even half-duplex!). Since there are so few applications that\n   take advantage of broadcast, multicast, and anycast semantics, it's\n   hard to plan ahead for a core protocol that could bridge those modes.\n   And even though most services reserve TCP and UDP ports, datagrams are\n   typically used for \"small enough\" messages -- it's the rare protocol\n   that intelligently copes with lost packets.\n   \n   Link-layers also affect the evolution of application protocols. The\n   Wireless Access Protocol suite is founded on a belief that every\n   Internet layer must be reinvented for the cellular environment.\n   Very-low-bandwidth and very-high-latency environments call for compact\n   message encoding and pipelining, among other features.\n   \n   Camp the first: Mail\n   \n   The initial call for APPLCORE came from folks in the email and\n   directory communities. A strawman proposal like Application Core\n   Protocol (draft-earhart-acp-spec) can trace its heritage back to\n   Postel's SMTP and FTP state machines and his theory of reply codes. It\n   defines a framework for transitioning to an authenticated connection,\n   issuing commands, and receiving interleaved, tagged responses a la\n   IMAP.\n   \n   While it's easy to imagine, say, NNTP's current-group and\n   current-article pointers and commands in this vein, the APPLCORE\n   charter per se does not call for a stateful solution. It's just a\n   coincidence that its author believes the proposed WG should \" focus on\n   a single \"core protocol\" based on the connection-based stateful\n   client-server structure that most successful IETF application\n   protocols follow.\"\n   \n   Camp the second: Web\n   \n   HTTP proponents would beg to differ at Chris Newman's imprecation that\n   it's one of the \"protocol models with which we have far less\n   experience...research problems and thus out-of-scope.\" They can\n   point at a handful of significant, standardized extension packages for\n   HTTP/1.1 -- and a massive set of informal experiments. Its stateless,\n   textual model is particularly hackable, even by shell scripts and\n   programs without any internal model of the Web.\n   \n   HTTP/1.1 enables all this by permitting new methods, header fields,\n   and content types. WebDAV, for example, modified the PUT method with\n   lock fields; added MOVE and COPY (limited by a Depth: header); and\n   manipulates metadata with XML-coded requests and responses.\n   \n   Complexity is the natural consequence of such freedom. Consider how\n   byte-ranges, the ability to request only a portion of the expected\n   response (typically, for partial rendering, e.g. a single page of a\n   PDF file), interact with all other possible extensions.\n   \n   This community's best solution is the Mandatory extension mechanism\n   (draft-frystyk-http-mandatory), which provides a namespace to discover\n   more about an extension, and switches to indicate whether to succeed\n   or fail if an extension isn't recognized. This permits multiple\n   extensions to interoperate by marking off their own method names,\n   header fields, and error codes. Extensions are identified by URIs and\n   marked as Mandatory or Optional obligations on the next server (proxy)\n   or only the origin server.\n   \n   The risk of continuing to subsume more application services within\n   HTTP is the tendency to abuse it as an opaque container for their own\n   traffic. One of its authors, Roy Fielding, declaimed: \"The Web uses\n   HTTP as a transfer protocol, not a transport protocol. HTTP includes\n   application semantics and any application that conforms to those\n   semantics while using HTTP is also using it as a transfer protocol.\n   Those that don't are using it as a transport protocol, which is just a\n   waste of bytes.\"\n   \n   Camp the third: Objects\n   \n   The third tack is to directly model Internet applications as\n   distributed programs, and the client-server protocol follows as a\n   consequence of the API. The IETF's standards-track Remote Procedure\n   Call v2 specification (RFC 1831) was issued four years ago, based on\n   fifteen years' experience at Sun and elsewhere. The popularity of\n   CORBA and Java RMI interfaces underscores the power of this approach.\n   \n   So while the Web camp could be said to provide OO interfaces through\n   document transfer (FORMs and TABLEs and so on), the HTTP-NG effort\n   aims to provide document transfer over an OO interface. Its three\n   layers begin with MEMUX to optimize transmission for the Web by\n   composing compression, encryption, and other services for its virtual\n   channels; then a messaging layer that can marshal binary request and\n   response messages; and its own upper layer for services like The\n   Classic Web Application (TCWA), WebDAV, printing, and so on.\n   \n   It's certainly appealing to reuse application protocols by subclassing\n   and adding your unique functionality, then composing it with other\n   off-the-shelf modules for security and performance. But Chris Newman\n   invokes the conventional wisdom at the IETF: \"RPC mechanisms are a\n   poor choice in general for standards-based protocols. It's much harder\n   to design an extensible and simple API than it is to design an\n   extensible and simple wire protocol.\"\n   \n   Prospects\n   \n   So with each camp set against the others, how likely is any compromise\n   core protocol -- or one camp's hegemony? The answers are not at layer\n   7 alone: we must climb higher. Technical analysis alone does not point\n   to a clear intersection of services, nor justifies any protocol's\n   universal utility.\n   \n   Layer 8: Economics\n   \n   First, investigate whose scarce resources are being reallocated.\n   \"Reuse\" claims litter the 120+ message archive of the debate\n   (http://lists.w3.org/Archives/Public/ietf-discuss/) -- but whose\n   efforts are being reused?\n   \n   There are at least three plausible actors: programmers, spec writers,\n   and standards committees. The first group doesn't benefit until\n   there's a single core protocol on the wire and a code library -- and\n   then only for developing 'multi-protocol' tools. The second benefits\n   by consulting the accumulated wisdom of APPLCORE to navigate the\n   archives and cite prior art. The third benefits from rigorous modeling\n   of the design alternatives and a framework to classify inter-extension\n   dependencies in order to judge which protocols ought to be blessed.\n   \n   Now we can identify institutions that would be motivated to invest in\n   this effort. Look for vendors who implement lots of protocols within a\n   single product. Microsoft, for example, promotes a single \"Internet\n   Information Server\" with the vision of vending the same information by\n   HTTP, DAV, and other protocols. Netscape has a new app for every\n   protocol. Apache, focused purely on HTTP, has little interest in\n   implementing printing, conference calls, or other whiz-bang\n   applications. In the second group are authors with experience from\n   multiple working groups. Such IETF luminaries are leading each camp,\n   respective examples such as Chris Newman, Henrik Frystyk Nielsen, and\n   Mike Spreitzer.\n   \n   Layer 9: Politics\n   \n   To identify the third class of actors, though, requires understanding\n   motivations at the highest level: Politics. The standardization\n   process is an institutional struggle, in this case to establish order\n   within the IETF Directorates, and to defend its turf from ISO and\n   other bodies.\n   \n   APPLCORE intends to \"go only in directions that at least two\n   successful IETF protocols have gone,\" Newman claims. This extends the\n   \"rough consensus\" maxim to bless reuse of solutions as guidance to\n   spec developers. But to envision and APPLCORE robust enough to measure\n   which protocols are worthy or not is another order entirely -- and one\n   the IESG may not support.\n   \n   For example, SG member Brian Carpenter commented \"that approach could\n   imply that HTTPng is the basis for all future applications\n   protocols...I doubt that the IETF is ready to make that step.\"\n   There are similar interests against defining the Internet as mail-like\n   or web-like.\n   \n   Instead, if no dominant camp emerges, a compromises which aims for\n   their intersection raises the scepter of another bogeyman: ISO. IETF\n   culture alternately derides for lowest-common-denominator designs with\n   lots of options required for the useful cases; and for wasteful\n   layering. Charges of ISOism have been leveled by all sides in this\n   debate. Grand Unification Theories from the Object Management Group\n   (OMG) don't go over well, either.\n   \n   All of these considerations feed into the decision whether IETF even\n   charters a WG on this topic. Without viable candidate protocols, it\n   smacks of design-by-committee -- which triggers quite an allergic\n   reaction in this community.\n   \n   Implication\n   \n   But if -- just suppose -- APPLCORE succeeded, what a wonderful world\n   it would be! An application designer would only have to focus on\n   understanding the underlying interaction pattern. Leave it to this bit\n   of middleware to choose the right addressing system, syntax, and\n   distribution algorithm in order to get the right bag of bits to the\n   right people by the right time. Internet application design seem more\n   like \"rational drug discovery,\" adapting a protocol tuned to its\n   requirements rather than merely chasing popular implementations and\n   patching them to match.\n   \n   We expect new kinds of hybrid applications: Event notification with\n   server-initiated delivery, not just polling. Smart pages that\n   represent live processes. Multiprotocol message archives accessible\n   over the web, on the phone, as a fax, by e-mail...\n   \n   Sure, it would only be a 'good enough,' but a single interface would\n   be immensely valuable. TCP isn't ideally tuned for many applications,\n   but its ubiquity has a quality all its own. Its twenty-year dominance\n   has relied on technical ingenuity to manage its evolution and explicit\n   political commitment. We have IP for packets, TCP for streams, and a\n   clear vacancy for a message middleware standard.\n   \n   The Perfect Beast\n   \n   Realistically, though, we suspect this outbreak of the Perfect Beast\n   meme will only take us as far as cataloging design patterns of\n   Internet application layer protocols. Thirty years' experience is long\n   enough to write a textbook, even if the ultimate solution isn't at\n   hand. We can capture common solutions to common problems along with\n   the rationale. Guidance like \"measure compatibility with capability\n   lists rather than version numbers\" would greatly reduce design-time\n   costs -- and guide repairs to today's protocols.\n   \n   It's instructive to reflect upon other outbreaks. Mightn't the search\n   for One True Application Protocol lead to the same cul-de-sac as the\n   One True Programming Language? That community has also played a game\n   of turtles: whether functional, imperative, or procedural ought to be\n   the most fundamental representation. LISP has been the language of the\n   future since 1959 -- even as it has grown to accommodate procedures\n   (Scheme), objects (CLOS), and a vast array of time-tested tools (the\n   Common Lisp environment). The risks of sprawling unification were\n   incoherence, poor performance, and refragmentation into sublanguages.\n   \n   There is a fundamental phenomenon at work: ontology recapitulates\n   community. Ask how many people need to understand a given sentence?\n   -- whether source code or protocol message. That's how universal\n   the solution needs to be. If we want every Internet-accessible\n   resources in a global hypermedia system, you can't expect more\n   than a snapshot representation; if you expect to manipulate a datebook\n   to automatically schedule a meeting, then only special-purpose\n   calendaring tools will be cognizant of other conflicts.\n   \n   All we can hope for is to make the common case easy and keep the hard\n   stuff possible...\n   \n   \n    Rohit Khare is a graduate student in the WebSoft group at the\n    University of California, Irvine; and a principal of 4K Associates,\n    a standards strategy practice.\n    \n   \n   \n   [Word count:~4,000..Note to the editors: feel free to elide or\n   substitute the intra-document headings Note: Table 1 can be copied\n   directly from the March/April 1998 issue's Table 1, with a suitable\n   change of tense in the caption.]\n   \n   \n<PRE>   \n     CAPTION: Three key aspects of the Transfer Protocols (TPs) Seventh\n                           Heaven covered in 1998\n                                      \nTransfer ProtocolAddressingDistributionContent\n- ------------------------------------------------------------------------\n\nTerminal TelnetHostPort1-1SyncBothBytestream w/interrupts\nFilesFTPHostPath1-1SyncBothText / Binary Files\nE-mailSMTPMailboxMsgid1-NAsyncPush822 + MIME\nUsenetNNTPNewsgroupMsgidN-NAsyncPush822 + MIME\nWebHTTPHostURL Path1-NSyncPull822 + MIME + \n                                                                HTTP caching\n\n</PRE>\n\n- ------- End of Failed Message\n\n------- End of Forwarded Message\n\n\n\n", "id": "lists-007-10921947"}, {"subject": "VCRs, working resources and locate-by-histor", "content": "I would like to use the locate-by-history report\nto locate _the_ VCR (if any exists) for a given\nversion history. So I'd expect at maximum 1 VCR\nbe reported per version history.\n\nIs this a correct assumption? I would like to hear\nthat possibly existing working resources are not\ncovered by the report.\n\nOne can phrase the question also as: is a working\nresource a VCR?\n\nThanks for the help,\n\nStefan\n\n\n\n", "id": "lists-007-1092452"}, {"subject": "Amended Charter HI-FI DOCS [a.k.a IPP2IFAX", "content": "On the agenda for IETF 44 there is a BOF entitled IPP2IFAX, at the\nsuggeston of the AD's the proposed charter has been substantially revised\nto concentrate specifically on the needs and requirements of document\ntransmission. The purpose of this is not to create any confusion with the\nrequirements of Internet Fax or distributed printing [Internet Print Protocol]\n\nPlease inform me ASAP of any revisions, comments or agenda items that need\nto be included. \n\nMeeting is ..same time ..same room.\n\nSorry about the short time frame to get this out, but I was in transit all\nof last week.\n\n\n####################\n\nHI-FI DOCS (a.k.a IPP2IFAX)\n\n44 IETF Minneapolis MN\n\nTuesday March 16, 1999\n\n9:00-10:00 AM  -  Rochester \n\n\nBash the Agenda 10 min\n\nReason for Name Change 5 min\n\nReason for Work Group  5 min\n\nProposed Charter 10 min\n\nDrafts: 10 min\n\ndraft-ietf-shockey-ipp2ifax-00.txt\n\nOpen floor for discussion.\n\n################################\n\n\nProposed Charter:\n\nWas IPP2IFAX ? New Name To Be Determined - High Integrity \nDocument Distribution  (HI-FI DOCS)\n\nChair(s):   Richard Shockey  \n<rshockey@ix.netcom.com>  [PROPOSED]\n     \n Applications Area Director(s):\nKeith Moore  <moore+iesg@cs.utk.edu>\n     Patrik F?ltstr?m <paf@swip.net>\n\n Area Advisor\n   Keith Moore  <moore+iesg@cs.utk.edu>\n\n Mailing lists:\n     General Discussion:ifx@pwg.org\n     \nTo Subscribe:\n\nmajordomo@pwg.org\n\n        In Body: subscribe ifx  [your-email-address]\n\nThe subject line should be blank\n\nArchive:          \n<http://www.pwg.org/hypermail/ifx>\n\nDescription of Working Group:\n\nThe transmission and reception of non-alterable \ndocuments is an essential communications medium.\n\nSeveral protocols and services have been \ndeveloped over the years to facilitate document \ntransmission, including the GSTN Fax service [ITU -\nT.30].  Within the IETF several protocols have been \ndeveloped that facilitate document transmission, \nincluding RFC2305 [Store and Forward Internet Fax] \nand the Internet Print Protocol [IPP].\n\nEach of these services has one or more severe \nlimitations or restrictions that may not be suitable for \nall document transmissions.\n\nAmong those limitations that could be applied to one \nor more of the above services:\n\n1. Limitations on Quality (resolution or color \ntransmission)\n2. Ability to repudiate request for receipt \nconfirmation (MDN ? DSN)\n3. Lack of clear and unambiguous identification of \nsender or recipient\n4. Lack of ability to monitor progress of document \ntransmission in real time\n5. Inability to establish reliable knowledge or \nnegotiation of recipient capabilities\n6. Inability to satisfy legal as well as general \ncustom and practice for document transmission \ntechnologies. (Typically these are applied to \nGSTN Fax)\n7. Least Common Denominators for Document\nTransmission\n8. Inability to establish security and confidentiality \nof document transmission\n\nThe purpose of the work group will be to investigate \ncurrent work within the IETF and identify protocols, \nprocedures and policies that can satisfy the \nrequirements for document transmission with \na high degree of fidelity and reliability.\n\nIt is believed that elements of the Internet Print \nProtocol 1.1, if extended and amended may \novercome many if not most of the limitations \ndescribed above. Work would define an appropriate \n?super set? of existing IPP 1.1 functionality to satisfy\nthese requirements.\n\nThe work group may consider attribute extensions \nand additional service requirements to IPP 1.1 that \nwould permit IPP to intreoperate with other \ndocument transmission services such as RFC2305 \n[Fax over SMTP] and traditional T.30 fax on the \nGSTN.\n\nThe WG will not propose any revisions or extensions \nto IETF Internet Fax standards [RFC2305] and its \nsuccessors.\n\nThe group will take note of other areas within the \nIETF that may have direct bearing on reliable \ndocument delivery.\n\nRelevant areas include:  \n\n- Security, Authentication and Encryption (SSL3 -\nTLS)\n- Sender Identification (vCard)\n- RFC2301 File Formats\n- Digital Signatures and Certificates\n- Third Party Receipt Confirmation\n\nThe working group will coordinate its activities with \nthe Internet Print Protocol working group [IPP] and \nthe Internet Fax working group [FAX] as well other \ndocument transmission related standards bodies \nand related work groups, notably the ITU-T Study \nGroup 8.   \n\n\nGoals and Milestones:  \n  \nMay  1999 : Submit Internet Draft of Goals and \nRequirements for High Reliability Document \nDistribution\n\nAugust  1999 : Submit Internet Draft for IPP High \nReliability Document Mode\n\nSeptember  1999 : Submit Internet Draft of Reliable \nGateway Services between IPP, SMTP and GSTN \nFacsimile\n\n\n\n\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nRichard Shockey\nShockey Consulting LLC                  \n8045 Big Bend Blvd. Suite 110    \nSt. Louis, MO 63119\nVoice 314.918.9020\nFax   314.918.9015\nINTERNET Mail & IFAX : rshockey@ix.netcom.com\neFAX 815.333.1237  \n<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n\n\n", "id": "lists-007-10958498"}, {"subject": "RE: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "> one of the other ADs ran across this draft, which layers a protocol\n> on top of HTTP.\n\nIt layers a protocol on top of something which is not\ndefined (yet, although it promises to): HTTP layered\nover (multicast and unicast) UDP.\n\nI think HTTP layered over multicast & unicast UDP will\nbe exceedingly difficult to define correctly. HTTP messages\nand responses are arbitrary length, and require one-for-one\nresponses to requests.\n\n>...  we're looking for a few good HTTP experts to\n> sanity check this draft\n\nThe 'sanity' of this approach escapes me.\n\nLarry\n\n\n\n", "id": "lists-007-10972072"}, {"subject": "RE: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "Do be kind, it is a version 0. There are some pretty egregious mistakes in\nthe draft (the misuse of the request-URI and Location header come to mind)\nwhich have been fixed in a V1, which will be released after the draft\nlock-out. The v0 draft should be seen as an indication of a general\ndirection.\n\nAs for layering, why do you believe this is a layering on top of HTTP? The\ndraft expands HTTP in a direction that others, such as SIP, have already\ngone. SIP already defines how to send SIP requests over unicast UDP and\nmulticast UDP. The only thing even mildly original about the spec is the\nANNOUNCE method which I suspect you can find strong parallels for in SIP.\nANNOUNCE is a fairly natural method to have once you have multicast support.\n\nThis spec seems more a natural progression than a layering.\n\nThen again, I'm obviously biased. =)\n\nYaron\n\n\n> -----Original Message-----\n> From: Keith Moore [mailto:moore@cs.utk.edu]\n> Sent: Friday, March 05, 1999 10:19 AM\n> To: web@apps.ietf.org\n> Cc: discuss@apps.ietf.org\n> Subject: need a reviewer (or three) for draft-cai-ssdp-v1-00.txt\n> \n> \n> one of the other ADs ran across this draft, which layers a protocol\n> on top of HTTP.  we're looking for a few good HTTP experts to\n> sanity check this draft, paying special attention to the proposed\n> methods and usage - and perhaps to show up at a BOF in Minneapolis\n> and comment on the draft.\n> \n> if you're willing to look at this before Minneapolis, please \n> send me a note.\n> \n> Keith\n> \n> p.s. I haven't read it yet myself...\n> \n\n\n\n", "id": "lists-007-10980898"}, {"subject": "Re: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "> As for layering, why do you believe this is a layering on top of HTTP? \n\nI still haven't had time to read the document myself...\n(and frankly, I'm hoping that others' reviews will either relieve me of \nthe need to do so, or make it clear that it's worth my time to do so...\ngotta reduce the Apps ADs' workload somehow)\n\n> The draft expands HTTP in a direction that others, such as SIP, have already\n> gone. SIP already defines how to send SIP requests over unicast UDP and\n> multicast UDP. The only thing even mildly original about the spec is the\n> ANNOUNCE method which I suspect you can find strong parallels for in SIP.\n> ANNOUNCE is a fairly natural method to have once you have multicast support.\n\n...however, I did do a fairly detailed review of SIP, and while I didn't\nfind any outright technical flaws (that didn't get fixed) I sort of hope we \ndon't invent more protocols like it.  It's close enough to HTTP to make it\ntempting for people to implement SIP-over-HTTP, but it's also incompatible \nwith HTTP/1.1, and as a matter of design choice rather than accident.  \n\nI don't like the idea of people trying to layer lots of\nsimilar-but-slightly-different things over HTTP. I suspect the result will\nbe that HTTP implementations will be (even further) burdened by hundreds of \nconditional flags in an attempt to be reusable by all of the different\nhigher-level protocols, and/or that various implementations of these protocols \nwill not adhere to the specifications where they differ from HTTP, and\ninteroperability will suffer.  And technically, HTTP/1.1 is a lousy protocol \nto use as a base for other protocols - its \"Christmas tree\" design history\nwhere lots of ad-hoc extensions from multiple vendors were piled on top of \neach other - makes it too complex.  SIP inherits much of HTTP/1.1 complexity,\nwithout the ability (in general) to use HTTP libraries or servers to \nfaithfully implement it.  I find this design decision difficult to justify.\n\nso this isn't a comment on your proposal per se, but please don't hold up\nSIP as an example of something to be emulated.\n\nKeith\n\n\n\n", "id": "lists-007-10991684"}, {"subject": "Problem: creation of a MS webfolder and length of DAV: heade", "content": "Hi,\n\nwe are experiencing a strange behaviour with the *creation* of a Microsoft\nwebfolder on our DeltaV server. When the DAV: header of an OPTIONS response\nbecomes too long, we get an \"The folder you entered does not appear to be\nvalid. Please choose another.\" error. Once a webfolder has been created,\neverything works fine, even if we make our server send longer DAV: headers.\n\nHere are the limits. The 1st one works fine, but the 2nd (one character\nmore) does not:\nDAV: 1, 2, version-control, version-history, workspace, label, merge\nDAV: 1, 2, version-control, version-history, workspace, update, merge\n\nI am using at client side: W2K_SP2 and IE 6.0 (but the problem occurs also\nwith IE 5.50).\n\nRegards,\nPeter\n \n\n\n\n", "id": "lists-007-1100053"}, {"subject": "RE: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "Actually, I was very unhappy with SIP for reasons I doubt you would agree\nwith. =) I thought SIP should have just run on top of HTTP/1.1. In fact, I\nwrote up an entire series of posts explaining exactly how to do this.\n\nThe point I was making, however, is that adding (unicast | multicast) UDP\nsupport to HTTP is a very natural progression as demonstrated by SIP.\n\nIn generally I have found HTTP to be a wonderful platform to leverage and\nfar from finding myself having to do weird things in order to keep\neverything working I have, more often than not, found that HTTP already\nprovides 99% of whatever I need and I only need to add a tiny extra bit to\nget me where I want to go. I also find that when I add that 1% in one place,\nI end up re-using that 1% over and over again in many other places.\n\nIn fact I have only one serious complaint about HTTP, which has nothing to\ndo with the spec. Most systems put very severe restrictions on the size of\nHTTP headers (2k or less is common). So I often find myself having to put\ninformation into the body of a request that I would have much rather put\ninto a header.\n\nOutside of that, I am an extremely satisfied customer of HTTP and definitely\nintend to continue investing in it.\n\nYaron\n\nP.S. As for HTTP's complexity. HTTP itself is an unbelievably simple\nprotocol. The problem is that it has inherited a lot of cruft over the\nyears, 99.99% of which is optional and not widely supported. I believe that\nwhat the world really needs is a re-written version of the HTTP spec. One\norganized into a more rational structure which shows the true beauty of\nHTTP's layered architecture. I would be willing to bet that one could write\na spec providing the absolute bare minimum information needed to create a\ncompliant client/proxy/server in 20 pages.\n\n> -----Original Message-----\n> From: Keith Moore [mailto:moore@cs.utk.edu]\n> Sent: Tuesday, March 09, 1999 9:32 PM\n> To: Yaron Goland\n> Cc: 'Keith Moore'; web@apps.ietf.org; discuss@apps.ietf.org\n> Subject: Re: need a reviewer (or three) for draft-cai-ssdp-v1-00.txt \n> \n> \n> > As for layering, why do you believe this is a layering on \n> top of HTTP? \n> \n> I still haven't had time to read the document myself...\n> (and frankly, I'm hoping that others' reviews will either \n> relieve me of \n> the need to do so, or make it clear that it's worth my time \n> to do so...\n> gotta reduce the Apps ADs' workload somehow)\n> \n> > The draft expands HTTP in a direction that others, such as \n> SIP, have already\n> > gone. SIP already defines how to send SIP requests over \n> unicast UDP and\n> > multicast UDP. The only thing even mildly original about \n> the spec is the\n> > ANNOUNCE method which I suspect you can find strong \n> parallels for in SIP.\n> > ANNOUNCE is a fairly natural method to have once you have \n> multicast support.\n> \n> ...however, I did do a fairly detailed review of SIP, and \n> while I didn't\n> find any outright technical flaws (that didn't get fixed) I \n> sort of hope we \n> don't invent more protocols like it.  It's close enough to \n> HTTP to make it\n> tempting for people to implement SIP-over-HTTP, but it's also \n> incompatible \n> with HTTP/1.1, and as a matter of design choice rather than \n> accident.  \n> \n> I don't like the idea of people trying to layer lots of\n> similar-but-slightly-different things over HTTP. I suspect \n> the result will\n> be that HTTP implementations will be (even further) burdened \n> by hundreds of \n> conditional flags in an attempt to be reusable by all of the different\n> higher-level protocols, and/or that various implementations \n> of these protocols \n> will not adhere to the specifications where they differ from HTTP, and\n> interoperability will suffer.  And technically, HTTP/1.1 is a \n> lousy protocol \n> to use as a base for other protocols - its \"Christmas tree\" \n> design history\n> where lots of ad-hoc extensions from multiple vendors were \n> piled on top of \n> each other - makes it too complex.  SIP inherits much of \n> HTTP/1.1 complexity,\n> without the ability (in general) to use HTTP libraries or servers to \n> faithfully implement it.  I find this design decision \n> difficult to justify.\n> \n> so this isn't a comment on your proposal per se, but please \n> don't hold up\n> SIP as an example of something to be emulated.\n> \n> Keith\n> \n\n\n\n", "id": "lists-007-11001823"}, {"subject": "Re: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "> Actually, I was very unhappy with SIP for reasons I doubt you would agree\n> with. =) I thought SIP should have just run on top of HTTP/1.1. In fact, I\n> wrote up an entire series of posts explaining exactly how to do this.\n> \n> The point I was making, however, is that adding (unicast | multicast) UDP\n> support to HTTP is a very natural progression as demonstrated by SIP.\n\nI would say that SIP provides a good example of why this should not be done.\n \nI do agree with you, however, that HTTP provides most of the features\nneeded by most client-server applications.  If the application only\nneeds to do RPC like things (even with moderately large payloads), \ndoesn't need efficiency (most don't), and isn't likely to be heavily \nused or used over wireless links, or multicast, then HTTP is probably \nfine.  However wireless is likely to become a lot more important very \nsoon and that to me is enough by itself to make HTTP a very dubious\ncontender as a base for future applications.  (similarly for SMTP and IMAP)\n\n> P.S. As for HTTP's complexity. HTTP itself is an unbelievably simple\n> protocol. The problem is that it has inherited a lot of cruft over the\n> years, 99.99% of which is optional and not widely supported. I believe that\n> what the world really needs is a re-written version of the HTTP spec. One\n> organized into a more rational structure which shows the true beauty of\n> HTTP's layered architecture. I would be willing to bet that one could write\n> a spec providing the absolute bare minimum information needed to create a\n> compliant client/proxy/server in 20 pages.\n\nThat seems like a stretch - in particular the interaction of cacheing\nproxies is just too complex.  But I'd love to see somebody try.\n\nKeith\n\n\n\n", "id": "lists-007-11015359"}, {"subject": "RE: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "> I do agree with you, however, that HTTP provides most of the features\n> needed by most client-server applications.  If the application only\n> needs to do RPC like things (even with moderately large payloads), \n> doesn't need efficiency (most don't), and isn't likely to be heavily \n> used or used over wireless links, or multicast, then HTTP is probably \n> fine.  However wireless is likely to become a lot more important very \n> soon and that to me is enough by itself to make HTTP a very dubious\n> contender as a base for future applications.  (similarly for \n> SMTP and IMAP)\n\nMy own experience shows that HTTP works like a champ over wireless. Its\nlarge granularity commands work extremely well over high latency links.\nHowever it may be that the particular usage profiles I'm involved with are\nbiased in a manner which make HTTP function properly. What issues do you\nhave with HTTP over unicast and multicast UDP?\n\n> \n> > P.S. As for HTTP's complexity. HTTP itself is an unbelievably simple\n> > protocol. The problem is that it has inherited a lot of \n> cruft over the\n> > years, 99.99% of which is optional and not widely \n> supported. I believe that\n> > what the world really needs is a re-written version of the \n> HTTP spec. One\n> > organized into a more rational structure which shows the \n> true beauty of\n> > HTTP's layered architecture. I would be willing to bet that \n> one could write\n> > a spec providing the absolute bare minimum information \n> needed to create a\n> > compliant client/proxy/server in 20 pages.\n> \n> That seems like a stretch - in particular the interaction of cacheing\n> proxies is just too complex.  But I'd love to see somebody try.\n> \n\nCaching proxies are simple, **IF** you only do the basic caching that actual\nworks. People run into problems when they try to get fancy and support\nfeatures no one needs or uses. I would bet you could explain the entire\nminimally compliant/maximally useful HTTP proxy caching system in two pages.\n\n> Keith\n> \n\nYaron\n\n\n\n", "id": "lists-007-11025147"}, {"subject": "Re: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "> My own experience shows that HTTP works like a champ over wireless. Its\n> large granularity commands work extremely well over high latency links.\n\nTCP doesn't work well over wireless links that have high packet loss rates.\nArguably the right way to solve this is with link-layer transmit or FEC, \nbut you don't want to do that for some kinds of traffic.  And now that\nTOS has been deprecated it's not clear (at least to me) how an application\ncan label its packets so that the link layer won't do this.\n\nWhether you think HTTP works well over high latency links probably depends\non how you use it - especially the granularity of interaction that your\napplication needs.  For many applications the TCP connection setup already\ncauses a significant degree of latency.\n\n> What issues do you have with HTTP over unicast and multicast UDP?\n\nJust the obvious ones.\n\nKeith\n\n\n\n", "id": "lists-007-11035581"}, {"subject": "RE: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "> As for layering, why do you believe this is a layering on top of HTTP?\n\nBecause draft-cai-ssdp-v1-00.txt says:\n     \"SSDP uses HTTP over multicast and unicast UDP.\"\n\nIt doesn't say \"SSDP defines a protocol that's kind of like HTTP.\"\n\nNow, you can call yourself Humpty Dumpty and say that \"HTTP\" means\nwhatever you say it means, but then, you might fall off that wall.\n\nLarry\n\n\n\n", "id": "lists-007-11044476"}, {"subject": "new improved apps document action pag", "content": "the apps document action page\n(http://www.apps.ietf.org/DocumentActions/index.html)\nhas been somewhat improved:\n\nit now lists each internet-draft, with requested status,\nfor each protocol action, and includes (where applicable)\npointers to the lastest drafts.  it is also capable of dealing \nwith documents (informational/experimental) that were not \nlast-called.  it also lists document change history.\n\neventually it is planned to include a log of status changes,\nso you can see what happened when.\n\n(and we're even catching up on document reviews!)\n\nKeith\n\n\n\n", "id": "lists-007-11052915"}, {"subject": "RE: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "On Wed, 10 Mar 1999, Yaron Goland wrote:\n\n    [Yaron:]\n> > > P.S. As for HTTP's complexity. HTTP itself is an unbelievably simple\n> > > protocol. The problem is that it has inherited a lot of \n> > cruft over the\n> > > years, 99.99% of which is optional and not widely \n> > supported. I believe that\n> > > what the world really needs is a re-written version of the \n> > HTTP spec. One\n> > > organized into a more rational structure which shows the \n> > true beauty of\n> > > HTTP's layered architecture. I would be willing to bet that \n> > one could write\n> > > a spec providing the absolute bare minimum information \n> > needed to create a\n> > > compliant client/proxy/server in 20 pages.\n> > \n\n    [Kieth:]\n> > That seems like a stretch - in particular the interaction of cacheing\n> > proxies is just too complex.  But I'd love to see somebody try.\n> > \n> \n> Caching proxies are simple, **IF** you only do the basic caching that actual\n> works. People run into problems when they try to get fancy and support\n> features no one needs or uses. I would bet you could explain the entire\n> minimally compliant/maximally useful HTTP proxy caching system in two pages.\n\nYes, I agree here, a compliant/useful HTTP proxy cache specification does\nnot have to be very long.  More exotic things like Vary and the merging of\nrange responses can be left out.  Even a lot of the cache-control\ndirectives can be left out, by speficying that they should all be treated\nas 'don't cache'. \n\nIt is true that caching proxies can interact in very complex ways, this is\nunfortunate but it was unavoidable in HTTP/1.1.  We already had an\ninstalled base we needed to be compatible with, and this installed base\nincluded design decisions that were subtly wrong in retrospect. \n\nBut proxy implementers can blisfully ignore most of the proxy interaction\ncomplexity, if the goal is just complicance.  HTTP/1.1 puts the problem\nof dealing with the complexity on the plate of dynamic web content\ndesigners and (especially) protocol extension designers. \n\nOne of the projects way down on my 'todo' list is to take HTTP/1.1, drop\nlots of stuff, straighten out the layering, and write the result up in a\nsmall document called 'http light'. \n\n\nKoen.\n\n\n\n", "id": "lists-007-11060057"}, {"subject": "APPLCORE user requirement", "content": "The charter of the APPLCORE group should include\ninvestigation of user needs. The \"users\" for APPLCORE are\nthe future application protocols, which are to use it, and\nthe developers of these protocols.\n\nSince we cannot know exactly what the user needs will be of\nfuture protocols, we might start by looking at common user\nneeds of existing application protocols.\n\nHere is an initial list of possible such user requirements.\nI am not saying that all these should be user requirements,\nbut that we should consider for each of them, whether they\nare to be satisfied by the core protocol or not.\n\n(1)  Connection establishment with various levels of\n     authentication and authorization.\n\n(2)  Capability negotiation (something like in ESTMP?).\n\n(3)  Transfer of data structures (like is done by RFC822\n     header syntax, MIME multiparts or XML).\n\n(4)  Transfer of both textual and binary data, including\n     video, images, and arbitrary files.\n\n(5)  Character set and natural language issues.\n\n(6)  Syntax specification languages like ABNF.\n\n(7)  Semantic specification languages. (The MUST, SHOULD,\n     etc. rules of IETF is a rudimentary such language, is this\n     enough, or do we want more?)\n\n(8)  Cache/replication control/management.\n\n(9)  Extension mechanism, including critical and non-critical\n     extension. (A critical extension is an extension which\n     must cause rejection by an agent which does not understand\n     it. A non-critical extension is an extension which can\n     be ignored or tunnelled by an agent which does not\n     understand it.)\n\n(10) Firewalls (how to pass them, how to allow them to stop\n     what they are designed to stop).\n\n(11) Content-Transfer-Encoding negotiation.\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-11070789"}, {"subject": "APPLCORE mailing list", "content": "Is there a mailing list for APPLCORE?\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-11079118"}, {"subject": "RE: Problem: creation of a MS webfolder and length of DAV: heade", "content": "Try breaking it up into multiple DAV:header lines, e.g.:\n\nDAV: 1,2\nDAV: version-control, version-history\nDAV: workspace, update, merge\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Nevermann, Dr., Peter [mailto:Peter.Nevermann@softwareag.com]\nSent: Friday, May 17, 2002 7:20 AM\nTo: ietf-dav-versioning@w3.org\nSubject: Problem: creation of a MS webfolder and length of DAV: header\n\n\nHi,\n\nwe are experiencing a strange behaviour with the *creation* of a Microsoft\nwebfolder on our DeltaV server. When the DAV: header of an OPTIONS response\nbecomes too long, we get an \"The folder you entered does not appear to be\nvalid. Please choose another.\" error. Once a webfolder has been created,\neverything works fine, even if we make our server send longer DAV: headers.\n\nHere are the limits. The 1st one works fine, but the 2nd (one character\nmore) does not:\nDAV: 1, 2, version-control, version-history, workspace, label, merge\nDAV: 1, 2, version-control, version-history, workspace, update, merge\n\nI am using at client side: W2K_SP2 and IE 6.0 (but the problem occurs also\nwith IE 5.50).\n\nRegards,\nPeter\n \n\n\n\n", "id": "lists-007-1108351"}, {"subject": "RE: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "I just read the draft.  I think the basic idea of putting a small HTTP\nmessage as the payload in a broadcast UDP message is rather cute.  But it\nwill only remain cute for me if the HTTP message size stays within the\nmaximum safe/generally supported size of a single broadcast UDP message. I\ndon't know what this size is nowadays, I am getting conflicting data from\nvarious sources.\n\nComplex to-be-defined mechanisms for supporting arbitrary-length\nHTTP-over-UDP broadcast would spoil the idea for me. \n\nAnyway, I would not consider this to be something on top of HTTP, it is\nrather something that re-uses some of the extensible syntax in HTTP, which\nis entirely legitimate.  As the use case is LAN based (or at least\nintranet based), I don't think the IETF should devote major resources to\nthis.\n\nKoen.\n\nOn Tue, 9 Mar 1999, Larry Masinter wrote:\n\n> > one of the other ADs ran across this draft, which layers a protocol\n> > on top of HTTP.\n> \n> It layers a protocol on top of something which is not\n> defined (yet, although it promises to): HTTP layered\n> over (multicast and unicast) UDP.\n> \n> I think HTTP layered over multicast & unicast UDP will\n> be exceedingly difficult to define correctly. HTTP messages\n> and responses are arbitrary length, and require one-for-one\n> responses to requests.\n> \n> >...  we're looking for a few good HTTP experts to\n> > sanity check this draft\n> \n> The 'sanity' of this approach escapes me.\n> \n> Larry\n> \n> \n> \n\n\n\n", "id": "lists-007-11086199"}, {"subject": "Extensibility methods in APPCORE protoco", "content": "At the APPCORE meeting in Minneapolis, it was said that APPCORE should\nnot contain any building block which is not used in two existing\nIETF standard.\n\nThis might be a good rule, but on one particular point, I think the\nrule should not be taken too litterally. That particular point is\nmethods of making it easier to extend a standard in the future.\nIETF standards have traditionally been very bad in this area,\nand this has caused unneccesary ugly methods of making extensions\nso as not to break existing software. I think it would be very\nimportant if APPCORE contained good methods for specifying standards\nso that they can easily be extended. This should include some kind\nof support for marking future extensions as critical or non-critical.\n(An agent which receives a criticial extension, which it cannot\nhandle, must reject the protocol unit, while an agent which receives\na non-criticial extension, which it cannot handle, can ignore it\nor forward it transparently without understanding it.)\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-11096080"}, {"subject": "RE: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "At one time at least, the ICP protocol of SQUID would ship small documents\nin UDP datagrams on the ICP response.\nThat community is probably able to give practical, recent experience.\n(They may still be doing it....)\n\n                    Harald\n-- \nHarald Tveit Alvestrand, Maxware, Norway\nHarald.Alvestrand@maxware.no\n\n\n\n", "id": "lists-007-11105095"}, {"subject": "Re: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "-----BEGIN PGP SIGNED MESSAGE-----\n\n\nHarald Alvestrand writes:\n\n| At one time at least, the ICP protocol of SQUID would ship small documents\n| in UDP datagrams on the ICP response.\n| That community is probably able to give practical, recent experience.\n\nThe main one is probably that ICP is gradually being abandoned in \nfavour of the new Cache Digest protocol.  For more info, check out:\n<URL:http://squid.nlanr.net/Squid/CacheDigest/cache-digest-v5.txt>\n\nFor problems with ICP returning object contents, see RFC 2186 ...\n\n      CAVEAT: ICP_OP_HIT_OBJ has some negative side effects which make\n      its use undesirable.  It transfers object data without HTTP and\n      therefore bypasses the standard HTTP processing, including\n      authorization and age validation.  Another negative side effect is\n      that ICP_OP_HIT_OBJ messages will often be much larger than the\n      path MTU, thereby causing fragmentation to occur on the UDP\n      packet.  For these reasons, use of ICP_OP_HIT_OBJ is NOT\n      recommended.\n\n ... and RFC 2187 ...\n\n   o    ICP_OP_HIT_OBJ is particularly vulnerable to security problems\n        because it includes object data.  For this, and other reasons,\n        its use is discouraged.\n\n   o    Falsifying, altering, inserting, or blocking ICP messages can\n        cause an HTTP request to fail only in two situations:\n\n        -    If the cache is behind a firewall and cannot directly\n             connect to the origin server.\n\n        -    If a false ICP_OP_HIT reply causes the HTTP request to be\n             forwarded to a sibling, where the request is a cache miss\n             and the sibling refuses to continue forwarding the request\n             on behalf of the originating cache.\n\nSayonara!\n\nMartin\n\n\n\n-----BEGIN PGP SIGNATURE-----\nVersion: 2.6.3i\nCharset: noconv\n\niQCVAwUBNu+40NZdpXZXTSjhAQG16wQApJXctu2XI1tTDigKP/NGsbSS3G+98gp5\n6vlgJ23+cJmtNjp9dB/GR6VR2csgDl8Jccp3Y8JJPGPGh4hEafMGcrsiWbdt3tKE\n2fMROqGMrg02qwHU2KVGMnM3Lhd3B1lsAHWdjXfj6xmCOYSudobLv/zfjJxm9m0y\nu2ucUaYg5Sw=\n=ng4U\n-----END PGP SIGNATURE-----\n\n\n\n", "id": "lists-007-11114606"}, {"subject": "Re: APPLCORE mailing list", "content": "On Mon, 15 Mar 1999, Jacob Palme wrote:\n> Is there a mailing list for APPLCORE?\n\n  ietf-applcore@imc.org\n\n  )Rob\n\n\n\n", "id": "lists-007-11125244"}, {"subject": "RE: need a reviewer (or three) for draft-cai-ssdp-v1-00.tx", "content": "At 09:26 16.03.99 +0100, Harald Alvestrand wrote:\n>At one time at least, the ICP protocol of SQUID would ship small documents\n>in UDP datagrams on the ICP response.\n\nYes, we did.\n>That community is probably able to give practical, recent experience.\n\nNo, it is not a good idea.\n>(They may still be doing it....)\nSome do, but it is still not a good idea\n - UDP fragementation\n - access control trouble (lack of HTTP headers)\n - pinelining requests give better performance ( we used to do this in the\ndays of HTTP/1.0 )\n\nThis is off the top of my head, there is more negative experience that I\nhave suppressed (we did do WAN UDP-packets for quite a while in the COM-MESH\nexperiment).  And of course we are changing to CacheDigest these days...\n\n\nIngrid\n\n\n\n", "id": "lists-007-11132765"}, {"subject": "Re: Extensibility methods in APPCORE protoco", "content": "At 13:17 17/03/99 +0100, Jacob Palme wrote:\n>At the APPCORE meeting in Minneapolis, it was said that APPCORE should\n>not contain any building block which is not used in two existing\n>IETF standard.\n\nI don't think extensibility is excluded by this rule -- both HTTP and SMTP\nhave extension mechanisms defined.\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-11141903"}, {"subject": "Need reviewers for a Version Control Protoco", "content": "Hi,\n\nAnyone interested in reviewing this draft on Internet based\nVersion Control Protocol ? A standard on this could lead to\ninteroperable applications used for internal document\nor source code management within an organization or over\npublic Internet.\n\nHere is the URL:\n\nhttp://www.ietf.org/internet-drafts/draft-ramaswamy-version-control-00.txt\n\nThanks,\nSaravanan Ramaswamy.\n\n\n\n", "id": "lists-007-11150230"}, {"subject": "Re: Need reviewers for a Version Control Protoco", "content": "At 09.57 -0800 1999-03-21, Saravanan Ramaswamy wrote:\n> Anyone interested in reviewing this draft on Internet based\n> Version Control Protocol ?\n\nYou should talk to the people involved in the deltav BOF at the last \nIETF. They include (I think...Jim Whitehead knows for sure!)\n\nJim Whitehead <ejw@ics.uci.edu>\n<gclemm@atria.com>\nJim Amsden <jamsden@us.ibm.com>\nBradley Sergeant <bradley_sergeant@intersolv.com>\nBruce Cragun <Cragun.Bruce@gw.novell.com>\nChris Kaler <ckaler@microsoft.com>\nDavid Durand <dgd@cs.bu.edu>\n\n   Patrik\n------------------------------------------------------------------\nArea Director, Applications Area               Email: paf@swip.net\nIETF                                             URL: http://paf.se\n                                          PGP Key ID: 0xBD236602\n\n   In theory there is no difference between theory and practice,\n   but in practice, there is.\n\n\n\n", "id": "lists-007-11157715"}, {"subject": "Re: Extensibility methods in APPCORE protoco", "content": "At 22.55 +0100 99-03-17, Graham Klyne wrote:\n> At 13:17 17/03/99 +0100, Jacob Palme wrote:\n> >At the APPCORE meeting in Minneapolis, it was said that APPCORE should\n> >not contain any building block which is not used in two existing\n> >IETF standard.\n>\n> I don't think extensibility is excluded by this rule -- both HTTP and SMTP\n> have extension mechanisms defined.\n\nYes, but none of them has a facility for marking extensions\nas critical or non-critical, and this is something I would\nvery much like to have in APPLCORE.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-11167705"}, {"subject": "Semantics of delete on a member of a working collectio", "content": "Hi,\n\nWhat is semantic of DELETE on a member of a working collection that is\nversion\nhistory resource ? Should it (try to) delete the version history or only the\nbinding ?\nIn case it should delete the version history then is it possible to delete\na version controlled resource without checkout-in-place feature ?\n\nRegards\nSasha\n\n\n\n", "id": "lists-007-1117340"}, {"subject": "Re: Extensibility methods in APPCORE protoco", "content": "At 21:35 22/03/99 +0100, Jacob Palme wrote:\n>At 22.55 +0100 99-03-17, Graham Klyne wrote:\n>> At 13:17 17/03/99 +0100, Jacob Palme wrote:\n>> >At the APPCORE meeting in Minneapolis, it was said that APPCORE should\n>> >not contain any building block which is not used in two existing\n>> >IETF standard.\n>>\n>> I don't think extensibility is excluded by this rule -- both HTTP and SMTP\n>> have extension mechanisms defined.\n>\n>Yes, but none of them has a facility for marking extensions\n>as critical or non-critical, and this is something I would\n>very much like to have in APPLCORE.\n\nWell, yes, but...\n\nIn the case of HTTP I believe that there does exist such a mechanism (but I\ncould be wrong there).\n\nIn the case of SMTP, because the necessary information is declared up front\n(by EHLO response) before a transaction is initiated, the client can base a\nrequest upon this information so I don't see a critical/nom-critical\ndesignation is needed.\n\nThe fact that it is not needed in all cases suggests to me that\ncritical/non-critical marking should not be part of a *core* protocol.\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-11175726"}, {"subject": "RE: Extensibility methods in APPCORE protoco", "content": "> -----Original Message-----\n> From: Graham Klyne [mailto:GK@Dial.pipex.com]\n\n> >> At 13:17 17/03/99 +0100, Jacob Palme wrote:\n> >Yes, but none of them has a facility for marking extensions\n> >as critical or non-critical, and this is something I would\n> >very much like to have in APPLCORE.\n\n> The fact that it is not needed in all cases suggests to me that\n> critical/non-critical marking should not be part of a *core* protocol.\n\nAnd the fact that HTTP did not have that from the beginning (and doesn't\nhave it as a core part of even 1.1) was a source of endless problems.  Don't\nbe use the rule to restrict you to repeating the mistakes of the past or you\ndefeat any point this effort may have.\n\n\n\n", "id": "lists-007-11185164"}, {"subject": "RE: Extensibility methods in APPCORE protoco", "content": "HTTP has many extensibility mechanisms, each with its own theory\nand practice for default handling, mandatory behavior, and interaction\nwith firewalls, access control policy, intermediate proxies, etc.\n\nIn HTTP, you can\n  use a new method (PROPPATCH)\n  use a new URL scheme (afs:)\n  use a new protocol name (SIP/1.0)\n  use a new protocol version (HTTP/1.3)\n  create a new header\n  use a new value for an old header, including\n  - create a new extension field for an old value\n  - create a new content-type for the message body\n  extend the data sent in the body.\n\nMost of these extension methods are used by one or more\napplications that are built out of HTTP. (HTCPCP attempts\nto use most of these.)\n\nThe theory and practice of these extension mechanisms differ.\nSome examples:\n\nServers are supposed to complain if they see new methods, or\nat least handle them with authorization for \"unknown methods\",\nbut some servers treat unrecognized methods as GET; a few\nproxies will forward unrecognized methods as if they were GET.\n\nMost proxies will complain if they are handed unknown URL\nschemes; the practice with origin servers isn't widely tested.\n\nSimilar extensibility mechanisms are also used by applications\nthat use or extend mail; I would include not only SMTP, but\nthe mail-based applications such as Internet Fax, EDI, and\nWorkflow interoperability.\n\nLarry\n-- \nhttp://www.parc.xerox.com/masinter\n\n\n\n", "id": "lists-007-11193577"}, {"subject": "RE: Extensibility methods in APPCORE protoco", "content": "Shouldn't this discussion be happening on the ietf-applcore list?\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-11203165"}, {"subject": "Re: Extensibility methods in APPCORE protoco", "content": "At 22.53 +0100 99-03-22, Graham Klyne wrote:\n> The fact that it is not needed in all cases suggests to me that\n> critical/non-critical marking should not be part of a *core* protocol.\n\nShould APPLCORE be restricted to only contain things which *all*\nprotocols need?\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-11210338"}, {"subject": "Re: Extensibility methods in APPCORE protoco", "content": "> Should APPLCORE be restricted to only contain things which *all*\n> protocols need?\n\nIMO, the feedback from the BOF showed that we are not going to be \ndesigning a \"core\" protocol anytime soon.  Instead, we are going to\nbe documenting useful protocol features.  Since that's what we're \ndoing, there's no reason why we cannot document any feature that is\nthought to be useful.\n\nAlso, it's far easier for a group to agree on pros and cons of certain \nprotocol features, than it is for a group to decide what should or \nshould not go \"in\" a core protocol.  The latter seems like an invitation\nto political disaster.\n\nKeith\n\n\n\n", "id": "lists-007-11218323"}, {"subject": "RE: Extensibility methods in APPCORE protoco", "content": "> At the APPCORE meeting in Minneapolis, it was said that APPCORE should\n> not contain any building block which is not used in two existing\n> IETF standard.\n\nNo.  In both the email leading up to the BOF, and in the BOF itself, the\nscope limitation was on problems, not solutions.\n\n\n\n", "id": "lists-007-11226174"}, {"subject": "RE: Extensibility methods in APPCORE protoco", "content": "The MDN spec has criticality flags.\nSo does X.509, which is referenced by the PKIX specs.\n\nSo I guess we do have precedent for them.\n\n                Harald\n\n-- \nHarald Tveit Alvestrand, Maxware, Norway\nHarald.Alvestrand@maxware.no\n\n\n\n", "id": "lists-007-11233954"}, {"subject": "RE: Extensibility methods in APPCORE protoco", "content": "> The MDN spec has criticality flags.\n> So does X.509, which is referenced by the PKIX specs.\n\n> So I guess we do have precedent for them.\n\nAlso X.400, which offers a pretty good precedent for how bad such flags can be,\neven when they are designed into the core protocol elements in a consistent\nway. I have many horror stories...\n\nConformance to the MDN specification in this general regard is also proving to\nbe a problem operationally, so much so that it has been seriously suggested\nthat it be removed from the standards track. (Note that I neither think this is\ngoing to happen nor want it to; I'm simply reporting what has happened.)\n\nI don't have much experience with X.509, but my guess is that we're going to\nsee all sorts of interoperability problems surrounding the criticality flags in\nit, especially as the increasingly obscure options are exercised.\n\nCriticality flags are a nice idea that for some reason just don't connect with\ntypical human behavior in the right ways. As such, they are a facility you're\nwell advised not to use in a protocol unless you have an overwhelming need.\n\nNed\n\n\n\n", "id": "lists-007-11241894"}, {"subject": "need review for draft-ietf-ldapext-acl-reqts-01.tx", "content": "Folks,\n\nThe LDAPEXT working group has submitted a document called\nAccess Control Requirements for LDAP for IESG approval.\nI'd appreciate some review of this document by the extended community.\n\nThe issue is not so much whether we should publish the document\nor whether they've dotted their i's and crossed their t's.\nWhat I want to know is, do people think that these are reasonable \ndesign goals for LDAP ACLs?  \n\nThe reason I'm taking this unusual step is that I'd rather have \ntheir design goals reviewed now, than to question them when the \nprotocol specification goes to Proposed Standard.  In addition \nto this list, I've also asked IESG to recruit security and \noperational experts to review this.\n\nKeith\n\np.s. yes, we should change the title to \"design goals\" rather than \n\"requirements\", and this should be published as Informational rather \nthan Proposed Standard (as it was Last Called).  We will ask for \nthese things to be fixed in the next revision.  But right now we're \nmore concerned with the criteria in the document, and we don't want \nto ask the authors to revise the document to fix the wording  \nbefore we submit it for additional review.\n\n\n\n", "id": "lists-007-11250581"}, {"subject": "RE: Semantics of delete on a member of a working collectio", "content": "The DELETE of a (version history) member of a working collection is\njust a deletion of that binding to that version history, and that\nthe DELETE/MOVE semantics from sections 5.6 and 5.8 do not apply.\n\nThis information needs to be added to the next rev of the spec,\nso I'll add an Errata entry for this.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Zivkov, Sasa [mailto:sasa.zivkov@sap.com]\nSent: Friday, May 17, 2002 8:50 AM\nTo: ietf-dav-versioning@w3.org\nSubject: Semantics of delete on a member of a working collection\n\n\nHi,\n\nWhat is semantic of DELETE on a member of a working collection that is\nversion\nhistory resource ? Should it (try to) delete the version history or only the\nbinding ?\nIn case it should delete the version history then is it possible to delete\na version controlled resource without checkout-in-place feature ?\n\nRegards\nSasha\n\n\n\n", "id": "lists-007-1125099"}, {"subject": "Re: need review for draft-ietf-ldapext-acl-reqts-01.tx", "content": "Keith,\n\nI think it was useful for you to send this message.\n\nI've looked at this document as a WG member, and it seems broadly sensible.\n\nThe problem is not this document, but how it ties into a broader picture.  \nThere are a few related things:\n\n1) What is LDAP.   Some of us view it as an access protocol, with one of its\nkey benefits being that it is a \"lowest common denominator\" that can connect\ninto NDS, X.500, Oracle Databases, or servers designed specifically to \nsupport LDAP.   Others view that LDAP is synonymous with \"Internet \nDirectory\".   To me, the former view is a massive strength, which has \nenabled everyone to agree on LDAP!  Whatever,  I think that there needs to \nbe a general view taken on this, and it goes much broader than the LDAP WG.\n\n2) I think that what we are talking about here is \"Internet Directory Access\nControl\".  It is not just to do with the access protocol.   \n\n3) A key issue for Internet Directory Access Control, is whether to use \nX.500 Access Control.  This has been discussed in the WG, and there is a \nstrong and clear view in the WG, that this should be looked at seriously.   \nI think that there has been a fairly clear view that X.500 Access Control \nmeets the functional requirements.   If it does not, there is a good liaison\nwith the X.500 cttee, and I am sure that they would look at dealing with \nfurther requirements.   There are some that think X.500 Access Control is \nthe right direction.  For the most part, these people are just getting on \nwith using this, as they view the spec to be done.   Others think that X.500\nbelongs with the dinosaurs, and are proposing specifications.   One group \nwriting a specification have written a document explaining why they don't \nlike X.500.   I don't think anyone has taken a more objective view here.  I \nview that having multiple specifications here will hurt (much more than \nreplication, where co-existence of multiple protocols would not really be a \nbig deal).   I feel strongly that the IETF should adopt X.500 Access \nControl for the Internet Directory: it will do the job.   I think that those\nwriting the ACL specs are suffering from NIH, and not taking a broader view.\nThe group proposing the ACL specs are using this requirements doc as a \nmechanism to promote their specification (i.e., it has a hidden agenda).\nI think that there is a third (silent) group, whose commercial interests \nwould prefer not to see a clean and coherent resolution.\n\n4) It may make sense to look at how this ties in to access control for \nrelated services, such as ACAP and IMAP.\n\n\nSteve Kille\n\n\nOn Fri, 26 Mar 1999 18:18:44 -0500 Keith Moore <moore@cs.utk.edu> wrote:\n\n> Folks,\n> \n> The LDAPEXT working group has submitted a document called\n> Access Control Requirements for LDAP for IESG approval.\n> I'd appreciate some review of this document by the extended community.\n> \n> The issue is not so much whether we should publish the document\n> or whether they've dotted their i's and crossed their t's.\n> What I want to know is, do people think that these are reasonable \n> design goals for LDAP ACLs?  \n> \n> The reason I'm taking this unusual step is that I'd rather have \n> their design goals reviewed now, than to question them when the \n> protocol specification goes to Proposed Standard.  In addition \n> to this list, I've also asked IESG to recruit security and \n> operational experts to review this.\n> \n> Keith\n> \n> p.s. yes, we should change the title to \"design goals\" rather than \n> \"requirements\", and this should be published as Informational rather \n> than Proposed Standard (as it was Last Called).  We will ask for \n> these things to be fixed in the next revision.  But right now we're \n> more concerned with the criteria in the document, and we don't want \n> to ask the authors to revise the document to fix the wording  \n> before we submit it for additional review.\n\n\n\n", "id": "lists-007-11258876"}, {"subject": "Re: Last Call: HTTP Extension Framework to Proposed Standar", "content": "Dear IESG,\n\nIn my earlier last call comments to\ndraft-frystyk-http-extensions-02.txt I advised against the 02 draft\ngoing to proposed.  After that there was a long private e-mail\nexchange between Henrik and me in which we managed to resolve most of\nmy 02 last call comments.  The 03 draft has just been released so here\nis a status update from my side.\n\nThe 03 draft has fixed most of my problems with the 02 draft, and I\nhave no objections against the 03 draft moving forward to proposed.\nOn the other hand, I am not actively encouraging that it moves\nforward, I am neutral on the matter of moving.\n\nI do not plan to use the http-extensions mechanism myself, my main\ninterest in reviewing it has been to make sure that its users would\nnot break caching for me as a HTTP/1.1 user.  I believe that the 03\nspec has lowered the risk of bad caching interactions to an acceptable\nlevel, so I see no reason for me to be against its deployment anymore.\n\nTwo of my 02 last call comments have not been resolved in the 03\ndraft, but I can live with that.  For reference I list these two\ncomments below.\n\nThe first comment, cut-and-pasted from my earlier message:\n\n|- Sec 5 point 4:\n|\n|              A server MUST NOT fulfill a request without\n|              understanding and obeying all mandatory extension\n|              declaration(s) in a request.\n|\n|This implies that a request cannot contain two mandatory extensions\n|which are to be executed by different upstream servers.  For example,\n|if I want my browser to send a mandatory extension to my firewall\n|proxy to enable some privacy processing, I cannot at the same time use\n|a browser plugin which sends a mandatory extension to trigger some\n|plugin-related functionality in the origin server.  Not being able to\n|combine two extensions in this way is a rather severe restriction\n|which kills the whole protocol for me.  It means that plugin vendors\n|cannot use the protocol for fear of proxies getting in the way, and\n|that proxy vendors cannot use the protocol for fear of plugin vendors\n|getting in the way.  Result: nobody can use it.\n|\n|The Ext: mechanism should be fixed to solve this problem, e.g. the\n|Ext: header should include the names of the extensions that were\n|understood and obeyed by different upstream servers.\n\nWith respect to my suggestion for a fix above: I now believe that a\nbetter way of fixing this would be to simply forbid proxies to fulfill\nend-to-end mandatory requests.\n\nThe above comment is really about usability of the spec, not about its\ninternal correctness.  As I do not consider myself to be a likely user\nof the spec, I can live with this comment not being resolved.\n\nThe second unresolved comment:\n\n|- Sec 5.1 Fulfilling a Mandatory Request\n|\n|There is no equivalent material on how to fulfill an optional request.\n\nThis is mostly an editorial nitpick, and I don't care much that it has\nnot been resolved.\n\nKoen.\n\n\n\n", "id": "lists-007-11270212"}, {"subject": "Re: Extensibility methods in APPCORE protoco", "content": "On Wed, 17 Mar 1999, Jacob Palme wrote:\n> At the APPCORE meeting in Minneapolis, it was said that APPCORE should\n> not contain any building block which is not used in two existing\n> IETF standard.\n\nI will ignore APPLCORE-related messages posted to discuss@apps.ietf.org. \nIf you want to make a comment about APPLCORE, please send it to\nietf-applcore[-request]@imc.org. \n\n- Chris\n\n\n\n", "id": "lists-007-11281256"}, {"subject": "Groupware URI", "content": "We are working on a groupware application. In this\napplication, a groupware user always uses the groupware\nserver, in which this user is registered. But the user can\nsee groupware objects in other groupware servers. Since the\nuser interface is web-based, the users use URIs to get to\ngroupware objects (=forums, contributions, users).\n\nThese URIs are constructed by combining the URL of the\nuser's local groupware server, with the URL of the object.\n\nExample:\nOn server cmc.dsv.su.se there is a forum named free-speech.\nOn server web4groups.at, a user is participating in this forum.\nThis user will then use the following URL to get to this forum:\nhttp://web4groups.at/cmc.dsv.su.se/free-speech\n\nIf a user at cmc.dsv.su.se access the same groupware object,\nthey use the URL\nhttp://cmc.dsv.su.se/cmc.dsv.su.se/free-speech\n\nThus, there are different URLs for the same groupware object,\ndepending om where a user's local groupware is. But it would\nbe nice to have some kind of designation of an object which\ndoes not change this way. We have done this by specifying\na new URN or URL scheme named \"gw\" (for groupware).\n\nThus, in the above case, the gw URL for this groupware object\nwould be gw://cmc.dsv.su.se/free-speech.\n\nOrdinary web browser will not understand gw: URIs, unless\nthey are helped by a directory which tells them which is\nthe local groupware server for that user. Knowing that,\nthey can construct the right URL for this user, i.e.\nconvert gw://cmc.dsv.su.se/free-speech to, for example,\nhttp://web4groups.at/cmc.dsv.su.se/free-speech\n\nQuestion 1: Is this the right way to go?\n\nQuestion 2: The \"gw:\" URI scheme, is it a new URL\nscheme or a new URN scheme?\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-11330669"}, {"subject": "get all versions labeled with a given labe", "content": "Hi,\n\nI wonder wether there is a way to get a list of versions (of different\nversion histories) having the same label?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-1133662"}, {"subject": "Content-Language and Multipart/alternativ", "content": "If a message is sent in the Content-Type: Multipart/alternative,\nwith a different (single) language in the Content-Language\nheader of each part, how should then the Multipart/alternative\nbe marked? Should it not be used at all, or should it contain a\nlist of the different languages in the subparts?\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-11339005"}, {"subject": "Re: Content-Language and Multipart/alternativ", "content": "--On Tue, May 4, 1999 9:32 +0200 Jacob Palme <jpalme@dsv.su.se> wrote:\n\n> If a message is sent in the Content-Type: Multipart/alternative,\n> with a different (single) language in the Content-Language\n> header of each part, how should then the Multipart/alternative\n> be marked? Should it not be used at all, or should it contain a\n> list of the different languages in the subparts?\n\nRFC 1766, section 2.1, third \"-\" item.  This question would have been more\nappropriate on a MIME-oriented mailing list\n (e.g. ietf-822[-request]@imc.org).\n\n- Chris\n\n\n\n", "id": "lists-007-11346523"}, {"subject": "SCMP Mail Discussion Lis", "content": "Simple Commerce Messaging Protocol ( SCMP ) \n\nSCMP is a general purpose commerce messaging protocol based on S/MIME.\n\nThere is a new mail list for discussion of the SCMP draft (\ndraft-arnold-scmp-02.txt ). Paul Hoffman at IMC has generously agreed to\nhost the list. To subscribe, send a message to \"ietf-scmp-request@imc.org\"\nwith the word \"subscribe\" in the body of the message.\n\nThanks.\n\nJason EatonCyberSource Corporation\nPhone 408.260.6044Security Engineering Manager\njeaton@cybersource.comhttp://www.cybersource.com\n\n\n\n", "id": "lists-007-11354284"}, {"subject": "Re: Issues in EU-funded ratings research projec", "content": "> The EU-funded research project SELECT\n> ( http://cmc.dsv.su.se/select ) has as its main goal to\n> develop a rating system for web pages. This system will\n> allow people, whenever they see a web page, to give their\n> rating of this web page on a scale from \"very poor\" to\n> \"superior\". The ratings will be stored in a data base, and\n> people will be able to make searches of rated documents,\n> such as \"find all documents whose upper quartile rating is\n> higher than 'good'\" and has the keyword 'SMTP'\" or \"find\n> all documents highly rated by people who often rate\n> documents the same way I rate documents\".\n\nYou might want to check out www.thirdvoice.com; they already do general\nannotations of Web pages rather than simple ratings. Their interface is pretty\ngood, too, although currently limited to IE on Windoze.\n\nAnd it isn't original with Thirdvoice either; I'm told that this sort of\nthing was present in some of the earliest browsers.\n\nNed\n\n\n\n", "id": "lists-007-11361946"}, {"subject": "Notes from the IETF meeting in Washington,  November 199", "content": "My personal notes (not official minutes) from the IETF\nmeeting in Washington, November 1999 can be found at URL\nhttp://www.dsv.su.se/jpalme/ietf/ietf-nov-99-notes.html\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-11391990"}, {"subject": "RFCs in HTML onlin", "content": "At the apps WG chairs meeting, it was suggested I send this URL to the apps\nlist:\n\n<http://www3.innosoft.com/rfc/>\n\nThis has all the RFCs converted to HTML using my heuristic converter (yes,\nit does make mistakes).\n\n- Chris\n\n\n\n", "id": "lists-007-11398875"}, {"subject": "I need apache hel", "content": "Dear sir\ni am trying to study the code of apache , and i find it difficult to\nunderstand so caould u help me to ,\nsend me papers on how the mechanism of apache work , from the acte when\nclient type the address untill apache give him requested page\n\nthanks\n\nAyman Ezzat\n\n\n\n", "id": "lists-007-11405314"}, {"subject": "HTTP Extensions Framework status", "content": "     I saw that a new draft was issued in March, but that's expired, and I\ncan't find anything further. Can anyone enlighten me as to the status of\nthis work?\n\n     Thanks,\n\n     Martin\n\nMartin Presler-Marshall - P3P Champion\nE-mail: mpresler@us.ibm.com\nPhone: (919) 254-7819 (tie-line 444-7819) Fax: (919) 543-4118 (tie-line\n441-4118)\n\n\n\n", "id": "lists-007-11411547"}, {"subject": "RE: get all versions labeled with a given labe", "content": "The short answer is \"no\" (at least, not with a single request).\n\nThere was a thread on this topic not too long ago, and the result\nwas a disagreement about whether or not a PROPFIND Depth:Infinity\nwith a Label header would get this for you or not.\n\nThe answer is probably \"in general, not\", because at least some\nimplementors will not be supporting this.  I've proposed adding\na DAV:get-labeled-version REPORT, which could be used with a\nDepth:Infinity header to do what you want here, but that is not in\nthe current version of the spec, so that doesn't do you any good\nfor right now.\n\nI'll try to get that spec'ed out and posted to the group in a couple\nof weeks, so that there is something out there for us to start\ndiscussing and folks to start playing with if they badly need\nthis functionality.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Wednesday, May 22, 2002 4:29 AM\nTo: 'ietf-dav-versioning@w3.org'\nSubject: get all versions labeled with a given label\n\n\nHi,\n\nI wonder wether there is a way to get a list of versions (of different\nversion histories) having the same label?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-1141589"}, {"subject": "RE: HTTP Extensions Framework status", "content": "> From: mpresler@us.ibm.com\n> Subject: HTTP Extensions Framework status?\n\n>      I saw that a new draft was issued in March, but that's\n> expired, and I\n> can't find anything further. Can anyone enlighten me as to\n> the status of\n> this work?\n\nWe've been trying to get it published as an RFC.\n\nSo far, there has been support within the IESG for making it an\nExperimental, but that would make it a no-no to reference in\nstandards-track documents.  Since there are a number of things that\nwould like to use it and go to standards-track, we are trying to get\nthat changed.\n\nMy own personal take on the situation is that there is resistance to\nanything that encourages more protocols to extend or layer on HTTP\nbecause that is viewed as a problem.  In some ways, I actually share\nthis view, but I also think that since it will happen anyway we should\nat least provide some guidance on the less-bad ways to do it.\n\n[in the interest of reducing duplicates, and because this is about the\nstatus and not the protocol, I've directed replies only to\ndiscuss@apps.ietf.org]\n\n--\nScott Lawrence           Director of R & D        <lawrence@agranat.com>\nAgranat Systems, Inc.  Embedded Web Technology   http://www.agranat.com/\n\n\n\n", "id": "lists-007-11419145"}, {"subject": "RE: HTTP Extensions Framework status", "content": "Scott Lawrence wrote:\n> My own personal take on the situation is that there is resistance to\n> anything that encourages more protocols to extend or layer on HTTP\n> because that is viewed as a problem.  In some ways, I actually share\n> this view, but I also think that since it will happen anyway we should\n> at least provide some guidance on the less-bad ways to do it.\n\nAs one of those people talking about the problem of layering other protocols over HTTP,\nlet me say I agree that it will be done anyway (at least for a while) and that we should\nindeed provide guidance on the less-bad ways to do it.\n\nMike\n\n\n\n", "id": "lists-007-11428966"}, {"subject": "Keep in touch", "content": "Want to keep in touch with old friends from school? The Gradfinder website\nis the perfect resource to do just that.\n\nOn Gradfinder you can add your current contact info, a current photo, and\ndetails about what you are up to these days. You can update your info at\nany time after that. All changes happen immediately. One key feature is\nthe ability to hide your email address from public view. Grads from your\nschool will still be able to email you without your email being exposed.\nThere is also a message board you can use to help organize reunions. You\ncan also upload as many photos as you want and use our photo album wizard\nto create online photo albums to share with friends and family.\n\nThere are currently over 100,000 schools listed from grade 1 to university\nfrom 60 countries around the world.\n\nThis service is free so check it out!\n\nThis site can be found at:\n\nhttp://www.gradfinder.com\n\n\nRemoval Info\n\nIf you would like to be removed from our mailing list forever simply click\nthe link below. If your email program does not support this just copy this\nlink into your web browser:\n\nhttp://www.gradfinder.com/remove.asp?emailId=3941\n\n\n\n", "id": "lists-007-11460185"}, {"subject": "INCREDIBLE $0 to $50,000 in 90 days!!", "content": "                       INCREDIBLE $0 to $50,000 in 90 days!!!\n\n          Dear Friend,\n\nYou can earn $50,000 or more in next the 90 days sending e-mail. Seem impossible? Read on for details.\n\n    With the millennium quickly approaching now is a time for reflecting on personal goals and accomplishments.  Are you happy with your you income?  Have you met your personal goals?   If you answer no to either of these questions then you fall into a category with most people I know, including myself!  \n\n    Hello, my name is Brian. I would like to first thank you for your time and interest.  I had barley completed several years of post secondary education when creditors began to press me for loan payments.  With the lean job market I began the process of gathering information on various business opportunities.  In my opinion, the majority of the information I received was not cost effective, took up too much time, or was so complicated it was difficult to follow.  I then received information on this program from a friend.  After reading and re-reading the program I realized what a great means for making money.  The initial cost was determined by me, this meant I wouldn't have to go further into debt.  My initial investment was $5.00 plus my time on the internet.\n\n    With the exponential growth of the internet and electronic commerce I realized the virtually unlimited market potential.  I was still skeptical, so I contacted one of the people who sent me the original EMAIL.  The response was as follows ' due to the popularity of this letter on the net, a major news program devoted a complete show to determine the legality of the program.  Their findings proved there was no laws against in participating.'   If you have any concerns about this I encourage you to contact the U.S. Post Office (1-800-425-2161 24hrs) to ease any concern you may have.\n\nSo now to business.  Here is how this amazing program can make you thousands of dollars.\n\nINSTRUCTIONS:\n    This method of raising capital REALLY WORKS 100% EVERY TIME.   I am sure you could use up to $50,000 or more in the next 90 days.  Before you dismiss this please take a few minutes and read the program carefully.\n\n    This is not a chain letter, but a perfectly legal money making opportunity. Basically, this is what you do.  As with all multi-level businesses, we build our business by recruiting new partners and selling our products. Every state in the USA allows you to recruit new multi-level business partners, and we offer a product for EVERY dollar sent. YOUR  ORDERS COME BY MAIL AND ARE FILLED BY E-MAIL, so you are not involved in personal selling. You do it privately in your own home, store or office. This is the GREATEST Multi-Level Mail Order Marketing anywhere.\n\n                             This is what you MUST do:\n\n          1. Order all 4 reports shown on the list below (you can't sell them if you don't order them).\n\n          => For each report, send $5.00 CASH, the NAME & NUMBER OF THE  REPORT YOU ARE                   ORDERING, YOUR E-MAIL ADDRESS, and YOUR NAME & RETURN ADDRESS (in                      case of a problem) to the person whose name appears on the list next to the report.  MAKE                SURE YOUR RETURN ADDRESS IS ON YOUR ENVELOPE IN CASE OF ANY MAIL                 PROBLEMS!\n\n          => When you place your order, make sure you order each of the four reports. You will need all                four reports so that you can save them on your computer resell them.\n\n          => Within a few days you will receive, via e-mail, each of the four reports. Save them on your                computer so they will be accessible for you to send to the 1,000's of people who will order                them from you.\n\n          2. IMPORTANT DO NOT alter the names of the people who are listed next to each report, or               their sequence on the list, in any way other than is instructed below in steps \"a\" through  \"f\"               or you will lose out on the majority of your profits.  Once you understand the way this works,               you'll also see how it doesn't work if you change it. Remember, this method has been                         tested, and if you alter it, it will not work.\n\n          a. Look below for the listing of available reports.\n\n          b. After you've ordered the four reports, take this advertisement and remove the name and                    address under REPORT #4. This person has made it through the cycle and is no doubt                      counting their $50,000!\n\n          c. Move the name and address under REPORT #3 down to REPORT  #4.\n\n          d. Move the name and address under REPORT #2 down to REPORT  #3.\n\n          e. Move the name and address under REPORT #1 down to REPORT   #2.\n\n          f. Insert your name/address in the REPORT #1 position.\n\nPlease make sure you COPY ALL INFORMATION, every name and  address, ACCURATELY!\n\n          3. Take this entire letter, including the modified list of names, and save it to your computer.                      Make NO changes to the instruction portion of this letter.\n\n     Your cost to participate in this is practically nothing (surely you can afford $20). You obviously already have an Internet connection and e-mail is FREE!\n\nThere are two primary methods of building a down line, sending bulk EMAIL and placing free adds on the internet.\n\nSENDING BULK E-MAIL:\n    Let's say that you decide to start small, just to see how it  goes, and we'll assume you and all those involved send out only 2,000 programs each. Let's also assume that the mailing receives a 0.5% response. Using a good list the response could be much better. Also, many people will send out hundreds of thousands of programs instead of 2,000. But, continuing with this example, you send out only 2,000 programs. With a 0.5% response, that is only 10 orders for REPORT #1. Those 10 people respond by sending out 2,000  programs each for a total of 20,000. Out of those 0.5%, 100  people respond and order REPORT #2. Those 100 mail out 2,000  programs each for a total of 200,000. The 0.5% response to  that is 1,000 orders for REPORT #3. Those 1,000 send out  2,000 programs each for a 2,000,000 total. The 0.5% response to that is 10,000 orders for REPORT #4. That's 10,000 $5 bills for you. CASH!!! Your total income in this example is $50 + $500 + $5,000 + $50,000 for a total of $55!\n!\n,550!!!\n\n    REMEMBER FRIEND, THIS IS ASSUMING 1,990 OUT OF THE 2,000 PEOPLE YOU MAIL TO WILL DO ABSOLUTELY NOTHING AND TRASH THIS PROGRAM! DARE TO THINK FOR A MOMENT WHAT WOULD HAPPEN IF EVERYONE, OR HALF SENT OUT 100,000 PROGRAMS INSTEAD OF 2,000.  Believe me, many people will do just that, and more!  REPORT #2 will show you the best methods for bulk e-mailing,  tell you where to obtain free bulk e-mail software and where to obtain e-mail lists.\n\nPLACING FREE ADS ON THE INTERNET:\n    Advertising on the Internet is very, very inexpensive, and  there are HUNDREDS of FREE places to advertise. Let's say you  decide to start small just to see how well it works. Assume your goal is to get ONLY 10 people to participate on your first level. (Placing a lot of FREE ads on the Internet will \nEASILY get a larger response.) Also assume that everyone else in YOUR ORGANIZATION gets ONLY 10 down line members. Follow this example to achieve the STAGGERING results below:\n\n          1st level--your 10 members with $5........................$50\n          2nd level--10 members from those 10 ($5 x 100)...........$500\n          3rd level--10 members from those 100 ($5 x 1,000)......$5,000\n          4th level--10 members from those 1,000 ($5 x 10,000)..$50,000\n                                         THIS TOTALS ---------->$55,550\n\n    Remember friends, this assumes that the people who  participate only recruit 10 people each.  think for a moment  what would happen if they got 20 people to participate! Most people get 100's of participants!  Think about it, for every $5.00 you receive, all you must do is e-mail them the report  ordered. THAT'S IT! ALWAYS  PROVIDE SAME-DAY SERVICE ON ALL ORDERS! This will guarantee  that the e-mail THEY send out with YOUR name and address on  it will be prompt because they can't advertise until the receive the report!\n\n                                 AVAILABLE REPORTS\n\n                     *** Order Each REPORT by NUMBER and NAME ***\n                                        Notes:\n          -> ALWAYS SEND $5 CASH (U.S. CURRENCY) FOR EACH REPORT. \n          CHEQUES NOT ACCEPTED.\n          -> ALWAYS SEND YOUR ORDER VIA FIRST CLASS MAIL.\n          -> Make sure the cash is concealed by wrapping it in at least \n          two sheets of paper. On one of those sheets of paper, \n          include:\n          (a) the number & name of the report you are ordering, (b) \n          your e-mail address, and (c) your name & postal address.\n\n          ____________________________________________________________\n\n                     PLACE YOUR ORDER FOR THESE REPORTS NOW:\n\n           REPORT #1 \"The Insider's Guide to Advertising for Free on the Internet\"\n                                     ORDER REPORT #1 FROM:\n                                      BP. ENT\n                                      P.O. Box 178\n                                      Saanichton, BC\n                                      V8M 2C3\n\n           REPORT #2 \"The Insider's Guide to Sending Bulk E-mail on the\n          Internet\"\n                                     ORDER REPORT #2 FROM:\n                                     M. Mathews\n                                     Suite 308 1581-H Hillside Ave\n                                     Victoria, BC.\n                                      V8T 2C1\n\n          REPORT #3 \"The Secrets to Multilevel Marketing on the Internet\"\n\n                                     ORDER REPORT #3 FROM:\n                                     Berkeley Ent.\n                                     42029-2200 Oak Bay Ave\n                                     Oak Bay, BC.\n                                     V8S 2T4\n\n           REPORT #4 \"How to become a Millionaire utilizing the Power \n          of Multilevel Marketing and the Internet\"\n\n                                     ORDER REPORT #4 FROM:\n                                       Patrick O'Brien\n                                       P.O.B 48067 \n                                       3575 Douglas St\n                                       Saanich, BC.\n                                       V82 7H5\n\n                 About 50,000 new people get online every month!\n\n                          ******* TIPS FOR SUCCESS *******\n          - TREAT THIS AS YOUR BUSINESS! Be prompt, professional, and  follow the directions \n             accurately.\n          - Send for the four reports IMMEDIATELY so you will have them when the orders start coming              in because: When you receive a  $5 order, you MUST send out the requested  product/report.\n         - ALWAYS PROVIDE SAME-DAY SERVICE ON THE ORDERS YOU RECEIVE.\n         - Be patient and persistent with this program. If you follow the instructions exactly, your results            WILL BE SUCCESSFUL!\n          - ABOVE ALL, HAVE FAITH IN YOURSELF AND KNOW YOU WILL SUCCEED!\n\n                         ******* YOUR SUCCESS GUIDELINES *******\n                   Follow these guidelines to guarantee your success:\n\n    If you don't receive 20 orders for REPORT #1 within two weeks, continue advertising or sending e-mails until you do.  Then, a couple of weeks later you should receive at least 100 orders for REPORT#2. If you don't, continue advertising or sending e-mails until you do.  Once you have received 100 or more orders for REPORT #2 you can relax because the system is already working for you, and the cash will continue to roll in!\n\nIt is important to remember every time your name is moved down on the list, you are placed in front of a different report. You can keep track of your progress by watching which report people are ordering from you. If you want to generate more income, send another batch of e-mails or continue placing ads and start the whole process again! There is no limit to the income you will generate from this business!\n\n\n             A PERSONAL NOTE FROM THE ORIGINATOR OF THIS PROGRAM:\n\n           By the time you have read the enclosed program and reports,  you should have concluded that such a program, and one that  is legal, could not have been created by an amateur.\n\n           Let me tell you a little about myself. I had a profitable business for 10 years. Then in 1979 my business began falling off. I was doing the same things that were previously  successful for me, but it wasn't working. Finally, I figured  it out. It wasn't me, it was the economy. Inflation and          recession had replaced the stable economy that had been with us since 1945. I don't have to tell you what happened to the unemployment rate...because many of you know from first hand         experience. There were more failures and bankruptcies than  ever before.\n\n           The middle class was vanishing. Those who knew what they  were doing invested wisely and moved up. Those who did not,  including those who never had anything to save or invest, were moving down into the ranks of the poor. As the saying goes, \"THE RICH GET RICHER AND THE POOR GET POORER.\" The traditional methods of making money will never allow you to  \"move up\" or \"get rich\", inflation will see to that.  You have just received information that can give you financial freedom for the rest of your life, with \"NO RISK\"  and \"JUST A LITTLE BIT OF EFFORT.\" You can make more money in the next few months than you have ever imagined.\n\n           I should also point out that I will not see a penny of this money, nor anyone else who has provided a testimonial for this program. I have already made over 4 MILLION DOLLARS! I  have retired from the program after sending thousands and thousands of programs.\n\n           Follow the program EXACTLY AS INSTRUCTED. Do not change it in any way. It works exceedingly well as it is now. Remember to e-mail a copy of this exciting report to everyone you can \n          think of. One of the people you send this to may send out 50,000...and your name will be on every one of them! Remember though, the more you send out the more potential customers you will reach.\n\n           So my friend, I have given you the ideas, information,  materials and opportunity to become financially independent.  IT IS UP TO YOU NOW!  \"THINK ABOUT IT\"\n\n           Before you delete this program from your mailbox, as I almost did, take a little time to read it and REALLY THINK    ABOUT IT. Get a pencil and figure out what could happen when   YOU participate. Figure out the worst possible response and  no matter how you calculate it, you will still make a lot of money! You will definitely get back what you invested. Any doubts you have will vanish when your first orders come in.   IT WORKS!\n\n                             Jody Jacobs, Richmond, VA\n\n    Before you make your decision as to whether or not you  participate in this program. Please answer one question. Do you really want to change your life?  If the answer is yes, please look at the following facts about this program:\n\n          1. You are selling a product, which does not Cost anything to \n          PRODUCE, SHIP OR ADVERTISE.\n          2. All of your customers pay you in CASH!\n          3. E-mail is without question the most powerful method of \n          distributing information on earth. This program combines the \n          distribution power of e-mail together with the revenue \n          generating power of multi-level marketing.\n          4. Your only expense--other than your initial $20 investment-\n          -is your time!\n          5. Virtually all of the income you generate from this program \n          is PURE PROFIT!\n          6. This program will change your LIFE FOREVER.\n\n           ACT NOW! Take your first step toward achieving financial \n          independence.\n\n           Order the reports and follow the program outlined above.\n          SUCCESS will be your reward.\n\n                   Thank you for your time and consideration.\n\n          ____________________________________________________________\n\n    PLEASE NOTE: If you need help with starting a business,  registering a business name, learning how income tax is  handled, etc., contact your local office of the Small Business administration (a Federal Agency) 1-800-827-5722 for free help and answers to questions. Also, the Internal Revenue Service offers free help via telephone and free seminars about business tax requirements. Your earnings are  highly dependent on your activities and advertising. The information contained on this site and in the report constitutes no guarantees stated or implied. In the event that it is determined that this site or report constitutes a guarantee of any kind, that guarantee is now void. The earnings amounts listed on this site and in the report are estimates only. If you have any questions of the legality of this program, contact the Office of Associate Director for Marketing Practices, Federal Trade Commission, and Bureau of Consumer Protection in Washington, D.C.\n________________________________________\nThis Message was Composed by a user of Extractor Pro '98 Bulk E- Mail Software. If \nyou wish to be removed from this advertiser's future mailings, please reply \nwith the subject \"Remove\" and this software will automatically block you \nfrom their future mailings.\n\n\n\n", "id": "lists-007-11467069"}, {"subject": "draft-ietf-ipp-not-http-delivery-0", "content": "I would really appreciate it if future revisions of this draft would not\nrefer to itself as the HTTP notification protocol.  Call it the IPP\nnotification protocol over HTTP, or \"Fred's least efficient mechanism\nfor RPC', but please do not call it HTTP.\n\n....Roy\n\n>A New Internet-Draft is available from the on-line Internet-Drafts directories.\n>This draft is a work item of the Internet Printing Protocol Working Group\n>of the IETF.\n>\n>Title: Internet Printing Protocol/1.1: HTTP-Based IPP \n>                          Notification Delivery Protocol\n>Author(s): H. Parra\n>Filename: draft-ietf-ipp-not-http-delivery-00.txt\n>Pages: 12\n>Date: 26-Oct-99\n>\n>The IPP notification specification [ipp-ntfy] requires the availability\n>of one or more delivery methods for dispatching notification reports to\n>interested parties. This document describes the semantics and syntax of\n>a protocol that a delivery method may use to deliver IPP notifications\n>using HTTP for a transport.\n>\n>A URL for this Internet-Draft is:\n>http://www.ietf.org/internet-drafts/draft-ietf-ipp-not-http-delivery-00.txt\n\n\n\n", "id": "lists-007-11491021"}, {"subject": "RE: get all versions labeled with a given labe", "content": ">...  I've proposed adding\n>a DAV:get-labeled-version REPORT, which could be used with a\n>Depth:Infinity header to do what you want here, but that is not in\n>the current version of the spec, so that doesn't do you any good\n>for right now.\n\nI kind of skimed through this thread. I think the report would be\nthe better way of doing it. And it would be all I had in mind.\n\n>\n>I'll try to get that spec'ed out and posted to the group in a couple\n>of weeks, so that there is something out there for us to start\n>discussing and folks to start playing with if they badly need\n>this functionality.\n>\n>Cheers,\n>Geoff\n>\n>\n>-----Original Message-----\n>From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n>Sent: Wednesday, May 22, 2002 4:29 AM\n>To: 'ietf-dav-versioning@w3.org'\n>Subject: get all versions labeled with a given label\n>\n>\n>Hi,\n>\n>I wonder wether there is a way to get a list of versions (of different\n>version histories) having the same label?\n>\n>Regards,\n>Daniel\n>\n\n\n\n", "id": "lists-007-1150925"}, {"subject": "E.164 numbers and DN", "content": "I have written an I-D which talks about the use of DNS as a repository for\nrouting \"messaging\" where normally E.164 numbers are used as identifiers.\n\nIt specifies that E.164 numbers should be domainnames when they are used on\nthe Internet (and not local part of email addresses, sip URLs etc), and how\nNAPTR and SRV records can be used to look up what services one can use when\none want to contact that number.\n\nIt also talks about the use of DNS as a resolution service in the SCP when\ndealing with SS7 signalling.\n\nThe name of the Internet-Draft (current version) is\ndraft-faltstrom-e164-02.txt. I will shortly update it with some references,\nand information about a mailing list:\n\n   Discussion on this Internet-Draft is to be held on the mailing list\n   ietf-e164-dns@imc.org, which is hosted by the Internet Mail\n   Consortium. To subscribe, send an email to\n   ietf-e164-dns-request@imc.org, with the text \"subscribe\" as the only\n   word in the body of the mail. There is an archive of the mailing\n   list at <http://www.imc.org/ietf-e164-dns/>. \n\n\n     Regards, Patrik\n\n\n\n", "id": "lists-007-11519604"}, {"subject": "Internet draft about Whois extension", "content": "I have written an Internet Draft on extensions to Whois which can make it\npossible for a whois server to give a referal to the whois client. This is\nsupposed to be used mostly internally in registry/registrar environments,\nbut it can also be used for creation of a global whois proxy. It is\nproposed that the IANA should keep enough information about whois servers\nthat exists (information should come from the TLD registrars) so proxy\nservices easilly can be created.\n\nThe name of the I-D is draft-faltstrom-whois-00, but a new version will\ncome out shortly with information about the mailing list, one reference\nadded etc. Nothing substantial has changed.\n\nIMC is hosting a mailing list for the purpose of discussions of this draft:\n\n   Discussion on this Internet-Draft is to be held on the mailing list\n   ietf-whois-ext@imc.org, which is hosted by the Internet Mail\n   Consortium. To subscribe, send an email to\n   ietf-whois-ext-request@imc.org, with the text \"subscribe\" as the\n   only word in the body of the mail. There is an archive of the\n   mailing list at <http://www.imc.org/ietf-whois-ext/>. \n\n\n      Patrik\n\n\n\n", "id": "lists-007-11527026"}, {"subject": "Low Cost Mortgage Loa", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-11535146"}, {"subject": "Freelance.co", "content": "Madam, Sir,\n\nWe noted your e-mail at the internet address\n\"http://www.apps.ietf.org/mailing-lists.html\"\n\nEveryone knows that finding the right projects can be a full time job!\nThat's why Freelance.com is dedicated to Independent Professionals. We are\nthere to promote your skills and your career. To you, this service is free\nand requires no exclusivity.\nFreelance.com is the only global Web-based service that introduces its\nclients to Independent Professionals by using the world's most accurate\nselection and customer-care technology ? real people. To achieve this, we\nare creating a sales network of Account Managers in all major cities across\nNorth America. This network will help you to find the most interesting\nprojects in IT consulting, engineering, web media and telecom with Fortune\n1000 and Internet companies. We are dedicated to Independent Professionals\nlocally, nationally and world-wide.Visit our web site at\nhttp://www.freelance.com to find out more about our\nservices. You will find at your disposal:\n\n- A list of available projects;\n- Contact information for the Account Manager nearest you;\n- Confidential online resume registration forms;\n- How to send us your resume\n- Other vital Independent Professional services (accounting, training,\ninsurance,? internet? links, networking...);\n- Our mailing list registration, to receive a daily e-mail listing of new\nprojects which match your skills.\n\nDon't? hesitate? to contact us if you have questions or comments.\n\nDo tell other Independent Professionals about us!Wishing you all the best\nwith your career as an Independent Professional,\n\n\nYann Marteil\nGeneral Manager Americas\n? -----------------------------------------------------------\n\nFREELANCE.COM?? The global source of projects, information and services for\nIndependent Professionals, Fortune 1000 and Internet companies.\n\n\nFreelance.com\n75 Maiden Lane, suite 507\nNew York, NY 10038\nTel : 212 402 68 68 - Fax : 212 402 68 69\nhttp://www.freelance.com\nContactUSA@freelance.com\n\n-----------------------------------------------------------\n\nWe are fully aware that this document has been mailed without your request.\n\nWe apologize if you are not concerned by this message.\nIf you don't reply with us you won't receive anything from us again.\n\n\n\n", "id": "lists-007-11562735"}, {"subject": "Personal notes from the IETF meetin", "content": "My personal notes from some of the sessions during the IETF\nmeeting in Pittsburgh last week can be found at\nhttp://dsv.su.se/jpalme/ietf/ietf-aug-00-notes.html\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-11591108"}, {"subject": "Review neede", "content": "Can someone please read draft-krebs-gnuqueue-protocol-00.txt and let \nme know whether this is ok for publication as \"Experimental RFC\" or \nnot?\n\n   Regards, Patrik\n   Area Director, Applications Area\n\n\n\n", "id": "lists-007-11597952"}, {"subject": "How to distinguish workspace from collection ", "content": "Hi,\n\nThe rfc3253 says that: \"The DAV:resourcetype of the workspace MUST be\nDAV:collection\".\n\nWhat is the recomended way for a deltaV client to check if a collection is a\nworkspace ?\nOne possibility is that client checks if DAV:workspace property of\nthat collection is the same like URL of this collection.  If yes then\nit is a workspace because DAV:workspace property for a workspace identifies\nitself.\n\nAny better way ?\n\nBest regards\nSasha Zivkov\n\n\n\n", "id": "lists-007-1160031"}, {"subject": "Do You want to earn $3000-$4000 or more per month", "content": "Have a nice day! \n \nDo You want to earn about $3000 per month? If yes just read this e-mail(business_eng.txt)!\nIt`s very eazy and absolutely FREE!!!\nGood luck!!!\n \nPlease excuse me if this e-mail disturbed You.\n\n------------------------------------------------------------------------------------------------\n\n????? ??? ????????? ? ????????? ???! \n \n??? ????????? ??? ?????? ?? ????????;-)\n???? ?? ???????? ????????? ??????? ? ???????? (? ???????, ???????????, ??? ??? ????????), ?? ?????? ?????? ?????????? (?? 50.000$ ? ?????!!!, ??? ??????? ?????? ?? ???) ? ??????? ????????? 90 ????. ??????? ????????????? ?????????? ???????? business_rus.txt\n ? ?? ?????????, ??? ? ???? ??? ??????? ??????? ??? ??????. ???? ?? ?????? ?????? (????? ???????? \n?? ?????????????!!!), ?? ??? ?? ??? ???!!! ????? ??????????? ????????? ??? ???????? ?? ???????? ??? ?? ??????????? ?????. ???? ????? ???-?? ????????? - ? ????????????? ????????.\n? ?????????, ?????.\n\n!!!???? ??????????? ??? ????? ?? ??????????????, ??????? ???? ????????? ? ?? ???? ????????? (\"????\" ????? ???? ????????, ??? ?? ??? ????? ? TV), ?? ?? ?????????, ??? ?????? ?????? ?????????? ??? ????? ???????: \n\"? ????? ???? ???????????? 1% ? ?????????? ?????? 100 ???????, ??? 100% ? ?????????? ????? ??????????? ??????.\" \n\nP.S. ????????????? ???????? ???????? ?? ??????? ???????, ????????? ? ?????? ?????????. \n\n???????? ?? ???? ? ?????????? ????????????? ? ???????!!\n\n?? ?????????? ??? ???????????! - ??? ?????? ?? ?????, ??? ?????? ?? ????????????\n\n \n\n\napplication/octet-stream attachment: Business_eng.txt\n\napplication/octet-stream attachment: Business_rus.txt\n\n\n\n\n", "id": "lists-007-11604775"}, {"subject": "Review neede", "content": "At 19.39 +0200 00-08-10, Patrik F?ltstr?m wrote:\n>Can someone please read draft-krebs-gnuqueue-protocol-00.txt and let me know whether this is ok for publication as \"Experimental RFC\" or not?\n\nThanks you all which have helped me.\n\n   Patrik\n\n\n\n", "id": "lists-007-11612986"}, {"subject": "RE: 3GPP-T-WG3 codec", "content": "On a related topic:\n\nCould we possibly merge the content negotiation mechanisms of the Internet Fax\ngroup (using CONNEG syntax) by registering a media feature for 'codec'; that\nwould allow IFAX-style negotiation using CONNEG feature expressions to talk\nabout WAV formats along with codec names.\n\n\nLarry\n\n\n\n", "id": "lists-007-11641858"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "Patrick,\n\nFWIW, there is a set of \"recommended\" codecs in the SMIL 2.0\ndraft of W3C, and I'm happy to explain why we chose those, if\nneeded:\n\nhttp://www.w3.org/TR/2000/WD-smil20-20000921/smil20-profile.html#BaselineFormatsNS\n\n> Widely Supported MIME Types\n> \n>    This section is informative.\n> \n>    The members of the W3C SYMM Working Group believe that the following\n>    MIME types will be widely supported by SMIL players:\n>      * audio/basic [592][MIME-2]\n>      * image/png ([593][PNG-MIME], [594][PNG-REC])\n>      * image/jpeg ([595][MIME-2], [596][JFIF])\n>    Implementers of SMIL players should thus strive to provide support for\n>    each of these types. Note, however, that this section is\n>    non-normative, and that support for these MIME types is not a\n>    precondition for conformance to this specification.\n> \n>    Authors are encouraged to encode media objects using one of the widely\n>    supported MIME types whenever possible. This will ensure that their\n>    SMIL documents can be played back by a wide range of SMIL players.\n> \n>    If authors use a MIME type that is not in the list of widely supported\n>    types, they should provide an alternative version encoded using a\n>    baseline format. This can be achieved by using a switch element as\n>    shown in the following example:\n> <switch>\n>   <audio src=\"non-baseline-format-object\" />\n>   <audio src=\"baseline-format-object\" />\n> </switch>\n> \n>    In this example, a player that supports the non-baseline format will\n>    play the first audio media object, and a player that does not support\n>    the non-baseline format will play the second media object.\n\nIn general, I'm a bit confused about the request - why would the \nIETF have to comment on the minimal set of codecs in a format\ndefined by another organisation ? This would make sense if the\ngoal is to define a minimal set of codecs that need to be supported\nby MIME mail readers, but otherwise, I don't see the point - am\nI missing something ?\n\n-Philipp\n\n> 3GPP-T-WG3 codecs\n> \n> From: Patrik F?ltstr?m (paf@cisco.com)\n> Date: Thu, Nov 30 2000\n> \n> *Next message: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n> \n>    * Previous message: Jacob Palme: \"Language translation in e-mail\"\n>    * In reply to: Jacob Palme: \"Language translation in e-mail\"\n>    * Next in thread: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>    * Reply: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>    * Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]\n>    * Other mail archives: [this mailing list] [other W3C mailing lists]\n>    * Mail actions: [ respond to this message ] [ mail a new topic ]\n> \n>   ------------------------------------------------------------------------\n> \n> Message-Id: <p05100543b64c4580118a@[10.0.1.28]>\n> Date: Thu, 30 Nov 2000 18:58:56 +0100\n> To: discuss@apps.ietf.org\n> From: Patrik F?ltstr?m  <paf@cisco.com>\n> Subject: 3GPP-T-WG3 codecs\n> \n> I need people interested in the are of codecs. Can someone help with\n> the following request?\n> \n> Let me know if you are interested (or know someone which are interested).\n> \n>     Patrik\n>     Co-Area Director, Applications Area\n> \n> Date: Wednesday, 29 November, 2000 15:06 -0800\n> From: \"Leuca, Ileana\" <ileana.leuca@attws.com>\n> To: \"'sob@harvard.edu'\" <sob@harvard.edu>\n> Subject: 3GPP-T-WG3 codecs\n> \n> Scott,\n> \n> the 3GPP-T2-WG3 defines the minimum set of supported formats for\n> Multimedia Messaging Services.\n> \n> Please help to find an IETF person(s) to be included in the\n> process of standardizing the minimum set of codex for audio,\n> video and image types.\n> \n> In summary the following text is proposed today:\n> ==========================================\n> Multiple media elements shall be combined into a composite\n> single MM using MIME multipart format as defined in RFC 2046\n> [x]. The media type of a single MM element shall be identified\n> by its appropriate MIME type whereas the media format shall be\n> indicated by its appropriate MIME subtype.\n> \n> In order to guarantee a minimum support and compatibility\n> between multimedia messaging capable terminals, the following\n> media formats shall be at least supported.\n> \n> Suggested formats or codecs for media type Audio:\n> - AMR / EFR; organised in octet format as specified in 3G TS\n> 26.101 and 3G TS 26.101\n> - MP3\n> - MIDI\n> - WAV\n> \n> Suggested formats or codecs for media type Image:\n> - JPEG\n> - GIF 89a .\n> \n> Suggested formats or codecs for media type Video:\n> - MPEG 4 (Visual Simple Profile, Level 1)\n> - ITU-T H.263\n> - Quicktime\n> \n> Minimum set of supported media shall support type Text formats.\n> Any character encoding (charset) that contains a subset of the\n> logical characters in Unicode [7] shall be used (e.g. US-ASCII\n> [8], ISO-8859-1[9], UTF-8[10], Shift_JIS, etc.).\n> Unrecognised subtypes of \"text\" shall be treated as subtype\n> \"plain\" as long as the MIME implementation knows how to handle\n> the charset. Any other unrecognised subtype and unrecognised\n> charset shall be treated as \"application/octet - stream\".\n> \n> ================================================================\n> ============ ==\n> thanks,\n> ileana\n> \n> --\n> \n>   ------------------------------------------------------------------------\n> \n>    * Next message: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>    * Previous message: Jacob Palme: \"Language translation in e-mail\"\n>    * In reply to: Jacob Palme: \"Language translation in e-mail\"\n>    * Next in thread: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>    * Reply: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>    * Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]\n>    * Other mail archives: [this mailing list] [other W3C mailing lists]\n>    * Mail actions: [ respond to this message ] [ mail a new topic ]\n\n\n\n", "id": "lists-007-11649466"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "At 14.39 -0500 00-12-07, Philipp Hoschka wrote:\n>In general, I'm a bit confused about the request - why would the\n>IETF have to comment on the minimal set of codecs in a format\n>defined by another organisation ? This would make sense if the\n>goal is to define a minimal set of codecs that need to be supported\n>by MIME mail readers, but otherwise, I don't see the point - am\n>I missing something ?\n\nBecause they want to have the same codecs in the other organization \nas we define for use in the IETF I guess.\n\n    paf\n\n\n-- \n\n\n\n", "id": "lists-007-11663918"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "Patrik F?ltstr?m a ?crit :\n> \n> At 14.39 -0500 00-12-07, Philipp Hoschka wrote:\n> >In general, I'm a bit confused about the request - why would the\n> >IETF have to comment on the minimal set of codecs in a format\n> >defined by another organisation ? This would make sense if the\n> >goal is to define a minimal set of codecs that need to be supported\n> >by MIME mail readers, but otherwise, I don't see the point - am\n> >I missing something ?\n> \n> Because they want to have the same codecs in the other organization\n> as we define for use in the IETF I guess.\n\nSounds reasonable, but in which effort does the IETF define minimally\nrequired codecs for a format ? If such an effort exists, I guess we'd\nbe interested to use the same codecs as well.\n\n\n\n", "id": "lists-007-11671716"}, {"subject": "RE: How to distinguish workspace from collection ", "content": "You could do it that way, but\nI'd just check whether DAV:workspace-checkout-set is\npresent in the DAV:supported-live-property value.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Zivkov, Sasa [mailto:sasa.zivkov@sap.com]\nSent: Tuesday, May 28, 2002 11:17 AM\nTo: ietf-dav-versioning@w3.org\nSubject: How to distinguish workspace from collection ?\n\n\nHi,\n\nThe rfc3253 says that: \"The DAV:resourcetype of the workspace MUST be\nDAV:collection\".\n\nWhat is the recomended way for a deltaV client to check if a collection is a\nworkspace ?\nOne possibility is that client checks if DAV:workspace property of\nthat collection is the same like URL of this collection.  If yes then\nit is a workspace because DAV:workspace property for a workspace identifies\nitself.\n\nAny better way ?\n\nBest regards\nSasha Zivkov\n\n\n\n", "id": "lists-007-1167750"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "Hi\nChoosing MPEG 4 among a  minimum set of supported formats really sounds\nlike joke to me.\nWho should be a able to take advantage of this minimal set as of today ?\n\n> Suggested formats or codecs for media type Video:\n> - MPEG 4 (Visual Simple Profile, Level 1)\n> - ITU-T H.263\n> - Quicktime\n\nThis would look more realistic to me:\n\n> Suggested formats or codecs for media type Video:\n> - MPX (MPEG-1, MPEG-2, MPEG 4)\n> - AVI\n> - Sure Stream (TM) RS G2\n> - Windows Media (TM) \n> - ITU-T H.263\n> - MOV Quicktime (TM)\n\n\nRegards\nHenning\n\n----------------\nIdeen Werft22 GmbH\n\nStadtturmstrasse 5 und 19\nCH 5400 Baden\nTelefon 056 204 29 13\nTelefax 056 202 29 01\nhttp://www.werft22.com\n\nLabor f?r Datenarchitektur\nTelefon 056 210 91 32\nTelefax 056 210 91 34\nhttp://virt.uals.com/\n\nHenning Timcke\n\nStreaming Live with Linux by Ideen Werft 22 GmbH:\nhttp://bahnhof.baden.ch\n\n\nPhilipp Hoschka wrote:\n> \n> Patrick,\n> \n> FWIW, there is a set of \"recommended\" codecs in the SMIL 2.0\n> draft of W3C, and I'm happy to explain why we chose those, if\n> needed:\n> \n> http://www.w3.org/TR/2000/WD-smil20-20000921/smil20-profile.html#BaselineFormatsNS\n> \n> > Widely Supported MIME Types\n> >\n> >    This section is informative.\n> >\n> >    The members of the W3C SYMM Working Group believe that the following\n> >    MIME types will be widely supported by SMIL players:\n> >      * audio/basic [592][MIME-2]\n> >      * image/png ([593][PNG-MIME], [594][PNG-REC])\n> >      * image/jpeg ([595][MIME-2], [596][JFIF])\n> >    Implementers of SMIL players should thus strive to provide support for\n> >    each of these types. Note, however, that this section is\n> >    non-normative, and that support for these MIME types is not a\n> >    precondition for conformance to this specification.\n> >\n> >    Authors are encouraged to encode media objects using one of the widely\n> >    supported MIME types whenever possible. This will ensure that their\n> >    SMIL documents can be played back by a wide range of SMIL players.\n> >\n> >    If authors use a MIME type that is not in the list of widely supported\n> >    types, they should provide an alternative version encoded using a\n> >    baseline format. This can be achieved by using a switch element as\n> >    shown in the following example:\n> > <switch>\n> >   <audio src=\"non-baseline-format-object\" />\n> >   <audio src=\"baseline-format-object\" />\n> > </switch>\n> >\n> >    In this example, a player that supports the non-baseline format will\n> >    play the first audio media object, and a player that does not support\n> >    the non-baseline format will play the second media object.\n> \n> In general, I'm a bit confused about the request - why would the\n> IETF have to comment on the minimal set of codecs in a format\n> defined by another organisation ? This would make sense if the\n> goal is to define a minimal set of codecs that need to be supported\n> by MIME mail readers, but otherwise, I don't see the point - am\n> I missing something ?\n> \n> -Philipp\n> \n> > 3GPP-T-WG3 codecs\n> >\n> > From: Patrik F?ltstr?m (paf@cisco.com)\n> > Date: Thu, Nov 30 2000\n> >\n> > *Next message: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n> >\n> >    * Previous message: Jacob Palme: \"Language translation in e-mail\"\n> >    * In reply to: Jacob Palme: \"Language translation in e-mail\"\n> >    * Next in thread: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n> >    * Reply: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n> >    * Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]\n> >    * Other mail archives: [this mailing list] [other W3C mailing lists]\n> >    * Mail actions: [ respond to this message ] [ mail a new topic ]\n> >\n> >   ------------------------------------------------------------------------\n> >\n> > Message-Id: <p05100543b64c4580118a@[10.0.1.28]>\n> > Date: Thu, 30 Nov 2000 18:58:56 +0100\n> > To: discuss@apps.ietf.org\n> > From: Patrik F?ltstr?m  <paf@cisco.com>\n> > Subject: 3GPP-T-WG3 codecs\n> >\n> > I need people interested in the are of codecs. Can someone help with\n> > the following request?\n> >\n> > Let me know if you are interested (or know someone which are interested).\n> >\n> >     Patrik\n> >     Co-Area Director, Applications Area\n> >\n> > Date: Wednesday, 29 November, 2000 15:06 -0800\n> > From: \"Leuca, Ileana\" <ileana.leuca@attws.com>\n> > To: \"'sob@harvard.edu'\" <sob@harvard.edu>\n> > Subject: 3GPP-T-WG3 codecs\n> >\n> > Scott,\n> >\n> > the 3GPP-T2-WG3 defines the minimum set of supported formats for\n> > Multimedia Messaging Services.\n> >\n> > Please help to find an IETF person(s) to be included in the\n> > process of standardizing the minimum set of codex for audio,\n> > video and image types.\n> >\n> > In summary the following text is proposed today:\n> > ==========================================\n> > Multiple media elements shall be combined into a composite\n> > single MM using MIME multipart format as defined in RFC 2046\n> > [x]. The media type of a single MM element shall be identified\n> > by its appropriate MIME type whereas the media format shall be\n> > indicated by its appropriate MIME subtype.\n> >\n> > In order to guarantee a minimum support and compatibility\n> > between multimedia messaging capable terminals, the following\n> > media formats shall be at least supported.\n> >\n> > Suggested formats or codecs for media type Audio:\n> > - AMR / EFR; organised in octet format as specified in 3G TS\n> > 26.101 and 3G TS 26.101\n> > - MP3\n> > - MIDI\n> > - WAV\n> >\n> > Suggested formats or codecs for media type Image:\n> > - JPEG\n> > - GIF 89a .\n> >\n> > Suggested formats or codecs for media type Video:\n> > - MPEG 4 (Visual Simple Profile, Level 1)\n> > - ITU-T H.263\n> > - Quicktime\n> >\n> > Minimum set of supported media shall support type Text formats.\n> > Any character encoding (charset) that contains a subset of the\n> > logical characters in Unicode [7] shall be used (e.g. US-ASCII\n> > [8], ISO-8859-1[9], UTF-8[10], Shift_JIS, etc.).\n> > Unrecognised subtypes of \"text\" shall be treated as subtype\n> > \"plain\" as long as the MIME implementation knows how to handle\n> > the charset. Any other unrecognised subtype and unrecognised\n> > charset shall be treated as \"application/octet - stream\".\n> >\n> > ================================================================\n> > ============ ==\n> > thanks,\n> > ileana\n> >\n> > --\n> >\n> >   ------------------------------------------------------------------------\n> >\n> >    * Next message: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n> >    * Previous message: Jacob Palme: \"Language translation in e-mail\"\n> >    * In reply to: Jacob Palme: \"Language translation in e-mail\"\n> >    * Next in thread: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n> >    * Reply: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n> >    * Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]\n> >    * Other mail archives: [this mailing list] [other W3C mailing lists]\n> >    * Mail actions: [ respond to this message ] [ mail a new topic ]\n\n\n\n", "id": "lists-007-11679658"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "At 12.56 +0100 00-12-08, Henning Timcke wrote:\n>Hi\n>Choosing MPEG 4 among a  minimum set of supported formats really sounds\n>like joke to me.\n>Who should be a able to take advantage of this minimal set as of today ?\n>\n>>  Suggested formats or codecs for media type Video:\n>>  - MPEG 4 (Visual Simple Profile, Level 1)\n>>  - ITU-T H.263\n>>  - Quicktime\n>\n>This would look more realistic to me:\n>\n>>  Suggested formats or codecs for media type Video:\n>>  - MPX (MPEG-1, MPEG-2, MPEG 4)\n>>  - AVI\n>>  - Sure Stream (TM) RS G2\n>>  - Windows Media (TM)\n>>  - ITU-T H.263\n>>  - MOV Quicktime (TM)\n\nI think it is important to be much much more detailed when specifying \na list like this.\n\nI am not working in this area much personally, but I feel we have \nthree layers of \"things\" that needs to be standardized for a sender \nto be able to send data to a receiver:\n\n   (a) Codec\n   (b) Format\n   (c) Transport Protocol\n\nAll three layers have to match for things to work. Several client \n(and server) software can handle many different permutations of the \nalternatives for each layer in this micro-stack.\n\nIs it not something like this which have to be specified?\n\n      paf\n\n\n>\n>\n>Regards\n>Henning\n>\n>----------------\n>Ideen Werft22 GmbH\n>\n>Stadtturmstrasse 5 und 19\n>CH 5400 Baden\n>Telefon 056 204 29 13\n>Telefax 056 202 29 01\n>http://www.werft22.com\n>\n>Labor f?r Datenarchitektur\n>Telefon 056 210 91 32\n>Telefax 056 210 91 34\n>http://virt.uals.com/\n>\n>Henning Timcke\n>\n>Streaming Live with Linux by Ideen Werft 22 GmbH:\n>http://bahnhof.baden.ch\n>\n>\n>Philipp Hoschka wrote:\n>>\n>>  Patrick,\n>>\n>>  FWIW, there is a set of \"recommended\" codecs in the SMIL 2.0\n>>  draft of W3C, and I'm happy to explain why we chose those, if\n>>  needed:\n>>\n>> \n>>http://www.w3.org/TR/2000/WD-smil20-20000921/smil20-profile.html#BaselineFormatsNS\n>>\n>>  > Widely Supported MIME Types\n>>  >\n>>  >    This section is informative.\n>>  >\n>>  >    The members of the W3C SYMM Working Group believe that the following\n>>  >    MIME types will be widely supported by SMIL players:\n>>  >      * audio/basic [592][MIME-2]\n>>  >      * image/png ([593][PNG-MIME], [594][PNG-REC])\n>>  >      * image/jpeg ([595][MIME-2], [596][JFIF])\n>>  >    Implementers of SMIL players should thus strive to provide support for\n>>  >    each of these types. Note, however, that this section is\n>>  >    non-normative, and that support for these MIME types is not a\n>>  >    precondition for conformance to this specification.\n>>  >\n>>  >    Authors are encouraged to encode media objects using one of the widely\n>>  >    supported MIME types whenever possible. This will ensure that their\n>>  >    SMIL documents can be played back by a wide range of SMIL players.\n>>  >\n>>  >    If authors use a MIME type that is not in the list of widely supported\n>>  >    types, they should provide an alternative version encoded using a\n>>  >    baseline format. This can be achieved by using a switch element as\n>>  >    shown in the following example:\n>>  > <switch>\n>>  >   <audio src=\"non-baseline-format-object\" />\n>>  >   <audio src=\"baseline-format-object\" />\n>>  > </switch>\n>>  >\n>>  >    In this example, a player that supports the non-baseline format will\n>>  >    play the first audio media object, and a player that does not support\n>>  >    the non-baseline format will play the second media object.\n>>\n>>  In general, I'm a bit confused about the request - why would the\n>>  IETF have to comment on the minimal set of codecs in a format\n>>  defined by another organisation ? This would make sense if the\n>>  goal is to define a minimal set of codecs that need to be supported\n>>  by MIME mail readers, but otherwise, I don't see the point - am\n>>  I missing something ?\n>>\n>>  -Philipp\n>>\n>>  > 3GPP-T-WG3 codecs\n>>  >\n>>  > From: Patrik F?ltstr?m (paf@cisco.com)\n>>  > Date: Thu, Nov 30 2000\n>>  >\n>>  > *Next message: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>>  >\n>>  >    * Previous message: Jacob Palme: \"Language translation in e-mail\"\n>>  >    * In reply to: Jacob Palme: \"Language translation in e-mail\"\n>  > >    * Next in thread: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>>  >    * Reply: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>>  >    * Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]\n>>  >    * Other mail archives: [this mailing list] [other W3C mailing lists]\n>>  >    * Mail actions: [ respond to this message ] [ mail a new topic ]\n>>  >\n>>  >   ------------------------------------------------------------------------\n>>  >\n>>  > Message-Id: <p05100543b64c4580118a@[10.0.1.28]>\n>>  > Date: Thu, 30 Nov 2000 18:58:56 +0100\n>>  > To: discuss@apps.ietf.org\n>>  > From: Patrik F?ltstr?m  <paf@cisco.com>\n>>  > Subject: 3GPP-T-WG3 codecs\n>>  >\n>>  > I need people interested in the are of codecs. Can someone help with\n>>  > the following request?\n>>  >\n>>  > Let me know if you are interested (or know someone which are interested).\n>>  >\n>>  >     Patrik\n>>  >     Co-Area Director, Applications Area\n>>  >\n>>  > Date: Wednesday, 29 November, 2000 15:06 -0800\n>>  > From: \"Leuca, Ileana\" <ileana.leuca@attws.com>\n>>  > To: \"'sob@harvard.edu'\" <sob@harvard.edu>\n>>  > Subject: 3GPP-T-WG3 codecs\n>>  >\n>>  > Scott,\n>>  >\n>>  > the 3GPP-T2-WG3 defines the minimum set of supported formats for\n>>  > Multimedia Messaging Services.\n>>  >\n>>  > Please help to find an IETF person(s) to be included in the\n>>  > process of standardizing the minimum set of codex for audio,\n>>  > video and image types.\n>>  >\n>>  > In summary the following text is proposed today:\n>>  > ==========================================\n>>  > Multiple media elements shall be combined into a composite\n>>  > single MM using MIME multipart format as defined in RFC 2046\n>>  > [x]. The media type of a single MM element shall be identified\n>>  > by its appropriate MIME type whereas the media format shall be\n>>  > indicated by its appropriate MIME subtype.\n>>  >\n>>  > In order to guarantee a minimum support and compatibility\n>>  > between multimedia messaging capable terminals, the following\n>>  > media formats shall be at least supported.\n>>  >\n>>  > Suggested formats or codecs for media type Audio:\n>>  > - AMR / EFR; organised in octet format as specified in 3G TS\n>>  > 26.101 and 3G TS 26.101\n>>  > - MP3\n>>  > - MIDI\n>>  > - WAV\n>>  >\n>>  > Suggested formats or codecs for media type Image:\n>>  > - JPEG\n>>  > - GIF 89a .\n>>  >\n>>  > Suggested formats or codecs for media type Video:\n>>  > - MPEG 4 (Visual Simple Profile, Level 1)\n>>  > - ITU-T H.263\n>>  > - Quicktime\n>>  >\n>>  > Minimum set of supported media shall support type Text formats.\n>>  > Any character encoding (charset) that contains a subset of the\n>>  > logical characters in Unicode [7] shall be used (e.g. US-ASCII\n>>  > [8], ISO-8859-1[9], UTF-8[10], Shift_JIS, etc.).\n>>  > Unrecognised subtypes of \"text\" shall be treated as subtype\n>>  > \"plain\" as long as the MIME implementation knows how to handle\n>>  > the charset. Any other unrecognised subtype and unrecognised\n>>  > charset shall be treated as \"application/octet - stream\".\n>>  >\n>>  > ================================================================\n>>  > ============ ==\n>>  > thanks,\n>>  > ileana\n>>  >\n>>  > --\n>>  >\n>>  >   ------------------------------------------------------------------------\n>>  >\n>>  >    * Next message: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>>  >    * Previous message: Jacob Palme: \"Language translation in e-mail\"\n>>  >    * In reply to: Jacob Palme: \"Language translation in e-mail\"\n>>  >    * Next in thread: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>>  >    * Reply: Glenn Parsons: \"RE: 3GPP-T-WG3 codecs\"\n>>  >    * Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]\n>>  >    * Other mail archives: [this mailing list] [other W3C mailing lists]\n>>  >    * Mail actions: [ respond to this message ] [ mail a new topic ]\n\n\n\n\n-- \n\n\n\n", "id": "lists-007-11696256"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "At 04.44 -0500 00-12-08, Philipp Hoschka wrote:\n>Sounds reasonable, but in which effort does the IETF define minimally\n>required codecs for a format ? If such an effort exists, I guess we'd\n>be interested to use the same codecs as well.\n\nIn  various wg's (not in _one_ place) codecs are defined. This \ninclude AVT and VPIM wg's for example.\n\nTo be honest, it might be the case that I should have initiated some \nwork on coordinating the selection of codecs earlier, but it has not \nhappened. Or rather, it has happened by having individuals informally \nsyncronizing between I-Ds which later turned into RFCs.\n\nDo you belive a specific RFC should be written on what codecs to choose?\n\n(A question to all people on this list.)\n\nCan people interested bring this up on the VPIM and AVT (and other) \nwg meetings next week?\n\nI am happy to sponsor the creation of a BCP on codec selections.\n\n   paf\n\n\n-- \n\n\n\n", "id": "lists-007-11714875"}, {"subject": "Fwd: WEBI (son of WREC), CDNP, and OPE", "content": "This is a copy of the document that the WEBI, CDNP and OPES groups/BoFs put \ntogether which explains how the groups interact:\n\n>Michael Condry\n>Ian Cooper\n>Mark Day\n>Mark Nottingham\n>Hilarie Orman\n>\n>\n>There are currently multiple proposals for IETF Applications Area working\n>groups related to Web transport/content distribution; WREC/WEBI, OPES and\n>CDNP. This discussion proposes deliniations between the groups, in order to\n>clarify their roles.\n>\n>Historically, WREC focused on caching and replication. WEBI is proposed to\n>replace WREC and slightly broaden its scope to include issues of general\n>import to intermediaries. WEBI work items will be distinguished by being\n>generic, in that they are not specific to one application domain (such as\n>content peering or value-added proxies). For example, invalidation\n>mechanisms and intermediate discovery protocols are of interest in multiple\n>applications. Note that if requirements for a particular application can not\n>be met by a general mechanism, it may be appropriate to define an\n>application-specific mechanism as well. WEBI might produce other groups as\n>workload requires.\n>\n>The Open Proxy Services architecture (OPES) allows for services to be\n>constructed \"inside the network\", allowing both the overlay of value-added\n>services and the introduction of a processing model in intermediaries. OPES\n>work items will be distinguished in that they involve definition and/or\n>support of value-added services on intermediaries. For example, this may\n>include a means of vectoring messages to \"callout servers\" and configuration\n>and managment of services, but should exclude general content routing\n>mechanisms.\n>\n>Content Distribution Network Peering (CDNP) defines a model and mechanisms\n>for the interconnection and cooperation of networks for content-related\n>tasks: direction (directing requests for content), distribution (moving\n>content out to surrogates) and accounting (tracking the delivery of content\n>from surrogates).  A single network may have its own mechanisms for these\n>tasks, and WEBI may define or standardize elements of those mechanisms. CDNP\n>focuses on the interactions required for direction, distribution, and\n>accounting between two or more networks with different administrations,\n>where the networks are potentially using different local mechanisms for\n>\n>Within WREC/WEBI, OPES and CDNP are largely orthogonal. The groups\n>should cooperate in order to avoid conflicting specifications.\n\n\n\n", "id": "lists-007-11723138"}, {"subject": "RE: 3GPP-T-WG3 codec", "content": "Philipp, I'd be interested in the rational that made you pick audio/basic \n\n> FWIW, there is a set of \"recommended\" codecs in the SMIL 2.0\n> draft of W3C, and I'm happy to explain why we chose those, if\n> needed:\n> \n> http://www.w3.org/TR/2000/WD-smil20-20000921/smil20-profile.html#BaselineF\n> ormatsNS\n> \n> > Widely Supported MIME Types\n> > \n> >    This section is informative.\n> > \n> >    The members of the W3C SYMM Working Group believe that the following\n> >    MIME types will be widely supported by SMIL players:\n> >      * audio/basic [592][MIME-2]\n> >      * image/png ([593][PNG-MIME], [594][PNG-REC])\n> >      * image/jpeg ([595][MIME-2], [596][JFIF])\n> >    Implementers of SMIL players should thus strive to provide support\n> for\n> >    each of these types. Note, however, that this section is\n> >    non-normative, and that support for these MIME types is not a\n> >    precondition for conformance to this specification.\n> > \n> >    Authors are encouraged to encode media objects using one of the\n> widely\n> >    supported MIME types whenever possible. This will ensure that their\n> >    SMIL documents can be played back by a wide range of SMIL players.\n> > \n> >    If authors use a MIME type that is not in the list of widely\n> supported\n> >    types, they should provide an alternative version encoded using a\n> >    baseline format. This can be achieved by using a switch element as\n> >    shown in the following example:\n> > <switch>\n> >   <audio src=\"non-baseline-format-object\" />\n> >   <audio src=\"baseline-format-object\" />\n> > </switch>\n> > \n> >    In this example, a player that supports the non-baseline format will\n> >    play the first audio media object, and a player that does not support\n> >    the non-baseline format will play the second media object.\n> \n> In general, I'm a bit confused about the request - why would the \n> IETF have to comment on the minimal set of codecs in a format\n> defined by another organisation ? This would make sense if the\n> goal is to define a minimal set of codecs that need to be supported\n> by MIME mail readers, but otherwise, I don't see the point - am\n> I missing something ?\n> \nI don't think the IETF _has_ to comment, we've just been asked..\n\nThis is more about the codecs available on various devices.  Few if any mail\nclients have audio codecs included.  \n\nCheers,\nGlenn.\n\n\n\n", "id": "lists-007-11732209"}, {"subject": "RE: 3GPP-T-WG3 codec", "content": "On Thu, 7 Dec 2000, Glenn Parsons wrote:\n\n>\n> Philipp, I'd be interested in the rational that made you pick audio/basic\n\nJust saw this in passing and thought I'd offer my 2c\n\nAudio/basic as I recall is a mu-law codec and  was impelmented in hardware\non Sun workstations and some early PC sound cards. It has been dropped\nfrom later soundcards so that conversion must be done in software.\nWAV seems to be the defacto standard, though I confess that there seem to\nbe many flavours and it is at heart a proprietary format. MP3, anyone ?\n\nAndrew Daviel\n\n\n\n", "id": "lists-007-11742872"}, {"subject": "RE: 3GPP-T-WG3 codec", "content": "At 13.17 -0800 00-12-11, Andrew Daviel wrote:\n>WAV seems to be the defacto standard, though I confess that there seem to\n>be many flavours and it is at heart a proprietary format. MP3, anyone ?\n\nDo we have someone reading these messages which can let me know if I \nam right or wrong when claiming that we talk about a sort of three \nlayer architecture:\n\n    Codec\n    Format\n  Transport\n\nIn the case of Waw, that is not a codec, but a format, which allow \ndifferent codecs.\n\n????\n\nHas anyone seen any compilation on what various \"words\" actually mean?\n\n     paf\n\n\n-- \n\n\n\n", "id": "lists-007-11751043"}, {"subject": "RE: 3GPP-T-WG3 codec", "content": "At 01:30 PM 12/11/00 , Patrik F?ltstr?m wrote:\n>At 13.17 -0800 00-12-11, Andrew Daviel wrote:\n>>WAV seems to be the defacto standard, though I confess that there seem to\n>>be many flavours and it is at heart a proprietary format. MP3, anyone\n>\n>Do we have someone reading these messages which can let me know if I am \n>right or wrong when claiming that we talk about a sort of three layer \n>architecture:\n>\n>    Codec\n>    Format\n>  Transport\n>\n>In the case of Waw, that is not a codec, but a format, which allow \n>different codecs.\n\nYou are correct (typo excluded).  Wav is a file format which may contain \nmany different codecs\n\n>Has anyone seen any compilation on what various \"words\" actually mean?\n\nTry the RTSP FAQ:\nhttp://www.realnetworks.com/devzone/library/rtsp/faq.htm\n\nSome of the information is a little outdated, but this particular question \nis a timeless one.  :)\n\nRob\n\n\n\n", "id": "lists-007-11759340"}, {"subject": "RE: RFC 3253 issue vs. DAV:auto-update and working resource", "content": "I never saw a response to Julian's questions. Can somebody enlighten us?\n\nlisa\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Julian Reschke\n> Sent: Wednesday, May 15, 2002 8:08 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: RFC 3253 issue vs. DAV:auto-update and working resources\n> \n> \n> Hi,\n> \n> [1] states that DAV:auto-update is a required property for a working\n> resource.\n> \n> However, [2] states that \"The DAV:auto-update property of the working\n> resource MUST NOT exist.\" is the CHECKOUT is done on a version.\n> \n> So, is it required or not? If not, how can I detect that \n> something is a\n> working resource?\n> \n> Julian\n> \n> [1] <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.9.2>\n> [2] \n> <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.9.3.p.4>\n> \n> \n\n\n\n", "id": "lists-007-1176131"}, {"subject": "Correction (RE: 3GPP-T-WG3 codecs", "content": "At 01:55 PM 12/11/00 , Rob Lanphier wrote:\n\n>At 01:30 PM 12/11/00 , Patrik F?ltstr?m wrote:\n>>Has anyone seen any compilation on what various \"words\" actually mean?\n>\n>Try the RTSP FAQ:\n>http://www.realnetworks.com/devzone/library/rtsp/faq.htm\n\nBleh....I just saw that I messed up the link.  Make that:\nhttp://www.realnetworks.com/devzone/library/rtsp/faq.html\n\nRob\n\n\n\n", "id": "lists-007-11768251"}, {"subject": "RE: 3GPP-T-WG3 codec", "content": "> Patrik F?ltstr?m a ?crit :\n> > \n> > At 14.39 -0500 00-12-07, Philipp Hoschka wrote:\n> > >In general, I'm a bit confused about the request - why would the\n> > >IETF have to comment on the minimal set of codecs in a format\n> > >defined by another organisation ? This would make sense if the\n> > >goal is to define a minimal set of codecs that need to be supported\n> > >by MIME mail readers, but otherwise, I don't see the point - am\n> > >I missing something ?\n> > \n> > Because they want to have the same codecs in the other organization\n> > as we define for use in the IETF I guess.\n> \n> Sounds reasonable, but in which effort does the IETF define minimally\n> required codecs for a format ? If such an effort exists, I guess we'd\n> be interested to use the same codecs as well.\n> \nIn the VPIM WG we defined the baseline audio codec for voice mail system\ninteroperability.  It is G.726 for VPIM v2.  For IVM the choice is currently\nMS-GSM but may be changed to G.711.\n\nIn the Fax WG, they defined the baseline image format.  It is TIFF-S for\nsimple mode.\n\n\n\n", "id": "lists-007-11776618"}, {"subject": "RE: 3GPP-T-WG3 codec", "content": "Glen wrote up such a proposal some time ago for the VPIM work ... I don't \nknow if it's still live.\n\n#g\n--\n\n\nAt 09:23 AM 12/3/00 -0800, Larry Masinter wrote:\n>On a related topic:\n>\n>Could we possibly merge the content negotiation mechanisms of the Internet Fax\n>group (using CONNEG syntax) by registering a media feature for 'codec'; that\n>would allow IFAX-style negotiation using CONNEG feature expressions to talk\n>about WAV formats along with codec names.\n>\n>\n>Larry\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-11785610"}, {"subject": "RE: 3GPP-T-WG3 codec", "content": "The rationale for picking audio/basic was that it\nis widely supported in SMIL players today, and doesn't\nrequire paying a license fee.\n\nIf you know of another license-free, widely \nsupported audio format with better \ncharacteristics than audio/basic, that may be\ninteresting.\n\n--- thierry michel <tmichel@w3.org> wrote:\n> RE: 3GPP-T-WG3 codecs\n>   ----- Original Message ----- \n>   From: Glenn Parsons \n>   To: discuss@apps.ietf.org ; www-smil@w3.org ;\n> 'Philipp Hoschka' \n>   Cc: 'IETF VPIM List' \n>   Sent: Monday, December 11, 2000 8:28 PM\n>   Subject: [Moderator Action] RE: 3GPP-T-WG3 codecs\n> \n> \n> \n> \n>   Philipp, I'd be interested in the rational that\n> made you pick audio/basic \n> \n>     FWIW, there is a set of \"recommended\" codecs in\n> the SMIL 2.0 \n>     draft of W3C, and I'm happy to explain why we\n> chose those, if \n>     needed: \n> \n>    \n>\nhttp://www.w3.org/TR/2000/WD-smil20-20000921/smil20-profile.html#BaselineFormatsNS\n> \n> \n>     > Widely Supported MIME Types \n>     > \n>     >    This section is informative. \n>     > \n>     >    The members of the W3C SYMM Working Group\n> believe that the following \n>     >    MIME types will be widely supported by SMIL\n> players: \n>     >      * audio/basic [592][MIME-2] \n>     >      * image/png ([593][PNG-MIME],\n> [594][PNG-REC]) \n>     >      * image/jpeg ([595][MIME-2], [596][JFIF])\n> \n>     >    Implementers of SMIL players should thus\n> strive to provide support for \n>     >    each of these types. Note, however, that\n> this section is \n>     >    non-normative, and that support for these\n> MIME types is not a \n>     >    precondition for conformance to this\n> specification. \n>     > \n>     >    Authors are encouraged to encode media\n> objects using one of the widely \n>     >    supported MIME types whenever possible.\n> This will ensure that their \n>     >    SMIL documents can be played back by a wide\n> range of SMIL players. \n>     > \n>     >    If authors use a MIME type that is not in\n> the list of widely supported \n>     >    types, they should provide an alternative\n> version encoded using a \n>     >    baseline format. This can be achieved by\n> using a switch element as \n>     >    shown in the following example: \n>     > <switch> \n>     >   <audio src=\"non-baseline-format-object\" /> \n>     >   <audio src=\"baseline-format-object\" /> \n>     > </switch> \n>     > \n>     >    In this example, a player that supports the\n> non-baseline format will \n>     >    play the first audio media object, and a\n> player that does not support \n>     >    the non-baseline format will play the\n> second media object. \n> \n>     In general, I'm a bit confused about the request\n> - why would the \n>     IETF have to comment on the minimal set of\n> codecs in a format \n>     defined by another organisation ? This would\n> make sense if the \n>     goal is to define a minimal set of codecs that\n> need to be supported \n>     by MIME mail readers, but otherwise, I don't see\n> the point - am \n>     I missing something ? \n> \n>   I don't think the IETF _has_ to comment, we've\n> just been asked.. \n> \n>   This is more about the codecs available on various\n> devices.  Few if any mail clients have audio codecs\n> included.  \n> \n>   Cheers, \n>   Glenn. \n> \n> \n\n\n__________________________________________________\nDo You Yahoo!?\nYahoo! Shopping - Thousands of Stores. Millions of Products.\nhttp://shopping.yahoo.com/\n\n\n\n", "id": "lists-007-11794054"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "Glenn,\n\nsee\nhttp://www.w3.org/AudioVideo/#SMIL\n\nNote that audio/basic, while ok for interoperability, is certainly\nnot the most frequently used audio codec in the SMIL area - but\nthis was the best we felt we could do in the interop area, for\nthe reasons already stated.\n\n-Philipp\n\nGlenn Parsons a ?crit :\n> \n> Forgive my ignorance, but could you give us an example of a SMIL player?\n> \n> On 12/12/00 5:54 am, \"Philipp Hoschka\" <hoschka@yahoo.com> wrote:\n> \n> > The rationale for picking audio/basic was that it\n> > is widely supported in SMIL players today, and doesn't\n> > require paying a license fee.\n> >\n> > If you know of another license-free, widely\n> > supported audio format with better\n> > characteristics than audio/basic, that may be\n> > interesting.\n> >\n> > --- thierry michel <tmichel@w3.org> wrote:\n> >> RE: 3GPP-T-WG3 codecs\n> >>   ----- Original Message -----\n> >>   From: Glenn Parsons\n> >>   To: discuss@apps.ietf.org ; www-smil@w3.org ;\n> >> 'Philipp Hoschka'\n> >>   Cc: 'IETF VPIM List'\n> >>   Sent: Monday, December 11, 2000 8:28 PM\n> >>   Subject: [Moderator Action] RE: 3GPP-T-WG3 codecs\n> >>\n> >>\n> >>\n> >>\n> >>   Philipp, I'd be interested in the rational that\n> >> made you pick audio/basic\n> >>\n> >>     FWIW, there is a set of \"recommended\" codecs in\n> >> the SMIL 2.0\n> >>     draft of W3C, and I'm happy to explain why we\n> >> chose those, if\n> >>     needed:\n> >>\n> >>\n> >>\n> > http://www.w3.org/TR/2000/WD-smil20-20000921/smil20-profile.html#BaselineForma\n> > tsNS\n> >>\n> >>\n> >>> Widely Supported MIME Types\n> >>>\n> >>>    This section is informative.\n> >>>\n> >>>    The members of the W3C SYMM Working Group\n> >> believe that the following\n> >>>    MIME types will be widely supported by SMIL\n> >> players:\n> >>>      * audio/basic [592][MIME-2]\n> >>>      * image/png ([593][PNG-MIME],\n> >> [594][PNG-REC])\n> >>>      * image/jpeg ([595][MIME-2], [596][JFIF])\n> >>\n> >>>    Implementers of SMIL players should thus\n> >> strive to provide support for\n> >>>    each of these types. Note, however, that\n> >> this section is\n> >>>    non-normative, and that support for these\n> >> MIME types is not a\n> >>>    precondition for conformance to this\n> >> specification.\n> >>>\n> >>>    Authors are encouraged to encode media\n> >> objects using one of the widely\n> >>>    supported MIME types whenever possible.\n> >> This will ensure that their\n> >>>    SMIL documents can be played back by a wide\n> >> range of SMIL players.\n> >>>\n> >>>    If authors use a MIME type that is not in\n> >> the list of widely supported\n> >>>    types, they should provide an alternative\n> >> version encoded using a\n> >>>    baseline format. This can be achieved by\n> >> using a switch element as\n> >>>    shown in the following example:\n> >>> <switch>\n> >>>   <audio src=\"non-baseline-format-object\" />\n> >>>   <audio src=\"baseline-format-object\" />\n> >>> </switch>\n> >>>\n> >>>    In this example, a player that supports the\n> >> non-baseline format will\n> >>>    play the first audio media object, and a\n> >> player that does not support\n> >>>    the non-baseline format will play the\n> >> second media object.\n> >>\n> >>     In general, I'm a bit confused about the request\n> >> - why would the\n> >>     IETF have to comment on the minimal set of\n> >> codecs in a format\n> >>     defined by another organisation ? This would\n> >> make sense if the\n> >>     goal is to define a minimal set of codecs that\n> >> need to be supported\n> >>     by MIME mail readers, but otherwise, I don't see\n> >> the point - am\n> >>     I missing something ?\n> >>\n> >>   I don't think the IETF _has_ to comment, we've\n> >> just been asked..\n> >>\n> >>   This is more about the codecs available on various\n> >> devices.  Few if any mail clients have audio codecs\n> >> included.\n> >>\n> >>   Cheers,\n> >>   Glenn.\n> >>\n> >>\n> >\n> >\n> > __________________________________________________\n> > Do You Yahoo!?\n> > Yahoo! Shopping - Thousands of Stores. Millions of Products.\n> > http://shopping.yahoo.com/\n> >\n\n\n\n", "id": "lists-007-11806510"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "Forgive my ignorance, but could you give us an example of a SMIL player?\n\nOn 12/12/00 5:54 am, \"Philipp Hoschka\" <hoschka@yahoo.com> wrote:\n\n> The rationale for picking audio/basic was that it\n> is widely supported in SMIL players today, and doesn't\n> require paying a license fee.\n> \n> If you know of another license-free, widely\n> supported audio format with better\n> characteristics than audio/basic, that may be\n> interesting.\n> \n> --- thierry michel <tmichel@w3.org> wrote:\n>> RE: 3GPP-T-WG3 codecs\n>>   ----- Original Message -----\n>>   From: Glenn Parsons\n>>   To: discuss@apps.ietf.org ; www-smil@w3.org ;\n>> 'Philipp Hoschka'\n>>   Cc: 'IETF VPIM List'\n>>   Sent: Monday, December 11, 2000 8:28 PM\n>>   Subject: [Moderator Action] RE: 3GPP-T-WG3 codecs\n>> \n>> \n>> \n>> \n>>   Philipp, I'd be interested in the rational that\n>> made you pick audio/basic\n>> \n>>     FWIW, there is a set of \"recommended\" codecs in\n>> the SMIL 2.0 \n>>     draft of W3C, and I'm happy to explain why we\n>> chose those, if \n>>     needed: \n>> \n>>    \n>> \n> http://www.w3.org/TR/2000/WD-smil20-20000921/smil20-profile.html#BaselineForma\n> tsNS\n>> \n>> \n>>> Widely Supported MIME Types\n>>> \n>>>    This section is informative.\n>>> \n>>>    The members of the W3C SYMM Working Group\n>> believe that the following\n>>>    MIME types will be widely supported by SMIL\n>> players: \n>>>      * audio/basic [592][MIME-2]\n>>>      * image/png ([593][PNG-MIME],\n>> [594][PNG-REC]) \n>>>      * image/jpeg ([595][MIME-2], [596][JFIF])\n>> \n>>>    Implementers of SMIL players should thus\n>> strive to provide support for\n>>>    each of these types. Note, however, that\n>> this section is \n>>>    non-normative, and that support for these\n>> MIME types is not a\n>>>    precondition for conformance to this\n>> specification. \n>>> \n>>>    Authors are encouraged to encode media\n>> objects using one of the widely\n>>>    supported MIME types whenever possible.\n>> This will ensure that their\n>>>    SMIL documents can be played back by a wide\n>> range of SMIL players.\n>>> \n>>>    If authors use a MIME type that is not in\n>> the list of widely supported\n>>>    types, they should provide an alternative\n>> version encoded using a\n>>>    baseline format. This can be achieved by\n>> using a switch element as\n>>>    shown in the following example:\n>>> <switch> \n>>>   <audio src=\"non-baseline-format-object\" />\n>>>   <audio src=\"baseline-format-object\" />\n>>> </switch> \n>>> \n>>>    In this example, a player that supports the\n>> non-baseline format will\n>>>    play the first audio media object, and a\n>> player that does not support\n>>>    the non-baseline format will play the\n>> second media object.\n>> \n>>     In general, I'm a bit confused about the request\n>> - why would the \n>>     IETF have to comment on the minimal set of\n>> codecs in a format\n>>     defined by another organisation ? This would\n>> make sense if the\n>>     goal is to define a minimal set of codecs that\n>> need to be supported\n>>     by MIME mail readers, but otherwise, I don't see\n>> the point - am \n>>     I missing something ?\n>> \n>>   I don't think the IETF _has_ to comment, we've\n>> just been asked..\n>> \n>>   This is more about the codecs available on various\n>> devices.  Few if any mail clients have audio codecs\n>> included.  \n>> \n>>   Cheers, \n>>   Glenn. \n>> \n>> \n> \n> \n> __________________________________________________\n> Do You Yahoo!?\n> Yahoo! Shopping - Thousands of Stores. Millions of Products.\n> http://shopping.yahoo.com/\n> \n\n\n\n", "id": "lists-007-11819746"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "How should this 3 - Layer Architecture respond to bandwidth issues\nand route selection ?\n\n\nHenning \n\nPatrik F?ltstr?m wrote:\n> \n> At 13.17 -0800 00-12-11, Andrew Daviel wrote:\n> >WAV seems to be the defacto standard, though I confess that there seem to\n> >be many flavours and it is at heart a proprietary format. MP3, anyone ?\n> \n> Do we have someone reading these messages which can let me know if I\n> am right or wrong when claiming that we talk about a sort of three\n> layer architecture:\n> \n>     Codec\n>     Format\n>   Transport\n> \n> In the case of Waw, that is not a codec, but a format, which allow\n> different codecs.\n> \n> ????\n> \n> Has anyone seen any compilation on what various \"words\" actually mean?\n> \n>      paf\n> \n> --\n\n\n\n", "id": "lists-007-11833047"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "> The rationale for picking audio/basic was that it\n> is widely supported in SMIL players today, and doesn't\n> require paying a license fee.\n> \n> If you know of another license-free, widely \n> supported audio format with better \n> characteristics than audio/basic, that may be\n> interesting.\n\nAIFF could be an alternative. If I remember correctly there are different \nmimetypes for aiff (uncompressed) and aifc (compressed) the aiff format \ndoesn't suffer of the WAV problem of having a gazillion different options for \ncompression scheme. It does (theoretically?) allow for choices in samplesize, \nsampleencoding (int/float/ulaw) and such, but at least it isn't open-ended.\n--\nJack Jansen             | ++++ stop the execution of Mumia Abu-Jamal ++++\nJack.Jansen@oratrix.com | ++++ if you agree copy these lines to your sig ++++\nwww.oratrix.nl/~jack    | see http://www.xs4all.nl/~tank/spg-l/sigaction.htm \n\n\n\n", "id": "lists-007-11841386"}, {"subject": "Use of the term &quot;Client&quot; and &quot;User Agent&quot", "content": "I am concerned with the use of the term \"Client\" in the Content\nDistribution Standards Work. In most other standards, two terms are\nused:\n\nUser Agent = The ultimate origin of a request and the ultimate\nrecipient of the final delivery.\n\nClient = A role played by one agent in relation to server agent. A\nclient is the agent which asks the server for some services, and the\nserver is the agent which delivers these services.\n\nIn the case of the DNS, for example, we can have the following structure:\n\n+------------------+    +--------------------+    +------------------+\n| DNS User| Client |-->-| First DNS | Client |-->-| 2nd DNS | Client |--> etc.\n| Agent   |        |    | Server    |        |    | Server  |        |\n+------------------+    +--------------------+    +------------------+\n\nThus, what you in your work name \"Client\" is what most other\nstandards call \"User Agent\". And most other standards define \"Client\"\nas a role which many different agents can fulfill in regards to a\nserver.\n\nPerhaps you should revise your terminology to agree with what is most\ncommon in most other standards work.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-11850639"}, {"subject": "RE: VCRs, working resources and locate-by-histor", "content": "   From: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\n\n   I would like to use the locate-by-history report to locate _the_\n   VCR (if any exists) for a given version history. So I'd expect at\n   maximum 1 VCR be reported per version history.\n   Is this a correct assumption?\n\nOnly if you are applying the request to a workspace (or a member of a\nworkspace).  If you are applying the request to a collection\ncontaining a number of workspaces, you might get several VCRs reported\n(at most one per workspace, though).\n\n   I would like to hear that possibly\n   existing working resources are not covered by the report.  One can\n   phrase the question also as: is a working resource a VCR?\n\nNo, a working resource is not a VCR, so you would never see a working\nresource in the result of the locate-by-history report, even if you\napplied the report to a collection containing working resources.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1185697"}, {"subject": "Re: 3GPP-T-WG3 codec", "content": "Jack Jansen wrote:\n\n>> The rationale for picking audio/basic was that it\n>> is widely supported in SMIL players today, and doesn't\n>> require paying a license fee.\n>> \n>> If you know of another license-free, widely \n>> supported audio format with better \n>> characteristics than audio/basic, that may be\n>> interesting.\n> \n> \n> AIFF could be an alternative. If I remember correctly there are different \n> mimetypes for aiff (uncompressed) and aifc (compressed) the aiff format \n> doesn't suffer of the WAV problem of having a gazillion different options for \n> compression scheme. It does (theoretically?) allow for choices in samplesize, \n> sampleencoding (int/float/ulaw) and such, but at least it isn't open-ended.\n\nHow about the Ogg/Vorbis format?\n\nIt doesn't suffer from the horrendous patenting/licencing issues \nassociated with MPEG1 layer 3/ TwinVQ / AAC etc...\n\nIt is also already supported by many encoders/decoders, and is set to be \nthe format of the future. Disadvantage for your purpose may be that like \nJPEG/MPEG/etc.. it is a lossy compression format (don't know if that is \nrelevant).\n\nSee:\n\nhttp://www.xiph.org/ogg/vorbis/index.html\n\n\n\n", "id": "lists-007-11859028"}, {"subject": "REMINDER to BOF Chairs etc post your mail list informatio", "content": "It might be helpful to post information and instructions on your new \nmailing lists here and on the IETF main list for some of the BOF work that \nwent on last week.\n\nI'm thinking of DOMREG whatever we decide to call it and WHOIS BOF.\n\nSome of us got the mailing list information  but there were many people \nstanding in the back of the rooms that might not have heard.\n\n\n\n\n\n\n\n\n >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nRichard Shockey\nSenior Technical Industry Liaison\nNeuStar Inc.\n1120 Vermont Avenue N.W.\nSuite 550\nWashington DC. 20005\nVoice 202.533.2811\nFax to EMail 815.333.1237 (Preferred for Fax)\nCell : 314.503.0640\nINTERNET Mail & IFAX : rich.shockey@neustar.com\nor   rshockey@ix.netcom.com\nhttp://www.neustar.com\n\n<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n\n\n", "id": "lists-007-11867292"}, {"subject": "Re: REMINDER to BOF Chairs etc post your mail list informatio", "content": "On Sunday 17 December 2000 18:26, you wrote:\n> It might be helpful to post information and instructions on your new\n> mailing lists here and on the IETF main list for some of the BOF work\n> that went on last week.\n>\n> I'm thinking of DOMREG whatever we decide to call it and WHOIS BOF.\n\nDOMREG became PROVREG (Prov stands for provisioning) and its list stays \nat ietf-provreg@cafax.se (send mail to their majordomo to subscribe)\n\nciao, .mau.\n\n\n\n", "id": "lists-007-11876306"}, {"subject": "OPES Draft Charter and Mailing INfo, please commen", "content": "Orthogonal Protocol Extension Services(opes)\n\n\nCo-chairs:\n    Michael Condry <condry@intel.com>\n    Hilarie Orman <HORMAN@novell.com>\n\nMailing Lists:\n    General Discussion: ietf-openproxy@imc.org\n    To Subscribe: ietf-openproxy-request@imc.org\n    Web: http://www.extproxy.org\n    Archive: ftp://ftp.ietf.org/ietf-mail-archive/opes\n\nDescription of Working Group:\n\nThe Orthogonal Protocol Extension Services architecture (OPES) enables \nconstruction of services executed on application data by participating \ntransit intermediaries.  Caching is the most basic intermediary service, \none that requires a basic understanding of application semantics by the \ncache server.  Because intermediaries divert data temporarily over a \npathway different from the transit pathway, one can think of the service \npath as being orthogonal to the main transit path.  The purpose of this \nworking group is to define the protocols and API's for a broad set of \nservices that facilitate efficient delivery of complex content or services \nrelated to content.  The advantage of standardizing these protocols and \nAPI's is that the services can be re-used across vendor products without \nmodifying the transit intermediaries or services.\n\nThe architecture supports services that are either co-located with the \ntransit intermediary or located on other servers (referred to as auxiliary \nservers in this charter).  The ICAP protocol is being developed for \ncarrying HTTP headers and data to cooperating servers; other protocols for \ncarrying SMTP or other protocols to cooperating servers will be supported \nby the framework, as they exist or become available.  This working group \ndefines the supporting configuration data and protocols for configuring \nservices on the transit intermediaries; this configuration makes it \npossible to administer collections of transit intermediaries and content \nservices as a coherent system.\n\nThere are four parts of a good service definition for transit-based \nextensions to an application protocol.  The first part defines the protocol \nprocessing point or points in the intermediary that could detect an \napplication data event of interest to the auxiliary service.  The second \npart defines the server, the access method for the server, and the \nmarshaled form for arguments added when delivering the application data to \nthe auxiliary server.  The third defines the post processing of the data \nreturned by the auxiliary.  The fourth element of the definition is an \nencoding of the above information combined with the service extension \nitself, defined as some form of loadable code or access method for invoking \nthe code.  The working group will define an information model and \nrealization of the model into repository and protocol elements.\n\nThese service definitions must be standardized in ways that are compatible \nwith the policy framework of the Policy working group. The definitions \nconstitute configuration information that can come from repositories or \nruntime protocols; for example, and ICAP server coming on-line can notify \nits clients of the services it offers, and it can update their status \n(\"up\", \"changed\", \"suspended\", \"moved\") while it is running.  A namespace \nfor services and a means for registering names will be considered.\n\nSome crucial data must be communicated from the intermediary to the \nauxiliary server in standardized semantics.  Identification and \nauthentication information for the application connection may be important \nto the auxiliary processing, for example.  The working group will define a \ncore set of information necessary for supporting generic application needs.\n\nPostprocessing the result from the auxiliary processor is done at the \noption of the intermediary, but instructions from the auxiliary server must \nbe communicated in a standardized manner.  Generic directives (\"drop\", \n\"hold\", \"assign attribute\", are examples.  The working group will define \npostprocessing directives and the rules for their interaction with the \nconfiguration policy.\n\nThe security model for intermediary services involves defining the \nadministrator roles and privileges for the application client, application \nserver, intermediary, and auxiliary server.  The working group will use the \nPolicy Configuration Information Model to define the security attributes \nand the enforceable policy.\n\nThe working group items for delivery are\n1.      A \"side transit\" protocol (ICAP) for use with HTTP\n2.      A policy-based configuration and definition model for orthogonal \nservice extensions\na.      To include representation of conditions leading to invocation of \nextension services, common data items (identities, authentication state, \netc.), postprocessing directives, and the access method for the service or \na representation of a loadable service (URL or encoded executable or \ninterpretable code, for example).\nb.      A specific repository-based embodiment of the model\nc.      A delivery protocol embodying the elements of the model as a \nlanguage; the protocol may be embedded in HTTP and/or ICAP.\nd.      Recommended procedures for registering service names and \nrepositories for extensions\n3.      A security model and security configuration policy definitions, \ni.e. roles, privileges, and enforcement point responsibilities.\n\nAfter these items have been delivered, the working group can examine the \nprogress in this area and, if appropriate, re-charter to with more\ngeneral work items in the OPES framework.\n\nExisting Internet-Drafts\nBasic Requirements:\n         http://draft-tomlinson-epsfw-00.txt\nInitial iCAP Callout Server:\n         http://draft-elson-opes-icap-00.txt\nA Rule Specification Language for Proxy Services:\n         http://draft-beck-opes-psrl-00.txt\nGeneral Use Cases:\n         http://draft-beck-opes-esfnep-01.txt\n\n\nGoals and Milestones:\n\nFeb 01: Requirements and roadmap documents for WG\nFeb 01: First draft of HTTP orthogonal protocol; first draft of policy \ninformation model\nMar 01: Meet at Minneapolis IETF\nMar 01: OPES architecture and requirements documents\nJun 01: Submission of security model and configuration policy to IETF\nJul 15: Draft of policy rules, enforcement semantics, standard data items, \nand post processing\nAug 01: Meet at London IETF\nAug 01: Final submission of HTTP orthogonal protocol.\nOct 01: Submission of repository specific and ICAP-based policy rule \ndeliver protocol\nDec 01: Salt Lake City IETF.\nDec 01: Review charter, if necessary, amend for additional orthogonal \nprotocol definitions, standard data items, postprocessing directives.\n\n\n\n\n\n\n\nMichael W. Condry\nDirector, Internet Strategy\n2111 N.E. 25th Ave.\nJF3-206\nHillsboro, OR 97124-5961\n\nPhone: (503) 264-9019\nFAX: (503) 264-3483\nEmail: condry@intel.com\n\n\n\n", "id": "lists-007-11884240"}, {"subject": "Re: OPES Draft Charter and Mailing INfo, please commen", "content": "> \n> 1.      A \"side transit\" protocol (ICAP) for use with HTTP\n\nI wasn't aware that we had decided it was going to be ICAP.\nSurely that decision depends on the full requirements analysis?\n\n   Brian\n\n\n\n", "id": "lists-007-11900840"}, {"subject": "Minute", "content": "Minutes of the OPES BOF, IETF49, San Diego, December 12, 2000\nChairs: Michael Condry, Hilarie Orman\nArea Director: Patrick Fahlstrom\n\n\"R\" indicates a response given a the meeting; \"A\" indicates\nan answer from the chairs after IETF concluded.\n\nQ:  What is the overlap with the MIDCOM and can we set up\na liaison with that group?\nA: (we've talked to Melinda Shore and might share a some policy\ndefinitions and identity representations with MIDCOM; also, the\nMIDCOM charter will be narrowed from what was proposed before\nthe BOF).\n\nQ:  (from Micah Beck ) Feels that the service being provided have very little\ntie to the content (e.g. ad insertion).  He would like to see more examples\ninvolving programming using and interpretive language.\n\nR:  (Hilarie)  Until an implementation framework is defined, this is\nout of scope.\n\nQ:  I would like to see other services as examples.\nR:  See the drafts and the presentation.\n\nQ: (Patrick Fahlstrom)\n    Three comments:\n    * The IETF likes to see more focus in the charters.\n    * Feels that we do not agree on our deliverables.\n    * Charter should have a list of deliverables, or the charter\n           should be to identify the list of deliverables.\nR: More details on deliverables are in the roadmap but can be moved\nto the charter.\n\nAfter the Examples Slides:\n\nQ:  (Pei Cao) With the example list this broad (\"all over the map\"), I am\nunconvinced that all these services will be supported.\nR:  These examples are used to create the baseline requirements\nso we can implement the common functionality.  The\nrequirements/architecture draft explains the framework in more detail.\n\nQ:  What protocols will we be talking about in this working group?\nR:  ICAP, configuration and distribution.\n\nQ:  The internet is a layered system with each layer adding\nvalue.  I hope that ICAP and the rest of the framework will show value.\nR:  ICAP is well defined and where we will start.\n\nQ:  (Patrick Fahlstrom):  I am concerned that we are saying what problems\nwe are solving and not what we are doing.  (I interpret this as we are\nconcentrating on the example problems that will be solved with the framework,\nrather than the framework itself.)\n\nR:  This is only a perception from the presentation, and that is\ndo to a lack of time.\n\nThe ICAP slide\nQ:  How much easier will ICAP protocol make [ICAP] application writing?\nR:  Departing from HTTP made writing the application much\neasier, and is an easy adaptation of Apache (mostly requiring the removal\nof 300-500 lines of code). There where some serious issues raised\nwhen trying to meet the HTTP standard that were done away with.\n\nQ:  Will ICAP be open source?\nA:  That is up to the various implementors.  There is commitment at this time.\n\nCDN Peering from Mark:\n\nCDN Peering is what it takes to transport information across\nadministrative boundaries.  There is little relationship with OPES.\n\nQ:  Will OPES be over top of  CDNP?\nR:  More along the lines of beside it.  OPES could run over a\nCDNP, and we will need some common ground - naming, in particular.\n\nQ:  (Balaji Pitchaikani) Would they share accounting?\nR:  Probably in terms of what intermediaries should be trusted?\nThe answer could come from the accounting system.\nQ:  (same person) Would like to see some documentation or participate in\ncreating a document.\nRR:  We need to define the when, why and where the OPES\nextensions will happen and define the protocol issues to provide the core\nfunctionality first.\n\nQ: (Barron Housel) Will adaptation, interpretation,\netc depend upon user awareness?  e.g. identifying display devices.\n\nR:  We are ironing out just what will be happening from the\nuser.  For instance, we may look into using avatars.\n\nQ:  Authentification and identification - how are we discovering this?  ICAP?\nR:  ICAP can be used, but we are concerned with maintaining and\nsending identity rather then discovering it.\n\nQ:  (Scott Brim) Just a concern - there are 5 or 6 groups that are close to\neach other, in this space.  Howe do we divide and separate the concerns?\nPerhaps a generalization of groups and a refocus.\nR:  Here we are being told to narrow the focus and not make it more\ngeneral.\nQ:  (same person) Again a mention that there is a lot in common with MIDCOM,\nwhich has a Thursday morning BOF.\n\n\n\n\n\n\n\napplication/octet-stream attachment: oeps-dec00.ppt\n\n\n\n\n", "id": "lists-007-11908491"}, {"subject": "Personal notes from the IETF meeting in San Dieg", "content": "My personal notes (not official minutes) from some of the\nsessions during the IETF meeting in San Diego, December 2000,\ncan be found at http://dsv.su.se/jpalme/ietf/ietf-dec-00-notes.html\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-11919513"}, {"subject": "RE: RFC 3253 issue vs. DAV:auto-update and working resource", "content": "The property is required, in the sense that it must be identified\nin the DAV:supported-live-property-set, but it only actually appears\non certain working resources.  This is just like DAV:checked-out and\nDAV:checked-in, which are both required properties, but only one\nof which can exist on a given resource at a given time.\n\nSo you can detect whether or not a resource is a working resource by\nchecking whether DAV:auto-update appears in its\nDAV:supported-live-property-set.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Wednesday, May 15, 2002 11:08 AM\nTo: ietf-dav-versioning@w3.org\nSubject: RFC 3253 issue vs. DAV:auto-update and working resources\n\n\nHi,\n\n[1] states that DAV:auto-update is a required property for a working\nresource.\n\nHowever, [2] states that \"The DAV:auto-update property of the working\nresource MUST NOT exist.\" is the CHECKOUT is done on a version.\n\nSo, is it required or not? If not, how can I detect that something is a\nworking resource?\n\nJulian\n\n[1] <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.9.2>\n[2] <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.9.3.p.4>\n\n\n\n", "id": "lists-007-1193803"}, {"subject": "Mail-related comments in ACM risk", "content": "I've noted a couple of mail-related postings in the ACM risks forum.\n\nThis issue is archived at <URL:http://catless.ncl.ac.uk/Risks/20.79.html>\n\n(1) In \"Risks of bouncing messages from closed e-mail lists\", a suggestion \nthat closed mailing list bounces can be used to create a mail loop (I don't \nthink this works, but I may be missing something).\n\n(2) In \"More risks with MS Outlook\", a possible issue with \nmultipart/alternative -- something to note in a future \"security \nconsiderations\" section?\n\n#g\n\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-11961873"}, {"subject": "Re: Mail-related comments in ACM risk", "content": "> I've noted a couple of mail-related postings in the ACM risks forum.\n\n> This issue is archived at <URL:http://catless.ncl.ac.uk/Risks/20.79.html>\n\n> (1) In \"Risks of bouncing messages from closed e-mail lists\", a suggestion\n> that closed mailing list bounces can be used to create a mail loop (I don't\n> think this works, but I may be missing something).\n\nYou're right, it is nonsense. The idea is to get two lists bouncing mail back\nto each other. But this only works if the lists put their address in the\nenvelope from of the bounce message. Not only would this be a standards\nviolation, it would be a terribly dumb thing to do.\n\nThe risk of using bounces off lists to relay is also considerably overstated.\nNot only is return of content suppressed a lot more often than this would\nindicate, getting the \"message\" as the content of a nondelivery notification\nis in practice not going to be a very effective means of communicating.\n\n> (2) In \"More risks with MS Outlook\", a possible issue with\n> multipart/alternative -- something to note in a future \"security\n> considerations\" section?\n\nThis is a known issue; the following text is currently in the\nmultipart/alternative description in the MIME specification:\n\n Multipart/alternative provides no mechanism that assures that the parts it\n contains provide equivalent information. This gives rise to a security\n consideration:  A message sender, knowing that one recipient will display one\n part of a multipart/alternative and another will display a different part,\n could put different information in the two parts, fooling the two recipients\n into thinking they received the same information when in fact they did not.\n\nNed\n\n\n\n", "id": "lists-007-11969518"}, {"subject": "Re: Mail-related comments in ACM risk", "content": "--On 2000-02-19 01.21 -0800, ned.freed@innosoft.com wrote:\n\n> You're right, it is nonsense. The idea is to get two lists bouncing mail\n> back to each other. But this only works if the lists put their address in\n> the envelope from of the bounce message. Not only would this be a\n> standards violation, it would be a terribly dumb thing to do.\n\nThe internal mail system at Tele2 did this...which afterwards is a quite\nfunny story:\n\n- The outgoing mail MTA had a limit of size of 5 MB for a message.\n- Incoming MTA had no limit at all.\n- I created a forwarding feature from this mail system on my account\n  to my email address on the internet (yes, we do NOT talk about internet\n  mail here)\n- Someone sent me a message which was 10 MB large\n\nI could say that the rest is left as an exercise to the reader...but here\nwe go:\n\nThe incoming MTA pass the mail over to my mail account. The forwarding\nmechanism forwarded the mail (added about 100k of junk) and sent the mail\nto my internet address. The outgoing MTA stopped the mail because of size\nand sent a bounce back to the sender, i.e. my forwarding mechanism, as they\nact as an agent for the user itself (added about 200k of junk telling what\nhappened). The forwarding mechanism on my account got this message, and\nforwarded it to my internet account.\n\n...\n\nTwo days later they called me and asked why I don't delete email on this\nmail system. I told them nicely that I don't use it at all, but promised to\nhave a look.\n\nLuckily the system is slooooow (runs on a specific operating system which\nprobably should not handle this kind of things) so it had only filled one\nraid with about 12GByte of repeated messages.\n\nI did \"select all - delete\", which was an operation which took some 2\nhours(!) after which the software on my client side crashed. Reboot, and\nselect-all-delete again and 30 minutes later the mail was gone.\n\n\nI got a very specific email address after this which doesn't even try to\nsend the message to my mail account from the incoming MTA...\n\n     paf\n\n\n\n", "id": "lists-007-11978760"}, {"subject": "Re: Mail-related comments in ACM risk", "content": "> --On 2000-02-19 01.21 -0800, ned.freed@innosoft.com wrote:\n\n> > You're right, it is nonsense. The idea is to get two lists bouncing mail\n> > back to each other. But this only works if the lists put their address in\n> > the envelope from of the bounce message. Not only would this be a\n> > standards violation, it would be a terribly dumb thing to do.\n\n> The internal mail system at Tele2 did this...which afterwards is a quite\n> funny story:\n\n> - The outgoing mail MTA had a limit of size of 5 MB for a message.\n> - Incoming MTA had no limit at all.\n> - I created a forwarding feature from this mail system on my account\n>   to my email address on the internet (yes, we do NOT talk about internet\n>   mail here)\n> - Someone sent me a message which was 10 MB large\n\n> I could say that the rest is left as an exercise to the reader...but here\n> we go:\n\n> The incoming MTA pass the mail over to my mail account. The forwarding\n> mechanism forwarded the mail (added about 100k of junk) and sent the mail\n> to my internet address. The outgoing MTA stopped the mail because of size\n> and sent a bounce back to the sender, i.e. my forwarding mechanism, as they\n> act as an agent for the user itself (added about 200k of junk telling what\n> happened). The forwarding mechanism on my account got this message, and\n> forwarded it to my internet account.\n\nBut at this point the message should have bounced again, but this time the MAIL\nFROM address should have been blank, so the MTA should have either sent the\nmessage to the local postmaster or deleted it entirely. Not having this happen\nmeans either you're the postmaster or there's a standards violation in there\nsomewhere...\n\nNow, I'm not saying such violations don't occur. They do. For example,\nwhen forwarding mail back out Exchange will change a blank MAIL FROM\nto the address of the message forwarder. This is far and away the most\ncommon source of loops we see these days.\n\nNed\n\n\n\n", "id": "lists-007-11988463"}, {"subject": "Re: IRC/Realtime Chat W", "content": "--On 1999-12-31 02.35 +0100, Harald Tveit Alvestrand <Harald@Alvestrand.no> \nwrote:\n\n> The only activity I've seen in this space recently is Christoph Kalt's\n> attempt to document the existing protocol before going any further - see\n> draft-kalt-irc-* for the details. Helping him get it out the door would\n> be a Good Thing - last updates were in October, according to my\n> timestamps.\n\nOn monday the 27th of december I asked to get the IRC documents on the IESG \nagenda. It missed the telechat last thursday (i.e. 30th) but I am pretty \nsure they will be discussed on the 13th of january.\n\n   paf\n\n\n\n", "id": "lists-007-12019833"}, {"subject": "A modest suppositio", "content": "I've been reading through David Burdett's draft on the\nrequirements for XML messaging for much of today, interrupted by a\ncouple of meetings with router and switch vendors.  Something about\nthe contrast has caused me to posit two things:\n\nConstant efforts to achieve efficiency by collapsing lower layers\n(e.g. POS's replacement of ATM) are and forever will be balanced by\nthe constant reinvention of those lower layers at the application\nlayer.\n\nmore specifically,\n\nEvery messaging protocol expands until it replicates the control\nmechanisms of TCP.\n\nIt's probably a good thing, really; it represents the\nDarwinian adaptive radiation being balanced by natural selection in\nthe network world, or justifies the fundamental control structures\nneeded throughout the stack, or something like that. Or maybe I need a\nbit more coffee.\n\nTed Hardie\n\n\n\n", "id": "lists-007-12027244"}, {"subject": "RE: Typo in RFC 3253, section 5.4.", "content": "Thanks, I've added this to the errata list.\n\nThe section should be:\n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<D:locate-by-history xmlns:D=\"DAV:\">\n <D:version-history-set>\n   <D:href>http://repo.webdav.org/his/23</D:href>\n   <D:href>http://repo.webdav.org/his/84</D:href>\n   <D:href>http://repo.webdav.org/his/129</D:href>\n </D:version-history-set>\n <D:prop>\n   <D:version-history/>\n </D:prop>\n</D:locate-by-history>\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Wednesday, May 15, 2002 8:32 AM\nTo: ietf-dav-versioning@w3.org\nSubject: Typo in RFC 3253, section 5.4.1\n\n\nHi,\n\nin the example request, the XML isn't well-formed:\n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<D:locate-by-history xmlns:D=\"DAV:\">\n <D:version-history-set>\n   <D:href>http://repo.webdav.org/his/23</D:href>\n   <D:href>http://repo.webdav.org/his/84</D:href>\n   <D:href>http://repo.webdav.org/his/129</D:href>\n <D:version-history-set/>\n <D:prop>\n   </D:version-history>\n </D:prop>\n</D:locate-by-history>\n\n\n\n[1] <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.5.4.1>\n\n\n\n", "id": "lists-007-1202734"}, {"subject": "Re: A modest suppositio", "content": "At 17.28 -0800 0-01-25, hardie@equinix.com wrote:\n> Constant efforts to achieve efficiency by collapsing lower layers\n> (e.g. POS's replacement of ATM) are and forever will be balanced by\n> the constant reinvention of those lower layers at the application\n> layer.\n>\n> more specifically,\n>\n> Every messaging protocol expands until it replicates the control\n> mechanisms of TCP.\n\nPeople who are expert on one layer, do not know enough about\nservices in other layers, so they repeat them in their own\nlayer. It is not only transmission control, also security\nand encryption is often repeated in multiple layers on top\nof each other.\n\nThere are even layers on top of each other doing the same\nthing within the application layer.\n\nExample: If you send HTML in e-mail, non-7-bit-characters\ncan either be encoded by the HTML sublayer (? to &auml;,\nas an example) or by the MIME layer on top of the HTML\nsublayer (? to =E4) using quoted-printable encoding.\nSo MIME and HTML do the similar task of special-koding\nnon-7-bit-characters twice on top of each other.\n\nExperienced users know that in plain text, the HTML\nencoding works better, but in parameters of various\nkinds, MIME encoding sometimes works better.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12034601"}, {"subject": "Shocking LOSE 10-100lbs. DESTIN", "content": "Hello From Destiny,\n\nYou will LOOSE 20-100 pounds easy!\nDo to Such a high demand for Destiny, we are able\nTo Dramatically reduce our price for the entire System!\nYou will LOVE our incredible offer on this\nScientific Breakthrough in Weight Loss.\nNow with a 105% Money Back Guarantee!   \nLOOK! http://home.swbell.net/zainprov/destiny.htm\n\n\n\nWe hope things are going well for you.  Good luck, God Bless, and \nHAVE A GREAT DAY!\n\n\n\nEither you are someone else subscribed to our list.  To be removed\nSimply reply with a blank email.  \n\nThank you,\n\nSherry Wilson\n\n\n\n", "id": "lists-007-12063838"}, {"subject": "Only include implemented features in a draft  standar", "content": "One of the major IETF rules is that a DRAFT STANDARD may\nonly contain features which have been implemented in two\nimplementations with an independent code base, and which\ncan co-work using the standard. This rule often causes the\nnumber of features in a standard to be reduced, when the\nstandard progresses from PROPOSED STANDARD to DRAFT\nSTANDARD.\n\nTwo students at Stockholm University have, as their\nmaster's thesis, made a test of how some mail clients\nsupport the MHTML standard (see\nhttp://towards/jpalme/ietf/mhtml-test/intro.html ).\nThey have found that some features in MHTML are supported\nby some implementations. But implementations often support\na feature of MHTML only in certain common simple ways.\nShould a draft standard really describe such a feature in\nits full, unlimited shape, even if no existing mail client\nsupports this? As a simple example (not taken from their\nreport), the MIME standard allows unlimited recursion\nthrough multiparts of any kind inside multiparts of any\nkind to any level. Suppose an investigation showed that\nthere were no two different implementations, who were able\nto exchange data with more than three recursive\nmultipart-inside-multipart levels? Should then the draft\nstandard really say that the standard supports unlimited\nrecursion, when this might not be supported by any existing\nimplementations?\n\nThese problems are especially large at the production\nside. Even if an implementation is actually able to\nreceive and interpret complex format, it is often not\nable to produce this format. And interoperability\ntesting requires, of course, both an agent which can\nproduce a format and an agent which can receive it.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12070411"}, {"subject": "example&#64;foo.ba", "content": "Is there any standardized domain names which can be used in\nexamples in standards document, such as \"example@foo.bar\",\nand which you are ensured that they will not be used for\nany real domains in the future? \n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12079695"}, {"subject": "Re: example&#64;foo.ba", "content": "At 12.22 +0200 00-06-13, Jacob Palme wrote:\n>Is there any standardized domain names which can be used in\n>examples in standards document, such as \"example@foo.bar\",\n>and which you are ensured that they will not be used for\n>any real domains in the future?\n\nSee RFC 2606.\n\n   Patrik Faltstrom\n   Area Director, Applications Area\n\n\n\n", "id": "lists-007-12087025"}, {"subject": "Re: example&#64;foo.ba", "content": "> Is there any standardized domain names which can be used in examples\n> in standards document, such as \"example@foo.bar\", and which you are\n> ensured that they will not be used for any real domains in the\n> future?\n\nSee RFC 2606.\n\nThomas\n\n\n\n", "id": "lists-007-12094208"}, {"subject": "Re: Only include implemented features in a draft standar", "content": "Jacob,\n\nIf at the time a document is a candidate to be advanced to Draft\n(or perhaps Full) standard, it can be shown that the implementations \nwhich claim to implement a particular feature do so incompletely,\nI think it would be reasonable to either wait before advancing the\ndocument to Draft until fully featured implementations are produced \nor to amend the Draft Standard version of the specification to \nreflect the omission of the less-than-fully-implemented feature.\n(depending on the nature of the feature).  in either case it might\nmake sense to amend the specification to more precisely specify\nwhat is required of a conforming implementation.\n\nhowever the examples you cited are not the sort of things that one\nusually discovers in interoperability tests.  most MUAs do have \nsome limitations on storage, for instance, so it is not reasonable\nto expect an MUA to be able to handle an arbitrarily nested \nMIME document, just as it is not reasonable to expect an MUA or message \nstore to handle a message of arbitrary size.  I'm not saying that\nsuch limitations never cause problems, but I don't think the interoperability \ntest mechanism is a good means of detecting/preventing such problems.\n\nwhen such problems do occur, I do think that it would be worthwhile to \ndocument those problems and make suggestions for improvements - if\nnot in an RFC, then perhaps on an IETF web page.    I'd very much like\nto see some sort of \"implementors notes\" document series be established\nfor such purposes.  \n\nKeith\n\n\n\n", "id": "lists-007-12101141"}, {"subject": "Re: Only include implemented features in a draft  standar", "content": "At 17.11 -0400 0-06-13, Keith Moore wrote:\n> however the examples you cited are not the sort of things that one\n> usually discovers in interoperability tests.  most MUAs do have\n> some limitations on storage, for instance, so it is not reasonable\n> to expect an MUA to be able to handle an arbitrarily nested\n> MIME document, just as it is not reasonable to expect an MUA or message\n> store to handle a message of arbitrary size.  I'm not saying that\n> such limitations never cause problems, but I don't think the interoperability\n> test mechanism is a good means of detecting/preventing such problems.\n\nDo you by \"interoperability test\" mean \"test if each application\ncan handle what the other implementations generate\"? If so, you\nare including only what the different implementations are able\nto produce. And most implementations can only produce a small\nsubset of what a standard allows. Our tests on MHTML implemen-\ntations show that existing mailers only use a small subset of\nvery simple variants of usage of the MHTML standard.\n\nIn the example of complex MIME multipart structures, most\nimplementations are not all all able to generate such\nstructures. There is simply no command in the command\nstructure of the mailer which the user can use to generate\nmost complex multipart structures. It is not a problem of\nstorage, but a problem of the design of the user interface.\nShould then such structures be part of the standard?\n\nBut there may be some MIME client which actually can\ngenerate abritrarily complex multipart structures. I have\nnot tested them all.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12111364"}, {"subject": "Re: Only include implemented features in a draft standar", "content": "> > however the examples you cited are not the sort of things that one\n> > usually discovers in interoperability tests.  most MUAs do have\n> > some limitations on storage, for instance, so it is not reasonable\n> > to expect an MUA to be able to handle an arbitrarily nested\n> > MIME document, just as it is not reasonable to expect an MUA or message\n> > store to handle a message of arbitrary size.  I'm not saying that\n> > such limitations never cause problems, but I don't think the interoperability\n> > test mechanism is a good means of detecting/preventing such problems.\n> \n> Do you by \"interoperability test\" mean \"test if each application\n> can handle what the other implementations generate\"? \n\nyes, this is what the IETF interoperability tests require.\n\nthere is no requirement for implementations to undergo conformance testing or \nto pass any kind of stress test.  \n\nthis was a deliberate and carefully considered decision.  \nconformance tests are expensive, and they don't tell you much about \nyour ability to interoperate with other implementations..\n\n> If so, you\n> are including only what the different implementations are able\n> to produce. And most implementations can only produce a small\n> subset of what a standard allows. Our tests on MHTML implemen-\n> tations show that existing mailers only use a small subset of\n> very simple variants of usage of the MHTML standard.\n\nthe trick is to document those variants. then when MHTML goes\nto DS, see if those variants are the only ones that have multiple\nimplementations.\n\n> In the example of complex MIME multipart structures, most\n> implementations are not all all able to generate such\n> structures. There is simply no command in the command\n> structure of the mailer which the user can use to generate\n> most complex multipart structures. It is not a problem of\n> storage, but a problem of the design of the user interface.\n> Should then such structures be part of the standard?\n\nno.  that would be adding a lot of complexity for little value.\n\nKeith\n\n\n\n", "id": "lists-007-12120850"}, {"subject": "question about Version-Contro", "content": "Hi,\n\nThere's someyhing about I've have questions : when a user calls the VERSION-CONTROL method on a versionable resource, it performs 3 operations :\n    - creation of a new version history,\n    - conversion of the versionable resource in version controlled resource,\n    - creation of a new version by copy of the versionable resource (content and properties).\n\nMy question is : why doing a copy of the version controlled resource ? why duplicating it ?\nIt is not enough, just keeping it, and creating the first version after checking it out, modifying it, and checking it in ?\n\nThanx in advance for answering at this (simple) question !\n\n\n\n", "id": "lists-007-1212330"}, {"subject": "Re: Only include implemented features in a draft  standar", "content": "At 16.58 -0400 0-06-14, Keith Moore wrote:\n>> In the example of complex MIME multipart structures, most\n>> implementations are not all all able to generate such\n>> structures. There is simply no command in the command\n>> structure of the mailer which the user can use to generate\n>> most complex multipart structures. It is not a problem of\n>> storage, but a problem of the design of the user interface.\n>> Should then such structures be part of the standard?\n>\n> no.  that would be adding a lot of complexity for little value.\n\nThe MIME standard is presently a DRAFT STANDARD. The MIME\nstandard says (RFC 2046, section 5.1.2):\n\n   It is essential that such entities be handled correctly when they are\n   themselves imbedded inside of another \"multipart\" structure.  MIME\n   implementations are therefore required to recognize outer level\n   boundary markers at ANY level of inner nesting.  It is not sufficient\n   to only check for the next expected marker or other terminating\n   condition.\n\nNote that the above text in the MIME standard is specified\nas only for receipt by the words \"MIME implementations are\ntherefore required to recognize\". How can an IETF DRAFT\nSTANDARD *ever* have a statement of that kind, with a\nrequirement which is only for receipt? Such requirements\ncannot be tested in interoperability tests, since these\nrequires that some implementation can both send and\nreceive. Should it not then be forbidden for an IETF DRAFT\nSTANDARD to contain any words which say that an\nimplementation should do certain things at receipt, unless\nthe standard also says that implementations must be able to\ngenerate the same structure. Is thus the above quoted\nparagraph from the MIME standard incorrect, since it\nspecifies a requirement only for receipt?\n\nWhen the MIME standard was advanced to DRAFT status, did you\nthen check if any implementation could produce deep nestings\nof multiparts? If you did not check this, how can then the\nstandard include a paragraph like the one quoted above,\nsince the statement requires any level of multipart nesting,\nbut since this has not been interoperability tested?\n\nIf no existing implementation can produce more than, say,\n4 levels of multipart nestings, why, then, does not the MIME\nstandard say that it is only valid for multipart nestings\nup to 4 levels deep?\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12130655"}, {"subject": "Re: Only include implemented features in a draft standar", "content": "> At 16.58 -0400 0-06-14, Keith Moore wrote:\n> >> In the example of complex MIME multipart structures, most\n> >> implementations are not all all able to generate such\n> >> structures. There is simply no command in the command\n> >> structure of the mailer which the user can use to generate\n> >> most complex multipart structures. It is not a problem of\n> >> storage, but a problem of the design of the user interface.\n> >> Should then such structures be part of the standard?\n> >\n> > no.  that would be adding a lot of complexity for little value.\n> \n> The MIME standard is presently a DRAFT STANDARD. The MIME\n> standard says (RFC 2046, section 5.1.2):\n> \n>    It is essential that such entities be handled correctly when they are\n>    themselves imbedded inside of another \"multipart\" structure.  MIME\n>    implementations are therefore required to recognize outer level\n>    boundary markers at ANY level of inner nesting.  It is not sufficient\n>    to only check for the next expected marker or other terminating\n>    condition.\n> \n> Note that the above text in the MIME standard is specified\n> as only for receipt by the words \"MIME implementations are\n> therefore required to recognize\".  How can an IETF DRAFT\n> STANDARD *ever* have a statement of that kind, with a\n> requirement which is only for receipt?  Such requirements\n> cannot be tested in interoperability tests, since these\n> requires that some implementation can both send and\n> receive. \n\nit's certainly true that not every protocol requirement can be \ntested by interoperability tests.   what we require is something\nlooser - that every protocol \"feature\" (where \"feature\" is\npurposely ill-defined) be tested.  basically it's up to IESG\nto decide whether the interoperability testing is adequate.\n\n> Should it not then be forbidden for an IETF DRAFT\n> STANDARD to contain any words which say that an\n> implementation should do certain things at receipt, unless\n> the standard also says that implementations must be able to\n> generate the same structure. Is thus the above quoted\n> paragraph from the MIME standard incorrect, since it\n> specifies a requirement only for receipt?\n\nno, it's correct.   some folks are indeed reluctant to put in \nrequirements that are not testable on the wire, and this is sometimes\nused as an argument for removing a requirement that someone thinks\nis bogus.  but the truth is that we do impose such requirements from \ntime to time, often for good reasons.\n\n> When the MIME standard was advanced to DRAFT status, did you\n> then check if any implementation could produce deep nestings\n> of multiparts? \n\nno because we are doing interoperability tests, not conformance\ntests.  we made sure that user agents could read multiparts sent\nby other UAs - in particular that they could parse nested multiparts.   \nwe didn't attempt to test implementation limits, nor were we required \nto do so by IETF rules.\n\n> If you did not check this, how can then the\n> standard include a paragraph like the one quoted above,\n> since the statement requires any level of multipart nesting,\n> but since this has not been interoperability tested?\n\nyou appear to be confusing interoperability tests with conformance or\nstress tests. conformance / stress tests can sometimes be useful but\nwe're not required to do them in order to advance a document.\n \n> If no existing implementation can produce more than, say,\n> 4 levels of multipart nestings, why, then, does not the MIME\n> standard say that it is only valid for multipart nestings\n> up to 4 levels deep?\n\nthere are certainly MIME implementations that can produce more than\n4 levels of multipart nestings, and there are MIME implementations\nthat can parse more than 4 levels of multipart nestings.\n\nKeith\n\np.s. I'm a bit puzzled by your choice of this particular issue.\n\na MIME implementation that could only handle 0, 1, or 2 levels\nof nesting would clearly be broken, as would a MIME implementation\nthat imposed a finite limit on the number of levels of nesting.\nbut a MIME implementation that can handle 2 levels and which does\nnot impose a finite limit can probably handle an arbitrary number\nof levels (until it runs out of memory).\n\n\n\n", "id": "lists-007-12141255"}, {"subject": "Re: Only include implemented features in a draft standar", "content": "Where it is shown that implementations commonly limit a feature in certain \nways, it may be appropriate to include language in standards that are \nraised on the track similar to what's in RFC 821:\n\n\"Implementations MUST handle at least <n> <metric> of <feature x>.\nImplementations SHOULD choose implementation techniques that place no\nrestrictions on <feature x>.\"\n\nThe text I'm referring to is this (RFC 821, section 4.5.3):\n\n          There are several objects that have required minimum maximum\n          sizes.  That is, every implementation must be able to receive\n          objects of at least these sizes, but must not send objects\n          larger than these sizes.\n\n\n           ****************************************************\n           *                                                  *\n           *  TO THE MAXIMUM EXTENT POSSIBLE, IMPLEMENTATION  *\n           *  TECHNIQUES WHICH IMPOSE NO LIMITS ON THE LENGTH *\n           *  OF THESE OBJECTS SHOULD BE USED.                *\n           *                                                  *\n           ****************************************************\n\nWe could debate whether the restriction on not sending more than the limit \nis right or wrong. It renders senders that were compliant to the unlimited \nspecification non-conformant to the limited specification, which I don't \nlike doing.\n\nBut if all implementations limit reception at some boundary, shipping the \nstandard without documenting the fact that limits are to be expected does \nnot appeal to me.\n\n                   Harald\n\n\n--\nHarald Tveit Alvestrand, EDB Maxware, Norway\nHarald.Alvestrand@edb.maxware.no\n\n\n\n", "id": "lists-007-12153636"}, {"subject": "Re: Only include implemented features in a draft standar", "content": "> But if all implementations limit reception at some boundary, shipping the \n> standard without documenting the fact that limits are to be expected does \n> not appeal to me.\n\nagreed.\n\nBut I'd be very surprised if all, or even most, MIME implementations\nhad fixed limits on the amount of multipart nesting.\n\nKeith\n\n\n\n", "id": "lists-007-12163882"}, {"subject": "Re: Only include implemented features in a draft  standar", "content": "At 08.05 -0400 0-06-15, Keith Moore wrote:\n>> If you did not check this, how can then the\n>> standard include a paragraph like the one quoted above,\n>> since the statement requires any level of multipart nesting,\n>> but since this has not been interoperability tested?\n>\n> you appear to be confusing interoperability tests with conformance or\n> stress tests. conformance / stress tests can sometimes be useful but\n> we're not required to do them in order to advance a document.\n\nI do not understand this. If a system is designed so that\nit cannot produce deep levels of multipart nestings, then\nno interoperability can be demonstrated for such nestings.\nThis is then, obviously, an interoperability and not a\nstress issue.\n\nConformance would be if you test whether a single system\ncan receive and correctly handle any kind of manually\nconstructed complex MIME multipart nestings. But since IETF\nrequires *interoperability* and not *conformance*, such a\ntest would not be acceptable as a basis for writing in the\nstandard that any level of nesting should be supported. So\nthe statements in the MIME standard that ANY level of\nmultipart nesting should be supported is *not* supported by\n*interoperability* tests. Should such a statement then be\nin a DRAFT STANDARD, if IETF requires that a DRAFT STANDARD\nshould only describes features which work in\n*interoperability* tests?\n\n> there are certainly MIME implementations that can produce more than\n> 4 levels of multipart nestings, and there are MIME implementations\n> that can parse more than 4 levels of multipart nestings.\n>\n> p.s. I'm a bit puzzled by your choice of this particular issue.\n\nSorry, maybe my example was not well chosen. It chose this\nexample because it is such a basic feature of MIME, which I\nbelieve everyone agrees should be there, that you should\nsupport multipart nesting to any level. But maybe my\nexample was wrong, in that there actually are two\nindependent implmentations which can produce arbitrarily\ndeep nestings.\n\nThe reason I am raising these issues is the issue of whether\nwe should start a process of moving the MHTML standard from\nproposed to draft. The testings made by two students show\nthat all the systems tested were only able to produce some\nvery simple combinations of use of MHTML, and that no system\nwas able to generate more complex combinations. And what I\nam wondering if is this should mean that we should change\nthe MHTML standard, when moving to draft, by describing the\nsimple combinations which systems actually do generate, and\nsay that the standard only applies to these simple combina-\ntions. For example, the students found that systems are able\nto receive and generate Content-Location, and are able to\nreceive and generate Multipart/alternative with HTML in one\nbranch and plain text in the other branch. But no two systems\nseems to be able to receive and generate a combination of\nthese two features. Does this mean that we should write in\nthe standard that Multipart/alternative and Content-\nLocation cannot be combined? Or that we should wait with\nmoving MHTML to draft until there are two interoperable\nsystems which can handle this combination?\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12172296"}, {"subject": "Re: Only include implemented features in a draft standar", "content": "> At 08.05 -0400 0-06-15, Keith Moore wrote:\n> >> If you did not check this, how can then the\n> >> standard include a paragraph like the one quoted above,\n> >> since the statement requires any level of multipart nesting,\n> >> but since this has not been interoperability tested?\n> >\n> > you appear to be confusing interoperability tests with conformance or\n> > stress tests. conformance / stress tests can sometimes be useful but\n> > we're not required to do them in order to advance a document.\n> \n> I do not understand this. If a system is designed so that\n> it cannot produce deep levels of multipart nestings, then\n> no interoperability can be demonstrated for such nestings.\n\ndepends on what you mean by 'system'.  if a particular MIME\nclient cannot produce deep levels of nesting, that's not \nan issue with MIME as a whole because (a) MIME is perfectly capable\nof representing deep levels of nesting, (b) there do exist MIME\ngenerators that can generate deeply nested messages, and (c) there\nalso exist MIME readers that can handle deep levels of nesting.\n\ngiven the above, it's difficult to see how the MIME spec is flawed,\nsince we have adequate evidence that folks can do deep nesting with\nMIME if they want to.  the purpose of the interoperability tests\nare to debug the spec, and in this case, the spec seems sufficiently\nclear as to how to implement multipart nesting.\n\n> This is then, obviously, an interoperability and not a\n> stress issue.\n\nno.  your premise is false, and your conclusion doesn't follow.  \n\n> So the statements in the MIME standard that ANY level of\n> multipart nesting should be supported is *not* supported by\n> *interoperability* tests.\n\ntrue.  but such statements are not required to be supported by\ninteroperability tests, any more than we require interoperability\ntests to determine whether (say) an SMTP implementation can\nhandle command lines or email addresses of the maximum allowable\nsize.\n\n>  Should such a statement then be\n> in a DRAFT STANDARD, if IETF requires that a DRAFT STANDARD\n> should only describes features which work in\n> *interoperability* tests?\n\nnesting of multiparts is a feature, and it has been tested and known\nto work.   but the degree to which nesting works is an implementation\ncharacteristic (it's not a characteristic of the spec) and we're not \nrequired to test for such things.\n\nthe purpose of interoperability testing is to debug the specs - to\nmake sure that they are clear enough to allow implementations to\ninteroperate.\n\n> > there are certainly MIME implementations that can produce more than\n> > 4 levels of multipart nestings, and there are MIME implementations\n> > that can parse more than 4 levels of multipart nestings.\n> >\n> > p.s. I'm a bit puzzled by your choice of this particular issue.\n> \n> Sorry, maybe my example was not well chosen. It chose this\n> example because it is such a basic feature of MIME, which I\n> believe everyone agrees should be there, that you should\n> support multipart nesting to any level. But maybe my\n> example was wrong, in that there actually are two\n> independent implmentations which can produce arbitrarily\n> deep nestings.\n\nI suspect that any mime implementation is limited in practice to\nsome level of nesting.   (whether sender or receiver)  just because\nmemory, disk, etc. are finite resources.\n\n> The reason I am raising these issues is the issue of whether\n> we should start a process of moving the MHTML standard from\n> proposed to draft. The testings made by two students show\n> that all the systems tested were only able to produce some\n> very simple combinations of use of MHTML, and that no system\n> was able to generate more complex combinations. And what I\n> am wondering if is this should mean that we should change\n> the MHTML standard, when moving to draft, by describing the\n> simple combinations which systems actually do generate, and\n> say that the standard only applies to these simple combina-\n> tions. For example, the students found that systems are able\n> to receive and generate Content-Location, and are able to\n> receive and generate Multipart/alternative with HTML in one\n> branch and plain text in the other branch. But no two systems\n> seems to be able to receive and generate a combination of\n> these two features. Does this mean that we should write in\n> the standard that Multipart/alternative and Content-\n> Location cannot be combined? Or that we should wait with\n> moving MHTML to draft until there are two interoperable\n> systems which can handle this combination?\n\nagain, the purpose is to debug the spec.  if the spec is unclear,\nor if it asks too much of implementations, that's a problem that\nneeds to be fixed.  \n\nsenders and receivers are a bit different - a sender may have specific needs\nand therefore might not implement all features of MHTML - it's perfectly\nreasonable for a sender to only implement the features it needs.\na receiver might need to implement more features.\n\nif you've found that the spec isn't clear enough regarding what MHTML\nfeatures have to be implemented by a receiver, then this should be clarified.\n\nif you've found that the spec isn't clear enough about how to generate\ncertain kinds of MHTML constructs, then this should be clarified.\n\nif you've found that the spec documents features that nobody seems to have\na use for in practice, then those features should probably be removed.\n\nif you've found that certain combinations of features don't work on\n>= 2 receivers, then the progression of MHTML should be delayed until\nthere are enough implementations that do, or the spec should be edited\nso that it's requirements aren't too onerous.\n\nbut if you've only found that senders don't seem to want to use certain\ncombinations of features (i.e. they don't want to combine them in \narbitrary ways), I don't see that as a problem, as long as receivers can\ndeal with all of the features (in whatever combination)\nin the messages that they receive.\n\nKeith\n\n\n\n", "id": "lists-007-12183167"}, {"subject": "Re: Only include implemented features in a draft  standar", "content": "I think I understand this now.\n\nWhat IETF requires for moving a standard to draft status is\nthat interoperability can be shown for every single feature\nin the standard.\n\nThere is however no requirement that interoperability can\nbe shown for any combination of two or more features in\nthe standard. Note that nested multiparts can be seen\nas \"a combination of the feature multipart with the\nfeature multipart\" two or more times.\n\nAlso, if a standard says that a certain requirement is\nonly valid for receipt, not for what is produced, then\ninteroperability is not required for this particular\nfeature (since interoperability testing cannot be done\non a requirement which is only valid for receipt,\ninteroperability testing requires that there is software\nto both receive and produce the tested feature).\n\nIs this a correct understanding of the IETF rules?\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12197087"}, {"subject": "Re: question about Version-Contro", "content": "\"Elodie Tasia\" <e.tasia@ever-team.com> wrote:\n\n> There's someyhing about I've have questions : when a user calls\n> the VERSION-CONTROL method on a versionable resource, it performs\n> 3 operations :\n>     - creation of a new version history,\n>     - conversion of the versionable resource in version controlled\n> resource,\n>     - creation of a new version by copy of the versionable resource\n> (content and properties).\n>\n> My question is : why doing a copy of the version controlled resource\n>  ? why duplicating it ?\n> It is not enough, just keeping it, and creating the first version\n> after checking it out, modifying it, and checking it in ?\n>\n> Thanx in advance for answering at this (simple) question !\n\nA version is created as a copy because the version-controlled resource can\nbe checked out and modified.  The version remains as an immutable copy of\nthe inital state of the VERSION-CONTROL'led resource.\n\nClearly, _implementations_ don't have to do a copy and can fake out the two\nresources (version and checked-in version-controlled resource) using the\nsame underlying storage.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-1219947"}, {"subject": "Re: Only include implemented features in a draft standar", "content": "> I think I understand this now.\n\nI think you're getting closer, but you're not there yet.\n\n> What IETF requires for moving a standard to draft status is\n> that interoperability can be shown for every single feature\n> in the standard.\n\nThis is how it is done in the applications area. Other areas tend to do\nthings a little differently. In particular, listing all the features and\ntesting them one by one may or may not be required.\n\n> There is however no requirement that interoperability can\n> be shown for any combination of two or more features in\n> the standard. Note that nested multiparts can be seen\n> as \"a combination of the feature multipart with the\n> feature multipart\" two or more times.\n\nBasically, yes, because otherwise you have a combinatoric explosion that\nis impossible to test.\n\nHowever, in the specific case of nested multiparts, as it happens they were\ntested quite extensively before MIME moved to draft. I don't recall if they\nwere called out as something we had to test, but I can assure you that we had\nno problem finding clients that were able to generate them and receiving agents\ncapable of handling such things, and we used those agents in our tests. Indeed,\nthe only problem I recall was that one of the agents I used in my testing -- an\nX.400 gateway -- produced nested message structures in X.400 that seriously\npissed some X.400 service provider and got me into trouble.\n\nAnd in actual practice multipart messages with very deep nestings often occur,\nsometimes intentionally, other times as a result of certain sorts of\nconfiguration errors. I've received messages nested several thousand levels\ndeep more than once. The usual error situation, in case you care, is a DSN\nbounce loop that employs multipart/report.\n\n> Also, if a standard says that a certain requirement is\n> only valid for receipt, not for what is produced, then\n> interoperability is not required for this particular\n> feature (since interoperability testing cannot be done\n> on a requirement which is only valid for receipt,\n> interoperability testing requires that there is software\n> to both receive and produce the tested feature).\n\nThis, I'm afraid, is totally incorrect. You are persisting in doing what you've\ndone from the start of this discussion -- confuse the MIME conformance\nrequirements with general IETF standards track interoperability requirements.\nThese are separate things. One applies to implementations, the other to the\nMIME standard.\n\nIt was felt at the time MIME was developed that something more than the usual\ninteroperability testing we'd get as the document advanced was needed. In\nparticular, it was felt that without a set of requirements as to how MIME\nmessages would be handled after reception by user agents, we would end up with\nthings that interoperated perfectly in the sense that they were able to\ngenerate and receive arbitrary MIME objects, but they still wouldn't handle\nthem in a way that was useful to an end user.\n\nWe resolved this issue by inventing the concept of MIME conformance. These\nrequirements spell out what we felt was minimally necessary for MIME to\nactually be a useful thing to a message recipient rather than a large mess.\n\nIn retrospect we should have also carried this concept over to specifying\nsending conformance requirements, but for none of the reasons you have given\nhere. The problem with the lack of specification of sender conformance has been\nthat there have been cases where user agent developers have implemented\nreasonably full MIME support  on reception but continued to generate some\nnonstandard format. Such an implementation can be claimed to be MIME\nconformant.\n\nBut the presence or absence of conformance requirements doesn't affect\nthe interoperability requirements needed to advance the standard in any\nway, shape, or form. In order to advance MIME individual features had to\nbe tested one by one, which we did.\n\nNed\n\n\n\n", "id": "lists-007-12205631"}, {"subject": "Re: Only include implemented features in a draft  standar", "content": "At 19.32 -0700 0-06-16, <ned.freed@innosoft.com> wrote:\n> But the presence or absence of conformance requirements doesn't affect\n> the interoperability requirements needed to advance the standard in any\n> way, shape, or form. In order to advance MIME individual features had to\n> be tested one by one, which we did.\n\nThis is almost what I wrote. The only difference, is that\nyou are saying that what is labelled as \"conformance\nrequirement\" and which is specified only for receipt, is by\nthat labelling exempt from the inter-operability\nrequirement.\n\nSo if a standards writer wants to put into his standard\na requirement which is only for receipt, and which thus\ncannot be interoperapility tested (since such testing\nrequires both production and receipt) then the standards\nwriter must label this requirement as a \"conformance\nrequirement\" in order to be allowed to progress it to\ndraft status without interoperability testing.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12217439"}, {"subject": "Re: Only include implemented features in a draft standar", "content": "> At 19.32 -0700 0-06-16, <ned.freed@innosoft.com> wrote:\n> > But the presence or absence of conformance requirements doesn't affect\n> > the interoperability requirements needed to advance the standard in any\n> > way, shape, or form. In order to advance MIME individual features had to\n> > be tested one by one, which we did.\n\n> This is almost what I wrote. The only difference, is that\n> you are saying that what is labelled as \"conformance\n> requirement\" and which is specified only for receipt, is by\n> that labelling exempt from the inter-operability\n> requirement.\n\nYou keep coming back to this notion that a conformance specification can\nsomehow defeat the interoperability requirements. This just isn't true. A\nprotocol can say what it likes about what it means for an implementation to be\nconformant. But this has no effect on interoperability requirements at all.\n\nSuppose, for example, a protocol came long that said an implementation can\nclaim to be conformant even if it implements absolutely none of the protocol.\nBy your logic this would completely remove any need for interoperability\ntesting for advancement along the standards track. But this isn't what would\nhappen: What would happen is that we'd still make the list of protocol features\nand make sure each of them interoperated between multiple implementations.\n\nI cannot say what the IESG looked at when advancing MIME to draft, but I can\ntell you that we implementors basically paid no attention at all to MIME\nconformance when we did the interoperability testing for MIME moving to draft\nstandard. We made a list of protocol features and checked to make sure they\nworked across multiple implementations. (Actually, truth be told, we did\nsufficient testing for MIME to move to draft even before it came out as\nproposed.)  And speaking for myself, I don't plan on treating other\nprotocols any differently. If there's a feature in the protocol specification\nit needs to be tested for interoperability, never mind what it means\nto be conformant.\n\n> So if a standards writer wants to put into his standard\n> a requirement which is only for receipt, and which thus\n> cannot be interoperapility tested (since such testing\n> requires both production and receipt) then the standards\n> writer must label this requirement as a \"conformance\n> requirement\" in order to be allowed to progress it to\n> draft status without interoperability testing.\n\nNo, you have it exactly backwards. A specification of, say, what sorts of\ndisplay options a client should have is by definition not a specification of\na feature of a protocol. As such, it is simply wrong to call it an interoperability\nrequirement.\n\nNow, I suppose it is possible that someone could get careless in a\nspecification and end up with a protocol feature being defined in a section\ncalled \"requirements for conformance\". But that certainly isn't true in MIME:\nWe even went so far as to put the specification of what it means to have a\nconforming MIME agent in a document totally separate from the MIME protocol\nspecification.\n\nNed\n\n\n\n", "id": "lists-007-12226737"}, {"subject": "Re: Only include implemented features in a draft standar", "content": "> > > If you did not check this, how can then the\n> > > standard include a paragraph like the one quoted above,\n> > > since the statement requires any level of multipart nesting,\n> > > but since this has not been interoperability tested?\n\n> > you appear to be confusing interoperability tests with conformance or\n> > stress tests. conformance / stress tests can sometimes be useful but\n> > we're not required to do them in order to advance a document.\n\n> I do not understand this. If a system is designed so that\n> it cannot produce deep levels of multipart nestings, then\n> no interoperability can be demonstrated for such nestings.\n\nThis would only be true if it was the case that there was no system anywhere\ncapable of producing deep levels of multipart nestings. And this is not\nthe case.\n\nWere we to insist that as a condition of interoperability testing all systems\nbe able to produce all possible protocol features, then most of the protocols\nwe have would have to be removed from the standards track.\n\nTake ICMP as an example from an entirely different area. ICMP defines a\nbunch of different sorts of messages, quite a few of which are only\nused in very specific circumstances. There are lots of agents that generate\nICMP packets that have no need to ever generate certain sorts of ICMP messages.\nIt it then appropriate to claim that these features of ICMP don't interoperate\nmerely because some agents cannot produce them? I think not.\n\n> This is then, obviously, an interoperability and not a\n> stress issue.\n\nNope, it is nothing of the sort.\n\n> Conformance would be if you test whether a single system\n> can receive and correctly handle any kind of manually\n> constructed complex MIME multipart nestings. But since IETF\n> requires *interoperability* and not *conformance*, such a\n> test would not be acceptable as a basis for writing in the\n> standard that any level of nesting should be supported. So\n> the statements in the MIME standard that ANY level of\n> multipart nesting should be supported is *not* supported by\n> *interoperability* tests. Should such a statement then be\n> in a DRAFT STANDARD, if IETF requires that a DRAFT STANDARD\n> should only describes features which work in\n> *interoperability* tests?\n\nI've already pointed out that deeply nested multiparts are frequently generated\n*in* *practice* and have been shown to interoperate, not once but over and over\nand over again.\n\n> Sorry, maybe my example was not well chosen. It chose this\n> example because it is such a basic feature of MIME, which I\n> believe everyone agrees should be there, that you should\n> support multipart nesting to any level. But maybe my\n> example was wrong, in that there actually are two\n> independent implmentations which can produce arbitrarily\n> deep nestings.\n\nThere are dozens of such implementations. Indeed, it hard to write a\nMIME-compliant user agent that can't generate them. (They call it forwarding\nwith a cover note...)\n\n> The reason I am raising these issues is the issue of whether\n> we should start a process of moving the MHTML standard from\n> proposed to draft. The testings made by two students show\n> that all the systems tested were only able to produce some\n> very simple combinations of use of MHTML, and that no system\n> was able to generate more complex combinations.\n\nI'm sorry, but I'm very skeptical of this claim. Perhaps they were unable\nto produce such things as a result of a single, simple, obvious operation. But\nI'll bet that very complex objects indeed can be produced if they work at\nit a bit.\n\n< And what I\n> am wondering if is this should mean that we should change\n> the MHTML standard, when moving to draft, by describing the\n> simple combinations which systems actually do generate, and\n> say that the standard only applies to these simple combina-\n> tions. For example, the students found that systems are able\n> to receive and generate Content-Location, and are able to\n> receive and generate Multipart/alternative with HTML in one\n> branch and plain text in the other branch. But no two systems\n> seems to be able to receive and generate a combination of\n> these two features.\n\nNow you are no longer talking about individual protocol features, you are\ninstead talking about combination of features. Trying to elaborate every\npossible combination isn't required, and should not be.\n\nI also have to again say I'm skeptical of this claim that such things cannot be\nproduced. Maybe I'm missing something here, but why can't you first create a\nmultipart/related with some program that likes to produce such things, and then\nhave another agent that does downgrade/alternative packaging produce the outer\nmultipart/alternative wrapper? I know for a fact that agents of the latter type\nexist (I wrote one), and you've already asserted that there is no shortage of\nagents of the former type.\n\n> Does this mean that we should write in\n> the standard that Multipart/alternative and Content-\n> Location cannot be combined?\n\nNo.\n\n> Or that we should wait with\n> moving MHTML to draft until there are two interoperable\n> systems which can handle this combination?\n\nNo.\n\nNed\n\n\n\n", "id": "lists-007-12238300"}, {"subject": "Re: Only include implemented features in a draft  standar", "content": "At 09.19 -0700 0-06-17, <ned.freed@innosoft.com> wrote:\n> You keep coming back to this notion that a conformance\n> specification can somehow defeat the interoperability\n> requirements. This just isn't true. A protocol can say\n> what it likes about what it means for an implementation to\n> be conformant. But this has no effect on interoperability \n> requirements at all.\n\nI am just trying to understand the IETF rules for moving a\nstandard from proposed to draft status.\n\nI do understand that the base requirement is still, that\nmoving a standard from proposed to draft requires that\nthere are two implementations based on different code base\nwhich can interoperate using every feature in the standard.\n\nAnd I do now understand that this rule is only valid for\nevery single feature, not for any combination of features,\nand not for an arbitrary number of recursive application of\nthe same feature.\n\nBut I still have the impression that there are exemptions\nfrom this, that there are certain things you can say in a\nstandards document which is exempt from the\ninteroperability requirement. But I do not quite understand\nwhich features are exempt in this way.\n\nIn particular, how can a standard ever specify a\nrequirement only for receipt, if all requirements must be\ninteroperability tested? Surely interoperability testing\nrequires that systems can both receive and generate a\ncertain format?\n\nFor example, the drums msgfmt document has a list of things\nyou should be able to receive but should not generate (the\nobsoleted features section). How can the contents of that\nsection be interoperability tested? Exactly why is such a\nsection allowed, even though it cannot be interoperability\ntested? Is it because the section is labelled \"obsolete\",\nbecause the section is labelled \"for receipt only\" or why?\n\nAt 23.18 -0700 0-06-17, <ned.freed@innosoft.com> wrote:\n> Take ICMP as an example from an entirely different area.\n> ICMP defines a bunch of different sorts of messages, quite\n> a few of which are only used in very specific\n> circumstances. There are lots of agents that generate ICMP\n> packets that have no need to ever generate certain sorts\n> of ICMP messages. It it then appropriate to claim that\n> these features of ICMP don't interoperate merely because\n> some agents cannot produce them? I think not.\n\nThe interoperability requirement is not for all\nimplementations, only for two different implementations\nbased on a different code base. So my understanding is that\nthere must be at least two different ICMP implementations\nwhich can send and receive every single ICMP message, and\nwhich can interoperate when handling this message, but it\nis not necessarily required that every implementation can\nhandle every ICMP message, not even that there are two\nimplementations which can handle all the ICMP messages in\njust those two implementations.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12251256"}, {"subject": "RE: Only include implemented features in a draft standar", "content": "Jacob, you're so close.  If you'd just stop assuming the conclusion you'd\nget it.\n\n\"How can the contents of that section be interoperability tested? Exactly\nwhy is such a section allowed, even though it cannot be interoperability\ntested?\"\n\nTwo different implementations must be able to correctly parse obsolete\nmessages.  Implementations should never generate those messages.  The\neasiest way to do the test (and hopefully every MUA vendor will do this) is\nsimply to telnet to port 25 and feed in the obsolete message from the\nexample.  Thus, the obsolete section would be interoperability tested if\nboth implementations produced the same parsed message.  There is no\nrequirement for interoperability on generation, and in fact, MUAs are\nrequired NOT to generate such messages.  Thus, your second sentence doesn't\nfollow.\n\nIf this still seems unclear, I would reread the whole thread and reread\nsection 4.1.2 in RFC 2026.\n\n- dan\n--\nDaniel Kohn <mailto:dan@dankohn.com>\ntel:+1-425-602-6222\nhttp://www.dankohn.com\n\n-----Original Message-----\nFrom: Jacob Palme [mailto:jpalme@dsv.su.se]\nSent: Sunday, 2000-06-18 03:01\nTo: IETF Applications Area Discussion List\nSubject: Re: Only include implemented features in a draft standard\n\n\nAt 09.19 -0700 0-06-17, <ned.freed@innosoft.com> wrote:\n> You keep coming back to this notion that a conformance\n> specification can somehow defeat the interoperability\n> requirements. This just isn't true. A protocol can say\n> what it likes about what it means for an implementation to\n> be conformant. But this has no effect on interoperability \n> requirements at all.\n\nI am just trying to understand the IETF rules for moving a\nstandard from proposed to draft status.\n\nI do understand that the base requirement is still, that\nmoving a standard from proposed to draft requires that\nthere are two implementations based on different code base\nwhich can interoperate using every feature in the standard.\n\nAnd I do now understand that this rule is only valid for\nevery single feature, not for any combination of features,\nand not for an arbitrary number of recursive application of\nthe same feature.\n\nBut I still have the impression that there are exemptions\nfrom this, that there are certain things you can say in a\nstandards document which is exempt from the\ninteroperability requirement. But I do not quite understand\nwhich features are exempt in this way.\n\nIn particular, how can a standard ever specify a\nrequirement only for receipt, if all requirements must be\ninteroperability tested? Surely interoperability testing\nrequires that systems can both receive and generate a\ncertain format?\n\nFor example, the drums msgfmt document has a list of things\nyou should be able to receive but should not generate (the\nobsoleted features section). How can the contents of that\nsection be interoperability tested? Exactly why is such a\nsection allowed, even though it cannot be interoperability\ntested? Is it because the section is labelled \"obsolete\",\nbecause the section is labelled \"for receipt only\" or why?\n\nAt 23.18 -0700 0-06-17, <ned.freed@innosoft.com> wrote:\n> Take ICMP as an example from an entirely different area.\n> ICMP defines a bunch of different sorts of messages, quite\n> a few of which are only used in very specific\n> circumstances. There are lots of agents that generate ICMP\n> packets that have no need to ever generate certain sorts\n> of ICMP messages. It it then appropriate to claim that\n> these features of ICMP don't interoperate merely because\n> some agents cannot produce them? I think not.\n\nThe interoperability requirement is not for all\nimplementations, only for two different implementations\nbased on a different code base. So my understanding is that\nthere must be at least two different ICMP implementations\nwhich can send and receive every single ICMP message, and\nwhich can interoperate when handling this message, but it\nis not necessarily required that every implementation can\nhandle every ICMP message, not even that there are two\nimplementations which can handle all the ICMP messages in\njust those two implementations.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12262416"}, {"subject": "Re: Only include implemented features in a draft standar", "content": "We're going around in circles. I'm going to try one more time and then I'm\ngoing to give up.\n\n> But I still have the impression that there are exemptions\n> from this, that there are certain things you can say in a\n> standards document which is exempt from the\n> interoperability requirement.\n\nOf course. You can say lots of things in a specification besides\ndescribing features of a protocol. The point is that such conformance\nspecifications aren't features of the protocol.\n\nIn the case of MIME, the conformance rules require certain things of a\nreceiving agent. But they do not specify any new features of the MIME protocol.\nFor example, the conformance rules specify that receivers must be able to\nhandle a certain subset of text/plain. But that isn't the specification of\ntext/plain. The specification of MIME's ability to have types in general, text\ntypes in particular, subtypes in general, the plain subtype of text in\nparticular, have this information carried in a content-type field with a given\nsyntqx, etc. etc. etc. are all somewhere else. It isn't the conformance\nsection that defines these features of the protocol.\n\nAnd if there was a mixup and the definition of some aspect of a\nprotocol was only done in a conformance section with limited\napplicability, then that would not excuse that feature from meeting\nthe interoperability requirements.\n\n> But I do not quite understand\n> which features are exempt in this way.\n\nNone are.\n\n> In particular, how can a standard ever specify a\n> requirement only for receipt, if all requirements must be\n> interoperability tested? Surely interoperability testing\n> requires that systems can both receive and generate a\n> certain format?\n\nYes, but the key word here is systems. Your simplistic testing of a\nsingle operations in a limited subset of generating agents don't\nsuffice to be able to assert that \"such and such cannot be generated\".\n\n> For example, the drums msgfmt document has a list of things\n> you should be able to receive but should not generate (the\n> obsoleted features section). How can the contents of that\n> section be interoperability tested?\n\nNow you're talking about a very different sort of beast: How to deal with\nobsolete features of a protocol that are already part of a standard that is in\nwidespread use. This is a completely different scenario than a new protocol on\nits way up, and what we're after here is the eventual removal of all this stuff\nfrom the standard. The only question is how to handle this removal gracefully.\n\nIn the case of DRUMS a clean break from the past was clearly impossible so\ncertain concessions were made. Specifically, what we're doing is allowing\nthe obsolete feature subset to be generated by an existing, incompliant\ninstalled base for purposes of interoperability testing.\n\nThis isn't to say that there aren't examples where all aspects of the obsolete\nsyntax haven't been generated. There are. I doubt we'll have any trouble\nfinding generated examples of every obsolete feature, no matter how we break\ndown the feature list. But as you say, these will by definition not have been\ngenerated by compliant implementations. And yes, we're allowing a sort of\nexemption in this case -- not in the sense of there being no generators, but\nonly in the sense that such generators are incompliant. But this is only\nbecause we're dealing with a protocol that's already widely deployed with\nfeatures we'd like to get rid of and which simply removing from the standard\nwas not an option.\n\n> Exactly why is such a\n> section allowed, even though it cannot be interoperability\n> tested? Is it because the section is labelled \"obsolete\",\n> because the section is labelled \"for receipt only\" or why?\n\nSee above.\n\nNed\n\n\n\n", "id": "lists-007-12275884"}, {"subject": "Re: question about Version-Contro", "content": "\"Elodie Tasia\" <e.tasia@ever-team.com> wrote:\n\n> > A version is created as a copy because the version-controlled resource\ncan\n> > be checked out and modified.  The version remains as an immutable copy\nof\n> > the inital state of the VERSION-CONTROL'led resource.\n>\n> Hmm, I compared the version-controlled resource to a sort of 'root', and\nI\n> thought it was immutable... I made a mistake.\n\nA version-controlled resource is a resource with defined DeltaV behavior,\nnotably CHECKOUT to make it mutable and CHECKIN to capture it's state as a\nversion resource and make it immutable.  RFC3253 has lots to say about\nversion-controlled resources.\n\n> But why is it possible to modify it, if I can create descendants with the\n> first version of the history ?\n\nYou can either modify the checked-out version-controlled resource, or a\nworking resource of a version to create a descendant depending upon whether\nthe server or client is maintaining the 'workspace' or work in progress.\nSee section 2.1 for an overview of the differences.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-1228488"}, {"subject": "RE: Only include implemented features in a draft standar", "content": "> Two different implementations must be able to correctly parse obsolete\n> messages.  Implementations should never generate those messages.  The\n> easiest way to do the test (and hopefully every MUA vendor will do this) is\n> simply to telnet to port 25 and feed in the obsolete message from the\n> example.  Thus, the obsolete section would be interoperability tested if\n> both implementations produced the same parsed message.  There is no\n> requirement for interoperability on generation, and in fact, MUAs are\n> required NOT to generate such messages.\n\nAnd of course this again begs the question of what it means to have a generator\nof a given protocol feature. As I pointed out before, while you may not\nbe able to get a set of GUI MUAs to generate deeply nested multiparts in\none go, such things do get generated quite regularly.\n\nIn the case of the obsolete stuff in DRUMS I would agree that this is\nreasonable. Although I suppose that in the abstract sense we'd be better off\nsimply removing any obsolete feature that has never been used. But this amounts\nto proving a negative about the installed base, which is impossible.\n\nAnd as a practical matter, finding real examples of all the obsolete\nstuff in DRUMS is likely going to prove to be depressingly easy.\n\nBut in the case of a new protocol, while the extreme situation of having\nnothing but hand-created examples of a single isolated feature is probably\nsufficient to meet the letter of the interoperability testing requirements, one\ncan argue that a feature that's demonstrably been shown to not be used other than in\ntesting isn't worth having and should probably be removed from the protocol.\nBut you're right in saying this isn't required for a move to draft.\n\nThere's also a slippery slope here should we start trying to figure out what\nconstitutes a legitimate \"generator\". For example, there are several\nimplementations of what you might call \"MIME object generators\" out there.\nThese are things that take one or more objects and put them in a MIME\nstructure. The ones I'm familiar with can be used to build basically arbitrary\nMIME structures with only a few commands. Is such a thing a generator? Where do\nwe draw the line?\n\nPersonally, I draw the line by not worrying this issue on this basis at all.\nWhen we move something from proposed to draft or from draft to full it makes\nsense to review the list of features not only from the perspective of \"does\nthis interoperate\" but also from the perspective of \"do we really need this\".\nThe former is required by the process and if not met, of course justifies the\nremoval of a protocol feature. The latter isn't required but isn't prohibited\neither, and can and has been used to remove unnecessary complexity from various\nprotocols.\n\nAnd this is especially true of the move to full standard. A good example here\nis multipart/parallel. There were several agents capable of sending and\nreceiving it back when MIME was moved to draft. But other, more powerful\nconstructs appear to have taken its place, and nobody bothers with it much any\nmore. \n\nThis was pointed out back when MIME recycled at draft, and at the time I\npointed out that the requirements for moving to draft had been met in full, and\nso it should stay in. I still believe this to be true for draft standard. But\nwhat about moving to full standard? I'm not sure multipart/parallel meets the\nrequirements for full standard. Perhaps it should be moved to a separate,\ninformational document at this point, should we ever get to moving MIME to full\nstandard...\n\nNed\n\n\n\n", "id": "lists-007-12287305"}, {"subject": "RE: Only include implemented features in a draft  standar", "content": "At 03.25 -0700 0-06-18, Dan Kohn wrote:\n> Two different implementations must be able to correctly parse obsolete\n> messages.  Implementations should never generate those messages.  The\n> easiest way to do the test (and hopefully every MUA vendor will do this) is\n> simply to telnet to port 25 and feed in the obsolete message from the\n> example.  Thus, the obsolete section would be interoperability tested if\n> both implementations produced the same parsed message.  There is no\n> requirement for interoperability on generation, and in fact, MUAs are\n> required NOT to generate such messages.  Thus, your second sentence doesn't\n> follow.\n\nI thought interoperability meant that one implementation\ncould receive what another implementation produced. You say\nthat interoperability means that two implementations will\nhandle the same manually generated input in the same way.\nIs that really right? Or is that a special variant of\ninteroperability, to be applied to \"receive-only\" specs,\nwhile \"send-and-receive\" specs will still be tested by\ntesting that one implementation can receive what another\nimplementation sends?\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12298544"}, {"subject": "RE: Only include implemented features in a draft standar", "content": "Jacob, what seems to be lacking in this discussion is an application of\njudgement.  The IETF has never defined interoperability rules as formally as\nyou seem to desire them.  Most RFCs (including the MIME specs), contain what\nformalists may see as a huge mishmash of requirements, implementation\nadvice, background discussion, non-normative definitions, and even humorous\nasides.  (My personal favorite is the discussion of incorrect\nimplementations in RFC 1982: \"Nothing can be done with these\nimplementations, beyond extermination.\")\n\nBut, while some might say that this is no way to run a standards\norganization, many (including myself) find that it the only way to do so,\nand any other approach to be stiflingly bureaucratic.\n\nSo, to your specific question, no, my suggestion below is not the official\nIETF policy on to how to deal with an obsolete features section.  But, it\nseems reasonable to me and it may very well seem reasonable to the IESG and\nthe AD responsible for overseeing the interoperability report.\n\nIf you want to review all the different approaches that have been taken to\nIETF interoperability testing, you might start with\n<http://www.google.com/search?q=interoperability+testing+ietf&num=30&sa=Goog\nle+Search>.  Instead, I would suggest that you use your judgement in\nconducting the testing and then produce a report like\n<http://www.w3.org/Protocols/HTTP/Forum/Reports/rollup.txt>, although\nhopefully far less detailed since MHTML is a much simpler standard.\n\nIf you really want help from this mailing list or ietf-822, then I would\nsuggest writing up your plan for interoperability testing and having it\nreviewed by the list (with the understanding that the IESG are the audience\nthat really counts at the end of the day).  But these abstract conversations\nare not getting us anywhere, and therefore I too hereby drop out of the\nthread.\n\n- dan\n--\nDaniel Kohn <mailto:dan@dankohn.com>\ntel:+1-425-602-6222\nhttp://www.dankohn.com\n\n\n-----Original Message-----\nFrom: Jacob Palme [mailto:jpalme@dsv.su.se]\nSent: Sunday, 2000-06-18 11:21\nTo: IETF Applications Area Discussion List\nSubject: RE: Only include implemented features in a draft standard\n\n\nAt 03.25 -0700 0-06-18, Dan Kohn wrote:\n> Two different implementations must be able to correctly parse obsolete\n> messages.  Implementations should never generate those messages.  The\n> easiest way to do the test (and hopefully every MUA vendor will do this)\nis\n> simply to telnet to port 25 and feed in the obsolete message from the\n> example.  Thus, the obsolete section would be interoperability tested if\n> both implementations produced the same parsed message.  There is no\n> requirement for interoperability on generation, and in fact, MUAs are\n> required NOT to generate such messages.  Thus, your second sentence\ndoesn't\n> follow.\n\nI thought interoperability meant that one implementation\ncould receive what another implementation produced. You say\nthat interoperability means that two implementations will\nhandle the same manually generated input in the same way.\nIs that really right? Or is that a special variant of\ninteroperability, to be applied to \"receive-only\" specs,\nwhile \"send-and-receive\" specs will still be tested by\ntesting that one implementation can receive what another\nimplementation sends?\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12307764"}, {"subject": "Interoperability definition (RE: Only include implemented   features in a draft standard", "content": "At 20:20 18.06.2000 +0200, Jacob Palme wrote:\n>I thought interoperability meant that one implementation\n>could receive what another implementation produced. You say\n>that interoperability means that two implementations will\n>handle the same manually generated input in the same way.\n>Is that really right? Or is that a special variant of\n>interoperability, to be applied to \"receive-only\" specs,\n>while \"send-and-receive\" specs will still be tested by\n>testing that one implementation can receive what another\n>implementation sends?\n\nWhen in doubt, read the specification.\n\nRFC 2026, section 4.1.2:\n\n\"For the purposes of this section, \"interoperable\" means to be functionally \nequivalent or interchangeable components of the system or process in which \nthey are used.\"\n\nSo two MTAs reacting identically to the same telnet session on port 25 are \ninteroperable, even though they never connect to each other.\n\n              Harald\n\n--\nHarald Tveit Alvestrand, EDB Maxware, Norway\nHarald.Alvestrand@edb.maxware.no\n\n\n\n", "id": "lists-007-12319598"}, {"subject": "Draft coding chapter for forthcoming boo", "content": "I am working on a book about Internet application layer\nprotocols and standards. The book is based on a course,\nwhich I give at my university.\n\nI have now revised the chapter about coding from this book,\nby adding a short description of HTML, CSS and XML. The new\nversion of the coding chapter can be found at\nhttp://dsv.su.se/jpalme/abook/coding.pdf\n\nI would appreciate if some of you experts on this area\ncould check the text for accuracy.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12362930"}, {"subject": "MOVE on Version History Members of a Working Collectio", "content": "Hi,\n\nLet's suppose we have a version controlled resource (a.txt) under a version\ncontrolled collection (mycoll) under a workspace (wsp01):\n\n/repo/ws/wsp01/mycoll/a.txt\n\nand we have another version controlled collection:\n\n/repo/ws/wsp01/mycoll2\n\nIf, now, we check out both mycoll and mycoll2 with apply-to-version\n(which results in creating two working collections wc_mycoll and\nwc_mycoll2, where wc_mycoll contains a binding to the version history\nof a.txt) and then do a move:\n\nMOVE wc_mycoll/a.txt\nDestination: wc_mycoll2\n\nthen, I suppose, the binding a.txt is removed from wc_mycoll and\na binding to the same version history is created in wc_mycoll2.\nIs that correct ?\n\nIf after that we checkin wc_mycoll2 then mycoll2 will contain \na VCR a.xml whose DAV:version-history will be the same like\nDAV:version-history of mycoll/a.txt.  Is that correct ?\nI suppose it is not because in this case we would have two VCR's\nin the same space pointing to the same version-history (mycoll/a.txt\nand mycoll2/a.txt).\n\nIn general my question is: Is it possible to move a VCR from one\nVCC (version controlled collection) to another using MOVE on\nworking collections ?\n\nRegards\nSasha\n\n\n\n", "id": "lists-007-1236733"}, {"subject": "A comparison of ABNF, ASN.1 and XM", "content": "I have made a short comparison of ABNF, ASN.1 and XML, by\nencoding the same information with all three coding methods.\n\nThe result of the comparison is not very surprising. The\nmeta description (ABNF, ASN.1 resp. DTD) was about equally\nlong with all three languages. My personal preference is\nfor ASN.1 as a meta language, since it is easy to read and\ngives stronger type control.\n\nThe encoded data required 169 octets for ABNF, 54 octets\nfor ASN.1-BER and 297 octets for XML. ASN.1-PER would\nprobably give even less octets. The readability of the\nencoded data was however much much better with ABNF and\nXML. XML gives especially good readability of the encoded\ndata for complex information structures. And the need for\nmany more octets with ABNF and especially XML can of course\nbe eliminated through compression. I made some tests with a\ncompression program, and it is able to eliminate almost all\nthe additional redundancy with ABNF and XML, but maybe not\nfor very small files.\n\nMy personal wish would be to have such a neat and strongly\ntyped metalanguage as ASN.1, but such neat and readable\nencoded data as XML. (I know that there is something called\nXER. But I do not believe that is what I am asking for. XER\nis an attempt to encode ASN.1 into a subset of XML. What I\nwould wish is an ASN.1-like replacement for the DTD meta\nlanguage, i.e. a meta language which can replace DTD for\nthe full span of the XML language.)\n\nThis message makes a number of statements on very\ncontroversial issues, so all of you may not agree with the\nconclusions!\n\nThe comparison can be found at:\nhttp://dsv.su.se/jpalme/abook/comparison.pdf in Acrobat format, and at\nhttp://dsv.su.se/jpalme/abook/comparison.ps in Postscript format\n\n(Note: My BER encoding is probably not 100% right. It is\ndifficult to produce correct BER encoding manually, and I\nhave no ASN.1-BER encoding program to help me. But this\nwill probably not influence the results of the comparison\nvery much.)\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12369850"}, {"subject": "RE: A comparison of ABNF, ASN.1 and XM", "content": "> My personal wish would be to have such a neat and strongly\n> typed metalanguage as ASN.1, but such neat and readable\n> encoded data as XML. (I know that there is something called\n> XER. But I do not believe that is what I am asking for. XER\n> is an attempt to encode ASN.1 into a subset of XML. What I\n> would wish is an ASN.1-like replacement for the DTD meta\n> language, i.e. a meta language which can replace DTD for\n> the full span of the XML language.)\n\nThe W3C is attempting to create such a thing - the XML Schema\nlanguage.  The current work divides the problem into two spaces\n\nStructures - http://www.w3.org/TR/xmlschema-1/\nDatatypes  - http://www.w3.org/TR/xmlschema-2/\n\nFor W3C members (I know, this doesn't help everyone here), the\nworking group page is:\n  http://www.w3.org/XML/Group/Schemas.html\nand the associated Interest Group charter page is\n  http://www.w3.org/XML/Group/1999/05/xml-schema-ig-charter.html\n\n--\nScott Lawrence      Director of R & D        <lawrence@agranat.com>\nAgranat Systems   Embedded Web Technology   http://www.agranat.com/\n\n\n\n", "id": "lists-007-12379450"}, {"subject": "I-D ACTION:draft-duerst-i18n-norm-02.tx", "content": "FYI. Looking forward to comments and discussion.\n\n> To: IETF-Announce: ;\n> From: Internet-Drafts@ietf.org\n> Reply-to: Internet-Drafts@ietf.org\n> Subject: I-D ACTION:draft-duerst-i18n-norm-02.txt\n> Date: Fri, 03 Mar 2000 06:27:06 -0500\n> Sender: nsyracus@cnri.reston.va.us\n> X-UIDL: 146de16750c381bc8e02661a1f939a42\n> \n> A New Internet-Draft is available from the on-line Internet-Drafts directories.\n> \n> \n> Title: Character Normalization in ITEF Protocols\n> Author(s): M. Duerst, M. Davis\n> Filename: draft-duerst-i18n-norm-02.txt\n> Pages: 12\n> Date: 02-Mar-00\n> \n> The Universal Character Set (UCS) [ISO10646, Unicode] covers a very wide\n> repertoire of characters. The IETF, in [RFC 2277], requires that future IETF protocols support UTF-8 [RFC 2279], an ASCII-compatible encoding of UCS. The wide range of characters included in the UCS has lead to some cases of duplicate encodings. This document proposes that in IETF protocols, the class of duplicates called canonical equivalents be dealt with by using Early Uniform Normalization according to Unicode Normalization Form C, Canonical Composition [UTR15]. This document describes both Early Uniform Normalization and Normalization Form C.\n> \n> A URL for this Internet-Draft is:\n> http://www.ietf.org/internet-drafts/draft-duerst-i18n-norm-02.txt\n> \n> Internet-Drafts are also available by anonymous FTP. Login with the username\n> \"anonymous\" and a password of your e-mail address. After logging in,\n> type \"cd internet-drafts\" and then\n> \"get draft-duerst-i18n-norm-02.txt\".\n> \n> A list of Internet-Drafts directories can be found in\n> http://www.ietf.org/shadow.html \n> or ftp://ftp.ietf.org/ietf/1shadow-sites.txt\n> \n> \n> Internet-Drafts can also be obtained by e-mail.\n> \n> Send a message to:\n> mailserv@ietf.org.\n> In the body type:\n> \"FILE /internet-drafts/draft-duerst-i18n-norm-02.txt\".\n> \n> NOTE:The mail server at ietf.org can return the document in\n> MIME-encoded form by using the \"mpack\" utility.  To use this\n> feature, insert the command \"ENCODING mime\" before the \"FILE\"\n> command.  To decode the response(s), you will need \"munpack\" or\n> a MIME-compliant mail reader.  Different MIME-compliant mail readers\n> exhibit different behavior, especially when dealing with\n> \"multipart\" MIME messages (i.e. documents which have been split\n> up into multiple messages), so check your local documentation on\n> how to manipulate these messages.\n> \n> \n> Below is the data which will enable a MIME compliant mail reader\n> implementation to automatically retrieve the ASCII version of the\n> Internet-Draft.\n> Content-Type: text/plain\n> Content-ID:<20000302145851.I-D@ietf.org>\n> \n> ENCODING mime\n> FILE /internet-drafts/draft-duerst-i18n-norm-02.txt\n> \n> <ftp://ftp.ietf.org/internet-drafts/draft-duerst-i18n-norm-02.txt>\n> \n\n\n#-#-#  Martin J. Du\"rst, World Wide Web Consortium\n#-#-#  mailto:duerst@w3.org   http://www.w3.org\n\n\n\n", "id": "lists-007-12388510"}, {"subject": "Re: I-D ACTION:draft-duerst-i18n-norm-02.tx", "content": "--On 2000-03-04 15.03 +0900, \"Martin J. Duerst\" <duerst@w3.org> wrote:\n\n>> Title: Character Normalization in ITEF Protocols\n\nI think the title should be different :-)\n\nITEF?\n\n   paf\n\n\n\n", "id": "lists-007-12399829"}, {"subject": "Email Advertising Special&ndash;&ndash;Ends Frida", "content": "PUT EMAIL MARKETING TO WORK FOR YOU...\n\nCall NOW and receive 50,000\nadditional emails with your order\nfor only $100. Thats 40,000 FREE emails!!!\n\nWE HAVE OPT-IN LISTS!!!!\n\nsee below for removal.\n\nSpecial Ends Friday March 31, 2000\n\nMLM'ers, We can build your downline.\n\nImagine having a product or idea and selling it\nfor only $10.\n\nNow imagine sending an ad for your product or idea\nto 25 million people!\n\nIf you only get a 1/10 of 1% response\nyou have just made $250,000!!\n\nYou hear about people getting rich off\nthe Internet everyday on TV,\nnow is the perfect time for you\nto jump in on all the action.\n\nFACT.\nWith the introduction of the Internet, one primary\nKEY to conducting your business successfully is\ncreating massive exposure in a cost effective\nmanner.\n\nFACT.\nThe experts agree that email marketing is one of\nthe most cost effective forms of promotion in\nexistence today.\n\nElectronic mail has overtaken the telephone as the\nprimary means of business communication.(American\nManagement Association)\n\nOf online users 41 percent check their email daily.\n\n\"A gold mine for those who can take advantage of\nbulk email programs\"- The New York Times\n\n\"Email is an incredible lead generation tool\"\n-Crains Magazine\n\n\"Blows away traditional Mailing\"-Advertising Age\n\n\"It's truly arrived. Email is the killer app so\nfar in the online world\"-Kate Delhagen, Forrester\nResearch Analyst\n\nWhy not let a professional company handle your\ndirect email marketing efforts for you?\n\n*We will assist you in developing your entire\ncampaign!\n\n*We can even create your ad or annoucement for\nyou!\n\n*No responses? We resend at no cost!\n\nFor More Information CALL NOW-702-248-1043\n\n\nFor removal see below.\n\nSPECIAL RATES\nSPECIAL ENDS Friday March 31, 2000\n\nTargeted Rates Upon Request.\n\nBONUS!!!\nCall In and receive 50,000 Extra Emails at\nNo Cost!\n\nCall NOW - 702-248-1043\n\n\n\n\n\n\n\n\n++++++++++++++++++++++++++++++++++++++++++++++++++\nWe are terribly sorry if you received this message\nin error.\nIf you wish to be removed. Please, type \"REMOVE\"\nin the subject line:   outnow@fiberia.com\n\n++++++++++++++++++++++++++++++++++++++++++++++++++\n\n\n\n", "id": "lists-007-12407092"}, {"subject": "No apologies if you receive this multiple times (was CFP: IEEE IC3N'2000", "content": "Is it necessary for email that is sent to multiple mailing lists to include,\nin its body, an apology to people who receive it multiple times?  If they\ncared, couldn't they set up an email client to filter out duplicates using\nthe Message-ID field?  Placing an apology in the message body clutters\neverybody's email.  I would like an apology for the apologies!\n\nDelving deeper, there seems to be a problem with communications applications\nhaving obscure features (e.g. Message-IDs) that people reinvent using social\nprotocols.  How can we entice people to use these features and receive the\nbenefits of automation without a large investment in learning?\n\nApologies of my own:\n1. Please redirect me, and this discussion, to any mailing lists that might\nbe more relevant to this topic.\n2. This isn't a criticism of this particular Call For Papers.  It seems to\nbe a deeper generic problem, worthy of research.\n\n\nTim\n\n> From: owner-end2end-interest@ISI.EDU\n> [mailto:owner-end2end-interest@ISI.EDU]On Behalf Of Atiquzzaman,\n> Mohammed\n> Sent: Monday, May 01, 2000 9:37 AM\n> To: 'tccc@ieee.org'; 'giga@tele.pitt.edu'; 'itc@fokus.gmd.de';\n> 'enternet@bbn.com'; 'end2end-interest@isi.edu'; 'itc@ieee.org'\n> Subject: CFP: IEEE IC3N'2000\n>\n>\n>                   (Our apologies if you receive this multiple times!!)\n>\n...\n\n\n\n", "id": "lists-007-12438308"}, {"subject": "Re: No apologies if you receive this multiple times (was CFP: IEEE IC3N'2000", "content": "[end2endinterest removed...not on topic for that discussion]\n\nin general you don't want to do duplicate suppression based on\nmessage-id alone, because sometimes the same message-id really\nis used for significantly different messages  (sometimes due\nto software bugs, but if duplicate supression were widespread\nit would probably be a target of malice ... to keep someone from\nseeing a message, send them a different message using the same\nmessage-id).  some lists significantly modify messages without \nmodifying the message-id.  (and you probably don't want them\nto modify the message-id - it's what lets you trace a message \nback to its source)\n\nyou can use message-id to find potential duplicates, and then\ncompare the messages themselves and use heuristics to determine\nwhether they really are more-or-less the same.  or a user agent\ncould remove extraneous information (e.g. received headers) from \nevery message it received, hash the result, and compare the hashes\nfor duplicates.   I don't know of any user agent that does either \nof these, and unless one gets lots of duplicate mail, it might\nnot be worth the bother.\n\nmail delivery systems should probably not try to eliminate duplicates\non behalf of their users. sometimes you actually want to know that\nyou got a copy of the message that was sent through a list even if\nyou already received a copy by other means.  so the user agent would\nneed to do the duplicate suppression if it is to be done at all.\n\nI don't think we need to find a technical solution to every \nsocial problem that exists with email.  the problem exists in other\nfields as well - people sometimes get more than one copy of the\nsame mail-order catalog, for instance - and we don't lose too much\nsleep over it.  \n\nin general, the purpose of apologies are to avoid getting compliants\nfrom people who are naive enough to think that this is the sender's\nproblem rather than the recipient's.\n\nKeith\n\n\n\n", "id": "lists-007-12450260"}, {"subject": "RE: MOVE on Version History Members of a Working Collectio", "content": "   From: Zivkov, Sasa [mailto:sasa.zivkov@sap.com]\n\n   Let's suppose we have a version controlled resource (a.txt) under a\n   version controlled collection (mycoll) under a workspace (wsp01):\n\n   /repo/ws/wsp01/mycoll/a.txt\n\n   and we have another version controlled collection:\n\n   /repo/ws/wsp01/mycoll2\n\n   If, now, we check out both mycoll and mycoll2 with apply-to-version\n   (which results in creating two working collections wc_mycoll and\n   wc_mycoll2, where wc_mycoll contains a binding to the version\n   history of a.txt) and then do a move:\n\n   MOVE wc_mycoll/a.txt\n   Destination: wc_mycoll2\n\n   then, I suppose, the binding a.txt is removed from wc_mycoll and\n   a binding to the same version history is created in wc_mycoll2.\n   Is that correct ?\n\nYes.\n\n   If after that we checkin wc_mycoll2 then mycoll2 will contain \n   a VCR a.xml whose DAV:version-history will be the same like\n   DAV:version-history of mycoll/a.txt.  Is that correct ?\n\nYes.\n\n   I suppose it is not because in this case we would have two VCR's\n   in the same space pointing to the same version-history (mycoll/a.txt\n   and mycoll2/a.txt).\n\nYou will actually have one VCR, with two bindings to it (i.e. one from\nmycoll/a.txt and another from mycoll2/a.txt).  This is required by\nworkspace semantics, which says that there can only be one VCR in a\nworkspace for a given version history, but you can have multiple\nbindings in that workspace to that VCR.\n\n   In general my question is: Is it possible to move a VCR from one\n   VCC (version controlled collection) to another using MOVE on\n   working collections ?\n\nYes.  (That is one of the benefits you get from the\n\"one VCR per version history\" semantics).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1245627"}, {"subject": "is AOL dropping mail with &gt; 100 recipients", "content": "I've received a report that AOL's mail servers are silently discarding\nany SMTP message that arrives with > 100 recipients in the SMTP envelope.\n\ncan anyone confirm or refute this report?\n\nKeith\n\n\n\n", "id": "lists-007-12460691"}, {"subject": "Re: No apologies if you receive this multiple times (was CFP: IEEE IC3N'2000", "content": "Carnegie Mellon's legacy e-mail system has been eliminating duplicates\nbased on message-id alone (well, with recepient envelope address) for\nmany years (circa 1985?), and our new system, the Cyrus IMAP server,\nalso does it.  We never get any user complaints except when it doesn't\nwork.\n\nThe denial-of-service attack is interesting, and text should probably\nbe added to the relevant document that message-ids should be\nreasonably unpredictable if it's not there already.\n\nLarry\n\n   From: Keith Moore <moore@cs.utk.edu>\n   Date: Tue, 02 May 2000 12:33:52 -0400\n\n   [end2endinterest removed...not on topic for that discussion]\n\n   in general you don't want to do duplicate suppression based on\n   message-id alone, because sometimes the same message-id really\n   is used for significantly different messages  (sometimes due\n   to software bugs, but if duplicate supression were widespread\n   it would probably be a target of malice ... to keep someone from\n   seeing a message, send them a different message using the same\n   message-id).  some lists significantly modify messages without \n   modifying the message-id.  (and you probably don't want them\n   to modify the message-id - it's what lets you trace a message \n   back to its source)\n\n   you can use message-id to find potential duplicates, and then\n   compare the messages themselves and use heuristics to determine\n   whether they really are more-or-less the same.  or a user agent\n   could remove extraneous information (e.g. received headers) from \n   every message it received, hash the result, and compare the hashes\n   for duplicates.   I don't know of any user agent that does either \n   of these, and unless one gets lots of duplicate mail, it might\n   not be worth the bother.\n\n   mail delivery systems should probably not try to eliminate duplicates\n   on behalf of their users. sometimes you actually want to know that\n   you got a copy of the message that was sent through a list even if\n   you already received a copy by other means.  so the user agent would\n   need to do the duplicate suppression if it is to be done at all.\n\n   I don't think we need to find a technical solution to every \n   social problem that exists with email.  the problem exists in other\n   fields as well - people sometimes get more than one copy of the\n   same mail-order catalog, for instance - and we don't lose too much\n   sleep over it.  \n\n   in general, the purpose of apologies are to avoid getting compliants\n   from people who are naive enough to think that this is the sender's\n   problem rather than the recipient's.\n\n   Keith\n\n\n\n", "id": "lists-007-12467606"}, {"subject": "Re: No apologies if you receive this multiple times (was CFP: IEEE IC3N'2000", "content": "just for grins, see whether you get this message or the \"fake\" one \nthat I just sent to you with the same message-id.\n(this is the real message)\n\nKeith\n\n> Carnegie Mellon's legacy e-mail system has been eliminating duplicates\n> based on message-id alone (well, with recepient envelope address) for\n> many years (circa 1985?), and our new system, the Cyrus IMAP server,\n> also does it.  We never get any user complaints except when it doesn't\n> work.\n> \n> The denial-of-service attack is interesting, and text should probably\n> be added to the relevant document that message-ids should be\n> reasonably unpredictable if it's not there already.\n> \n> Larry\n\n\n\n", "id": "lists-007-12479675"}, {"subject": "Re: No apologies if you receive this multiple times (was CFP: IEEE IC3N'2000", "content": "i received the 'fake' message.  interestingly enough, i'm unable to\ntell exactly where the duplicate message got filtered out---only one\never hit our IMAP server, and our delivery system is still mostly\nunder control of AMS, which functions in it's own strange and mystical\nways that I do not totally comprehend.\n\nI read this list via a shared bboard---which also has duplicate\ndelivery suppression (the mail system views it just like any other\nuser).\n\nMore interesting then your denial-of-service attack on yourself is the\nproblem of a mailing list that both you and I are on: \n- you receive a message, and decide to prevent me receiving it\n- you immediately send me a message with the same message-id\n\nIf the mailing list exploder decided to deliver to me later than you\n(especially if it's a large mailing list) you have a good chance of\ndenying me receiving a message.\n\nIt's hard to come up with a simple scheme to prevent this, since most\nof the obvious things to hash can easily be duplicated, and you\ngenerally want a message with the same message-id but a different body\nto be repressed --- since it's probably the \"[to unsubscribe, blah]\"\nmessage from a mailing list.\n\nLarry\n\n\n\n", "id": "lists-007-12489167"}, {"subject": "Re: No apologies if you receive this multiple times (was CFP: IEEE IC3N'2000", "content": "> More interesting then your denial-of-service attack on yourself is the\n> problem of a mailing list that both you and I are on: \n> - you receive a message, and decide to prevent me receiving it\n> - you immediately send me a message with the same message-id\n> \n> If the mailing list exploder decided to deliver to me later than you\n> (especially if it's a large mailing list) you have a good chance of\n> denying me receiving a message.\n\nyes, that's my point.   I can just send you a copy of an advertisement\nfor toner cartridges with the same message-id as the message I don't\nwant you to see.\n\n> It's hard to come up with a simple scheme to prevent this, since most\n> of the obvious things to hash can easily be duplicated, \n\nnot sure what you mean here - my idea is for the recipient's \nuser agent (or in your case, message store) to index \nmessages received by message-id, but have the potential to \nstore duplicates.\n\nso when a message gets received, the message-id is extracted,\nand a secure hash is made of the message (minus its received\nfields and anything else that seems extraneous).  if there\nwas another message with that message-id and the same hash,\nthe new message is ignored.  if there was another message\nwith the same message-id but a different hash, the new message\nis treated as a separate message.\n\n> and you generally want a message with the same message-id but a \n> different body to be repressed --- since it's probably the \n> \"[to unsubscribe, blah]\" message from a mailing list.\n\nmaybe, but the mail system doesn't know for sure.\n\nKeith\n\n\n\n", "id": "lists-007-12498590"}, {"subject": "great web hosting deal", "content": "GET YOUR OWN 5 MEG WEBSITE FOR ONLY $11.95 PER MONTH TODAY!\n\nSTOP PAYING $19.95 or more PER MONTH OR MORE TODAY for your web site, WHEN YOU CAN GET ONE FOR ONLY $11.95 PER MONTH!\n\nDO YOU ALREADY HAVE A WEBSITE? ALL YOU HAVE TO DO IS TRANSFER THE DOMAIN TO OUR SERVERS AND UPLOAD YOUR DATA AND YOU ARE READY TO GO! YOUR NEW WEB SPACE CAN BE CREATED INSTANTLY WITH JUST A SIMPLE PHONE CALL OUR OFFICE.\n\nYOU CAN CHANGE YOUR SITE AS MUCH AS YOU WANT with no extra charge!  UNLIMITED TRAFFIC -- no extra charge!\n\n\nA SET UP FEE OF $40.00 APPLIES for FIRST TIME CUSTOMERS.\n\nALL FEES PREPAID IN ADVANCE FOR THE YEAR PLUS A $40.00 SET UP CHARGE.\n\nFOR DETAILS CALL 1 888 248 0765  or fax 240 337 8325\n\nPES WEB HOSTING -- Toronto, Ontario\n_______________________________________________________________\n\nWant to do bulk email?\n\nAsk us how today!\n\nFor an investment of $395.00 for our Direct Mail mailing program and our highly prized email extractor program Nitro for $495.00,\nyou can be in business today!\n\nIf you manage your own mailing list, you somebody do your mailing for you, here is the way to do it your self!\nEmail 10,000 to 20,000 per hour with our programs!\n\nCall 1888 248 0765 for a free demo today!\n  or fax 240 337 8325\n\n_________________________________________________________________\n\nGet your own offshore trust! \nPROTECT YOUR PERSONAL ASSETS FROM LAWSUITS or Do SOME ESTATE PLANNING!\nGET THAT OFFSHORE BANK ACCOUNT YOU ALWAYS WANTED!\n\nFor further information please fax 240 337 8325\n\n\n\n\nTHANK YOU\n\nto be removed email pro@natas.kfa.cx\n\n\n\n", "id": "lists-007-12508458"}, {"subject": "Re: No apologies if you receive this multiple times (was CFP: IEEE  IC3N'2000", "content": "> Carnegie Mellon's legacy e-mail system has been eliminating duplicates\n> based on message-id alone (well, with recepient envelope address) for\n> many years (circa 1985?), and our new system, the Cyrus IMAP server,\n> also does it.  We never get any user complaints except when it doesn't\n> work.\n\nWell, all I can say is that I know quite a few people who have been involved in\nthe CMU mail system's design and implementation, and several of them have told\nme of quite a few problems and considerable user dissatisfaction with this\n\"feature\".\n\nNed\n\n\n\n", "id": "lists-007-12515980"}, {"subject": "RE: No apologies if you receive this multiple times (was CFP: IEEE IC3N'2000", "content": "> so when a message gets received, the message-id is extracted,\n> and a secure hash is made of the message (minus its received\n> fields and anything else that seems extraneous).  if there\n> was another message with that message-id and the same hash,\n> the new message is ignored.  if there was another message\n> with the same message-id but a different hash, the new message\n> is treated as a separate message.\n\nSo forget the message-ID and just store the secure hash.\n\n\n\n", "id": "lists-007-12524790"}, {"subject": "Re: No apologies if you receive this multiple times (was CFP: IEEE IC3N'2000", "content": "> > so when a message gets received, the message-id is extracted,\n> > and a secure hash is made of the message (minus its received\n> > fields and anything else that seems extraneous).  if there\n> > was another message with that message-id and the same hash,\n> > the new message is ignored.  if there was another message\n> > with the same message-id but a different hash, the new message\n> > is treated as a separate message.\n> \n> So forget the message-ID and just store the secure hash.\n\nyep, if you're going to just compare hashes then you might as well\nforget the message-ID altogether.\n\nthe message-id could still be useful if you want to compare the \nmessage using other means, or to point out to a human\n\"hey, we've got these two messages with the same message-id\".\n\nKeith\n\n\n\n", "id": "lists-007-12533688"}, {"subject": "RE: No apologies if you receive this multiple times (was CFP: IEE E IC3N'2000", "content": "I believe the issue here is a misunderstanding on what level of heuristics a\nmailer could be expected to achieve.  I strongly suspect that it is\ncomputationally infeasible to avoid both false positives (denial of service\nattacks) and false negatives (having two versions of a message because, for\ninstance, one of the mailing lists adds unsubscribe information to the\nbody).\n\nIf I were going to design my ideal mailer, I would instead suggest that the\nbest user interface metaphor is a merged document, a la the Compare\nDocuments feature in Word or diff in Unix.  That is, it is quite unlikely to\nget two exactly identical messages (at the very least, the Received headers\nwill probably be different.).  The question is how different are they.\nRather than asking the computer to decide whether they are one message or\ntwo, have it perform a diff, and show messages with the same Message ID as a\nsingle merged message, including strike through and underlined for new text\n(or whatever syntactic elements one prefers to highlight the differences).\n\nIf (as is most often the case for me), the duplicates only differ by\nReceived headers, then that information would be hidden unless I selected\nShow Headers and I could treat it as one message.  But, I could be confident\nthat if, for any reason, the message had changed in any sort of significant\nform, I would see that as strike through and new text underlines in the main\ntext.\n\n- dan\n--\nDaniel Kohn <mailto:dan@dankohn.com>\ntel:+1-425-602-6222  fax:+1-425-602-6223\nhttp://www.dankohn.com\n\n-----Original Message-----\nFrom: Lawrence Greenfield [mailto:leg+@andrew.cmu.edu]\nSent: Tuesday, 2000-05-02 11:25\nTo: Tim Moors; Keith Moore\nCc: Atiquzzaman@andrew.cmu.edu, Mohammed; discuss@apps.ietf.org\nSubject: Re: No apologies if you receive this multiple times (was CFP:\nIEEE IC3N'2000) \n\n\nCarnegie Mellon's legacy e-mail system has been eliminating duplicates\nbased on message-id alone (well, with recepient envelope address) for\nmany years (circa 1985?), and our new system, the Cyrus IMAP server,\nalso does it.  We never get any user complaints except when it doesn't\nwork.\n\nThe denial-of-service attack is interesting, and text should probably\nbe added to the relevant document that message-ids should be\nreasonably unpredictable if it's not there already.\n\nLarry\n\n   From: Keith Moore <moore@cs.utk.edu>\n   Date: Tue, 02 May 2000 12:33:52 -0400\n\n   [end2endinterest removed...not on topic for that discussion]\n\n   in general you don't want to do duplicate suppression based on\n   message-id alone, because sometimes the same message-id really\n   is used for significantly different messages  (sometimes due\n   to software bugs, but if duplicate supression were widespread\n   it would probably be a target of malice ... to keep someone from\n   seeing a message, send them a different message using the same\n   message-id).  some lists significantly modify messages without \n   modifying the message-id.  (and you probably don't want them\n   to modify the message-id - it's what lets you trace a message \n   back to its source)\n\n   you can use message-id to find potential duplicates, and then\n   compare the messages themselves and use heuristics to determine\n   whether they really are more-or-less the same.  or a user agent\n   could remove extraneous information (e.g. received headers) from \n   every message it received, hash the result, and compare the hashes\n   for duplicates.   I don't know of any user agent that does either \n   of these, and unless one gets lots of duplicate mail, it might\n   not be worth the bother.\n\n   mail delivery systems should probably not try to eliminate duplicates\n   on behalf of their users. sometimes you actually want to know that\n   you got a copy of the message that was sent through a list even if\n   you already received a copy by other means.  so the user agent would\n   need to do the duplicate suppression if it is to be done at all.\n\n   I don't think we need to find a technical solution to every \n   social problem that exists with email.  the problem exists in other\n   fields as well - people sometimes get more than one copy of the\n   same mail-order catalog, for instance - and we don't lose too much\n   sleep over it.  \n\n   in general, the purpose of apologies are to avoid getting compliants\n   from people who are naive enough to think that this is the sender's\n   problem rather than the recipient's.\n\n   Keith\n\n\n\n", "id": "lists-007-12542692"}, {"subject": "RE: MOVE on Version History Members of a Working Collectio", "content": ">    From: Zivkov, Sasa [mailto:sasa.zivkov@sap.com]\n> \n>    Let's suppose we have a version controlled resource (a.txt) under a\n>    version controlled collection (mycoll) under a workspace (wsp01):\n> \n>    /repo/ws/wsp01/mycoll/a.txt\n> \n>    and we have another version controlled collection:\n> \n>    /repo/ws/wsp01/mycoll2\n> \n>    If, now, we check out both mycoll and mycoll2 with apply-to-version\n>    (which results in creating two working collections wc_mycoll and\n>    wc_mycoll2, where wc_mycoll contains a binding to the version\n>    history of a.txt) and then do a move:\n> \n>    MOVE wc_mycoll/a.txt\n>    Destination: wc_mycoll2\n> \n>    then, I suppose, the binding a.txt is removed from wc_mycoll and\n>    a binding to the same version history is created in wc_mycoll2.\n>    Is that correct ?\n> \n> Yes.\n> \n>    If after that we checkin wc_mycoll2 then mycoll2 will contain \n>    a VCR a.xml whose DAV:version-history will be the same like\n>    DAV:version-history of mycoll/a.txt.  Is that correct ?\n> \n> Yes.\n> \n>    I suppose it is not because in this case we would have two VCR's\n>    in the same space pointing to the same version-history (mycoll/a.txt\n>    and mycoll2/a.txt).\n> \n> You will actually have one VCR, with two bindings to it (i.e. one from\n> mycoll/a.txt and another from mycoll2/a.txt).  This is required by\n> workspace semantics, which says that there can only be one VCR in a\n> workspace for a given version history, but you can have multiple\n> bindings in that workspace to that VCR.\n\nI always thought that there can be only one URL in a workspace for\none VCR :-(\n\nSo, there is not *the* URL of a VCR in a workspace ?\n\nIn the example above if both URL's mycoll/a.txt and mycoll2/a.txt are\nthe same VCR then they must share the same set of live/dead properties\nand content.\nRight ?\n\nAnd if I DELETE mycoll/a.txt is the VCR deleted also ?\nOr does the server do the reference counting and deletes the VCR when\nthe last binding to it is deleted ?\n\nAlso if we take a look on a part of rfc3253:\n\n    14.4 Additional DELETE Semantics\n\n      Additional Preconditions:\n\n          (DAV:cannot-modify-checked-in-parent): If the request-URL\n          identifies a version-controlled resource, the DELETE MUST fail\n          when the collection containing the version-controlled resource is\n          a checked-in version-controlled collection, unless DAV:auto-\n          version semantics will automatically check out the version-\n          controlled collection.\n\nSo, here you mention *the* collection containing the VCR.\nBut in the example above which collection is *the* collection containing\nthe VCR mycoll or mycoll2 ?\n\n\n> \n>    In general my question is: Is it possible to move a VCR from one\n>    VCC (version controlled collection) to another using MOVE on\n>    working collections ?\n> \n> Yes.  (That is one of the benefits you get from the\n> \"one VCR per version history\" semantics).\n> \n> Cheers,\n> Geoff\n\n\n\n", "id": "lists-007-1255094"}, {"subject": "Re: No apologies if you receive this multiple  times (was CFP: IEEE IC3N'2000", "content": "At 15.29 -0400 0-05-02, Keith Moore wrote:\n> so when a message gets received, the message-id is extracted,\n> and a secure hash is made of the message (minus its received\n> fields and anything else that seems extraneous).  if there\n> was another message with that message-id and the same hash,\n> the new message is ignored.  if there was another message\n> with the same message-id but a different hash, the new message\n> is treated as a separate message.\n\nUsually the messages are not identical. The names listed\nin the To, Cc and Bcc headers are usually different.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12555591"}, {"subject": "RE: No apologies if you receive this multiple  times (was CFP: IEEE IC3N'2000", "content": "At 15.21 -0700 0-05-02, Larry Masinter wrote:\n> So forget the message-ID and just store the secure hash.\n\nThe Message-ID has the advantage of identifying also not-quite-\nidentical messages, for example with different information in\nthe To, Cc and Bcc headers or Resent-From added or something\nlike that. You cannot make a secure hash on just the content\nof a message, there is an obvious probability that several\nentirely unrelated messages will have the same textual content,\nfor example \"Yes\" or \"I love you!\".\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12564113"}, {"subject": "Re: No apologies if you receive this multiple  time", "content": "At 12.33 -0400 0-05-02, Keith Moore wrote:\n> mail delivery systems should probably not try to eliminate duplicates\n> on behalf of their users. sometimes you actually want to know that\n> you got a copy of the message that was sent through a list even if\n> you already received a copy by other means.  so the user agent would\n> need to do the duplicate suppression if it is to be done at all.\n>\n> I don't think we need to find a technical solution to every\n> social problem that exists with email.  the problem exists in other\n> fields as well - people sometimes get more than one copy of the\n> same mail-order catalog, for instance - and we don't lose too much\n> sleep over it.\n\nI have many times complained that so few mailers utilize\nthe opportunities provided by Message-ID, In-Reply-To,\nReferences and (not yet standard) Supersedes to correlate\nrelated messages. Such correlation functions will provide\nsimple user commands for actions such as \"find the message\nwhich this message is a reply to\", \"find all replies to\nthis message\", \"find all message in this thread\".\n\nDuplicate messages can be detected either by Message-ID\nor by some kind content checksum. Instead of rejecting\none of them (like Usenet News servers do) they should\nbe correlated.\n\n(If a Usenet News server gets a message with Message-ID\nxyz to newsgroup A, and then gets the same message again\nto newsgroup B, it will reject the second copy of the\nsame message, instead of delivering it to newsgroup B.\nI can understand why it works like that, but it is not\nnice and proper. If two mailing lists gateway to two\nnewsgroups, then this means that messages sent to both\nmailing lists will only occur on one of the newsgroups.)\n\nExample of you can correlate messages with the same Message-ID:\n\nYou get a message with\n    To: marys@foo.bar.net\n    Message-ID: xyz@foo.net.bar\n\nAnd another message with identical content, and the headers\n    To: lizaq@foo.bar.net\n    Message-ID: xyz@foo.net.bar\n\nYou can then display this to the user something like this:\n    To: marys@foo.bar.net\n    To: lizaq@foo.bar.net\n    Message-ID: xyz@foo.net.bar\n\nIf two messages have the same Message-ID but not identical\ncontent, it is still useful to correlate them, for example\n    From: marys@foo.bar.net\n    To: lizaq@foo.bar.net\n    Other messages with the same Message-ID\n\nThe recipient can then click on this link to see the other\nmessages with the same ID.\n\nSee also http://dsv.su.se/jpalme/ietf/message-threading.html\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12572973"}, {"subject": "RE: No apologies if you receive this multiple  time", "content": "At 21.25 -0700 0-05-02, Dan Kohn wrote:\n> I believe the issue here is a misunderstanding on what level of heuristics a\n> mailer could be expected to achieve.  I strongly suspect that it is\n> computationally infeasible to avoid both false positives (denial of service\n> attacks) and false negatives (having two versions of a message because, for\n> instance, one of the mailing lists adds unsubscribe information to the\n> body).\n\nI am an moderator of a LISTSERV mailing list. Sometimes,\nthe same message is sent twice to the mailing list. The\nLISTSERV software recognizes this, even if the Message-ID\nis not identical. The LISTSERV then asks me as a moderator\nwhether this, presumably identical message, should really\nbe sent to the mailing list again. This seems a good and\nproper way to handle it - note the possible correlation,\nask a human what to about it.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12584968"}, {"subject": "Re: No apologies if you receive this multiple time", "content": "> I have many times complained that so few mailers utilize\n> the opportunities provided by Message-ID, In-Reply-To,\n> References and (not yet standard) Supersedes to correlate\n> related messages. Such correlation functions will provide\n> simple user commands for actions such as \"find the message\n> which this message is a reply to\", \"find all replies to\n> this message\", \"find all message in this thread\".\n\nLess so now than 5 years ago.  It's a shame that MS Outlook, used with\nMS Exchange, doesn't seem to set either References or In-Reply-To.\nIt's making non-inferential threading harder and harder to do for\nmailing lists.  Shouldn't we be discussing this on the 822 mailing\nlist?\n\nBill\n\n\n\n", "id": "lists-007-12592780"}, {"subject": "Re: No apologies if you receive this multiple  time", "content": "At 12.22 -0700 0-05-03, Bill Janssen wrote:\n> Less so now than 5 years ago.  It's a shame that MS Outlook, used with\n> MS Exchange, doesn't seem to set either References or In-Reply-To.\n> It's making non-inferential threading harder and harder to do for\n> mailing lists.  Shouldn't we be discussing this on the 822 mailing\n> list?\n\nThe people at Microsoft do listen to complaints of this kind,\nso we should try to influence them. Everyone who knows\nsomeone at Microsoft, remind them of this issue, and recommend\nthem to read http://dsv.su.se/jpalme/ietf/message-threading.html\nthen maybe the next generation of Outlook will get good thread\nsupport!\n\nI am sending a copy of this e-mail to one friend of mine who\nworks at Microsoft, and who has done good work in the past\non getting his company produce standards-compliant products.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12601274"}, {"subject": "Instant Financial Data on Every UK Busines", "content": "Do you need fast accurate information to assist you when appraising\npotential customers, and suppliers?\n\nThe UK Data internet website www.ukdata.com contains 28 million pages of\ndata with full information on every UK company!\n\nCredit Reports-Director Searches-Accounts-Annual Returns\n\nAll of these products and many more are available to you immediately, and\ncan be downloaded to and printed from your personal computer.\n\nFree samples of all reports are available at www.ukdata.com.\n\nPlease also visit www.formacompany.co.uk the on-line company formation\nwebsite\n\nThank You\n\nCharles Fletcher\nwww.ukdata.com an instant report on every UK business\nwww.formacompany.co.uk the on-line company formation site\nwww.irishdata.ie - instant reports on all Irish companies\n\n\n\n", "id": "lists-007-12609729"}, {"subject": "UK Company Formations www.formacompany.co.u", "content": "Do you need a company registered in the UK.\n\nPlease visit www.formacompany.co.uk where you can form your new company\non-line for only ?98\n\n\nThank you\n\n\nMaureen Cavely\nwww.formacompany.co.uk\n\n\n\n", "id": "lists-007-12616885"}, {"subject": "Language translation in e-mail standard", "content": "I have been thinking many times on how to best support\nlanguage translation in e-mail standards. We have now\nreceived a research grant, which will allow us to\nimplement this next year.\n\nSome requirements on a language translation standard:\n\n(1) It should cater for both machine and human translations.\n\n(2) It should cater for more than one translation of the\n     same message, usually first a machine translation and\n     later on a human translation of the same message.\n\n(3) It should cater for both the case where all language\n     versions are sent at the same time, and when one\n     language version is sent first and the translations\n     are sent later.\n\n(4) It should cater for sending a message to a human\n     or machine for translation, with information on\n     where to forward it after translation.\n\n(5) It should cater for people to indicate that they\n     can read more than one language, and to indicate\n     preferences, like in HTTP where you can specify\n     Accept-Language: da, en-gb;q=0.8, en;q=0.7.\n     It should users to specify that they want\n     for example the original language for French\n     and English, and that they prefer a German\n     original to a machine-translation to English,\n     but prefer the English translation if it was\n     made by a human.\n\n(6) It should gracefully degrade its functionality\n     to old mailers not using the standard.\n\nAny comments on these requirements? Anything missing?\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12655672"}, {"subject": "RE: MOVE on Version History Members of a Working Collectio", "content": "   From: Zivkov, Sasa [mailto:sasa.zivkov@sap.com]\n\n   > You will actually have one VCR, with two bindings to it (i.e. one from\n   > mycoll/a.txt and another from mycoll2/a.txt).  This is required by\n   > workspace semantics, which says that there can only be one VCR in a\n   > workspace for a given version history, but you can have multiple\n   > bindings in that workspace to that VCR.\n\n   I always thought that there can be only one URL in a workspace for\n   one VCR :-(\n\nNo, it is inherent in namespace versioning that you can encounter\nmultiple URL's for the same VCR (in particular, whenever you move,\nand then restore the old version of the origin collection, you will\nalways end up with two collections containing the same VCR.\n\n   So, there is not *the* URL of a VCR in a workspace ?\n\nNo, a VCR can have multiple URL's in a workspace that map to it.\n\n   In the example above if both URL's mycoll/a.txt and mycoll2/a.txt are\n   the same VCR then they must share the same set of live/dead properties\n   and content.\n   Right ?\n\nSame content, dead properties, and RFC3253 live properties, yes.  For\nother live properties, you cannot say (since the semantics of live\nproperties is unconstrained).\n\n   And if I DELETE mycoll/a.txt is the VCR deleted also ?\n\nDELETE removes just the specified binding to a resource,\nunless there are some extra semantics defined for a DELETE\nof that kind of rsource.  If that is the last binding\nto a resource, it becomes inaccessible (through the protocol).\n\n   Or does the server do the reference counting and deletes the VCR when\n   the last binding to it is deleted ?\n\nWhether or not the resource is \"destroyed\" or \"obliterated\" as a\nresult is server dependent.  In particular, there may be other protocols\nthat still provide access to the state of that resource.\n\n   Also if we take a look on a part of rfc3253:\n\n       14.4 Additional DELETE Semantics\n\n Additional Preconditions:\n\n     (DAV:cannot-modify-checked-in-parent): If the request-URL\n     identifies a version-controlled resource, the DELETE MUST fail\n     when the collection containing the version-controlled resource\nis\n     a checked-in version-controlled collection, unless DAV:auto-\n     version semantics will automatically check out the version-\n     controlled collection.\n\n   So, here you mention *the* collection containing the VCR.\n   But in the example above which collection is *the* collection containing\n   the VCR mycoll or mycoll2 ?\n\nYou can talk about \"the\" collection in the context of a particular URL\n(as in the case cited above, where there is a request-URL).  In\nparticular \"the\" collection of a resource wrt a particular URL is the\ncollection identified by the URL formed by stripping off the last\nsegment of the URL.  That is the collection whose state will be modified\nby the DELETE (since the bindings are part of the state of the collection).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1266082"}, {"subject": "transfer protoco", "content": "i have been thinking about an xml based transfer and control protocol for\nfuture applications.  it would serve some of the same functionality as HTTP,\nbut would be much more flexible and could perform operations other than just\nsimple file transfer.  the main focus here is that it would be a general\nprotocol using xml, and could be extended by all sorts of applications for\ncommunication.  is there already a working group to develop such a protocol,\nand if not, would there be any interest in one?\n\nlet me know what you think.\n\nbartram nason\nbnason@indiana.edu\n\n\n\n", "id": "lists-007-12663469"}, {"subject": "RE: transfer protoco", "content": "http://www.w3.org/TR/SOAP/\n\n-----Original Message-----\nFrom: bart on the run [mailto:bnason@indiana.edu]\nSent: Monday, November 13, 2000 6:19 PM\nTo: discuss@apps.ietf.org\nSubject: transfer protocol\n\n\ni have been thinking about an xml based transfer and control protocol\nfor future applications.  it would serve some of the same functionality\nas HTTP, but would be much more flexible and could perform operations\nother than just simple file transfer.  the main focus here is that it\nwould be a general protocol using xml, and could be extended by all\nsorts of applications for communication.  is there already a working\ngroup to develop such a protocol, and if not, would there be any\ninterest in one?\n\nlet me know what you think.\n\nbartram nason\nbnason@indiana.edu\n\n\n\n", "id": "lists-007-12671290"}, {"subject": "RE: transfer protoco", "content": "Bart,\n\nLook at the SOAP project in the W3C.\n\nIt was proposed in the IETF about a year ago but fell as a lead balloon; now\nit has showed up in the W3C instead.\n\nCarl-Uno\n\nCarl-Uno Manros\nManager, Print Services\nXerox Architecture Center - Xerox Corporation\n701 S. Aviation Blvd., El Segundo, CA, M/S: ESAE-231\nPhone +1-310-333 8273, Fax +1-310-333 5514\nEmail: manros@cp10.es.xerox.com \n\n\n-----Original Message-----\nFrom: bart on the run [mailto:bnason@indiana.edu]\nSent: Monday, November 13, 2000 6:19 PM\nTo: discuss@apps.ietf.org\nSubject: transfer protocol\n\n\ni have been thinking about an xml based transfer and control protocol for\nfuture applications.  it would serve some of the same functionality as HTTP,\nbut would be much more flexible and could perform operations other than just\nsimple file transfer.  the main focus here is that it would be a general\nprotocol using xml, and could be extended by all sorts of applications for\ncommunication.  is there already a working group to develop such a protocol,\nand if not, would there be any interest in one?\n\nlet me know what you think.\n\nbartram nason\nbnason@indiana.edu\n\n\n\n", "id": "lists-007-12680214"}, {"subject": "RE: transfer protoco", "content": "> Look at the SOAP project in the W3C.\n\n> It was proposed in the IETF about a year ago but fell as a lead balloon; now\n> it has showed up in the W3C instead.\n\nSOAP may have been a lead balloon, but BEEP certainly is anything but.\nSee http://www.ietf.org/html.charters/beep-charter.html for details of\nwhat the IETF is doing in this general area.\n\nNed\n\n\n\n", "id": "lists-007-12689913"}, {"subject": "RE: transfer protoco", "content": "> Look at the SOAP project in the W3C.\n>\n> It was proposed in the IETF about a year ago but fell as a lead balloon; now\n> it has showed up in the W3C instead.\n\nArguably a quality issue for the W3C's Architecture participants, and the\nsubject of heady enthusiasms in the marketing arms of the XML communities.\n\nCheers,\nEric\n\n\n\n", "id": "lists-007-12697572"}, {"subject": "Re: transfer protoco", "content": "There's also XP, which has similar buoyancy issues.\n\nhttp://www.thinlink.com/xp\n\n\n\n\"Manros, Carl-Uno B\" wrote:\n\n> Bart,\n>\n> Look at the SOAP project in the W3C.\n>\n> It was proposed in the IETF about a year ago but fell as a lead balloon; now\n> it has showed up in the W3C instead.\n>\n> Carl-Uno\n\n\n\n", "id": "lists-007-12704373"}, {"subject": "Language translation in e-mai", "content": "My proposal for translation in e-mail standards is now ready,\nyou can find it at http://dsv.su.se/jpalme/ietf/jp-ietf-home.html#translation\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12711828"}, {"subject": "3GPP-T-WG3 codec", "content": "I need people interested in the are of codecs. Can someone help with \nthe following request?\n\nLet me know if you are interested (or know someone which are interested).\n\n    Patrik\n    Co-Area Director, Applications Area\n\n\n\nDate: Wednesday, 29 November, 2000 15:06 -0800\nFrom: \"Leuca, Ileana\" <ileana.leuca@attws.com>\nTo: \"'sob@harvard.edu'\" <sob@harvard.edu>\nSubject: 3GPP-T-WG3 codecs\n\n\n\nScott,\n\nthe 3GPP-T2-WG3 defines the minimum set of supported formats for\nMultimedia Messaging Services.\n\nPlease help to find an IETF person(s) to be included in the\nprocess of standardizing the minimum set of codex for audio,\nvideo and image types.\n\nIn summary the following text is proposed today:\n==========================================\nMultiple media elements shall be combined into a composite\nsingle MM using MIME multipart format as defined in RFC 2046\n[x]. The media type of a single MM element shall be identified\nby its appropriate MIME type whereas the media format shall be\nindicated by its appropriate MIME subtype.\n\nIn order to guarantee a minimum support and compatibility\nbetween multimedia messaging capable terminals, the following\nmedia formats shall be at least supported.\n\nSuggested formats or codecs for media type Audio:\n- AMR / EFR; organised in octet format as specified in 3G TS\n26.101 and 3G TS 26.101\n- MP3\n- MIDI\n- WAV\n\nSuggested formats or codecs for media type Image:\n- JPEG\n- GIF 89a .\n\nSuggested formats or codecs for media type Video:\n- MPEG 4 (Visual Simple Profile, Level 1)\n- ITU-T H.263\n- Quicktime\n\nMinimum set of supported media shall support type Text formats.\nAny character encoding (charset) that contains a subset of the\nlogical characters in Unicode [7] shall be used (e.g. US-ASCII\n[8], ISO-8859-1[9], UTF-8[10], Shift_JIS, etc.).\nUnrecognised subtypes of \"text\" shall be treated as subtype\n\"plain\" as long as the MIME implementation knows how to handle\nthe charset. Any other unrecognised subtype and unrecognised\ncharset shall be treated as \"application/octet - stream\".\n\n\n================================================================\n============ ==\nthanks,\nileana\n\n-- \n\n\n\n", "id": "lists-007-12719572"}, {"subject": "RE: 3GPP-T-WG3 codec", "content": "Patrik,\n\nI would suggest that the members of the VPIM WG have interest in this and\nmay be interested in this process (I can say that I am).  I think the point\nof this is to define a minimum set of codecs for multimedia messaging for\n3G.  We have been doing the same for unified messaging in VPIM & IVM (though\nwe have just been talking about voice and fax).  It is interesting to note\nthat with IVM we originally had support for numerous codecs suggested as the\nbaseline, but after discussion we reduced it to one.\n\nI am intrigued that they list the WAV header format as baseline but do not\nidentify any of its 300+ codecs.  \n\nI am not surprised they want to use their AMR/EFR codec -- but I'd like to\nknow how different it is from GSM 6.10 (of which a variant is the current\nproposed baseline for IVM).  I believe AMR/EFR for 3G is the same as GSM\n6.90.  And, of course, this is different from the North American wireless\ncodecs :-(\n\nI am curious why they don't list G.711 mu-law as one of the audio codecs.\nIt would seem that if we are getting into transcoding, that one would want\nto list the lowest common denominator.   \n\nCheers,\nGlenn.\n\n> ----------\n> From: Patrik F?ltstr?m\n> Sent: Thursday, November 30, 2000 12:58 pm\n> To: discuss@apps.ietf.org\n> Subject: 3GPP-T-WG3 codecs\n> \n> I need people interested in the are of codecs. Can someone help with \n> the following request?\n> \n> Let me know if you are interested (or know someone which are interested).\n> \n>     Patrik\n>     Co-Area Director, Applications Area\n> \n> \n> \n> Date: Wednesday, 29 November, 2000 15:06 -0800\n> From: \"Leuca, Ileana\" <ileana.leuca@attws.com>\n> To: \"'sob@harvard.edu'\" <sob@harvard.edu>\n> Subject: 3GPP-T-WG3 codecs\n> \n> \n> \n> Scott,\n> \n> the 3GPP-T2-WG3 defines the minimum set of supported formats for\n> Multimedia Messaging Services.\n> \n> Please help to find an IETF person(s) to be included in the\n> process of standardizing the minimum set of codex for audio,\n> video and image types.\n> \n> In summary the following text is proposed today:\n> ==========================================\n> Multiple media elements shall be combined into a composite\n> single MM using MIME multipart format as defined in RFC 2046\n> [x]. The media type of a single MM element shall be identified\n> by its appropriate MIME type whereas the media format shall be\n> indicated by its appropriate MIME subtype.\n> \n> In order to guarantee a minimum support and compatibility\n> between multimedia messaging capable terminals, the following\n> media formats shall be at least supported.\n> \n> Suggested formats or codecs for media type Audio:\n> - AMR / EFR; organised in octet format as specified in 3G TS\n> 26.101 and 3G TS 26.101\n> - MP3\n> - MIDI\n> - WAV\n> \n> Suggested formats or codecs for media type Image:\n> - JPEG\n> - GIF 89a .\n> \n> Suggested formats or codecs for media type Video:\n> - MPEG 4 (Visual Simple Profile, Level 1)\n> - ITU-T H.263\n> - Quicktime\n> \n> Minimum set of supported media shall support type Text formats.\n> Any character encoding (charset) that contains a subset of the\n> logical characters in Unicode [7] shall be used (e.g. US-ASCII\n> [8], ISO-8859-1[9], UTF-8[10], Shift_JIS, etc.).\n> Unrecognised subtypes of \"text\" shall be treated as subtype\n> \"plain\" as long as the MIME implementation knows how to handle\n> the charset. Any other unrecognised subtype and unrecognised\n> charset shall be treated as \"application/octet - stream\".\n> \n> \n> ================================================================\n> ============ ==\n> thanks,\n> ileana\n> \n> -- \n> \n> \n\n\n\n", "id": "lists-007-12729076"}, {"subject": "RE: 3GPP-T-WG3 codec", "content": "At 13.16 -0600 00-11-30, Glenn Parsons wrote:\n>I would suggest that the members of the VPIM WG have interest in \n>this and may be interested in this process (I can say that I am).\n\nGood. Can you please contact the people (you saw the addresses) and \nsay that they should activate themselves in the VPIM wg? And, I think \nyou should appoint individuals in your wg which actively be \n(informal) liasons between VPIM and this effort, which have as a task \nto try to globally minimize the number of codecs.\n\n    paf\n\n\n-- \n\n\n\n", "id": "lists-007-12741658"}, {"subject": "CHECKOUT VCR with Label: header and DAV:auto-updat", "content": "Hello,\n\nit is not specified (neither 8.8 nor 9.3) that checking-out a VCR with\nLabel: header is similar to checking-out a VCR with the DAV:apply-to-version\nflag with respect to setting the DAV:auto-update property in the resulting\nWR.\n\nIt it just missing or is there any reason for not being similar?\n\nThanks,\nPeter\n\n\n\n", "id": "lists-007-1276473"}, {"subject": "cable service", "content": "> > NOTE: THIS IS AN ADVERTISEMENT FOR LEGAL TV\n> > DE-SCRAMBLER.  IF YOU HAVE NO INTEREST IN THIS\n> > INFORMATION PLEASE CLICK DELETE NOW. THANK YOU--\n> >\n> > LEGAL CABLE TV DE-SCRAMBLER\n> > Want to watch Sporting Events?--Movies?--Pay-Per-View??\n> > You can assemble from electronic store parts for about $12.00.\n> > We Send You:\n> > E-Z To follow Assembly Instructions.\n> > E-Z To read Original Drawings.\n> > Electronic parts lists.\n> > PLUS SOMETHING NEW YOU MUST HAVE!\n> > Something you can't do without.\n> > THE UP-TO-DATE REPORT: USING A DESCRAMBLER LEGALLY\n> > Warning: You should not build a TV Descrambler without\n> > reading this report first.\n> > Frequently Asked Questions--CABLE TV DESCRAMBLER\n> > Q: Will the descrambler work on Fiber, TCI, Jarrod\n> > A: The answer is YES.\n> > Q: Do I need a converter box?\n> > A: This plan works with or without a converter box.\n> > Specific instructions are included in the plans for each!\n> > Q: Can the cable company detect that I have the descrambler?\n> > A: No, the signal descrambles right at the box and does\n> > not move back through the line!\n> > Q: Do I have to alter my existing cable system,\n> > television or VCR?\n> > A: The answer is no!\n> > Q: Does this work with my remote control?\n> > A: The answer is yes. The descrambler is\n> > manually controlled--but very easy to use!\n> > Q: Can you email me the plans?\n> > A: No the program comes with an easy to follow picture guide.\n> > Q: Does this work everywhere across the country?\n> > A: Yes, every where in the USA plus England,\n> > Brazil, Canada and other countries!\n> > Q: Is this deal guaranteed?\n> > A: Yes, if you are unhappy for any reason we will refund your money.\n> > Q: When I order, when will I get my stuff?\n> > A: We mail out all orders within 48 hours of receiving them.\n> > ORDER INFORMATION\n> > ACT WITHIN THE NEXT 14 DAYS AND RECEIVE TWO FREE BONUS!!\n> > THE CABLE MANUAL! This manual contains hard to find information your\n> > cable company does not want you to know. Also receive The RADAR\n> > JAMMER PLANS! Never get another speeding ticket. Build you own\n> > radar jammer, this unit will jam police radar so they can't get a\nreading\n> on\n> > your vechicle. Radar jammers are legal in 48 states. It is simple to\n> build.\n> > The FREE BONUSES ALONE ARE WORTH ACTING NOW!\n> > THE CABLE DESCRAMBLER KIT COMES WITH A THIRTY DAY\n> > MONEY BACK GUARANTEE! IF YOUR NOT COMPLETELY SATISFIED,\n> > SEND THE CABLE DESCRAMBLER KIT BACK AND YOU KEEP\n> > THE BONUSES FOR FREE. YOU HAVE NOTHING TO LOSE\n> > ONLY FREE CABLE TV TO GAIN! ACT NOW! SIMPLY SEND\n> > $14.00 CHECK OR, MONEY ORDER.\n> > INFORMATION TO:\n> >\n> > NET SERVICES\n> > PO BOX 42013\n> > URBANDALE, IA 50322\n> >\n> > \n> >\n> > THIS INFORMATION IS SOLD FOR EDUCATIONAL PURPOSES ONLY!\n> > This mailing is done by an independent marketing co.\n> > We apologize if this message has reached you in error.\n> > Save the Planet, Save the Trees! Advertise\n> > via E mail. No wasted paper! Delete with\n> > one simple keystroke! Less refuse in our Dumps!\n> > This is the new way of new millenium!\n> >  If you would like to be removed move233@dcemail.com\n>\n>\n>\n\n\n\n", "id": "lists-007-12774279"}, {"subject": "How does DNS wor", "content": "There is one thing about DNS that I do not understand.\nCan anyone explain it to me.\n\nI have registered the domain name kom2000.nu at the\nregistrar for the \"nu\" domain. I have then added\nreferences from kom2000.nu to the host we are using\nfor this service, into the DNS servers at my university\ndepartment and at Stockholm University.\n\nI can easily understand that someone looking for\n\"kom2000.nu\" will first turn to his local DNS server.\nIf this server does not contain the information,\nit is easy for me to understand that the request\nis forwarded to the DNS server for the \"nu\" domain.\n\nBut the information for \"kom2000.nu\" is *not* stored\nin the \"nu\" domain DNS server, it is stored in the\n\"su.se\" and \"dsv.su.se\" DNS servers.\n\nSuppose someone somewhere far away looks for \"kom2000.nu\".\nHow can his name server know that this information\nis available from the \"su.se\"? There is nothing\nin the name \"kom2000.nu\" that tells you to look\nat that particular DNS server?\n\nThe only solution I can guess at on how it works,\nis that there are some central DNS servers which\naccumulate all DNS entries from all the world into\nlarge central data bases. Is this how it works?\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12783194"}, {"subject": "Re: How does DNS wor", "content": "At 11:54 09/10/2000 +0200, Jacob Palme wrote:\n>Suppose someone somewhere far away looks for \"kom2000.nu\".\n>How can his name server know that this information\n>is available from the \"su.se\"? There is nothing\n>in the name \"kom2000.nu\" that tells you to look\n>at that particular DNS server?\n\nthe root servers tell him that the following servers serve the .nu domain:\n\n;; ANSWER SECTION:\nnu.                     5h15m48s IN NS  NZ.NS.NIC.nu.\nnu.                     5h15m48s IN NS  NS0.TELIA.NIC.nu.\nnu.                     5h15m48s IN NS  NS0.DE.NIC.nu.\nnu.                     5h15m48s IN NS  NS.NIC.nu.\n\n(they will also inform the querier about the IP addresses of those machines).\nany of these servers tell him that the following servers serve the \nkom2000.nu domain:\n\nkom2000.nu.             1D IN NS        ns.su.se.\nkom2000.nu.             1D IN NS        ns2.su.se.\n\nIf you are interested in the details, I recommend RFC 1034/1035, or the \nO'Reilly DNS books.\n\n\n--\nHarald Tveit Alvestrand, alvestrand@cisco.com\n+47 41 44 29 94\nPersonal email: Harald@Alvestrand.no\n\n\n\n", "id": "lists-007-12791352"}, {"subject": "FREE! Get A Great Price On A New Car!                                              (11af5d23", "content": "Get A Great Price On A New Car!\n\nAbsolutely Free!\n\nWant to save time and money? \n\nWant to have quick access to car quotes?\n\nWant to have all makes and models available to you?\n\nIf you answered yes to any of these, then take advantage of this free, no-hassle service. Simply click on the link below to get low prices on all makes and models of new and used cars, without having to negotiate with a dealer. It?s painless and stress-free!\n\n\n\nCLICK-HERE-->  http://3627528622/  <--CLICK-HERE\n\n************************************************** \nIf you wish to unsubscribe from this list, simply\ngo to http://3627528622/remove.html and follow\nthe instructions. You will be removed immediately.\nPLEASE NOTE: replying to this message will not \nremove you, you MUST follow the link above. \nThank you.\n************************************************** \n\n\n\n", "id": "lists-007-12799637"}, {"subject": "Testing application programs protocol", "content": "When trying out different TCP-based application programs,\nI have found that a piece of software named OTSessionWatcher\nis very useful. This software logs every character sent\nand received through all TCP connections on my Macintosh\nonto files, so that I can see exactly what is actually\ntransferred by different clients and servers.\n\nDoes anyone know if a similar piece of software exists\nfor Windows 98, Windows NT and Windows 2000 computers.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12807638"}, {"subject": "RE: Testing application programs protocol", "content": "Yes, Carnivore.  It is not what we could call open source.  (See below).\n\n- dan\n--\nDan Kohn <mailto:dan@dankohn.com>\n<http://www.dankohn.com>  <tel:+1-650-327-2600>\n\n\n------- Forwarded Message\n\nDate: Tue, 24 Oct 2000 23:56:30 -0400\nTo: politech@politechbot.com\nFrom: Declan McCullagh <declan@well.com>\nSubject: FC: FBI agent reportedly gives public demo of Carnivore\nCc: mthomas@fbi.gov\nReply-To: declan@well.com\nX-URL: Politech is at http://www.politechbot.com/\n\n[NANOG is the North American Network Operators Group; their most recent \nmeeting was October 22 through October 24. --Declan]\n\n********\n\nDate: Tue, 24 Oct 2000 19:31:43 -0400\nFrom: An Metet <anmetet@mixmaster.shinn.net>\nComments: This message did not originate from the Sender address above.\nIt was remailed automatically by anonymizing remailer software.\nPlease report problems or inappropriate use to the\nremailer administrator at <abuse@mixmaster.shinn.net>.\nTo: cypherpunks@einstein.ssz.com\nSubject: CDR: Public Demo of Carnivore and Friends\n\nFBI agent Marcus C. Thomas (who is mentioned in the EPIC FOIA documents)\nmade a very interesting presentation at NANOG 20 yesterday morning,\ndiscussing Carnivore.\n\nAgent Thomas gave a demonstration of both Carnivore 1.34 (the currently\ndeployed version) and Carnivore 2.0 (the development version) as well as\nsome of the other DragonWare tools.\n\nMost of this information isn't new, but it demonstrates that the\nDragonWare tools can be used to massively analyze all network traffic\naccessible to a Carnivore box.\n\nThe configuration screen of Carnivore shows that protocol information can\nbe captured in 3 different modes: Full, Pen, and None. There are check\nboxes for TCP, UDP, and ICMP.\n\nCarnivore can be used to capture all data sent to or from a given IP\naddress, or range of IP addresses.\n\nIt can be used to search on information in the traffic, doing matching\nagainst text entered in the \"Data Text Strings\" box. This, the agent\nassured us, was so that web mail could be identified and captured, but\nother browsing could be excluded.\n\nIt can be used to automatically capture telnet, pop3, and FTP logins with\nthe click of a check box.\n\nIt can monitor mail to and/or from specific email addresses.\n\nIt can be configured to monitor based on IP address, RADIUS username, MAC\naddress, or network adaptor.\n\nIPs can be manually added to a running Carnivore session for monitoring.\n\nCarnivore allows for monitoring of specific TCP or UDP ports and port\nranges (with drop down boxes for the most common protocols).\n\nCarnivore 2.0 is much the same, but the configuration menu is cleaner, and\nit allows Boolean statements for exclusion filter creation.\n\n- --\n\nThe Packeteer program takes raw network traffic dumps, reconstructs the\npackets, and writes them to browsable files.\n\nCoolMiner is the post-processor session browser. The demo was version\n1.2SP4. CoolMiner has the ability to replay a victim's steps while web\nbrowsing, chatting on ICQ, Yahoo Messenger, AIM, IRC. It can step through\ntelnet sessions, AOL account usage, and Netmeeting. It can display\ninformation sent to a network printer. It can process netbios data.\n\nCoolMiner displays summary usage, broken down by origination and\ndestination IP addresses, which can be selectively viewed.\n\nCarnivore usually runs on Windows NT Workstation, but could run on Windows\n2000.\n\nSome choice quotes from Agent Thomas:\n\n\"Non-relevant data is sealed from disclosure.\"\n\n\"Carnivore has no active interaction with any devices on the network.\"\n\n\"In most cases Carnivore is only used with a Title III. The FBI will\ndeploy Carnivore without a warrant in cases where the victim is willing to\nallow a Carnivore box to monitor his communication.\"\n\n\"We rely on the ISP's security [for the security of the Carnivore box].\"\n\n\"We aren't concerned about the ISP's security.\"\n\nWhen asked how Carnivore boxes were protected from attack, he said that\nthe only way they were accessible was through dialup or ISDN. \"We could\ntake measures all the way up to encryption if we thought it was\nnecessary.\"\n\nWhile it doesn't appear that Carnivore uses a dial-back system to prevent\nunauthorized access, Thomas mentioned that the FBI sometimes \"uses a\nfirmware device to prevent unauthorized calls.\"\n\nWhen asked to address the concerns that FBI agents could modify Carnivore\ndata to plant evidence, Thomas reported that Carnivore logs FBI agents'\naccess attempts. The FBI agent access logs for the Carnivore box become\npart of the court records. When asked the question \"It's often common\npractice to write back doors into [software programs]. How do we know you\naren't doing that?\", Thomas replied \"I agree 100%. You're absolutely\nright.\"\n\nWhen asked why the FBI would not release source, he said: \"We don't sell\nguns, even though we have them.\"\n\nWhen asked: \"What do you do in cases where the subject is using\nencryption?\" Thomas replied, \"This suite of devices can't handle that.\" I\nguess they hand it off to the NSA.\n\nHe further stated that about 10% of the FBI's Carnivore cases are thwarted\nby the use of encryption, and that it is \"more common to find encryption\nwhen we seize static data, such as on hard drives.\"\n\n80% of Carnivore cases have involved national security.\n\n- --\n\nAlso of interest was a network diagram that looked very similar to the one\nin the EPIC FOIA document at\nhttp://www.epic.org/privacy/carnivore/omnivorecapabilities1.html , except\nthat there was no redaction of captions.\n\n- --\n\nMarcus Thomas can be contacted for questions at mthomas@fbi.gov or at\n(730) 632-6091. He is \"usually at his desk.\"\n\n\n\n\n- -------------------------------------------------------------------------\nPOLITECH -- the moderated mailing list of politics and technology\nYou may redistribute this message freely if it remains intact.\nTo subscribe, visit http://www.politechbot.com/info/subscribe.html\nThis message is archived at http://www.politechbot.com/\n- -------------------------------------------------------------------------\n\n\n------- End of Forwarded Message\n\n\n\n\n\n-----Original Message-----\nFrom: Jacob Palme [mailto:jpalme@dsv.su.se]\nSent: Thursday, 2000-10-26 01:53\nTo: discuss@apps.ietf.org\nSubject: Testing application programs protocols\n\n\nWhen trying out different TCP-based application programs,\nI have found that a piece of software named OTSessionWatcher\nis very useful. This software logs every character sent\nand received through all TCP connections on my Macintosh\nonto files, so that I can see exactly what is actually\ntransferred by different clients and servers.\n\nDoes anyone know if a similar piece of software exists\nfor Windows 98, Windows NT and Windows 2000 computers.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-12815333"}, {"subject": "Documentation Specialist Seeking Contract Wor", "content": "Documentation Specialists Seeking Contract Work - Technical Writing, \nEditing,Graphics, Robohelp, HTML, SGML, etc. \n\nSenior technical writers, senior editors, project leaders and electronic documentation \nspecialists seek contract work. Clients have included companies such \nas Microsoft and Koch Petroleum. Excellent communication skills, able \nto work with all levels of the company from programmers to CEO.  \nExcellent background in technical, marketing and creative writing.\nFamiliar with educational material as well as e-commerce.  \nWriting samples, full resume and references available on request.\n\nExperience in creating both published and online documentation.\n\nREQUIRED:\nPrefer Corp to Corp Sole relationship directly with the client. \nAgents are also welcome in the same capacity.\n\nProduction is done at our facility.  We are fully equipped. \n\nPLEASE REPLY ONLY BY PHONE\nContact - Casey Lea or Domhnall CGN Adams, CS - \n\nTO INQUIRE ABOUT SERVICES, AVAILABILITY, OR TO CONFIRM REMOVAL FROM OUR LIST \nCALL 780-998-4066 PST\n\nRates: Fees are charged by the hour or by the project.  \n_________________________________________________________\nThis Message was Composed by a user of Extractor Pro '98 Bulk E- Mail Software. If \nyou wish to be removed from this advertiser's future mailings, please reply \nwith the subject \"Remove\" and this software will automatically block you \nfrom their future mailings.\n\n\n\n", "id": "lists-007-12832842"}, {"subject": "RE: CHECKOUT VCR with Label: header and DAV:auto-updat", "content": "This is done just for regularity (i.e. the semantics of the Label\nheader are that the method is applied to the version selected by\nthat label).\n\nIf a client wants DAV:auto-update behavior, it would have to first\nUPDATE the VCR to be the desired version, and then CHECKOUT the VCR\nwith the DAV:apply-to-version flag).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Nevermann, Dr., Peter [mailto:Peter.Nevermann@softwareag.com]\nSent: Thursday, June 06, 2002 7:47 AM\nTo: ietf-dav-versioning@w3.org\nSubject: CHECKOUT VCR with Label: header and DAV:auto-update\n\n\n\nHello,\n\nit is not specified (neither 8.8 nor 9.3) that checking-out a VCR with\nLabel: header is similar to checking-out a VCR with the DAV:apply-to-version\nflag with respect to setting the DAV:auto-update property in the resulting\nWR.\n\nIt it just missing or is there any reason for not being similar?\n\nThanks,\nPeter\n\n\n\n", "id": "lists-007-1284228"}, {"subject": "Concurso Flamenc", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-12864675"}, {"subject": "Noticias de actualida", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-12870613"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "If there has been no charter proposed for a MMMS working group, I \nintend to propose one as follows.  I would like to know how the \nArea Directors feel about the following ideas, many of which are \ninformed by the comments of Patrik, Ned, and others in the Apps \nDiscussion archives -- http://wilma.cs.utk.edu/mail-archive/discuss.1999-12\n\nProposed MMMS working group purpose:  The MMMS working group will \nproduce a series of Internet-Drafts, and attempt to produce RFCs, \ndescribing the use of end-to-end Internet multimedia messaging and \nrelated services on mobile devices.  The specifications will concern \napplication-level services as well as general end-to-end Internet \nservice specifications and lower-level services such as non-wireless \nserial PPP access from mobile devices.  No new protocols will be \ncreated; only existing open Internet standards and protocols free from\nany intellectual property encumbrance will be incorporated into MMMS \nspecifications, along with specific implementation interoperability \nguidelines.\n\nProposed special document status and process for MMMS specifications:  \nRecognizing that it may be impossible to achieve consensus on topics \nin which large and diverse corporate concerns have vested interests \nopposed to open standards, the MMMS working group will have a special \ngoal to produce Internet-Drafts which will identified as \"Frozen MMMS \nRFC-track Internet-Drafts.\"  These documents might never become RFCs \nbecause of an expected lack of consensus, but upon identification as \nsuch by the Working Group, they will be announced and archived as \nfrozen documents.  Developers may rely on such documents as static \nand vendors and customers will be encouraged to refer to them in their \nprocurement process.  The level of consensus required to designate \nFrozen MMMS RFC-track Internet-Drafts will be a simple majority of \nthose working group participants who are not affiliated with \norganizations having direct or indirect financial interests in \nclosed-protocol mobile services.  Any member of the working group not \naffiliated with organizations having direct or indirect financial \ninterests in closed-protocol mobile services may call a vote on the \ndesignation of any Internet-Draft as a Frozen MMMS RFC-track \nInternet-Draft, and if after one week's time there are more such MMMS \nWG participants in favor than dissenting, the WG Chair, the author of \nthe draft, or the participant calling the vote will then take steps to \nestablish a permanent archive of the draft and publish an announcement \nof its availability to the IETF community.  Anyone affiliated with \norganizations having direct or indirect financial interests in \nclosed-protocol mobile services may not call a vote or vote on such \nspecial designation, but all participants will have normal consensus \nrights in the traditional RFC process, and all Internet-Drafts must \nfollow the existing IESG intellectual property disclosure process.  \n\nProposed milestones:  The goals of the MMMS WG will include the \npublication of specifications, as described above, on the following \ntopics:  interoperable end-to-end Internet service access on mobile \ndevices, including descriptions of existing end-to-end wireless \nInternet service arrangements; implementation guidelines for multimedia \nmessaging services on mobile devices using existing Internet messaging \nstandards; guidelines concerning performance implications of link \nconstraints, including TCP behaviors during extended periods of \nwireless link downtime; and wired PPP access from mobile Internet \ndevices.\n\nJim Mathis:  Would you be interested in chairing a MMMS working group \ncharted as described above?  Would your organization's current apparent \ncommitment to closed-protocol mobile messaging solutions make you an \ninappropriate chair for such a group?  If you would not want to, or do \nnot feel you would be an appropriate chair, I would volunteer to serve \nas an interim chair.\n\nCheers,\nJames\n\n> At the November meeting, about 90 people attended the Mobile \n> Multimedia Messaging Service BOF:\n>\n>  http://www.ietf.org/proceedings/99nov/46th-99nov-ietf-42.html\n> \n> But the mailing list has been dead:\n>\n>  http://www.imc.org/ietf-mmms/mail-archive/threads.html\n>\n> MMMS-related topics seem to be fairly prevalent on the general \n> IETF discussion list, with a lot of general agreement that the \n> status quo has some real problems.\n> \n> Has anyone started on a working group charter?\n> \n> There needs to be an organized effort to provide explicit and \n> well-documented alternatives to the closed-protocol, \n> pseudo-internet mobile access consortia, who are a real barrier \n> to easy and reasonable mobile multimedia messaging services.  \n> I for one would certainly contribute a great deal of time and \n> effort to the success of such a working group.\n\n\n\n", "id": "lists-007-12876906"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "At 14.52 -0700 00-09-15, James P. Salsman wrote:\n>If there has been no charter proposed for a MMMS working group, I\n>intend to propose one as follows.\n\nI have no memory of a charter.\n\n>Proposed milestones:  The goals of the MMMS WG will include the\n>publication of specifications, as described above, on the following\n>topics:  interoperable end-to-end Internet service access on mobile\n>devices, including descriptions of existing end-to-end wireless\n>Internet service arrangements; implementation guidelines for multimedia\n>messaging services on mobile devices using existing Internet messaging\n>standards; guidelines concerning performance implications of link\n>constraints, including TCP behaviors during extended periods of\n>wireless link downtime; and wired PPP access from mobile Internet\n>devices.\n\nThis is too open-ended. I want a more specific list of documents that \nyou are to create, and the list of issues you are to discuss should \nalso say what is _NOT_ in scope of the wg.\n\nMy personal interest is not so much in multimedia, but in a \ndiscussion on how one should design an application layer protocol \n(and maybe \"how should one use existing protocols, like IMAP\") so it \nworks for \"mobile\" clients.\n\nYou should by the way define a \"mobile client\"...\n\nI felt the discussion at the BOF ended up with \"a client which have \nvery limited bandwidth to the network, often connected to many \ndifferent internet providers, limited memory and screen\", or \nsomething like that.\n\n   paf\n\n\n\n", "id": "lists-007-12890420"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "patrik,\n\nwould it be useful, in the context of establishing peer-to-peer communications\n(or even client/server communications) with limited-function mobile devices,\nto use SIP as a framework for negotiating the parameters that should guide the\nnature of the exchange? I'm thinking, for instance, of a web server that may\nusefully discover the functional limits of a mobile before it starts to send\ncontent to that device. The mobile uses SIP to report to the server that it\nhas X amount of memory, Y amount of display area, color or not, average \ndata rate it can send or receive, and so on. This information would be used\nby the server to configure what it sends to be compatible with the receiving\nunit.\n\nperhaps this is an idea that is already being pursued in an IETF working group?\n\nVint\n\nAt 09:35 AM 9/16/2000 +0200, Patrik F?ltstr?m wrote:\n>At 14.52 -0700 00-09-15, James P. Salsman wrote:\n>>If there has been no charter proposed for a MMMS working group, I\n>>intend to propose one as follows.\n>\n>I have no memory of a charter.\n>\n>>Proposed milestones:  The goals of the MMMS WG will include the\n>>publication of specifications, as described above, on the following\n>>topics:  interoperable end-to-end Internet service access on mobile\n>>devices, including descriptions of existing end-to-end wireless\n>>Internet service arrangements; implementation guidelines for multimedia\n>>messaging services on mobile devices using existing Internet messaging\n>>standards; guidelines concerning performance implications of link\n>>constraints, including TCP behaviors during extended periods of\n>>wireless link downtime; and wired PPP access from mobile Internet\n>>devices.\n>\n>This is too open-ended. I want a more specific list of documents that you are to create, and the list of issues you are to discuss should also say what is _NOT_ in scope of the wg.\n>\n>My personal interest is not so much in multimedia, but in a discussion on how one should design an application layer protocol (and maybe \"how should one use existing protocols, like IMAP\") so it works for \"mobile\" clients.\n>\n>You should by the way define a \"mobile client\"...\n>\n>I felt the discussion at the BOF ended up with \"a client which have very limited bandwidth to the network, often connected to many different internet providers, limited memory and screen\", or something like that.\n>\n>  paf\n\n\n\n", "id": "lists-007-12900330"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "At 08.12 -0400 00-09-16, vint cerf wrote:\n>would it be useful, in the context of establishing peer-to-peer communications\n>(or even client/server communications) with limited-function mobile devices,\n>to use SIP as a framework for negotiating the parameters that should guide the\n>nature of the exchange?\n\nMaybe. The rescap wg is looking into \"capabilies\" in a different way \n(I presume).\n\n>I'm thinking, for instance, of a web server that may\n>usefully discover the functional limits of a mobile before it starts to send\n>content to that device. The mobile uses SIP to report to the server that it\n>has X amount of memory, Y amount of display area, color or not, average\n>data rate it can send or receive, and so on. This information would be used\n>by the server to configure what it sends to be compatible with the receiving\n>unit.\n>\n>perhaps this is an idea that is already being pursued in an IETF \n>working group?\n\nI think \"discovery\" of capabilities is an interesting discussion, and \nof course it should be dealt with aswell. Some of this information \ncan be handled by just looking att the tcp control block :-)\n\nNow, I would like, to be honest, this wg to more look at what \nstupid(?) design flaws have been made in the existing protocols given \ncertain capabilities than the actual discovery process. IMAP in \ndisconnected mode is a good idea, maybe, but might be too chatty. \nI.e. long rtt makes chatty protocols like IMAP and SMTP (just as some \nexamples) quite boring. Can something be done about that (batch \nsmtp?).\n\nSay we have a very fat pipe between earth and the moon (which current \ntcp should be able to handle). Should we run IMAP over that link \nwhich have quite some RTT?\n\nWhat happens if we have only a 2.4k inmarsat sattelite phone with \n900ms rtt, can we still do useful stuff with normal applications \ngiven ppp (the solution is not to change ppp in this discussion)?\n\n   paf\n\n\n\n", "id": "lists-007-12912187"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "At 08:12 AM 9/16/00 -0400, vint cerf wrote:\n>would it be useful, in the context of establishing peer-to-peer communications\n>(or even client/server communications) with limited-function mobile devices,\n>to use SIP as a framework for negotiating the parameters that should guide the\n>nature of the exchange? I'm thinking, for instance, of a web server that may\n>usefully discover the functional limits of a mobile before it starts to send\n>content to that device. The mobile uses SIP to report to the server that it\n>has X amount of memory, Y amount of display area, color or not, average\n>data rate it can send or receive, and so on. This information would be used\n>by the server to configure what it sends to be compatible with the receiving\n>unit.\n>\n>perhaps this is an idea that is already being pursued in an IETF working \n>group?\n\n\nThe Content Negotiation work would cover this sort of exchange, I believe.\n\nd/\n\n\n\n", "id": "lists-007-12922910"}, {"subject": "version controlled collection feature, additional UNCHECKOUT semantic", "content": "Hi,\n\nI noticed that the RFC doesn't specify additional UNCHECKOUT semantics for a\nversion controlled collection resources.\n\nHowever it seems to me that it's far from obvious what UNCHECKOUT should do.\nIs it supposed to restore the bindings for version controlled resources? I\nwould guess so... What is it supposed to do for VCRs that have been deleted\nsince the last CHECKOUT? Restore a new VCR from a server-selected version\nfrom the version history?\n\nFeedback appreciated :-)\n\nJulian\n\n\n\n", "id": "lists-007-1292823"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "Howdy,\n\n\"James P. Salsman\" wrote:\n> Proposed special document status and process for MMMS specifications:\n> Recognizing that it may be impossible to achieve consensus on topics\n> in which large and diverse corporate concerns have vested interests\n> opposed to open standards, the MMMS working group will have a special\n> goal to produce Internet-Drafts which will identified as \"Frozen MMMS\n> RFC-track Internet-Drafts.\"  These documents might never become RFCs\n\nI think this is a Bad Idea -- particularly in conjunction with:\n\n> frozen documents.  Developers may rely on such documents as static\n> and vendors and customers will be encouraged to refer to them in their\n> procurement process.  \n\nThese documents would become de facto standards (although they won't\nhave had the standards-review) and they would break the paradigm\nof Internet-Drafts (which is \"don't implement\").\n\nIf you want to get public documentation on how things are done,\nit would be more suitable I think to go with traditional Informational\nRFCs -- and you can label them as \"Informal understanding of how to\ndo X\", if you like.\n\nLeslie.\n\n\n\n-- \n\n-------------------------------------------------------------------\n\"Reality with a delicate splash of the imaginary... \n    ... or was that the other way around?\"\n   -- ThinkingCat\n\nLeslie Daigle\nleslie@thinkingcat.com\n-------------------------------------------------------------------\n\n\n\n", "id": "lists-007-12933441"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "Howdy,\n\nYes, RESCAP should be doing this.  (Too many people with full\nplates, not enough people poking -- so poke ;-)\n\nLeslie.\n\nPatrik F?ltstr?m wrote:\n> \n> At 08.12 -0400 00-09-16, vint cerf wrote:\n> >would it be useful, in the context of establishing peer-to-peer communications\n> >(or even client/server communications) with limited-function mobile devices,\n> >to use SIP as a framework for negotiating the parameters that should guide the\n> >nature of the exchange?\n> \n> Maybe. The rescap wg is looking into \"capabilies\" in a different way\n> (I presume).\n> \n> >I'm thinking, for instance, of a web server that may\n> >usefully discover the functional limits of a mobile before it starts to send\n> >content to that device. The mobile uses SIP to report to the server that it\n> >has X amount of memory, Y amount of display area, color or not, average\n> >data rate it can send or receive, and so on. This information would be used\n> >by the server to configure what it sends to be compatible with the receiving\n> >unit.\n> >\n> >perhaps this is an idea that is already being pursued in an IETF\n> >working group?\n> \n> I think \"discovery\" of capabilities is an interesting discussion, and\n> of course it should be dealt with aswell. Some of this information\n> can be handled by just looking att the tcp control block :-)\n> \n> Now, I would like, to be honest, this wg to more look at what\n> stupid(?) design flaws have been made in the existing protocols given\n> certain capabilities than the actual discovery process. IMAP in\n> disconnected mode is a good idea, maybe, but might be too chatty.\n> I.e. long rtt makes chatty protocols like IMAP and SMTP (just as some\n> examples) quite boring. Can something be done about that (batch\n> smtp?).\n> \n> Say we have a very fat pipe between earth and the moon (which current\n> tcp should be able to handle). Should we run IMAP over that link\n> which have quite some RTT?\n> \n> What happens if we have only a 2.4k inmarsat sattelite phone with\n> 900ms rtt, can we still do useful stuff with normal applications\n> given ppp (the solution is not to change ppp in this discussion)?\n> \n>    paf\n\n-- \n\n-------------------------------------------------------------------\n\"Reality with a delicate splash of the imaginary... \n    ... or was that the other way around?\"\n   -- ThinkingCat\n\nLeslie Daigle\nleslie@thinkingcat.com\n-------------------------------------------------------------------\n\n\n\n", "id": "lists-007-12943519"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "Patrik,\n\nThanks for your message:\n\n>... I want a more specific list of documents that you are to create,\n\nTwo documents would probably make sense:\n\n(1) End-to-End Internet Services for Mobile Devices\n\nScope:  Specifications and interoperability guidelines for \nend-to-end mobile IP connection and transport services required \nfor support of standard Internet messaging (e.g., TCP, UDP, ICMP, \nwith general descriptions of such wireless Internet services that \nalready exist), along with guidelines for TCP operation during \nindefinite wireless link downtime, determining bandwidth and link \nconditions, and a very few hardware-level specifications (e.g., \nserial cable PPP access for connected devices.)\n\n(2) Internet Multimedia Messaging Services for Mobile Devices\n\nScope:  Specifications and interoperability guidelines for \nmultimedia messaging using MIME-based Internet messages and \nrelated services on mobile devices, including application and \nsession services (e.g., IMAP and POP with guidelines for their \nuse in a wireless context, SMTP to and from wireless devices), \nand specific guidelines for MIME message content types and \nencodings for interoperable, unencumbered media formats (such as \nthe open formats in the RTP Profile RFC 1890.)\n\n> and the list of issues you are to discuss should also say what \n> is _NOT_ in scope of the wg.\n\nNot in scope:  No new protocols or formats will be created. No \nspecifications with any intellectual property encumbrances will \nbe incorporated. No content negotiation or preference-profile \nservices will be defined (as those are already within the scope \nof the conneg and rescap working groups, and the W3C Content \nCapability and Preference Profile (cc/pp) working group), \nalthough of course those groups and their documents would all be \ncited in the Internet Multimedia Messaging Services for Mobile \nDevices document.\n\n> You should by the way define a \"mobile client\"...\n\nGood point.\n\n> I felt the discussion at the BOF ended up with \"a client which \n> have very limited bandwidth to the network, often connected to \n> many different internet providers, limited memory and screen\"\n\nThe bandwidth limitations of wireless devices these days are \noften not too bad. Ricochet/Metricom is usually never more than \ntwice as slow as a typical telephone modem. (By the way, at \nleast one person thinks I'm affiliated with Ricochet/Metricom; \nI am not.) \n\nSome of the experimental 2.5 GHz IEEE 802.11 protocol variants \nwork with cells many miles in radius and are capable of shared \nbandwidths many times greater than a T1 -- for example:\n  http://www.overlan.com/pages/prod/rf11plus.html\n(I'm not affiliated with C-Spec/Overlan, either.)\n\nThe real bandwidth issue isn't the typical bit rate; instead, \nwireless devices will for many reasons have occasional sudden \nbandwidth dips or outright link failure for extended periods of \ntime. TCP parameters need to be configured to be more forgiving \nof those situations; that would be addressed in detail in the \nEnd-to-End Internet Services for Mobile Devices document.\n \nMemory limitations, while real, are still keeping pace with \nMoore's Law in general, and should be expected to continue for \nsome time. It might make more sense to say that mobile devices \nare less likely to have any kind of mass storage, and rely upon \nexisting email session mechanisms for rejecting messages of too \ngreat a length, or with components in unreadable formats. Those \nconcerns would be well within the scope of the Internet \nMultimedia Messaging Services for Mobile Devices document.\n\nScreen-size is a valid user interface concern, being addressed by \nthe rescap, conneg, and W3C CC/PP working groups, and I would be \nvery reluctant to suggest that topic for any MMMS specifications.\n\nCheers,\nJames\n\n\n\n", "id": "lists-007-12955020"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "Depending on the assumptions, it seems that either capability discovery\nintegrated with the actual protocol or a separate protocol (as in\nrescap) makes sense. (Among other considerations, this depends on\nrequirements for setup delay, number of message exchanges or\nrestrictions on information access.) For interactive multimedia\ncommunications, there is a nascent SDPng effort to describe\ncapabilities, with the current version of SDP being used in RTSP, SIP,\nSAP and Megaco/MGCP. This work is still in the requirements stage, but\nit may well borrow from the content negotiation work, but some\nrequirements differ somewhat.\n\n\nvint cerf wrote:\n> \n> patrik,\n> \n> would it be useful, in the context of establishing peer-to-peer communications\n> (or even client/server communications) with limited-function mobile devices,\n> to use SIP as a framework for negotiating the parameters that should guide the\n> nature of the exchange? I'm thinking, for instance, of a web server that may\n> usefully discover the functional limits of a mobile before it starts to send\n> content to that device. The mobile uses SIP to report to the server that it\n> has X amount of memory, Y amount of display area, color or not, average\n> data rate it can send or receive, and so on. This information would be used\n> by the server to configure what it sends to be compatible with the receiving\n> unit.\n> \n> perhaps this is an idea that is already being pursued in an IETF working group?\n>\n\n\n\n", "id": "lists-007-12967060"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "At 15.41 +0200 00-09-16, Patrik F?ltstr?m wrote:\n>Say we have a very fat pipe between earth and the moon (which \n>current tcp should be able to handle). Should we run IMAP over that \n>link which have quite some RTT?\n\nBy the way, my examples with IMAP and SMTP might be simplistic, too simplistic.\n\nReplace those with streaming media stuff over multicast or RTP \nor...and you get what I mean, I hope.\n\n   paf\n\n\n\n", "id": "lists-007-12977270"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "James;\n\n> Thanks for your message:\n> \n> >... I want a more specific list of documents that you are to create,\n> \n> Two documents would probably make sense:\n> \n> (1) End-to-End Internet Services for Mobile Devices\n\n\"End-to-end\" means to do things at the end of the communication\nas much as possible.\n\nIn this case of interactive multimedia communication, there is human\ninvolvement. So, the end to select service is beyond mobile device\nin human brain.\n\nUsers choose proper URL for his terminal capability.\n\nUsers do not want to be annoyed by the result of negotiation by\n*INTELLIGENT* intermediate systems.\n\nUsers do not want to be annoyed by delay for the negotiation.\n\nAnd, at the other side of the communication, users can't provide\nso much variation of the content.\n\nMasataka Ohta\n\nPS\n\nOf course, people in telephone companies do not do it end to end\nbut may want to call it end to end.\n\n\n\n", "id": "lists-007-12986083"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "At 17.44 -0700 00-09-16, James P. Salsman wrote:\n>(1) End-to-End Internet Services for Mobile Devices\n>\n>Scope:  Specifications and interoperability guidelines for\n>end-to-end mobile IP connection and transport services required\n>for support of standard Internet messaging (e.g., TCP, UDP, ICMP,\n>with general descriptions of such wireless Internet services that\n>already exist), along with guidelines for TCP operation during\n>indefinite wireless link downtime, determining bandwidth and link\n>conditions, and a very few hardware-level specifications (e.g.,\n>serial cable PPP access for connected devices.)\n\nI think this must be syncronized with the work of the PILC wg. See \nhttp://www.ietf.org/html.charters/pilc-charter.html.\n\n    paf\n\n\n\n", "id": "lists-007-12995115"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "> I think this must be syncronized with the work of the PILC wg. See \n> http://www.ietf.org/html.charters/pilc-charter.html.\n\nPatrik, thanks for drawing attention to this.  Other activities\nin the same arena that TSV has going on are ROHC and a proto-working\ngroup (we'll be airing a draft charter for it soon) about end2end\nconsiderations in mobility.  It had a BOF (craps) in Pittsburgh, but the\nscope of any WG will be more focuses than the BOF was.\n\nROHC: http://www.ietf.org/html.charters/rohc-charter.html\n\nCRAPS: http://www2.ietf.org/proceedings/00jul/minutes/craps-00jul.txt\n\nAllison\n\n\n\n", "id": "lists-007-13003962"}, {"subject": "RE: version controlled collection feature, additional UNCHECKOUT  semantic", "content": "The semantics of UNCHECKOUT are the same as UPDATE (see 14.11).\nIn particular, yes, restoring a deleted VCR produces a server-selected\nversion, unless there is already a VCR for that version history\nin the workspace (in which case you just restore a binding to that VCR).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Wednesday, June 12, 2002 4:34 PM\nTo: ietf-dav-versioning@w3.org\nSubject: version controlled collection feature, additional UNCHECKOUT\nsemantics\n\n\n\nHi,\n\nI noticed that the RFC doesn't specify additional UNCHECKOUT semantics for a\nversion controlled collection resources.\n\nHowever it seems to me that it's far from obvious what UNCHECKOUT should do.\nIs it supposed to restore the bindings for version controlled resources? I\nwould guess so... What is it supposed to do for VCRs that have been deleted\nsince the last CHECKOUT? Restore a new VCR from a server-selected version\nfrom the version history?\n\nFeedback appreciated :-)\n\nJulian\n\n\n\n", "id": "lists-007-1300939"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "Patrik and I had a rapid-fire in-room discussion after the MMMS BOF in\nWashington. I walked away with the understanding that MMMS, or something\nlike MMMS, would have the same role in the APPS area as PILC has in TSV.\n\nThis was a sound-byte, of course, and not a charter, but it made sense to me\nat the time.\n\nAnd, just FYI, there is a certain amount of hand-waving in appendices of the\nPILC ERROR document, for instance, about the limits of what PILC can\naccomplish without a corresponding effort at the application level. Patrik's\nexample of application-level stop-and-wait protocols (\"enter userid\", \"enter\npassword\", etc.) shows the kind of interaction that TCP can't fix (if you\nwait a full round-trip for an answer before asking the next question and\nwaiting some more, it doesn't really matter what TCP is trying to do\nunderneath you, and heaven forbid you are doing this over geosynchronous\nsatellite hops).\n\nIf there was an MMMS, we would definitely hand this text off to MMMS (we're\nTSV weenies, after all).\n\nSpencer, PILC co-chair\n\n----- Original Message -----\nFrom: Allison Mankin <mankin@isi.edu>\nTo: Patrik F?ltstr?m <paf@cisco.com>\nCc: James P. Salsman <bovik@best.com>; <discuss@apps.ietf.org>;\n<ietf-mmms@imc.org>; <ietf@ietf.org>\nSent: Sunday, September 17, 2000 2:24 PM\nSubject: Re: Mobile Multimedia Messaging Service\n\n\n> > I think this must be syncronized with the work of the PILC wg. See\n> > http://www.ietf.org/html.charters/pilc-charter.html.\n>\n> Patrik, thanks for drawing attention to this.  Other activities\n> in the same arena that TSV has going on are ROHC and a proto-working\n> group (we'll be airing a draft charter for it soon) about end2end\n> considerations in mobility.  It had a BOF (craps) in Pittsburgh, but the\n> scope of any WG will be more focuses than the BOF was.\n>\n> ROHC: http://www.ietf.org/html.charters/rohc-charter.html\n>\n> CRAPS: http://www2.ietf.org/proceedings/00jul/minutes/craps-00jul.txt\n>\n> Allison\n>\n> -\n> This message was passed through ietf+censored@alvestrand.no, which\n> is a sublist of ietf@ietf.org. Not all messages are passed.\n> Decisions on what to pass are made solely by Harald Alvestrand.\n\n\n\n", "id": "lists-007-13012839"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "To: The Internet Technical Community\n\n\n\n>>>>> On Sat, 16 Sep 2000 17:44:56 -0700 (PDT), \"James P. Salsman\" <bovik@best.com> said:\n\n\n  James> (1) End-to-End Internet Services for Mobile Devices\n\n  James> Scope:  Specifications and interoperability guidelines for \n  James> end-to-end mobile IP connection and transport services required \n  James> for support of standard Internet messaging ...\n\n\nThe beauty of the Internet End-to-End model is that people don't have\nto wait for the IETF to create a working group, a charter, a chair,\n, blessings, .... to move forward.\n\nRemember the web (http, ...)? \nWhat was IETF's role in Internet's main modern application?\n\n\nAs far as the domain of Internet services for mobile devices go, the\nkey issue is \"Efficiency\".\n\n\nCompletely outside of the IETF but in the tradition of Internet\ntechnical community which includes:\n\n- Stable and wide publication (RFC publication)\n        - Patent-Free Specification\n        - Open working group protocol development and maintenance\n\nA large body of work exists which addresses the Mobile Messaging\narea. \n\n\nIt is called \n    \n     LEAP: Lightweight and Efficient Application Protocol.\n\n\nTo fully describe our vision of the Mobile Messaging industry, there\nis a 200 page document called:\n\n     \"The LEAP Manifesto\"\n\nThe LEAP Manifesto addresses every topic so far touched on in this\nthread -- and a great deal more.\n\n\nThose who believe in the IETF's exclusivity in protocol development\ncan start from scratch and form yet another working group, write yet\nanother charter, and go and talk, ...\n\n\nThose who want to build good things and move forward fast, can evaluate\nthe merits of LEAP and participate in its evolution and enhancement.\n\nThe starting point URL is: http://www.leapforum.org/\n\nThe main current areas of work for LEAP are:\n\n    - Efficient Security Services\n    - Compact Markup Languages\n    - Portation of the reference implementation to additional\n      platforms\n\n\nThose interested are invited to join the relevant mailing lists.\n\n\nIn the early stages of formation of an industry, competition amongst\nopen protocols is healthy. \n\n\n...Mohsen.\n\n\n\n", "id": "lists-007-13024709"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "Patrik,\n\nThank you for your reply:\n\n>>... guidelines for TCP operation during\n>> indefinite wireless link downtime....\n> \n> I think this must be syncronized with the work of the PILC wg. See \n> http://www.ietf.org/html.charters/pilc-charter.html\n\nYes, the next document milestone from PLIC seems to have been delayed:\n\n DoneDraft on asymmetric network paths.\n Oct 99Draft of TCP Over Wireless document to the IESG as BCP\n Nov 99Document on low bandwidth links to IESG for publication as BCP.\n\nDoes anyone know who is supposed to be working on the PLIC Wireless \ndocument?  The closest I could find was:\n\n  http://iceberg.cs.berkeley.edu/papers/Ludwig-FlowAdaptive/index.html\n\nCheers,\nJames\n\n\n\n", "id": "lists-007-13036054"}, {"subject": "The LEAP Manifesto &ndash;&ndash; Executive Summar", "content": "                    The\nLightweight & Efficient Application Protocol\n                   (LEAP)\n                 Manifesto\n\n\n\n  Shaping the Future of Mobile & Wireless\n           Applications Industry\n\n             A Call to Action\n\n\n\n             EXECUTIVE SUMMARY\n\n\n                Mohsen Banan\n     <public@mohsen.banan.1.byname.net>\n\n\n\n                Version 0.5\n               July 17, 2000\n\n\nCopyright (c)2000 Mohsen Banan.\n\n\nPermission is granted to make and distribute verbatim\ncopies of this manual provided the copyright notice and\nthis permission notice are preserved on all copies.\n\n\n\nContents\n========\n\n\n1  Executive Summary\n\n   1.1 Technological Scope\n   1.2 Efficiency is the Key Requirement\n   1.3 Conventional Origins of Protocols\n   1.4 Expect the Unexpected\n   1.5 Our Solution\n   1.6 A Brief History of LEAP\n   1.7 Making Our Solution Widespread\n   1.8 Complete and Ready\n   1.9 Getting the Complete Manifesto\n\n\n\n1  Executive Summary\n====================\n\nUntil now, the Internet has been largely based\nupon simple protocols.  However, the era of simple\nprotocols is now over.  The new Internet reality\nis that of wireless networks, providing service to\nlegions of miniaturized, hand-held mobile devices.\nThis reality places an entirely new set of\nrequirements on the underlying communications\nprotocols:  they must now provide the power\nefficiency demanded by hand-held wireless devices,\ntogether with the bandwidth efficiency demanded by\nwide area wireless networks.\n\nIt is now time for a new generation of protocols\nto be implemented, designed to address the need\nfor performance, rather than simplicity.\n\nThe industry-wide adoption of this new generation\nof powerful and efficient protocols will have\nenormous consequences.  Protocols addressing the\ncorrect requirements will become the lynchpin of a\nhuge new industry.  The stakes are enormous, and\nferocious competition is to be expected within all\nsegments of the industry.  All manner of wild\nclaims and misrepresentations are also to be\nexpected.  At the time of writing, the main\nclaimant to the protocol throne is the Wireless\nApplications Protocol, or WAP. However, WAP will\neventually prove to be entirely inadequate to the\nrole being claimed for it.\n\nWe have designed a set of protocols, the\nLightweight & Efficient Application Protocols, or\nLEAP, which we believe is destined to displace WAP\nand become the de facto industry standard.  These\nprotocols, published as Internet RFC 2524 and RFC\n2188, are designed to address all the technical\nrequirements of the industry, and are oriented\ntowards providing the greatest benefit to the\nindustry and the consumer.\n\nThis manifesto is about our vision of the future\nof the Mobile and Wireless Applications Industry.\nIn the remainder of the manifesto we present the\ndetails of our vision, and we justify our claims.\nWe justify our assertion that the industry needs a\nnew generation of protocols, we explain why our\nprotocols fulfil this need, and we describe how\nand why these protocols will achieve dominance.\n\nThe protocols are free, open and in place.\nOpen-source software implementations of the\nprotocols are being made available for all major platforms.\nThe combination of free protocols and open-source\nsoftware ensures acceptance of the protocols in\nthe Internet mainstream.  There can be no stopping\nthis.\n\n\n1.1  Technological Scope\n------------------------\n\nMost of our discussion throughout this Manifesto\nis framed in terms of a particular technology,\nnamely, Mobile Messaging.  It is important to bear\nin mind, however, that Mobile Messaging is just\none aspect of a broader technology:  Mobile\nConsumer Data Communications.  Mobile Consumer\nData Communications refers to the general ability\nof an end-user to send and receive digital data at\na hand-held device via a wireless network.  This\ntechnology includes Mobile Messaging as a special\ncase, but also includes other wireless data\ntransfer capabilities such as general Internet\naccess, web browsing, etc.\n\nMuch of the discussion set forth in this Manifesto\napplies with equal force to all mobile data\ncommunications applications, not just that of\nmessaging.  However, it is currently well\nunderstood that the dominant application for\nmobile data communications is, in fact, Mobile\nMessaging, not web browsing or other Internet\napplications.  Therefore throughout this Manifesto\nwe will focus our attention on the messaging\napplication.\n\nThough our discussion will be framed in terms of\nMobile Messaging, the reader should bear in mind\nthat the same principles apply to all forms of\nmobile data communications.\n\n\n1.2  Efficiency is the Key Requirement\n--------------------------------------\n\nEngineering is the art of making intelligent\ntrade-offs between conflicting requirements.  A\nperennial engineering trade-off is that which must\nbe made between the need for simplicity, and the\nneed for performance.  In the case of wireless\ndata communications, performance means such things\nas data transfer speed, power efficiency, and\nbandwidth efficiency.\n\nThe 1980s and 1990s were the decades of simple\nprotocols - protocols such as the very aptly named\nSimple Mail Transfer Protocol (SMTP), and Simple\nNetwork Management Protocol (SNMP). A great deal\nof the success of these and other Internet\nprotocols can be attributed to their simplicity.\n\nThe first generation of network engineers and\nnetwork operators were only able to view network\ncommunications in relatively simple terms.  It was\nappropriate to cater to that simplicity with\nsimple protocols.  A key reason for the success of\nthese early protocols is the lack of technical\nsophistication on the part of first-generation\nnetwork engineers and operators.\n\nSimple protocols are easier to make widespread\nthan ``good'' protocols (meaning those which have\nbetter capabilities and performance), for the\nbasic reason that network engineers and operators\nare able to adopt and implement simple protocols\nmuch more easily than ``good'' protocols.\n\nHowever, things have changed.  Network\ncommunications has now expanded dramatically and\nforcefully into the wireless and mobile data\ncommunications arena, and wireless applications\ndemand efficiency.  The move to wide-area wireless\nhas significantly shifted the location of the\nideal engineering balance between simplicity and\nperformance - moving it away from simplicity, and\ntowards performance.\n\nWe therefore need a new generation of\nhigh-performance, efficient protocols, to cater to\nthe demands of wireless applications.  The point\nis sometimes made that the need for efficiency in\nthe wireless arena is a temporary one -- that\nadvances in wireless engineering technology in the\nform of third generation (3G) systems will\neliminate existing bandwidth limitations,\nobviating the need for efficient protocols.  As\nlong as the capacity of wireless networks remains\nfinite, however, the need for efficiency will\npersist.  Efficient usage is an inherent\nrequirement for any finite resource, therefore the\nrequirement for efficient bandwidth usage and\nbattery longevity is permanent.\n\n\n1.3  Conventional Origins of Protocols\n--------------------------------------\n\nWhere will the required protocols come from?\nTraditionally, industry-wide protocols have their\norigins in one of two sources:\n\n\n 1. The major players in the industry itself.  In\n    the case of wireless communications, this\n    means the major telecommunications and\n    wireless network companies.\n\n 2. Professional protocol and standards producing\n    associations.  In the case of wireless\n    communications, this means the IETF, ITU, ISO,\n    ANSI, TIA and others.\n\nUnfortunately, neither of these groups has\nproduced a set of protocols which meets the\nindustry's needs.  The first group above,\nrepresented by a set of telephone companies, has\ngenerated the WAP specification.  However, as we\nwill argue in detail later, this specification is\ngrossy unfit for its claimed purpose.  Among other\nthings it is poorly designed, not the product of\nopen peer review, and crippled with Intellectual\nProperty Right (IPR) restrictions.  It is\nessentially a business construct, not an\nengineering one.  In the long run WAP cannot\npossibly survive as a viable solution.  In the\nshort run it can only have a destructive effect on\nthe wireless industry.\n\nThe second group above, most notably represented\nby IETF, has likewise failed to produce an\nacceptable standard.  IETF represents the\ntradition of simple protocols, a tradition which\nwireless communications has made obsolete.\nUnfortunately, IETF remains rooted in this\ntradition, and has not adapted to the new\nrealities of wireless communications.  Until it\ndoes so, IETF will remain ineffective as a\nprotocols and standards body.  In the area of\nefficient protocols, IETF is simply bankrupt.\n\n\n1.4  Expect the Unexpected\n--------------------------\n\nFortunately, there are other sources of\ninnovation.  One of these is the radical new\ndevelopment that comes out of nowhere, taking\neverybody by surprise.  Typically this originates\nin the actions of a small group of independent\nexperts, with a deep understanding of the\ntechnology and industry, and who are passionate\nabout and committed to its health and vigor.\n\nNote that the World Wide Web itself originated in\nneither of the traditional sources, but instead\ncame from an entirely different and unexpected\ndirection:  a group of physicists at the CERN\nlaboratory in Switzerland.  As another example,\nPretty Good Privacy (PGP), now the de facto\nstandard for electronic data encryption, also came\nfrom neither traditional source.  It was\nessentially the creation of a single man:  Phil\nZimmermann.  Armed with a vision and a belief in\nits value, Zimmermann single-handedly made PGP the\ndominant consumer encryption application -\ndisplacing the IETF alternatives in the process.\nThe solution to the current wireless application\ndilemma is also likely to come from an unexpected\nsource -- and we believe that we are that source.\nIn the world of the Internet, we have learned to\nexpect the unexpected.\n\n\n1.5  Our Solution\n-----------------\n\nWe have developed a set of protocols which we\nbelieve address all aspects of the industry's\nneeds.  Beyond their purely technical\nrequirements, a fundamental requirement of all\nindustry-building protocols is that they be\ncompletely open and free from patents and other\nIPR restrictions -- either because no patents\nactually exist, or because reasonably\nnon-restrictive licenses are granted by the patent\nholder.  In the rest of this document, this is\nwhat we mean when we speak of ``patent-free''\nprotocols.\n\nThe presence of patented components within a\nprotocol is extremely undesirable, since this\nundermines the ultimate purpose of the protocol:\nits unrestricted adoption and usage.  The process\nthat we have followed in developing our protocols\nhas been such as to ensure that they are entirely\nopen and, as far as this can be guaranteed,\npatent-free.  A significant part of this process\nconsists of our full committment to the processes\nand procedures of the Free Protocols Foundation\n(FPF).\n\nThe FPF is an organizational framework for the\ndevelopment and maintenance of free protocols.  It\nallows developers to declare publicly that the\nprotocols they have developed are intended to be\npatent-free, and that it is their intention to\nkeep them patent-free into perpetuity.  We have\nmade this declaration through the Free Protocols\nFoundation with regard to our own protocols.\n\nNote that this is in sharp contrast to the WAP\nprotocols, which include severe IPR restrictions.\nThis creates an unfair market advantage in favor\nof the initial WAP designers.  Our intention is to\ncreate a protocol which does not favor any one\nindustry player over another, and places\ncompetition where it belongs:  on the merits of\neach company's individual products and services.\n\nWe have created the general framework for a set of\nhigh-performance, efficient protocols which are\nideal for mobile and wireless applications.  We\nrefer to this general framework as the Lightweight\n& Efficient Application Protocol (LEAP).\n\nThe need for efficient protocols extends across\nall aspects of wireless data communications,\nincluding e-mail, web browsing, and other\napplications.  The LEAP architecture accommodates\nall of these applications.  Our initial\nimplementation, however, is focussed on the Mobile\nMessaging application, since we believe that this\nis the dominant application for wide-area wireless\nnetworks.\n\nAll efficient applications have the requirement\nfor an efficient transport mechanism.  For this\nreason, the initial focus of our protocol\ndevelopment effort has been on creating a general\nefficient transport mechanism.  The resulting\nprotocol is referred to as Efficient Short Remote\nOperations (ESRO). ESRO is a reliable,\nconnectionless transport mechanism, forming the\nfoundation for the development of efficient\nprotocols when TCP is too much and UDP is too\nlittle.\n\nOur Efficient Mail Submission and Delivery (EMSD)\nprotocol is built on top of ESRO, and is designed\nto address the Mobile Messaging application.\nBoth of these protocols have been published as\nInternet RFCs:  ESRO as RFC 2188, and EMSD as RFC\n2524.  RFC publication ensures that the protocols\nare freely, easily and permanently accessible to\nanyone who wishes to use them.\n\nNote that this also is in stark contrast to WAP,\nwhich is self-published by the members-only WAP\nForum.  Furthermore, the WAP Forum reserves the\nright to make unilateral changes to its protocols;\neach of the WAP protocols carries on its cover\npage the disclaimer, ``subject to change without\nnotice.''\nPublication of a protocol as an Internet RFC\nensures that the protocol will remain stable and\npermanently available to anyone who wishes to use\nit, and for this reason is the mainstream Internet\npublishing method.  The declining of the WAP Forum\nto publish their specifications as Internet RFCs\nsuggests either that the forum wishes to retain an\ninappropriate degree of control over the\nspecifications, or that the specifications do not\nmeet the minimum technical standards required for\nRFC publication.\n\n\n1.6  A Brief History of LEAP\n----------------------------\n\nLEAP originated in 1994 as part of the research\nand development initiatives of McCaw Cellular's\nwireless data group (now AT&T Wireless Services).\nThe development work that would eventually lead to\nLEAP was initially undertaken in the context of\nthe CDPD network; its scope was later expanded to\ninclude the Narrowband PCS network also.\n\nBy 1996 McCaw Cellular was fully committed to\npaging, had recently purchased two nationwide\nnarrowband wireless PCS licenses, and wished to\ndevelop an efficient wireless message transport\nand delivery system.  Neda Communications, Inc.,\nan independent consulting company working under\ncontract to McCaw Cellular, played a significant\nrole in the development of the required system.\nNeda Communications had also been involved from\nthe outset in the development of the CDPD\nspecification.\n\nIn 1997 however, soon after the purchase of McCaw\nCellular by AT&T, the company abandoned narrowband\nPCS paging altogether.  Prior to this event, Neda\nCommunications had secured from AT&T the necessary\nrights to continue independent development of the\nprotocols.  Therefore, recognizing the eventual\nfuture need for these protocols, Neda then\nundertook to continue development of the protocols\nindependently of AT&T. They were eventually\ncompleted by Neda, published as RFCs, and now form\nthe cornerstone of the LEAP protocols.\n\n\n1.7  Making Our Solution Widespread\n-----------------------------------\n\nOur ultimate goal is to make these protocols\nwidespread.  Developing and publishing a set of\nprotocols, however, is just the beginning.\nProtocols become accepted as standards as a result\nof public review, modification by consensus, and\nultimately by standing the test of usage in the\nindustry at large.\n\nTo provide a forum for these processes, we have\ncreated EMSD.org and ESRO.org.  Each of these\norganizations allows public review of the\nrespective protocol, and provides a mechanism for\ncorrection and enhancement of the protocol as a\nresult of collective experience.  Any interested\nperson can become a member of these organizations\nand participate in the further development of the\nprotocols.  The only requirement for membership is\nthat participants must adhere to the principles\nand procedures of the Free Protocols Foundation,\nensuring that the protocols remain permanently\npatent-free.\n\nNote that this also is in sharp contrast to WAP.\nParticipation in WAP, far from being open and\npublic, requires a $27,000 membership fee (as of\nFebruary 2000), and takes place entirely behind\nclosed doors.\n\nIn order for the protocols to become widely\naccepted, they must be implemented in the form of\nsoftware solutions that are readily available for\ndeployment by end-users.  We have therefore\ncreated open-source software implementations of\nthe protocols for most common platforms.  Protocol\nengines are available in the form of portable code\nwhich has been ported to a variety of platforms.\nOn the device side, software is available for\nWindows CE, Palm OS, EPOC, and others.  On the\nmessage center side, software is available for NT,\nSolaris, and Linux.\n\nAs noted above, our initial emphasis is on the\nMobile Messaging application.  Protocol engines\nare only a single component of a larger picture;\nin order to provide complete solutions to the user\nit is necessary to integrate these protocols into\nother existing pieces of software.  To that end we\nhave created MailMeAnywhere.org, where\nfully-integrated solutions in open-source format\nare made available to the user.\n\nWe will initially ``prime the pump'' by providing\nfree subscriber services through ByName.net and\nByNumber.net.  This will provide initial support\nfor adoption of the protocols by end-user devices.\nUsage of the protocols among a sufficient number\nof user devices will then provide the motivation\nfor usage among the message center systems.\n\n\n1.8  Complete and Ready\n-----------------------\n\nAll the components that are needed to accomplish\nthese goals are complete, in place, and ready to\ngo.  These components are:\n\n\nThe Protocols. The protocols are well-designed,\n    meet all the technical requirements of the\n    industry, and are published as RFCs -- the\n    mainstream Internet publishing procedure.\n    http://www.rfc-editor.org provides the\n    complete text of RFC 2188 and RFC 2524.\n\nOpen Maintenance Organizations. The protocols are\n    maintained at EMSD.org and ESRO.org, allowing\n    open and non-exclusionary participation in the\n    maintenance of the protocols.\n    http://www.esro.org and http://www.emsd.org\n    provide complete details.\n\nFreedom from Patents. The protocols are\n    patent-free to the best of our knowledge, and\n    are guaranteed to stay that way.  This ensures\n    permanent, unrestricted access to the\n    protocols.\n    http://www.FreeProtocols.org provides further\n    information.\n\nOpen-Source Software Implementations. These are\n    being made available for a wide variety of of\n    platforms and end-user devices:  pagers and\n    cell-phones; hand-held PCs (Windows CE, Palm\n    PC) and Palm Pilot; Windows 98, Windows 95,\n    and Windows NT; Pine (UNIX, Windows, DOS).\n    http://www.MailMeAnywhere.org provides\n    complete details.\n\nFree Subscriber Services. These are provided to\n    support initial deployment of the protocols in\n    end-user devices.\n    http://www.ByName.net and\n    http://www.ByNumber.net provide complete\n    details.\n\n\nCollectively, the above components represent a\ncomplete recipe for the success of our protocols.\nAll the pieces of the puzzle are complete, and\nthere are no missing pieces.\n\n\n1.9  Getting the Complete Manifesto\n-----------------------------------\n\nThis Executive Summary provides an overview of\nwhat we are trying to do.  For complete details on\nevery aspect of our vision, see the full\nmanifesto, available at the LEAP Forum website at\nhttp://www.LEAPForum.org/leap\n\nThis Executive Summary and the full Manifesto are\navailable in HTML, PostScript, PDF, and plain text\nformats.\n\n\n\n", "id": "lists-007-13046114"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "At 09:23 AM 9/16/00 -0700, Dave Crocker wrote:\n>At 08:12 AM 9/16/00 -0400, vint cerf wrote:\n>>would it be useful, in the context of establishing peer-to-peer \n>>communications\n>>(or even client/server communications) with limited-function mobile devices,\n>>to use SIP as a framework for negotiating the parameters that should \n>>guide the\n>>nature of the exchange? I'm thinking, for instance, of a web server that may\n>>usefully discover the functional limits of a mobile before it starts to send\n>>content to that device. The mobile uses SIP to report to the server that it\n>>has X amount of memory, Y amount of display area, color or not, average\n>>data rate it can send or receive, and so on. This information would be used\n>>by the server to configure what it sends to be compatible with the receiving\n>>unit.\n>>\n>>perhaps this is an idea that is already being pursued in an IETF working \n>>group?\n>\n>\n>The Content Negotiation work would cover this sort of exchange, I believe.\n\nSee RFC 2506, RFC 2533, RFC 2534.\n\nBut also note...\n\nThere is work in W3C (CC/PP working group) that addresses exactly this \narea, from a perspective of data format.  Some initial public drafts are \navailable for comment at http://www.w3.org/Mobile/CCPP/.\n\nThere was also a BOF held in Pittsburgh to garner interest in HTTP \nextensions to convey capability information described using CC/PP, and \nmaybe other formats.\n\nBoth the CONNEG and CC/PP work have (rightly in my view) focused purely on \nformats for expression of capabilities.  Details of protocols for conveying \nsuch information may reasonably vary between applications (HTTP, SIP, \ne-mail, etc.).\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-13073740"}, {"subject": "Multimedia EMSD? (was Re: Mobile Multimedia Messaging Service", "content": "Mohsen,\n\nThank you for your message:\n\n> A large body of work exists which addresses the Mobile Messaging\n> area....\n>     \n>      LEAP: Lightweight and Efficient Application Protocol.\n>... \n> Those who want to build good things and move forward fast, can evaluate\n> the merits of LEAP and participate in its evolution and enhancement.\n> \n> The starting point URL is: http://www.leapforum.org/\n\nWould you confirm, please, that the LEAP Efficient Mail Submission and \nDelivery protocol (EMSD) is capable of MIME messages with multimedia \ncontent?\n\nI am concerned that the string \"multipart\" does not appear on:\n\n  http://www.emsd.org/dataCom/emsd/emsdRfcs/emsdp-rfc/split/node10.html\n\nCheers,\nJames\n\n\n\n", "id": "lists-007-13085587"}, {"subject": "LABEL request only allows one set, one add..", "content": "Is it an oversight that the LABEL request only allows one set, one add, or\none remove at a time (or one of each, but not two of any?)\n\nFor example, say I wanted to add <label-name>foo</label-name> and\n<label-name>bar</label-name> to a version in one request.  The definition of\nthe LABEL request body is:\n\n  <!ELEMENT label ANY>\n  ANY value: A sequence of elements with at most one\n  DAV:add, DAV:set, or DAV:remove element.\n\n  <!ELEMENT add (label-name)>\n  <!ELEMENT set (label-name)>\n  <!ELEMENT remove (label-name)>\n\n  <!ELEMENT label-name (#PCDATA)> PCDATA value: string\n\nSince <add> can only contain one label-name, only one label can be added per\neach request.  I would have to issue two LABEL requests to add both foo and\nbar labels.\n\nLisa\n\n\n\n", "id": "lists-007-1309558"}, {"subject": "RE: Multimedia EMSD? (was Re: Mobile Multimedia Messaging Service ", "content": "Hi,\n\nWe don't need yet-another mail delivery protocol by some new forum.\nWe have already e.g. SIP which is capable of carrying MIME messages,\nincluding multipart\nand which supports capability negotiation.\n\n--\nPetri\n\n\n> -----Original Message-----\n> From: EXT James P. Salsman [mailto:bovik@best.com]\n> Sent: 18. September 2000 11:55\n> To: public@mohsen.banan.1.byname.net\n> Cc: discuss@apps.ietf.org; ietf-mmms@imc.org; ietf@ietf.org;\n> interest@lists.emsd.org; interest@lists.esro.org;\n> interest@lists.leapforum.org\n> Subject: Multimedia EMSD? (was Re: Mobile Multimedia \n> Messaging Service)\n> \n> \n> Mohsen,\n> \n> Thank you for your message:\n> \n> > A large body of work exists which addresses the Mobile Messaging\n> > area....\n> >     \n> >      LEAP: Lightweight and Efficient Application Protocol.\n> >... \n> > Those who want to build good things and move forward fast, \n> can evaluate\n> > the merits of LEAP and participate in its evolution and enhancement.\n> > \n> > The starting point URL is: http://www.leapforum.org/\n> \n> Would you confirm, please, that the LEAP Efficient Mail \n> Submission and \n> Delivery protocol (EMSD) is capable of MIME messages with multimedia \n> content?\n> \n> I am concerned that the string \"multipart\" does not appear on:\n> \n  http://www.emsd.org/dataCom/emsd/emsdRfcs/emsdp-rfc/split/node10.html\n\nCheers,\nJames\n\n\n\n", "id": "lists-007-13095742"}, {"subject": "Re: Multimedia EMSD? (was Re: Mobile Multimedia Messaging Service", "content": ">>>>> On Mon, 18 Sep 2000 01:55:21 -0700 (PDT), \"James P. Salsman\" <bovik@best.com> said:\n\n  >> Those who want to build good things and move forward fast, can evaluate\n  >> the merits of LEAP and participate in its evolution and enhancement.\n  >> \n  >> The starting point URL is: http://www.leapforum.org/\n\n  James> Would you confirm, please, that the LEAP Efficient Mail Submission and \n  James> Delivery protocol (EMSD) is capable of MIME messages with multimedia \n  James> content?\n\nConfirmed.\n\nPlease see sections 6.2.1 and 6.2.2 of RFC-2524, pages (58-62).\n\n  James> I am concerned that the string \"multipart\" does not appear on:\n\n  James>   http://www.emsd.org/dataCom/emsd/emsdRfcs/emsdp-rfc/split/node10.html\n\n\"multipart\" as a string, is a value. \n\nStructure of the Body is through MIME.\n\n...Mohsen.\n\n\n\n", "id": "lists-007-13109611"}, {"subject": "Re: pilc minutes for IETF 4", "content": "Here are some questions about the plic minutes:\n\n  http://pilc.grc.nasa.gov/pilc/list/archive/0967.html\n\n>   TCP over Wireless draft. The working group charter specifies that \n>   PILC will produce a 'TCP over Wireless' RFC that is a meta list of \n>   the existing PILC recommendations. This was reported in Adelaide as \n>   being completed in October 1999 because Aaron had confused it with \n>   the LTN draft. Actually, it requires some work. Gabe Montenegro has \n>   volunteered to sync up with the WAP forum to see if we can build \n>   this document on a work in progress that already exists in that \n>   body. The document should be only 3 or 4 pages long and should go to \n>   wg last call by January 2001. Gabe noted that there is currently no \n>   buy in by the WAP forum as yet, he will attend a forum meeting in \n>   September and try to resolve. Several members of WAP were in the \n>   room and volunteered to assist if needed. \n \nIs this WAP \"work in progress\" available for public inspection and \nreview?  If not, would someone who can see it please abstract it and \npost (anonymously if need be) please?  \n\nDoes any WAP product use TCP at all?\n\n> Discussion on DoCoMo draft (draft-inamura-docomo-00.txt) \n \n  http://search.ietf.org/internet-drafts/draft-inamura-docomo-00.txt\n\n>   Aaron noted that DoCoMo would like to publish this as informational \n>   RFC, but we don't want to get in a mode of publishing RFCs each time \n>   someone does this and requested input from the group. \n\nI would certainly support doing anything that would encourage DoCoMo \nto use end-to-end Internet protocols, and if they are as close as that \ndraft suggests, publishing it as an Information RFC might help them \nprovide TCP application services more easily.\n\n>   A speaker noted that the recommendations are pretty generic and \n>   suggested the working group use this as a starting point for the TCP \n>   over wireless document, or as an appendix to this document. Aaron \n>   suggested it might be necessary to take the simulation results out \n>   in order to use this document for the TCP over wireless \n>   document. Another speaker suggested using path MTU discovery instead \n>   of fixing it at 1500. Question: Maybe your tcp stack in the Opnet \n>   simulator is not the best TCP. Have you run this on real stacks, \n>   rather than on a simulator. Imaura - yes they have, but no \n>   published results. \n> \n>   Aaron noted that another alternative was that the DoCoMo would be \n>   sent forth as informational, and would not be a recommendation. Tim \n>   Shepard asked why would one want to disseminate this information? \n>   Doesn't seem to make sense to have multiples of TCP/some link \n>   technology. Is this advice on how to tune TCP for the handset? \n>   Response from author: yes. \n> \n>   Comment: This shows that tcp stack works over wireless error prone links. \n> \n>   Comment: Doesn't think these results are any different from what a \n>            modern TCP stack does anyway. \n\nI think the TCP parameters and resulting behavior might be more \ndifferent than typical TCP stacks than whoever made that comment\nmight think.  There seems to be a lack of understanding about the \nparameters involved, and most if not all of the important ones are \nat least touched on in the DoCoMo I-D and the documents it cites.\n\n>   Gabe: This is similar to what was done in ecn document \n\nWhat is the ecn document?\n\n>   Question: What bandwidth was used in the simulations? \n>   Imaura: 384kbs \n>   Comment: Doesn't think this is realistic, since this is only the \n>            rate if you are the only one in the cell. WAP is designed \n>            to use slower links. \n\nWAP is designed as if Moore's Law didn't exist.\n\n> Discussion on Long lived TCPs draft (draft-magret-pilc-lltcp-00.txt) \n\n  http://search.ietf.org/internet-drafts/draft-magret-pilc-lltcp-00.txt\n\n>   Comment: this is probably not a good idea -- leads to ICMP flooding. \n\nIs there any evidence to back this comment up?  It seems that ICMP \ntraffic is specifically addressed by Magret and Yang.\n\n>   Also, if there is a long outage you do want to go through slow start \n>   again, because the network has changed. There are better link level \n>   solutions to this problem. \n\nLike what?\n\nThanks.\n\nCheers,\nJames\n\n\n\n", "id": "lists-007-13120340"}, {"subject": "RE: Multimedia EMSD? (was Re: Mobile Multimedia Messaging Service ", "content": ">>>>> On Mon, 18 Sep 2000 12:04:10 +0300, petri.koskelainen@nokia.com said:\n\n  petri> Hi,\n  petri> We don't need yet-another mail delivery protocol by some new forum.\n  petri> We have already e.g. SIP which is capable of carrying MIME messages,\n  petri> including multipart\n  petri> and which supports capability negotiation.\n\n\nIf you want to go after the Mobile set of requirements, then \nyou need to deal with \"Efficiency\".\n\nSee \"The Efficiency of EMSD\" paper in The LEAP Manifesto --\nhttp://www.leapforum.org/ -- for details.\n\nIf you think that Efficiency is not relevant in the Mobile Multimedia\nMessaging Service problem space, then you don't need yet-another mail\ndelivery protocol.\n\nGrep for the word \"Efficient\" on the title of RFC series and see what\nyou get.\n\n...Mohsen.\n\n\n\n", "id": "lists-007-13133193"}, {"subject": "Re: Mobile Multimedia Messaging Servic", "content": "Mohsen;\n\n>   James> (1) End-to-End Internet Services for Mobile Devices\n> \n>   James> Scope:  Specifications and interoperability guidelines for \n>   James> end-to-end mobile IP connection and transport services required \n>   James> for support of standard Internet messaging ...\n> \n> \n> The beauty of the Internet End-to-End model is that people don't have\n> to wait for the IETF to create a working group, a charter, a chair,\n> , blessings, .... to move forward.\n\nYes, in this case, people are using different URLs already.\n\nIt is solved at the so far end of communication that it works\neven with iMODE or WAP without the Internet end-to-end model.\n\n> What was IETF's role in Internet's main modern application?\n\nThe role is to delay IANA resigtration trying to keep influential\npower on application protocols but resulting only to make IANA\nregistration less important.\n\n> As far as the domain of Internet services for mobile devices go, the\n> key issue is \"Efficiency\".\n\nNo. It is wrong to assume that bandwidth for mobile devices is\nlimited forever.\n\nSimplicity is the key issue.\n\nMasataka Ohta\n\n\n\n", "id": "lists-007-13143804"}, {"subject": "Re: pilc minutes for IETF 4", "content": "Reiner,\n\nThanks for your reply:\n\n>>...  There seems to be a lack of understanding about the\n>> parameters involved, and most if not all of the important ones are\n>> at least touched on in the DoCoMo I-D and the documents it cites.\n>\n> You need to be more precise. Which parameters are you talking about?\n\nThese from http://search.ietf.org/internet-drafts/draft-inamura-docomo-00.txt\n\n     Feature        Parameter/Recommendation  RFC/Status\n     -------------------------------------------------------------------\n     MTU size              1500B              N/A\n     Window size           64KB               RFC 793  Standard\n     Initial window        2 mss              RFC 2581 Proposed Standard\n     Initial window        up to 4380B        RFC 2414 Experimental\n     Use of SACK           Recommend          RFC 2018 Proposed Standard\n\nSo, given the ECN-like properties of Radio Link Control -- 3G TS 25.322; \nwhich also seems to be incorporated in current versions of GSM --\n  http://webapp.etsi.org/action/OP/OP20000929/en_301349v080400o.pdf\n-- is there really any need to add explicit link condition adaptation \nat the TCP or ICMP protocol levels?  I don't want to be in a position \nof advocating the change or addition of anything to those protocols \nunless absolutely necessary.\n\nAs far as robust wireless TCP goes, you are absolutely right that good \nservice requires a maximum RTO shorter than the standard 64 seconds.  \nWhat is that value in your TCP-Eiffel?\n\nAnd one parameter that the DoCoMo draft doesn't mention (perhaps it \ngoes without saying to most people) is a total retransmit timeout much \nlonger than the typical 2-9 minutes.  Again, what do you use; an hour?\n\nCheers,\nJames\n\nP.S. Please keep at least ietf-mmms@imc.org in on this, as the lack \nof ubiquitous wireless TCP is related to Mobile Multimedia Messaging \napplications.\n\n\n\n", "id": "lists-007-13153446"}, {"subject": "Re: pilc minutes for IETF 4", "content": "> As far as robust wireless TCP goes, you are absolutely right that\n> good service requires a maximum RTO shorter than the standard 64\n> seconds.  What is that value in your TCP-Eiffel?\n\nWhy should the maximum RTO be less than 64 seconds?  If the RTO gets\nto that point it was because of exponential backoff.  So, one of two\nthings has happened...\n\n  * Extreme congestion.  In this case you want your RTO timer to be\n    backed off to a large time to avoid aggrivating the congestion\n    even more.\n\n  * An outage.  In this case, it is potentially painful when the\n    link is re-established because you have to wait for some (likely\n    large) amount of time before re-starting transmission.  So, for\n    this case, we'd like to have a lower maximum RTO.\n\nBut, how does the end host figure out which situation it is in?\nThere may be heuristics, but it seems to me that having an explicit\nmechanism that \"kicks\" TCP in the second case is likely the way to\ngo (i.e., an ICMP or holding on to the last segment(s) to trigger\nthe restart of the connection).\n\nallman\n\n\n---\nhttp://roland.grc.nasa.gov/~mallman/\n\n\n\n", "id": "lists-007-13163424"}, {"subject": "Dear  ISP / Webmaster", "content": "Dear  ISP / Webmaster:\n\nGet new members and keep them with Speedycam!  You can now offer your \nmembers a way to interact with each other via live video and chat !  Your \nmembers can have their own live video web page with chat and real time \nvideo conferencing with audio!  Your members will love it. Our members stay \nan average of 35 minutes per log-in!   We have award winning software that \ntakes less than 15 seconds to download and self install so even a complete \nnovice can use it with ease. Web pages are created on the fly as soon as \nyour someone signs up. Your members will love it !  We are offering this to \nonly a  limited amount of web master so contact us today to get started. \nYou give this to your members for FREE and then simply pay us a small \nmonthly fee.  Prices start at $500 per month for unlimited use. We pay all \nthe bandwidth charges, no hidden fees!  We are also interested in possible \npartnerships with isp's.\nhttp://www.speedycam.com\n\nTo test out our product, enter the code : isptrial  in the \"Referrer\" field \non the join page.\nJust email us before January 1, 2001 to cancel your demo and we will never \nbill you.\n  You may also email info@speedycam.com  for a demo and for custom \nvideo/audio solutions for your company.\n\n\n\nYou were sent this email because you are part of a  webmaster list, if you \nwish to be removed from our list send a email to : remove@speedycam.com\nThank you. \n\n\n\n", "id": "lists-007-13172099"}, {"subject": "RE: LABEL request only allows one set, one add..", "content": "I wouldn't say it was an oversight, but rather a use\ncase that wasn't sufficiently common to warrant making\nthe protocol more complicated to support it.\nIn particular, you would have to define the semantics\nof what would happen if one part of the request would fail\nand the other would succeed, and how to marshall that\nerror information.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Lisa Dusseault [mailto:ldusseault@xythos.com]\nSent: Friday, June 14, 2002 9:31 PM\nTo: DeltaV (E-mail)\nSubject: LABEL request only allows one set, one add...\n\n\n\n\nIs it an oversight that the LABEL request only allows one set, one add, or\none remove at a time (or one of each, but not two of any?)\n\nFor example, say I wanted to add <label-name>foo</label-name> and\n<label-name>bar</label-name> to a version in one request.  The definition of\nthe LABEL request body is:\n\n  <!ELEMENT label ANY>\n  ANY value: A sequence of elements with at most one\n  DAV:add, DAV:set, or DAV:remove element.\n\n  <!ELEMENT add (label-name)>\n  <!ELEMENT set (label-name)>\n  <!ELEMENT remove (label-name)>\n\n  <!ELEMENT label-name (#PCDATA)> PCDATA value: string\n\nSince <add> can only contain one label-name, only one label can be added per\neach request.  I would have to issue two LABEL requests to add both foo and\nbar labels.\n\nLisa\n\n\n\n", "id": "lists-007-1317798"}, {"subject": "TCP timeout parameters and wireless (was Re: pilc minutes for IETF 48", "content": "Mark,\n\nThank you for your message:\n\n>... how does the end host figure out which situation (congestion \n> or outage) it is in? \n\nThere are two end hosts.  Only one of them has a good chance of \nknowing, and the other doesn't usually care these days.\n\nI agree that a well-designed signaling method (whether by TCP \nextensions or ICMP extensions) is a good idea, and I am sure \nthat will be better-used in the future.\n\nFor now, though, in the situation most nets are in, if people \nwant services that can be accessed reliably by wireless \ncommunications, they might want to at least lower their TCP \nmaximum retransmition timeout values, consider lowering their \nRTO maximum, read Reiner's comments on the DoCoMo draft:\n\n  http://pilc.grc.nasa.gov/pilc/list/archive/0996.html\n\nand have a look at his TCP-Eifel page:\n\n  http://iceberg.cs.berkeley.edu/downloads/tcp-eifel\n\nNow, I wonder which cellphone will be the first to play MIME\naudio/mpeg attachments AND have PPP available on a DB-9 RS-232.\n\nCheers,\nJames\n\n\n\n", "id": "lists-007-13180109"}, {"subject": "Re: TCP timeout parameters and wireless (was Re: pilc minutes for IETF 48", "content": "Mark,\n\nThanks for your message:\n\n>... It is my opinion that it is a mistake to reduce the maximum\n> RTO too low....\n\nAbsolutly; I'm worried that even mentioning the RTO maximum will \ndetract attention from the maximum retransmition timeout which is \nthe REAL problem with TCP over wireless, more than all the other \nTCP parameters combined, certainly.\n\nI mean, what difference does it make if you have to wait an extra \nminute to get a connection back as long as you can get it back \ninstead of having it dropped after nine minutes?\n\nCheers,\nJames\n\n\n\n", "id": "lists-007-13189674"}, {"subject": "RE: MP4 Player Available for Downloa", "content": "Rob,\n\n>Absolutely.  You've opened up a huge door for me to give a long sales\n>pitch, but out of courtesy to the people on this list, I'll try to keep it\n>brief.  \n\nLet's see if the same words mean the same thing for both of us.\nWith MPEG-4 anybody is allowed to take the standard or the reference\nsoftware (source code) and make an implementation that conforms to the\nstandard for commercial purposes. And this not just e.g. for the \"player\"\nbut for the pieces of the player as well.\nCan I do the same with RealNetworks products? I mean, I take the source code\nof your RealProducer or RealServer or RealPlayer, modify it (still keeping\nconformity with the original product) and make a product of mine that\ncompetes with RealNetworks'?\n\n>Stated by the people working on it.  \n\nYou mean, this has been stated by those who have an interest in a certain\nbusiness model, but not by _all_ people who have a variety of different\nbusiness models.\n\n>When the chair of the working group\n>working on a standard says that he doesn't know the IPR situation with the\n>spec he's working on, \n\nThe chair is prevented from this by the rules of the organisation he works\nin\n\n>that should raise big red flags in the minds of\n>those who are actually concerned with licensability.\n\nIt seems that several kilobytes of mail have passed in vain. So, for the\nlast time:\n1. MPEG has developed a standard (MPEG-4) but is prevented from addressing\nlicensing issues by the rules of the organisation (ISO) MPEG works in\n2. an independent organisation (MPEG-4 Industry Forum - M4IF) has been set\nup by some individuals (I was one of them, even though I am no longer active\nin it because the organisation is up and running) to promote the standard\n3. A major activity of M4IF has been to start discussions about MPEG-4\nlicensing\n4. For Systems, Visual and Audio these discussions have led to a process\nthat will likely lead to the creation of patent pool(s).\n5. Note that patent pools will be strictly outside of M4IF\n6. For Video the discussions are well advanced, but the discussions are held\nby IPR holders only\n7. The MP3 and MPEG-2 cases have been mentioned to illustrate how licensing\nof standardised technologies that have a complex IPR situation (say, the 100\npatents of MPEG-2) is possible and can give rise to businesses worth several\ntens of billion dollars (e.g. DVD is the fastest growing CE product in\nhistory).\n8. It is not MPEG's fault if IPR licensing is made complex by legislation.\nOf course people will believe what they want to believe, particularly when\nthe coming true of one belief suits one's agenda better than another.\nLeonardo Chiariglione\n\n\nHi Leonardo,\n\nMore answers inline:\n\nOn Sat, 31 Mar 2001, Chiariglione Leonardo wrote:\n> [Rob Lanphier wrote:]\n> >MPEG-4 is a very different technology than MPEG-2, and \"licensable\" is v=\nery\n> >different than openly available.\n>\n> Is RealNetworks technology licensable or openly available?\n\nAbsolutely.  You've opened up a huge door for me to give a long sales\npitch, but out of courtesy to the people on this list, I'll try to keep it\nbrief.  We give away versions of RealPlayer, RealServer and RealProducer,\nand license our technology to many companies.  It's also an open,\nextensible architecture which anyone can write new datatypes\n(standards-based or otherwise):\n\nAbout our ubiquity (and hence availability):\nhttp://www.realnetworks.com/company/pressroom/pr/2001/metrics.html\nAbout our extensibility:\nhttp://www.realnetworks.com/company/pressroom/pr/2001/autoupdate.html\n\nAs to the standards we support, there's RTP, RTSP, SDP, SMIL, H.261,\nG.711, PNG, and countless others I'm forgetting, all of which have\nspecifications available for interoperability with our system -- and all\nof which are available for royalty-free implementation to the best of my\nknowledge.  Additionally, we support many of the MPEG family of standards\n(MP3 audio natively, and MPEG-1/MPEG-2 video via third party support\nthrough our plugin architecture).  We even have partners working on MPEG-4\nsupport.\n\n> >I'm saying that there doesn't\n> >exist  multimedia standard with the stated goal of being royalty-free.\n>\n> Stated by whom?\n\nStated by the people working on it.  When the chair of the working group\nworking on a standard says that he doesn't know the IPR situation with the\nspec he's working on, that should raise big red flags in the minds of\nthose who are actually concerned with licensability.\n\nRob\n\n-----Original Message-----\nFrom: Rob Lanphier [mailto:robla@real.com]\nSent: 2001 marzo sabato 21:37\nTo: Chiariglione Leonardo\nCc: discuss@apps.ietf.org\nSubject: RE: MP4 Player Available for Download\n\n\nThis message uses a character set that is not supported by the Internet\nService.  To view the original message content,  open the attached message.\nIf the text doesn't display correctly, save the attachment to disk, and then\nopen it using a viewer that can display the original character set. \n\n\n\n", "id": "lists-007-13236278"}, {"subject": "RE: MP4 Player Available for Downloa", "content": ">the use of the word\n>\"property\" to describe ideas and expression of ideas has led to a\nwidespread \n>confusion that ideas are like tangible property.  they're not.  \n\nRegrettably this confusion has lasted for some time. Martial (a Latin poet)\nwas not happy 2000 years ago when he discovered that somebody had presented\nas his a work by Martial. He was the one who coined the word \"plagiarius\".\n\n>for one thing, \n>the laws of supply and demand that apply to tangible property do not apply\nto \n\"intellectual property\". \n\nA German philosopher had the idea that there should be no property at all.\n153 years ago  he published a program of work which was implemented and had\nsome success for some time. What about publishing a similar manifesto for\n_intellectual_ property?\n\n>quite often \"intellectual property\" is worth more \n>if you give it away than if you try to control it.\n\nRight, please do so for _your own_ \"intellectual property\".\n\n>holders of IPR \n>midunderstand this at their peril.\n\nIn the little country village I live there is a saying: \"Don't teach cats to\nclimb trees\"\n\n>meanwhile, the net will treat IPR as damage and route around it. \n\nThis is what the followers of the philosopher above did for some time with\nsome success (net and IPR should be properly renamed in the new context)\n\nLeonardo Chiariglione\n\n\n-----Original Message-----\nFrom: Keith Moore [mailto:moore@cs.utk.edu]\nSent: 2001 marzo sabato 20:33\nTo: Chiariglione Leonardo\nCc: 'Keith Moore'; 'Rob Lanphier'; discuss@apps.ietf.org\nSubject: Re: MP4 Player Available for Download\n\n\n> >then the sooner the rest of the world abandons\n> >them, the better\n> \n> For whom? For owners of proprietary technologies who do not have the least\n> intention of making _their_ IPR available?\n\nno.  for everyone else.  the \"owners\" of the proprietary technology can go\nbankrupt, for all I care, and the rest of the world will be better off if \nthey do so.  of course, we'd be even better off if they got a clue.\n\nthe term \"intellectual property\" is a misnomer.  the use of the word\n\"property\" to describe ideas and expression of ideas has led to a widespread\n\nconfusion that ideas are like tangible property.  they're not.  for one\nthing, \nthe laws of supply and demand that apply to tangible property do not apply\nto \n\"intellectual property\".  quite often \"intellectual property\" is worth more \nif you give it away than if you try to control it.  holders of IPR \nmidunderstand this at their peril.\n\nmeanwhile, the net will treat IPR as damage and route around it. \n\nKeith\n\n\n\n", "id": "lists-007-13250131"}, {"subject": "Re: MP4 Player Available for Downloa", "content": "I think the point is that it's much easier to make a standard accessible\nto everyone if the standard is *designed* to minimize reliance on \nencumbered IPR.  If ISO cannot do that, that's quite unfortunate.\nIETF's rules are slightly different - the organization cannot make\na determiniation about the validity of IPR, but individuals within \nIETF are free to discuss such things and make their own decisions\nto contribute (or not) to a consensus based on such things.\n\nMPEG-4 might eventually reach the point where licensing isn't difficult\nfor those who have money to pay lawyers and purchase licenses.  That still \nleaves free software developers out of the picture.  Experience shows that \nfree software developers have often been a major force in deploying a new \ntechnology on the network - thus creating a market for commercial developers, \nwhile providing near-zero-cost implementations to those who cannot or \nprefer not to pay for them.  Cutting out the free software developers \ntherefore makes it much less likely that MPEG-4 will be widely deployed.\n\nOf course, nobody can use MPEG-4 until the licensing issues are worked out.\nMaking lawyers part of the critical path for deployment of MPEG-4 doesn't \nseem wise either.\n\nhow many more weights does this thing need until it sinks of its own accord?\n\nKeith\n\n\n\n", "id": "lists-007-13261176"}, {"subject": "RE: LABEL request only allows one set, one add..", "content": "That's a great point, but it makes me realize I may be reading the\ndefinition wrong.  I had assumed it to be possible to add one label, remove\na second and set a third, all in the same request. This assumption was based\non the following language:\n\n     The request body MUST be a DAV:label element.\n\n      <!ELEMENT label ANY>\n      ANY value: A sequence of elements with at most one DAV:add,\n      DAV:set, or DAV:remove element.\n\nPerhaps this is supposed to mean that only one child element can be inside\nlabel, but \"a sequence\" does imply more than one.  If you mean to restrict\nit to one only, then the definition should be:\n\n<!ELEMENT label (add | set | remove)>\n\nLisa\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, June 14, 2002 8:24 PM\n> To: DeltaV (E-mail)\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n>\n> I wouldn't say it was an oversight, but rather a use\n> case that wasn't sufficiently common to warrant making\n> the protocol more complicated to support it.\n> In particular, you would have to define the semantics\n> of what would happen if one part of the request would fail\n> and the other would succeed, and how to marshall that\n> error information.\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> Sent: Friday, June 14, 2002 9:31 PM\n> To: DeltaV (E-mail)\n> Subject: LABEL request only allows one set, one add...\n>\n>\n>\n>\n> Is it an oversight that the LABEL request only allows one\n> set, one add, or\n> one remove at a time (or one of each, but not two of any?)\n>\n> For example, say I wanted to add <label-name>foo</label-name> and\n> <label-name>bar</label-name> to a version in one request.\n> The definition of\n> the LABEL request body is:\n>\n>   <!ELEMENT label ANY>\n>   ANY value: A sequence of elements with at most one\n>   DAV:add, DAV:set, or DAV:remove element.\n>\n>   <!ELEMENT add (label-name)>\n>   <!ELEMENT set (label-name)>\n>   <!ELEMENT remove (label-name)>\n>\n>   <!ELEMENT label-name (#PCDATA)> PCDATA value: string\n>\n> Since <add> can only contain one label-name, only one label\n> can be added per\n> each request.  I would have to issue two LABEL requests to\n> add both foo and\n> bar labels.\n>\n> Lisa\n>\n\n\n\n", "id": "lists-007-1327003"}, {"subject": "Re: MP4 Player Available for Downloa", "content": "[First, I apologize for the blank messages I sent yesterday.  Mail system\nfailure].\n\nRob Lanphier writes:\n> As to the standards we support, there's RTP, RTSP, SDP, SMIL, H.261,\n> G.711, PNG, and countless others I'm forgetting, all of which have\n> specifications available for interoperability with our system -- and\nall\n> of which are available for royalty-free implementation to the best of\nmy\n> knowledge.  Additionally, we support many of the MPEG family of\nstandards\n> (MP3 audio natively, and MPEG-1/MPEG-2 video via third party support\n> through our plugin architecture).  We even have partners working on\nMPEG-4\n> support.\n\nI am not a multimedia expert, so please forgive what will sound like\nnaive questions.  Clearly Real and Microsoft have failed to adopt enough\ncommon standards, since consumers have to install two players so that\nthey can be assured that they can play any content.\n\nCan you point me at the standards organization that advanced SMIL?  I'm\nfamiliar with H.*, G.*,  and PNG, as well as the IETF standards and the\nMPEG standards.  My understanding is that this is largely the crux of the\nproblem.  If both Real and Microsoft grock the interchange formats of the\naudio and video, the thing that separates you guys is layout.\n\nAnd if layout is the problem, perhaps some of the people in W3C could\ncomment on what standards are applicable.\n\nEliot Lear\n[lear@ofcourseimright.com]\n\n\n\n", "id": "lists-007-13270095"}, {"subject": "RE: MP4 Player Available for Downloa", "content": ">MPEG-4 might eventually reach the point where licensing isn't difficult\n>for those who have money to pay lawyers and purchase licenses. That still \n>leaves free software developers out of the picture.  \n\nThis is the wrong perception. Patent pools are established so that anybody\ncan get a license without paying a fortune to lawyers. The existing MPEG-2\npatent pool charges 4 dollars (I am told) for an MPEG-2 decoder and 5\ndollars (again, I am told) for an MPEG-2 encoder. No question asked if not\nthat there should be a fair mechanism to count the pieces.\n\n>how many more weights does this thing need until it sinks of its own\naccord?\n\nThe ship is advancing full steam, no iceberg is sight\n\nLeonardo Chiariglione\n\n\n-----Original Message-----\nFrom: Keith Moore [mailto:moore@cs.utk.edu]\nSent: 2001 aprile domenica 16:09\nTo: Chiariglione Leonardo\nCc: 'Rob Lanphier'; discuss@apps.ietf.org\nSubject: Re: MP4 Player Available for Download\n\n\nI think the point is that it's much easier to make a standard accessible\nto everyone if the standard is *designed* to minimize reliance on \nencumbered IPR.  If ISO cannot do that, that's quite unfortunate.\nIETF's rules are slightly different - the organization cannot make\na determiniation about the validity of IPR, but individuals within \nIETF are free to discuss such things and make their own decisions\nto contribute (or not) to a consensus based on such things.\n\nMPEG-4 might eventually reach the point where licensing isn't difficult\nfor those who have money to pay lawyers and purchase licenses.  That still \nleaves free software developers out of the picture.  Experience shows that \nfree software developers have often been a major force in deploying a new \ntechnology on the network - thus creating a market for commercial\ndevelopers, \nwhile providing near-zero-cost implementations to those who cannot or \nprefer not to pay for them.  Cutting out the free software developers \ntherefore makes it much less likely that MPEG-4 will be widely deployed.\n\nOf course, nobody can use MPEG-4 until the licensing issues are worked out.\nMaking lawyers part of the critical path for deployment of MPEG-4 doesn't \nseem wise either.\n\nhow many more weights does this thing need until it sinks of its own accord?\n\nKeith\n\n\n\n", "id": "lists-007-13279212"}, {"subject": "Re: MP4 Player Available for Downloa", "content": "> >MPEG-4 might eventually reach the point where licensing isn't difficult\n> >for those who have money to pay lawyers and purchase licenses. That still\n> >leaves free software developers out of the picture.\n> \n> This is the wrong perception. Patent pools are established so that anybody\n> can get a license without paying a fortune to lawyers. The existing MPEG-2\n> patent pool charges 4 dollars (I am told) for an MPEG-2 decoder and 5\n> dollars (again, I am told) for an MPEG-2 encoder.\n\nThat's exhorbitant compared to the cost of the software, which is zero.\nof course, this might explain why there are so many unlicensed players \nand encoders out there - people are widely ignoring these patents.\nstill, while it's heartening to see patents being routinely ignored, \nit's not good to have the developers or distributors of free software \nthreatened by the possibility of patent lawsuits.  \n\nprotocol standards need to be free, period.\n\n> The ship is advancing full steam, no iceberg is sight\n\nthe same thing was true of the Titanic.\n\nKeith\n\n\n\n", "id": "lists-007-13290032"}, {"subject": "RE: MP4 Player Available for Downloa", "content": ">That's exhorbitant compared to the cost of the software, which is zero.\n\nThat is the cost for a hardware based device. 1%-2% for IPR is not\nunreasonable by the people concerned.\n\n>protocol standards need to be free, period.\n\nWhat about word and powerpoint?\n\n>the same thing was true of the Titanic.\n\nNot the same captain\n\nLeonardo Chiariglione\n\n-----Original Message-----\nFrom: Keith Moore [mailto:moore@cs.utk.edu]\nSent: 2001 aprile domenica 21:19\nTo: Chiariglione Leonardo\nCc: 'Keith Moore'; 'Rob Lanphier'; discuss@apps.ietf.org\nSubject: Re: MP4 Player Available for Download\n\n\n> >MPEG-4 might eventually reach the point where licensing isn't difficult\n> >for those who have money to pay lawyers and purchase licenses. That still\n> >leaves free software developers out of the picture.\n> \n> This is the wrong perception. Patent pools are established so that anybody\n> can get a license without paying a fortune to lawyers. The existing MPEG-2\n> patent pool charges 4 dollars (I am told) for an MPEG-2 decoder and 5\n> dollars (again, I am told) for an MPEG-2 encoder.\n\nThat's exhorbitant compared to the cost of the software, which is zero.\nof course, this might explain why there are so many unlicensed players \nand encoders out there - people are widely ignoring these patents.\nstill, while it's heartening to see patents being routinely ignored, \nit's not good to have the developers or distributors of free software \nthreatened by the possibility of patent lawsuits.  \n\nprotocol standards need to be free, period.\n\n> The ship is advancing full steam, no iceberg is sight\n\nthe same thing was true of the Titanic.\n\nKeith\n\n\n\n", "id": "lists-007-13298814"}, {"subject": "Re: MP4 Player Available for Downloa", "content": "> >That's exhorbitant compared to the cost of the software, which is zero.\n> \n> That is the cost for a hardware based device. 1%-2% for IPR is not\n> unreasonable by the people concerned.\n\n1-2% of parts cost or of retail cost?  when I was doing hardware\nengineering for a large consumer electronics firm, even a fifty\ncent increase in parts cost needed considerable justification.\n \n> >protocol standards need to be free, period.\n> \n> What about word and powerpoint?\n\nwhat about them?  they're not standards, they present considerable\nsecurity risks to those who use them, and powerpoint seems to be \ndetrimental to the minds of those who use it.  I discourage their\nuse as much as possible.\n\n> >the same thing was true of the Titanic.\n> \n> Not the same captain\n\nof course not!\n\nbut it might be well to point out that while he was quite \nexperienced at sea, the nature of the vessels he was captaining \nhad changed.  when a crisis struck, he wasn't prepared for those changes...\n\nKeith\n\np.s. until that voyage he described his career as \"uneventful\".\n\n\n\n", "id": "lists-007-13309038"}, {"subject": "RE: MP4 Player Available for Downloa", "content": ">even a fifty\n>cent increase in parts cost needed considerable justification.\n\nSomething like the cost of doing business\n\n>what about them?  they're not standards,\n\nSo what? Tens of million people use them. And I am one of them because I\nknow that when I send a word attachment people can read it.\n\n>p.s. until that voyage he described his career as \"uneventful\".\n\nOne day I should tell you the MPEG story. I like the idea of my last 13\nyears perceived as uneventful\n\nLeonardo Chiariglione\n\n\n-----Original Message-----\nFrom: Keith Moore [mailto:moore@cs.utk.edu]\nSent: domenica 1 aprile 2001 22.04\nTo: Chiariglione Leonardo\nCc: 'Keith Moore'; 'Rob Lanphier'; discuss@apps.ietf.org\nSubject: Re: MP4 Player Available for Download\n\n\n> >That's exhorbitant compared to the cost of the software, which is zero.\n> \n> That is the cost for a hardware based device. 1%-2% for IPR is not\n> unreasonable by the people concerned.\n\n1-2% of parts cost or of retail cost?  when I was doing hardware\nengineering for a large consumer electronics firm, even a fifty\ncent increase in parts cost needed considerable justification.\n \n> >protocol standards need to be free, period.\n> \n> What about word and powerpoint?\n\nwhat about them?  they're not standards, they present considerable\nsecurity risks to those who use them, and powerpoint seems to be \ndetrimental to the minds of those who use it.  I discourage their\nuse as much as possible.\n\n> >the same thing was true of the Titanic.\n> \n> Not the same captain\n\nof course not!\n\nbut it might be well to point out that while he was quite \nexperienced at sea, the nature of the vessels he was captaining \nhad changed.  when a crisis struck, he wasn't prepared for those changes...\n\nKeith\n\np.s. until that voyage he described his career as \"uneventful\".\n\n\n\n", "id": "lists-007-13317840"}, {"subject": "Re: MP4 Player Available for Downloa", "content": "> >what about them?  they're not standards,\n> \n> So what? Tens of million people use them. And I am one of them because I\n> know that when I send a word attachment people can read it.\n\nand the people who can't read it don't matter, right?\n\nKeith\n\n\n\n", "id": "lists-007-13328247"}, {"subject": "Re: MP4 Player Available for Downloa", "content": "On Sun, 1 Apr 2001, Eliot Lear wrote:\n> I am not a multimedia expert, so please forgive what will sound like\n> naive questions.  Clearly Real and Microsoft have failed to adopt enough\n> common standards, since consumers have to install two players so that\n> they can be assured that they can play any content.\n\nNo, you're right, there's been a breakdown here.  There's not much to\ninteroperate with in Microsoft's player.  I believe we support all of the\nstandards that they do, but that's not saying much.  We both support\nplaying MP3 over HTTP, I think (I know RealPlayer does).\n\nMicrosoft continues to push the MMS (Microsoft Media Server) protocol,\nwhich is their proprietary alternative to RTSP.  We support both RTSP/RTP\n(completely standard) and RTSP/RDT (our standard/proprietary hybrid).\n\n> Can you point me at the standards organization that advanced SMIL?\n\nThe W3C:  http://www.w3.org/AudioVideo\n\n> I'm\n> familiar with H.*, G.*,  and PNG, as well as the IETF standards and the\n> MPEG standards.  My understanding is that this is largely the crux of the\n> problem.  If both Real and Microsoft grock the interchange formats of the\n> audio and video, the thing that separates you guys is layout.\n\nBut that's the problem:  there's no standard interchange format, other\nthan MPEG-4, which has the problems we've been bickering about.\n\nA very long time ago (early 1998), there were a couple of drafts submitted\nto the IETF on this:\n\nAdvanced Streaming Format (Microsoft):\nhttp://www.alternic.org/drafts/drafts-f-g/draft-fleischman-asf-01.html\n\nRealMedia File Format (RealNetworks):\nhttp://www.alternic.org/drafts/drafts-h-i/draft-heftagaub-rmff-00.html\n\n...but there was never really a lot of followup on either draft.  I know\nthat we would have gladly participated in a working group had one been\nformed around the subject at the time, but we never pushed the issue, and\nI assume Microsoft nor anyone else did either.  Perhaps it's time to\nrevive the issue.\n\n> And if layout is the problem, perhaps some of the people in W3C could\n> comment on what standards are applicable.\n\nAs I mentioned, we've worked with the W3C for a very long time on SMIL,\nand support SMIL 1.0 in our player, which is a W3C Recommendation.\nMicrosoft continues to support a couple of different specifications,\nneither of which are the SMIL Language:\n\n1.  Windows Media player supports a proprietary format known as ASX.  This\nis a very limited format somewhere in between a simple playlist like M3U\nand SMIL.  It's an XML-ish markup language that doesn't really conform to\nXML.\n\n2.  Internet Explorer supports \"HTML+Time\", which has morphed into\n\"XHTML+SMIL\" in the W3C.  IE's implementation is not really geared toward\nA/V layout so much as the types of animations you see in Powerpoint\npresentations.  Some of the more advanced demos are a little more like\nFlash, but I haven't really seen any tools with the sophistication of\nMacromedia Flash that work with it (and the W3C's SVG looks like a much\nmore promising application for standards-based Flash-like applications).\nFurthermore, the specification is a work in progress and not implemented\nin any playback engine that I'm aware of other than IE.\n\nHope this helps.\n\nRob\n\n\n\n", "id": "lists-007-13336175"}, {"subject": "RE: MP4 Player Available for Downloa", "content": "On Sun, 1 Apr 2001, Chiariglione Leonardo wrote:\n> >Absolutely.  You've opened up a huge door for me to give a long sales\n> >pitch, but out of courtesy to the people on this list, I'll try to keep it\n> >brief.\n>\n> Let's see if the same words mean the same thing for both of us.\n> With MPEG-4 anybody is allowed to take the standard or the reference\n> software (source code) and make an implementation that conforms to the\n> standard for commercial purposes.\n\nAnyone is free to use it, so long as they don't mind getting sued for\npatent infringment.  Moreover, that should be qualified to say \"any ISO\nmember\", because it's not exactly freely downloadable as I understand it.\nIs there a publically available URL to the source code?\n\nDon't get me wrong...we're not against paying patent royalties.\nRealPlayer is a fully licensed MP3 implementation.  But that's because\nit's clear that one can go to Thomson and get that license, and we were\nable to negotiate a deal that is consistent with our business model.\n\nEven if RealNetworks manages to negotiate a license that would let us ship\nan MPEG-4 solution, it's unclear who we'll be interoperating with.\nFurthermore, it seems pretty clear that any open source implementation\nthat someone would actually want to use will exist.\n\n> And this not just e.g. for the \"player\"\n> but for the pieces of the player as well.\n> Can I do the same with RealNetworks products? I mean, I take the source code\n> of your RealProducer or RealServer or RealPlayer, modify it (still keeping\n> conformity with the original product) and make a product of mine that\n> competes with RealNetworks'?\n\nWell, we have made our source code available under certain terms in some\nbusiness deals.  However, we're not a standards body; we're a company\nwhich makes its living selling software (among other things).  \"Open\nstandards\"  and \"open source\" are two completely different things.  Since\nwe were having a standards argument, I was focusing on the \"open\nstandards\" use of the word \"open\".\n\nAnyone is free to use the specifications we support (and in some cases,\nhelped create), and create an implementation that competes with ours.\n\nOn the source code side, we have done plenty of work on reference\nsoftware.  We recently put our open source RTSP proxy reference up on\nSourceForge, which is under a very BSD-ish license:\n\nhttp://rtsp.sourceforge.net\n\nThe primary purpose of this software is to provide a firewall reference,\nbut its modularized in such a way that client or server software could be\nwritten.\n\nWe're interested in working with and interoperating with anyone working on\nopen source reference software in streaming media.  I've had many\nconversations with people in the open source community already on this\nsubject, and hope to have many more.\n\n> >Stated by the people working on it.\n>\n> You mean, this has been stated by those who have an interest in a certain\n> business model, but not by _all_ people who have a variety of different\n> business models.\n\nWhy did you even bother quoting that sentence, when you weren't going to\nquote the context?  Let me repeat my assertion...reconstructed with my\nclarification and dolled up a little bit:\n\nI'm saying that there doesn't exist a complete multimedia standard with\nthe stated goal of available on a royalty-free basis, as stated by the\npeople working on the standard.  I think it's possible...but it doesn't\nexist yet.\n\n> >When the chair of the working group\n> >working on a standard says that he doesn't know the IPR situation with the\n> >spec he's working on,\n>\n> The chair is prevented from this by the rules of the organisation he works\n> in\n>\n> >that should raise big red flags in the minds of\n> >those who are actually concerned with licensability.\n>\n> It seems that several kilobytes of mail have passed in vain.\n\nIt depends on what your goals are.  I think this thread has probably been\nvery educational for those who previously thought that MPEG-4 was a truly\nopen standard.  I understand that the rules of ISO seem to prohibit the\ndevelopment of a truly open standard, but ISO isn't the only game in town.\n\nI've personally given up on ISO, which is why I was sending my email to\nthe IETF.  I mistakenly also sent it to the ISO/MPEG working group.  I\nthink your participation in this discussion has been incredibly valuable\nin helping others understand the issues involved.  However, I'm pretty\nsure we're no longer at the point where we don't understand the facts of\nthe matter, but rather, I think we just plain disagree on what constitutes\nan acceptable outcome.\n\n> So, for the\n> last time:\n> 1. MPEG has developed a standard (MPEG-4) but is prevented from addressing\n> licensing issues by the rules of the organisation (ISO) MPEG works in\n> 2. an independent organisation (MPEG-4 Industry Forum - M4IF) has been set\n> up by some individuals (I was one of them, even though I am no longer active\n> in it because the organisation is up and running) to promote the standard\n> 3. A major activity of M4IF has been to start discussions about MPEG-4\n> licensing\n> 4. For Systems, Visual and Audio these discussions have led to a process\n> that will likely lead to the creation of patent pool(s).\n> 5. Note that patent pools will be strictly outside of M4IF\n> 6. For Video the discussions are well advanced, but the discussions are held\n> by IPR holders only\n> 7. The MP3 and MPEG-2 cases have been mentioned to illustrate how licensing\n> of standardised technologies that have a complex IPR situation (say, the 100\n> patents of MPEG-2) is possible and can give rise to businesses worth several\n> tens of billion dollars (e.g. DVD is the fastest growing CE product in\n> history).\n> 8. It is not MPEG's fault if IPR licensing is made complex by legislation.\n\nI'm not trying to assign blame, but rather, assess the acceptability of\nthe outcome.  I realize that you were prohibited from asking the questions\nyou needed to in order to understand the IPR situation.  However, I was\npointing out the fact that you don't know the IPR situation as a symptom\nof a problem, not necessarily a cause.\n\n> Of course people will believe what they want to believe, particularly when\n> the coming true of one belief suits one's agenda better than another.\n\nLeonardo, you keep repeating this, and this thinly-veiled aspersions on my\nmotivations is becoming offensive.  Either come out with a real criticism\nso I can defend myself, or knock it off with this indirect questioning of\nmy agenda.\n\nI'll put my cards on the table.  I work for RealNetworks, who, as you\npointed out, has a duty to its stockholders to look out for its corporate\ninterests just like any other publically-traded company.  We have\nproprietary elements to our software (RealAudio, RealVideo, RDT,\nSureStream), but we also recognize that practical standards fuel the\ngrowth of the industry as a whole.  Where practical standards exist, we\nsupport them, and we partcipate in the creation of new ones (RTSP and SMIL\nare two we've been heavily involved in).  This whole thread began with the\nexploration of where we can have more practical standards.\n\nMPEG-4 doesn't seem like a practical standard.  It seems like a way for a\nlot of patent holders to lock up the industry for the next 10-20 years,\nprovided they can even agree on how to do it.\n\nRob\n\n\n> Hi Leonardo,\n>\n> More answers inline:\n>\n> On Sat, 31 Mar 2001, Chiariglione Leonardo wrote:\n> > [Rob Lanphier wrote:]\n> > >MPEG-4 is a very different technology than MPEG-2, and \"licensable\" is v=\n> ery\n> > >different than openly available.\n> >\n> > Is RealNetworks technology licensable or openly available?\n>\n> Absolutely.  You've opened up a huge door for me to give a long sales\n> pitch, but out of courtesy to the people on this list, I'll try to keep it\n> brief.  We give away versions of RealPlayer, RealServer and RealProducer,\n> and license our technology to many companies.  It's also an open,\n> extensible architecture which anyone can write new datatypes\n> (standards-based or otherwise):\n>\n> About our ubiquity (and hence availability):\n> http://www.realnetworks.com/company/pressroom/pr/2001/metrics.html\n> About our extensibility:\n> http://www.realnetworks.com/company/pressroom/pr/2001/autoupdate.html\n>\n> As to the standards we support, there's RTP, RTSP, SDP, SMIL, H.261,\n> G.711, PNG, and countless others I'm forgetting, all of which have\n> specifications available for interoperability with our system -- and all\n> of which are available for royalty-free implementation to the best of my\n> knowledge.  Additionally, we support many of the MPEG family of standards\n> (MP3 audio natively, and MPEG-1/MPEG-2 video via third party support\n> through our plugin architecture).  We even have partners working on MPEG-4\n> support.\n>\n> > >I'm saying that there doesn't\n> > >exist  multimedia standard with the stated goal of being royalty-free.\n> >\n> > Stated by whom?\n>\n> Stated by the people working on it.  When the chair of the working group\n> working on a standard says that he doesn't know the IPR situation with the\n> spec he's working on, that should raise big red flags in the minds of\n> those who are actually concerned with licensability.\n>\n> Rob\n>\n> -----Original Message-----\n> From: Rob Lanphier [mailto:robla@real.com]\n> Sent: 2001 marzo sabato 21:37\n> To: Chiariglione Leonardo\n> Cc: discuss@apps.ietf.org\n> Subject: RE: MP4 Player Available for Download\n>\n>\n> This message uses a character set that is not supported by the Internet\n> Service.  To view the original message content,  open the attached message.\n> If the text doesn't display correctly, save the attachment to disk, and then\n> open it using a viewer that can display the original character set.\n>\n\n\n\n", "id": "lists-007-13346998"}, {"subject": "RE: MP4 Player Available for Downloa", "content": "At 20.57 -0700 01-04-01, Rob Lanphier wrote:\n>I've personally given up on ISO, which is why I was sending my email to\n>the IETF.  I mistakenly also sent it to the ISO/MPEG working group.  I\n>think your participation in this discussion has been incredibly valuable\n>in helping others understand the issues involved.  However, I'm pretty\n>sure we're no longer at the point where we don't understand the facts of\n>the matter, but rather, I think we just plain disagree on what constitutes\n>an acceptable outcome.\n\nAs Area Director of Applications Area which uses this mailing list \nfor discussions of various topics, I ask you all to now stop this \ndiscussion in its current form.\n\nI have been talking with several  people the last couple of months, \nand it is clear that there are some interest in having some \ndiscussion in the IETF using the IPR rules IETF uses, and using the \nopen process which IETF uses.\n\nBecause of this, I ask people to to to focus so the goal is to \npresent an agenda for a BOF in London during the 51'st IETF.\n\nIETF will by itself follow liason agreements regarding \"new work \nitems\" with other organizations like ISO and W3C to minimize the \namount of duplicate work which is done.\n\nI therefore ask people to synchronize, and come with a proposal for a \nBOF when the IETF is announced, and BOF proposals are asked for.\n\n    paf\n\n\n-- \nPatrik F?ltstr?m <paf@cisco.com>                         Cisco Systems\nConsulting Engineer                                  Office of the CSO\nPhone: (Stockholm) +46-8-6859131            (San Jose) +1-408-525-8509\n        PGP: 2DFC AAF6 16F0 F276 7843  2DC1 BC79 51D9 7D25 B8DC\n\n\n\n", "id": "lists-007-13365524"}, {"subject": "RE: MP4 Player Available for Downloa", "content": ">At 10:00 AM 3/14/01 -0800, Dave Singer wrote:\n>>I hate to carry on an off-topic thread, but the MPEG-4 file format \n>>is not heavily encumbered.  To my knowledge, we (Apple) are the \n>>only IPR owners in the file format per se, and the license needed \n>>would be the same as for the QT file format (i.e. it's the same \n>>IPR), for which we have plenty of examples of licensees (including \n>>Real Networks).\n>\n>Are you really willing to stand up and disclose the terms of the \n>Apple/RealNetworks agreement?  I think it's entirely inappropriate \n>to cite the Apple/RealNetworks agreement as an example of an MPEG-4 \n>file format licensing success story, and entirely inappropriate to \n>discuss the terms of any deal that go beyond the joint press release:\n>\n>http://www.realnetworks.com/company/pressroom/pr/2000/apple.html\n>\n>Besides that, I don't think it's at all reasonable that if \n>RealNetworks and some other company/project want to interoperate, \n>that that other company/project should have to go to Apple to get \n>permission.  Do you?\n>\n>Rob\n\nOf course not.  I was merely dealing with a common complaint about \nlicensable technology -- that people seem to be unable to obtain \nlicenses.  I wanted to point out that this was not the case here.  As \nyou note, I am merely pointing out a fact of public knowledge:  that \nApple and Real have agreed on terms for Real to use the QT Streaming \nformat.  This is also true of a number of other companies who also \nsupport the QT Streaming format.\n-- \nDavid Singer\nApple Computer/QuickTime\n\n\n\n", "id": "lists-007-13374848"}, {"subject": "RE: LABEL request only allows one set, one add..", "content": "Lisa,\n\nI think the usage of \"ANY\" is intentional (for RFC3253). The wording just\nstates what DAV's XML enxtensibilty rules require -- the DAV:label element\nmay contain a sequence of arbitrary elements, of which there may be only one\nDAV:add, DAV:set or DAV:remove element.\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Lisa Dusseault\n> Sent: Saturday, June 15, 2002 4:10 PM\n> To: 'Clemm, Geoff'; 'DeltaV (E-mail)'\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n>\n> That's a great point, but it makes me realize I may be reading the\n> definition wrong.  I had assumed it to be possible to add one\n> label, remove\n> a second and set a third, all in the same request. This\n> assumption was based\n> on the following language:\n>\n>      The request body MUST be a DAV:label element.\n>\n>       <!ELEMENT label ANY>\n>       ANY value: A sequence of elements with at most one DAV:add,\n>       DAV:set, or DAV:remove element.\n>\n> Perhaps this is supposed to mean that only one child element can be inside\n> label, but \"a sequence\" does imply more than one.  If you mean to restrict\n> it to one only, then the definition should be:\n>\n> <!ELEMENT label (add | set | remove)>\n>\n> Lisa\n>\n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Friday, June 14, 2002 8:24 PM\n> > To: DeltaV (E-mail)\n> > Subject: RE: LABEL request only allows one set, one add...\n> >\n> >\n> >\n> > I wouldn't say it was an oversight, but rather a use\n> > case that wasn't sufficiently common to warrant making\n> > the protocol more complicated to support it.\n> > In particular, you would have to define the semantics\n> > of what would happen if one part of the request would fail\n> > and the other would succeed, and how to marshall that\n> > error information.\n> >\n> > Cheers,\n> > Geoff\n> >\n> > -----Original Message-----\n> > From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> > Sent: Friday, June 14, 2002 9:31 PM\n> > To: DeltaV (E-mail)\n> > Subject: LABEL request only allows one set, one add...\n> >\n> >\n> >\n> >\n> > Is it an oversight that the LABEL request only allows one\n> > set, one add, or\n> > one remove at a time (or one of each, but not two of any?)\n> >\n> > For example, say I wanted to add <label-name>foo</label-name> and\n> > <label-name>bar</label-name> to a version in one request.\n> > The definition of\n> > the LABEL request body is:\n> >\n> >   <!ELEMENT label ANY>\n> >   ANY value: A sequence of elements with at most one\n> >   DAV:add, DAV:set, or DAV:remove element.\n> >\n> >   <!ELEMENT add (label-name)>\n> >   <!ELEMENT set (label-name)>\n> >   <!ELEMENT remove (label-name)>\n> >\n> >   <!ELEMENT label-name (#PCDATA)> PCDATA value: string\n> >\n> > Since <add> can only contain one label-name, only one label\n> > can be added per\n> > each request.  I would have to issue two LABEL requests to\n> > add both foo and\n> > bar labels.\n> >\n> > Lisa\n> >\n>\n>\n\n\n\n", "id": "lists-007-1338093"}, {"subject": "Web desig", "content": "Hi!\nHopefully you're the right person to be talking too, if not, please pass\nthis message to the appropriate person in your organization or delete it\nand accept our apologies! We are a web hosting company and we receive many\nenquires about web design, which we do not do. As a service to our\ncustomers and web designers we are launching a free searchable database of\ndesigners and design firms.\n\nIf you or your company would like to be listed, please take a moment to\nvisit http://www.asgard.net/us/ and click on the Web Design link.\nEvery person who adds themselves before April 15 will go in the draw for a\nnew Microsoft Optical Intellimouse.\n\nThere are absolutely no obligations to list in the directory, but we would\nappreciate it if you also review our services. We offer .com domain\nregistrations for US$12/yr (free with our business plan) and websites from\nUS$4.95/mth. Furthermore, we pay *ongoing* commissions up to 30% to\nbusinesses and individuals who refer clients to our services. This can be\nquite a lucrative addition to your existing income, with no extra\nexpenses. You can review more information about our services and partner\nprogram on our website.\n\nAgain, our apologies if this reached you by mistake. We retrieved your\nemail address from search engine listings under 'web design' which is\nundoubtedly a less than perfect method! Be assured it is a once and only\nmailing and we won't bother you again.\n\nThank you for your time!\nAsgard Web Technologies\nhttp://www.asgard.net\nemail:info@asgard.net\n\n\n\n", "id": "lists-007-13384228"}, {"subject": "huidziekt", "content": "Vijf jaar voordat deze foto's werden genomen werd bij mij diagnose \nreumatische artritis gesteld en als zodanig ook behandeld. Niets hielp. \nToen de ziekte zich zo manifesteerde zoals u hieronder kunt zien..........\nhttp://www.naardedokter.com/testimonials/sys_lup_eryth.htm\n\n\n\n", "id": "lists-007-13391899"}, {"subject": "New date and time draf", "content": "FYI,\n\nI've submitted a revision of the date and time draft Chris Newman wrote \nsome time ago.\n\nOne of the goals for the current revision is to create a separate \nspecification that answers a clear and present requirement from other parts \nconcerning which there is less clear consensus.  Specifically, this draft \naims to move forward the timestamp elements of Chris' original work, while \nallowing the trickier \"schedule events\" elements to be picked up and \ndeveloped by a group with more specific relevant expertise and goals, if \nrequired.\n\n#g\n--\n\nA New Internet-Draft is available from the on-line Internet-Drafts directories.\nThis draft is a work item of the Instant Messaging and Presence Protocol \nWorking Group of the IETF.\n\n         Title           : Date and Time on the Internet: Timestamps\n         Author(s)       : C. Newman, G. Klyne\n         Filename        : draft-ietf-impp-datetime-00.txt\n         Pages           : 16\n         Date            : 03-Apr-01\n\nThis document defines a date and time format for use in Internet\nprotocols that is a profile of the ISO 8601 [ISO8601] standard for\nrepresentation of dates and times using the Gregorian calendar.\n\nA URL for this Internet-Draft is:\nhttp://www.ietf.org/internet-drafts/draft-ietf-impp-datetime-00.txt\n\n\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-13398122"}, {"subject": "Re: New date and time draf", "content": ">         Title           : Date and Time on the Internet: Timestamps\n>         Author(s)       : C. Newman, G. Klyne\n>         Filename        : draft-ietf-impp-datetime-00.txt\n\nI'd just like to offer kudos to the two of you for doing the detail \nwork to put this together.  This is the unglorious but very useful \nsort of thing that is not done enough and not recognized enough. \nWould that we'd had it when we were doing HTTP.  Thank you.\n\n\n\n", "id": "lists-007-13406681"}, {"subject": "Protocol conversion issue", "content": "I am tutoring two students, who are writing a masters paper\nin the area of protocol conversion. There are a number\nof important issues, such as:\n\n- When should the protocol converter modify data, and not\n   modify data\n\n- Should the protocol converter keeps its own data base\n   of transactions, which can be used to enhance later\n   transactions with data from earlier transactions\n   (example: If an incoming e-mail is converted from\n   Internet mail to vendor-specific mail, you save\n   the original mail in Internet format, to use if\n   you need to send it back to Internet again.)\n\nQuestion: Does anyone know of anything written on this\nissue of protocol conversion? Any input for the paper\nwhich the students are to work on?\n\n(Note: Their area is not e-mail, I just gave that\nfor an example above.)\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-13413687"}, {"subject": "RE: Protocol conversion issue", "content": "Please unsubscribe me or let me know how to unsubscribe.  \n\n-----Original Message-----\nFrom: Jacob Palme [mailto:jpalme@dsv.su.se] \nSent: Wednesday, April 11, 2001 2:50 AM\nTo: discuss@apps.ietf.org\nSubject: Protocol conversion issues\n\nI am tutoring two students, who are writing a masters paper\nin the area of protocol conversion. There are a number\nof important issues, such as:\n\n- When should the protocol converter modify data, and not\n   modify data\n\n- Should the protocol converter keeps its own data base\n   of transactions, which can be used to enhance later\n   transactions with data from earlier transactions\n   (example: If an incoming e-mail is converted from\n   Internet mail to vendor-specific mail, you save\n   the original mail in Internet format, to use if\n   you need to send it back to Internet again.)\n\nQuestion: Does anyone know of anything written on this\nissue of protocol conversion? Any input for the paper\nwhich the students are to work on?\n\n(Note: Their area is not e-mail, I just gave that\nfor an example above.)\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-13421433"}, {"subject": "available: Security Design for Application Protocol", "content": "My extemporaneous talk on \"Security Design for Application Protocols\" at the \nApps Area session at the 50th IETF (Minneapolis) is now available here in \n.html & .pdf formats (URLs folded; the .pdf is the easier to deal with and use \nimho)..\n\nhttp://www.stanford.edu/~hodges/talks\n /Hodges-SecurityDesignForAppProtocols-2001-04-10.pdf\n\n /Hodges-SecurityDesignForAppProtocols-2001-04-10.html\n\nI'm working on getting the .ppt source file up there on my website and hope to \nhave there in the next few days.\n\nthanks,\n\nJeffH\n\n\n\n", "id": "lists-007-13430390"}, {"subject": "Customer Care Center                          1596", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-13438426"}, {"subject": "Two new drafts: Multipart/Interleaved and Application/BatchBee", "content": "I recently published two drafts\n\n\nhttp://www.ietf.org/internet-drafts/draft-herriot-multipart-interleaved-00.t\nxt\n\nhttp://www.ietf.org/internet-drafts/draft-herriot-application-batchbeep-00.t\nxt\n\n(Note that the first draft is not available via the Internet Drafts Search\nengine, but is accessible via the URL supplied above).\nThe problem that motivates these two proposals is the case of an XML\ndocument with attachments, such as gif images. Normally, a Multipart/Related\nrepresentation would suffice. The first body part would be the XML and the\nremaining body parts would be gif images, each referenced from the XML. But\nwhen a memory constrained printer encounters a reference to a gif image body\npart in the XML, it might not have the space to hold the remaining XML while\nit scans ahead for the gif image. This problem suggests the need to be able\nto interleave chunks of XML and gif images. Each of the two drafts provide a\nsolution for interleaving chunks.\nBoth drafts define new MIME types. The first draft defines\nMultipart/Interleaved and Application/Chunk content types, which extend\nMultipart/Related for use with memory constrained devices. The second draft\ndefines Application/BatchBeep content type, which defines a MIME type whose\ncontents is the client-to-server portion of a BEEP session.  Although the\ntwo drafts are based on two very different ideas, the examples show that the\ntwo solutions are nearly byte-for-byte identical. The primary difference is\nthat the boundary string in the Multipart/Interleaved solution is a trailer\nand/or header in the Application/BatchBeep solution.\nI would appreciate any comments on these drafts.\nBob Herriot\n--------------------------------------------------------------------\nThe following is the abstract for the Multipart/Interleaved draft.\nThe Multipart/Interleaved content-type, like the Multipart/Related\ncontent-type, provides a mechanism for representing objects that consist of\nmultiple components.  Each body part of a Multipart/Related entity\nrepresents a component, whereas each body part of a Multipart/Interleaved\nentity represents either a component or a part of a component. A body part\nthat represents a part of a component has the content-type of\nApplication/Chunk. With Multipart/Related, a body part and its reference in\nsome other body part may be separated by many octets -- more octets than a\nmemory-constrained device can deal with. With Multipart/Interleaved, a body\npart can represent a part of a component. This allows a body part and its\nreference in some other body part to be made quite close -- close enough for\na memory-constrained device to deal with.  This document defines the\nMultipart/Interleaved content-type and the Application/Chunk content-type.\nIt also provides examples of its use.\n---------------------------------------------------------------------\nThe following is the abstract for the Application/BatchBeep draft.\nThe Application/BatchBeep content-type, like the Multipart/Related\ncontent-type, provides a mechanism for representing objects that consist of\nmultiple components.  An Application/BatchBeep entity contains the wire\nrepresentation of the client-to-server part of a BEEP (Blocks Extensible\nExchange Protocol) session, which consists of sequence of frames. Each frame\ncontains a message or a part of a message. Each message (other than channel\n0 messages) represents a component of the compound object, just as a body\npart of a Multipart/Related entity represents a component. With a\nMultipart/Related entity, a body part and its reference in some other body\npart may be separated by many octets -- more octets than a\nmemory-constrained device can deal with. With an Application/BatchBeep\nentity, a frame can contain part of a message. This allows a message and its\nreference in some other message to be made quite close -- close enough for a\nmemory-constrained device to deal with.  This document defines the\nApplication/BatchBeep content-type. It also provides examples of its use.\n\n\n\n", "id": "lists-007-13445236"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application/BatchBee", "content": "I only glanced at this, so maybe I misunderstood it.  However...\ngiven that the components of a multipart/interleaved aren't likely to be\nusable by a traditional MIME reader anyway, I see little point in\nusing the MIME multipart syntax to distinguish one chunk from another.\nand I don't really see a good way to build this in such a way that\nexisting MIME readers are likely to deal with it well.\n\nI would suggest a new application/multiplexed content-type which would\nbe divided up into chunks, each chunk representing the next consecutive\nelement of some stream.  Each stream could be a MIME body part, with\nthe normal header and content, but each stream could also be fragmented\nas necessary.  Ideally, the semantics would be similar to multipart\nrelated, and it would be possible to transform an application/multiplexed \ncontent into an equivalent multipart/related content - just that in\nthe first case the various components would be divided up into chunks\nand multiplexed into a single body part (as far as MIME was concerned)\nand in the second case the components would each appear as a separate\nMIME body part within an enclosing multipart/related.\n\nKeith\n\n\n\n", "id": "lists-007-13457049"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and   Application/BatchBee", "content": "By way of historical context, I will note that my own reaction to the idea \nof these specifications was that they should just use BEEP:  The purpose of \nthe multiplexing at to permit multiple data streams without one blocking \nthe other, and with constrained buffering requirements at the receiver.\n\nThat is a dynamic requirement that depends upon the detail of the transport \nand the receiver.\n\nThat's the job of a protocol, not a format.\n\nd/\n\nAt 12:36 PM 4/16/2001, Herriot, Robert wrote:\n>I recently published two drafts\n>\n>http://www.ietf.org/internet-drafts/draft-herriot-multipart-interleaved-00.txt\n>\n>http://www.ietf.org/internet-drafts/draft-herriot-application-batchbeep-00.txt\n\n>----------\n\nDave Crocker   <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking   <http://www.brandenburg.com>\ntel: +1.408.246.8253;   fax: +1.408.273.6464\n\n\n\n", "id": "lists-007-13465833"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application/BatchBee", "content": "> I only glanced at this, so maybe I misunderstood it.  However...\n> given that the components of a multipart/interleaved aren't likely to be\n> usable by a traditional MIME reader anyway, I see little point in\n> using the MIME multipart syntax to distinguish one chunk from another.\n> and I don't really see a good way to build this in such a way that\n> existing MIME readers are likely to deal with it well.\n\nI have a much more fundamental issue with this idea. I see very little utility\nin this mechanism because it presumes that a client can predict when the server\nwill need certain content. I doubt very much clients will in general be able to\ndo this.\n\nPerhaps this would work in the extremely simple case of an XML document with a\nfew embedded GIFs (although in such a case I'd simply embed the GIFs in the XML\ntext itself -- there are techniques for doing this). But anything else is going\nto be a problem. For example, consider the case where you have a couple of GIFs\nthat are repeated dozens or hundreds of times throughout the document. (This is\na very common thing to do.) Now the client either has to assume that the server\nwill cache the image or it has to repeat it every time it is used. The former\nmay not work and the latter could easily increase the amount of data\ntransferred by several orders of magnitude.\n\nOr consider the case where a more complex document structure with multiple XML\nparts. Cases will arise where the client has no clear idea what order the\nserver is going to operate in.\n\nIn fact you don't even know level of granularity is needed even in the simple\ncases. Even if you make this something the print server tells the client, I'm\nnot even sure how it would describe its constraints.\n\nAs I mentioned at the WG meeting in Minneapolis, I believe the correct solution\nto this problem is for the server to ask for stuff when it needs it. The\nobvious way to do this would be with two IPP connections, but this runs into\nproblems with firewalls. A better approach would be to use BEEP's multiple\nsession capability -- the client could send the control document over and the\nserver could request things from the client on a different channel. The result\nis a single connection, just in time data delivery, and no need for the client\nto have to try and predict when the server will need something. The\ndisadvantage is that it's a new protocol, but frankly, if this problem is worth\nsolving we should not be afraid of a new protocol to solve it. (I also question\nwhether or not more code would actually be needed -- predicting when a printer\nwill need something strikes me as quite possible a lot more code.)\n\n> I would suggest a new application/multiplexed content-type which would\n> be divided up into chunks, each chunk representing the next consecutive\n> element of some stream.  Each stream could be a MIME body part, with\n> the normal header and content, but each stream could also be fragmented\n> as necessary.  Ideally, the semantics would be similar to multipart\n> related, and it would be possible to transform an application/multiplexed\n> content into an equivalent multipart/related content - just that in\n> the first case the various components would be divided up into chunks\n> and multiplexed into a single body part (as far as MIME was concerned)\n> and in the second case the components would each appear as a separate\n> MIME body part within an enclosing multipart/related.\n\nThese are all just syntactic details. I think the problems here are\nmore fundamental than that.\n\nNed\n\n\n\n", "id": "lists-007-13474705"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and   Application/BatchBee", "content": "At 04:54 PM 4/16/2001, ned.freed@mrochek.com wrote:\n>A better approach would be to use BEEP's multiple\n>session capability -- the client could send the control document over and the\n>server could request things from the client on a different channel. The result\n>is a single connection, just in time data delivery, and no need for the client\n>to have to try and predict when the server will need something. The\n>disadvantage is that it's a new protocol, but frankly, if this problem is \n>worth\n>solving we should not be afraid of a new protocol to solve it.\n\nI like this description quite a lot.\n\nIt also sounds like exactly the same task that a Web client has when \nrendering a web page...\n\nd/\n\n\n----------\nDave Crocker   <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking   <http://www.brandenburg.com>\ntel: +1.408.246.8253;   fax: +1.408.273.6464\n\n\n\n", "id": "lists-007-13486756"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application/BatchBee", "content": "from dcrocker:\n\n> That is a dynamic requirement that depends upon the detail of the\ntransport\n> and the receiver.\n>\n> That's the job of a protocol, not a format.\n\n\nfrom ned.freed:\n\n> A better approach would be to use BEEP's multiple\n> session capability -- the client could send the control document over and\nthe\n> server could request things from the client on a different channel. The\nresult\n> is a single connection, just in time data delivery, and no need for the\nclient\n> to have to try and predict when the server will need something.\n\nfrom mtr:\n\nbingo!\n\n/mtr\n\n\n\n", "id": "lists-007-13496267"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and   Application/BatchBee", "content": "One possible solution to the problem described would be to take\nthe XML document, cut out suitable pieces and put them into\nseparate external entities, change the remainder of the XML document\nappropriately, and then use plain old Multipart/Related,\nwith the core XML document first, and then the separated-out\nentities and the gifs interleaved as appropriate. For external\nentities, see http://www.w3.org/TR/REC-xml#sec-external-ent.\n\nRegards,   Martin.\n\n\nAt 12:36 01/04/16 -0700, Herriot, Robert wrote:\n>I recently published two drafts\n>\n>\n>http://www.ietf.org/internet-drafts/draft-herriot-multipart-interleaved-00.t\n>xt\n>\n>http://www.ietf.org/internet-drafts/draft-herriot-application-batchbeep-00.t\n>xt\n>\n>(Note that the first draft is not available via the Internet Drafts Search\n>engine, but is accessible via the URL supplied above).\n>The problem that motivates these two proposals is the case of an XML\n>document with attachments, such as gif images. Normally, a Multipart/Related\n>representation would suffice. The first body part would be the XML and the\n>remaining body parts would be gif images, each referenced from the XML. But\n>when a memory constrained printer encounters a reference to a gif image body\n>part in the XML, it might not have the space to hold the remaining XML while\n>it scans ahead for the gif image. This problem suggests the need to be able\n>to interleave chunks of XML and gif images. Each of the two drafts provide a\n>solution for interleaving chunks.\n>Both drafts define new MIME types. The first draft defines\n>Multipart/Interleaved and Application/Chunk content types, which extend\n>Multipart/Related for use with memory constrained devices. The second draft\n>defines Application/BatchBeep content type, which defines a MIME type whose\n>contents is the client-to-server portion of a BEEP session.  Although the\n>two drafts are based on two very different ideas, the examples show that the\n>two solutions are nearly byte-for-byte identical. The primary difference is\n>that the boundary string in the Multipart/Interleaved solution is a trailer\n>and/or header in the Application/BatchBeep solution.\n>I would appreciate any comments on these drafts.\n>Bob Herriot\n\n\n\n", "id": "lists-007-13504667"}, {"subject": "RE: Two new drafts: Multipart/Interleaved and Application/BatchBe e", "content": "Keith,\n\nThanks for the feedback.\n\nI agree that existing MIME readers would treat a multipart/interleaved\nentity as a multipart/mixed entity and would see all of the\napplication/chunk body parts are opaque data. I also agree that only updated\nMIME readers could deal with multipart/interleaved and application/chunk. So\nperhaps, there is no advantage in adding another multipart subtype. That's\nthe sort of feedback I'm looking for.\n\nYour application/multiplexed suggestion sounds very close the\napplication/batchbeep that I describe in the other draft I submitted\n(http://www.ietf.org/internet-drafts/draft-herriot-application-batchbeep-00.\ntxt).\n\nAs I see it, the issue is whether the solution should extend multipart or\nwhether it should be completely new. I think you are saying that it should\nbe completely new but easily transformable into multipart/related.  The\nexamples in the application/batchbeep draft show that the conversion between\napplication/batchbeep and multipart/related is simple. The\napplication/batchbeep representation also has the advantage that each chunk\nhas a length field rather than a boundary string to determine the end of the\nchunk. Some people I've talked to want the efficiency of a length field\nrather than a boundary string to search for.\n\nWhat do you think of the application/batchbeep proposal?\n\nBob Herriot\n\n> -----Original Message-----\n> From: Keith Moore [mailto:moore@cs.utk.edu]\n> Sent: Monday, April 16, 2001 3:27 PM\n> To: Herriot, Robert\n> Cc: discuss@apps.ietf.org\n> Subject: Re: Two new drafts: Multipart/Interleaved and\n> Application/BatchBeep \n> \n> \n> I only glanced at this, so maybe I misunderstood it.  However...\n> given that the components of a multipart/interleaved aren't \n> likely to be\n> usable by a traditional MIME reader anyway, I see little point in\n> using the MIME multipart syntax to distinguish one chunk from another.\n> and I don't really see a good way to build this in such a way that\n> existing MIME readers are likely to deal with it well.\n> \n> I would suggest a new application/multiplexed content-type which would\n> be divided up into chunks, each chunk representing the next \n> consecutive\n> element of some stream.  Each stream could be a MIME body part, with\n> the normal header and content, but each stream could also be \n> fragmented\n> as necessary.  Ideally, the semantics would be similar to multipart\n> related, and it would be possible to transform an \n> application/multiplexed \n> content into an equivalent multipart/related content - just that in\n> the first case the various components would be divided up into chunks\n> and multiplexed into a single body part (as far as MIME was concerned)\n> and in the second case the components would each appear as a separate\n> MIME body part within an enclosing multipart/related.\n> \n> Keith\n> \n\n\n\n", "id": "lists-007-13514799"}, {"subject": "RE: LABEL request only allows one set, one add..", "content": "It may be intentional, but I find it misleading.  XML documents can be\nextended by extending the DTD.  The DTD doesn't help validate the XML\n*according to the standard* unless it restricts the XML to that allowed by\nthe standard.\n\nAt least the English ought to be clarified.\n\nlisa\n\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Saturday, June 15, 2002 10:01 AM\n> To: Lisa Dusseault; 'Clemm, Geoff'; 'DeltaV (E-mail)'\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n> Lisa,\n>\n> I think the usage of \"ANY\" is intentional (for RFC3253). The\n> wording just\n> states what DAV's XML enxtensibilty rules require -- the\n> DAV:label element\n> may contain a sequence of arbitrary elements, of which there\n> may be only one\n> DAV:add, DAV:set or DAV:remove element.\n>\n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> Lisa Dusseault\n> > Sent: Saturday, June 15, 2002 4:10 PM\n> > To: 'Clemm, Geoff'; 'DeltaV (E-mail)'\n> > Subject: RE: LABEL request only allows one set, one add...\n> >\n> >\n> >\n> > That's a great point, but it makes me realize I may be reading the\n> > definition wrong.  I had assumed it to be possible to add one\n> > label, remove\n> > a second and set a third, all in the same request. This\n> > assumption was based\n> > on the following language:\n> >\n> >      The request body MUST be a DAV:label element.\n> >\n> >       <!ELEMENT label ANY>\n> >       ANY value: A sequence of elements with at most one DAV:add,\n> >       DAV:set, or DAV:remove element.\n> >\n> > Perhaps this is supposed to mean that only one child\n> element can be inside\n> > label, but \"a sequence\" does imply more than one.  If you\n> mean to restrict\n> > it to one only, then the definition should be:\n> >\n> > <!ELEMENT label (add | set | remove)>\n> >\n> > Lisa\n> >\n> > > -----Original Message-----\n> > > From: ietf-dav-versioning-request@w3.org\n> > > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> Clemm, Geoff\n> > > Sent: Friday, June 14, 2002 8:24 PM\n> > > To: DeltaV (E-mail)\n> > > Subject: RE: LABEL request only allows one set, one add...\n> > >\n> > >\n> > >\n> > > I wouldn't say it was an oversight, but rather a use\n> > > case that wasn't sufficiently common to warrant making\n> > > the protocol more complicated to support it.\n> > > In particular, you would have to define the semantics\n> > > of what would happen if one part of the request would fail\n> > > and the other would succeed, and how to marshall that\n> > > error information.\n> > >\n> > > Cheers,\n> > > Geoff\n> > >\n> > > -----Original Message-----\n> > > From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> > > Sent: Friday, June 14, 2002 9:31 PM\n> > > To: DeltaV (E-mail)\n> > > Subject: LABEL request only allows one set, one add...\n> > >\n> > >\n> > >\n> > >\n> > > Is it an oversight that the LABEL request only allows one\n> > > set, one add, or\n> > > one remove at a time (or one of each, but not two of any?)\n> > >\n> > > For example, say I wanted to add <label-name>foo</label-name> and\n> > > <label-name>bar</label-name> to a version in one request.\n> > > The definition of\n> > > the LABEL request body is:\n> > >\n> > >   <!ELEMENT label ANY>\n> > >   ANY value: A sequence of elements with at most one\n> > >   DAV:add, DAV:set, or DAV:remove element.\n> > >\n> > >   <!ELEMENT add (label-name)>\n> > >   <!ELEMENT set (label-name)>\n> > >   <!ELEMENT remove (label-name)>\n> > >\n> > >   <!ELEMENT label-name (#PCDATA)> PCDATA value: string\n> > >\n> > > Since <add> can only contain one label-name, only one label\n> > > can be added per\n> > > each request.  I would have to issue two LABEL requests to\n> > > add both foo and\n> > > bar labels.\n> > >\n> > > Lisa\n> > >\n> >\n> >\n>\n>\n\n\n\n", "id": "lists-007-1351532"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application/BatchBee", "content": "Dave Crocker wrote:\n\n> At 04:54 PM 4/16/2001, ned.freed@mrochek.com wrote:\n> \n>> A better approach would be to use BEEP's multiple\n>> session capability -- the client could send the control document over \n>> and the\n>> server could request things from the client on a different channel. \n>> The result\n>> is a single connection, just in time data delivery, and no need for \n>> the client\n>> to have to try and predict when the server will need something. The\n>> disadvantage is that it's a new protocol, but frankly, if this problem \n>> is worth\n>> solving we should not be afraid of a new protocol to solve it.\n> \n> \n> I like this description quite a lot.\n> \n> It also sounds like exactly the same task that a Web client has when \n> rendering a web page...\n\nI agree (as I did in person in Minneapolis) with Ned that the \nfundamental problem is that of just-in-time delivery, and the sender \ncannot know what that means.  For example, in looking at our server \nlogs, we do not find that browsers all request the images for a \ngiven HTML document in the same order.\n\nThese drafts were motivated by the buffering problems of an IPP \nprinter, but similar problems would be faced by any device that must \ncombine mulitple components to produce a whole (wireless PDA \ndisplaying an alert with a specific font and a graphic).  Far better \nis to provide a means of doing bidirectional requests.\n\nIPP already incorporates print-by-reference, so having the sender \nincorporate references to objects it is prepared to provide through \na special-purpose HTTP server is not much of a stretch - putting the \nsequencing control of them into the renderer where it belongs.\n\nThe HTTP Upgrade mechanism could be used to switch the HTTP/IPP \nconnection to BEEP/xxx for any value of xxx (including HTTP, even if \nthat would give people alergic reactions).\n\n-- \nScott Lawrence      Architect            slawrence@virata.com\nVirata       Embedded Web Technology    http://www.emweb.com/\n\n\n\n", "id": "lists-007-13526861"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "All:\n\nJust as a bit of background, the purpose, especially of mulitpart/interleaved,\nwas for environments (not IPP) where the client CANNOT/DOES NOT have the\nresources necessary to support a server (e.g. Cell Phone) and this therefore\ndoes a BETTER (but not foolproof) job of putting the resources in  \"proximity\"\nto where it is reference (think printing something like XHTML with images.)\nAlso, some of these environments are NOT tcp.  Don't argue with me about whether\nor not the Cell Phone can afford to include a server so the printer can get the\nimage as it needs it.  This is one of the underlying requirements based upon\nwhat functions can afford to be included by the manufacturer of these devices.\nThe printer guys didn't make up the rules.... we just have to live with them and\nsolve the problems based on them.\n\nOh and by the way, we also didn't decide the base protocols either so when the\nprotocols chosen don't do what is necessary, we have to solve the problem with\npackaging.  Because of bandwidth issues (again, think non-TCP, non-internet,\nnon-megabit pipes), the 33% inefficiency of base64 encoding with the XHTML/SOAP\nis also not acceptable.\n\n**********************************************\n* Don Wright                 don@lexmark.com *\n* Chair, Printer Working Group               *\n* Chair, IEEE MSC                            *\n*                                            *\n* Director, Alliances & Standards            *\n* Lexmark International                      *\n* 740 New Circle Rd                          *\n* Lexington, Ky 40550                        *\n* 859-825-4808 (phone) 603-963-8352 (fax)    *\n**********************************************\n\n\n\n\nScott Lawrence <slawrence%virata.com@interlock.lexmark.com> on 04/17/2001\n01:49:15 PM\n\nTo:   discuss%apps.ietf.org@interlock.lexmark.com\ncc:    (bcc: Don Wright/Lex/Lexmark)\nSubject:  Re: Two new drafts: Multipart/Interleaved and  Application/BatchBeep\n\n\n\nDave Crocker wrote:\n\n> At 04:54 PM 4/16/2001, ned.freed@mrochek.com wrote:\n>\n>> A better approach would be to use BEEP's multiple\n>> session capability -- the client could send the control document over\n>> and the\n>> server could request things from the client on a different channel.\n>> The result\n>> is a single connection, just in time data delivery, and no need for\n>> the client\n>> to have to try and predict when the server will need something. The\n>> disadvantage is that it's a new protocol, but frankly, if this problem\n>> is worth\n>> solving we should not be afraid of a new protocol to solve it.\n>\n>\n> I like this description quite a lot.\n>\n> It also sounds like exactly the same task that a Web client has when\n> rendering a web page...\n\nI agree (as I did in person in Minneapolis) with Ned that the\nfundamental problem is that of just-in-time delivery, and the sender\ncannot know what that means.  For example, in looking at our server\nlogs, we do not find that browsers all request the images for a\ngiven HTML document in the same order.\n\nThese drafts were motivated by the buffering problems of an IPP\nprinter, but similar problems would be faced by any device that must\ncombine mulitple components to produce a whole (wireless PDA\ndisplaying an alert with a specific font and a graphic).  Far better\nis to provide a means of doing bidirectional requests.\n\nIPP already incorporates print-by-reference, so having the sender\nincorporate references to objects it is prepared to provide through\na special-purpose HTTP server is not much of a stretch - putting the\nsequencing control of them into the renderer where it belongs.\n\nThe HTTP Upgrade mechanism could be used to switch the HTTP/IPP\nconnection to BEEP/xxx for any value of xxx (including HTTP, even if\nthat would give people alergic reactions).\n\n--\nScott Lawrence      Architect            slawrence@virata.com\nVirata       Embedded Web Technology    http://www.emweb.com/\n\n\n\n", "id": "lists-007-13536711"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "don@lexmark.com wrote:\n\n\n> Just as a bit of background, the purpose, especially of mulitpart/interleaved,\n> was for environments (not IPP) where the client CANNOT/DOES NOT have the\n> resources necessary to support a server (e.g. Cell Phone) and this therefore\n> does a BETTER (but not foolproof) job of putting the resources in  \"proximity\"\n> to where it is reference (think printing something like XHTML with images.)\n\nI don't see how this packaging issue saves resources in the IPP \nclient - it has to muster all the components anyway to send them, \nregardless of what order they are sent in.  Indeed, it would be \neasier for the sender if they were all just sent sequentially \nwithout the interleaving.  The only motivation I could see for the \ninterleaving was solving the problem of not having buffer space in \nthe receiver to buffer the entire composite object.  Perhaps I \nmisunderstood...\n\n\n-- \nScott Lawrence      Architect            slawrence@virata.com\nVirata       Embedded Web Technology    http://www.emweb.com/\n\n\n\n", "id": "lists-007-13549725"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application  /BatchBee", "content": "Scott:\n\n1) It is NOT for IPP clients\n2) It IS intended to help the printing of images on printers with little buffer\nspace\n3) It IS for clients that do not have \"server\" functionality.  The client opens\nthe connection, pushes the content and is done.\n\n**********************************************\n* Don Wright                 don@lexmark.com *\n* Chair, Printer Working Group               *\n* Chair, IEEE MSC                            *\n*                                            *\n* Director, Alliances & Standards            *\n* Lexmark International                      *\n* 740 New Circle Rd                          *\n* Lexington, Ky 40550                        *\n* 859-825-4808 (phone) 603-963-8352 (fax)    *\n**********************************************\n\n\n\nScott Lawrence <slawrence%virata.com@interlock.lexmark.com> on 04/17/2001\n03:05:29 PM\n\nTo:   discuss%apps.ietf.org@interlock.lexmark.com\ncc:    (bcc: Don Wright/Lex/Lexmark)\nSubject:  Re: Two new drafts: Multipart/Interleaved and Application /BatchBeep\n\n\n\ndon@lexmark.com wrote:\n\n\n> Just as a bit of background, the purpose, especially of mulitpart/interleaved,\n> was for environments (not IPP) where the client CANNOT/DOES NOT have the\n> resources necessary to support a server (e.g. Cell Phone) and this therefore\n> does a BETTER (but not foolproof) job of putting the resources in  \"proximity\"\n> to where it is reference (think printing something like XHTML with images.)\n\nI don't see how this packaging issue saves resources in the IPP\nclient - it has to muster all the components anyway to send them,\nregardless of what order they are sent in.  Indeed, it would be\neasier for the sender if they were all just sent sequentially\nwithout the interleaving.  The only motivation I could see for the\ninterleaving was solving the problem of not having buffer space in\nthe receiver to buffer the entire composite object.  Perhaps I\nmisunderstood...\n\n\n--\nScott Lawrence      Architect            slawrence@virata.com\nVirata       Embedded Web Technology    http://www.emweb.com/\n\n\n\n", "id": "lists-007-13558566"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "one reason I didn't suggest the \"printer fetches things on demand\" model\nmyself was that I didn't know your requirements - other than that you \nseemed to be assuming that the document would fit into a MIME message.\nthere are certainly conditions under which the \"on demand\" model would\nnot work - among them being long round-trip delay conditions and\nintermittent connectivity.\n\n(however I'll confess I'm intrigued - under what conditions does a cell\nphone need to send a complex document to a printer?  I can see how a\ncell phone might want to dump its address book, or forward an incoming\nfax, or some such.  but although these seem like potentially large \ndocuments, they don't seem like complex documents.  I can also see how\nI might want to transmit a complex document to a printer from my palm III\nto a cell phone - but the palm III is quite perfectly of speaking TCP and\nacting as a server for any document that is already stored in its memory.)\n\nBut I have to wonder about problem definitions that place so many \nconstraints on a solution that no reasonable solution seems possible.\nIt's not that such problems don't exist, it's that one gets the \nimpression that the problem definition raises the bar higher than \nnecessary or the solution set is constrained more than necessary.\n\nIn particular \"the resources necessary to support a server\" basically \nmeans the ability to multiplex and demultiplex data over a communications\nchannel, along with (perhaps) the ability to accept unanticipated \ninput.  I'm not claiming that all cell phones can do this, but a device \nthat cannot do this is limited indeed!  Surely the processing overhead \nassociated with handling complex documents far exceeds that required\nto do simple multiplexing and demultiplexing.  An environment that is so\nbandwidth constrained that base64 is an onerous amount of overhead\nprobably shouldn't be using either MIME or XML framing either - it should \nprobably be using some binary protocol that does framing, multiplexing,\nand lossless data compression all at the same time (since they interact\nwith one another).  And intuitively, trying to make a resource-poor client \ntransmit arbitrarily complex documents to a resource-poor printer sounds \nlike an unrealistically hard problem.  I'd be looking for ways to place \nfirm limits on the allowable size/complexity of the document.  \n\nRealistically, unless you impose some such constraints, interoperability \nis just going to be a crap shoot anyway.\n\nKeitt\n\n\n\n", "id": "lists-007-13570286"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application  /BatchBee", "content": "Keith Moore said:\n\n\"An environment that is so\nbandwidth constrained that base64 is an onerous amount of overhead\nprobably shouldn't be using either MIME or XML framing either - it should\nprobably be using some binary protocol that does framing, multiplexing,\nand lossless data compression all at the same time (since they interact\nwith one another).\"\n\nTell me about it!!!!!  But if it doesn't use XML it isn't kewl and therefore is\nunacceptable!  I proposed binary and was shot down immediately by the\n\"politically correct\" XML!\n\n\"(however I'll confess I'm intrigued - under what conditions does a cell\nphone need to send a complex document to a printer?\"\n\nImagine an address book with icons and background images within each cell of an\nXHTML table.\n\n**********************************************\n* Don Wright                 don@lexmark.com *\n* Chair, Printer Working Group               *\n* Chair, IEEE MSC                            *\n*                                            *\n* Director, Alliances & Standards            *\n* Lexmark International                      *\n* 740 New Circle Rd                          *\n* Lexington, Ky 40550                        *\n* 859-825-4808 (phone) 603-963-8352 (fax)    *\n**********************************************\n\n\n\nKeith Moore <moore%cs.utk.edu@interlock.lexmark.com> on 04/17/2001 03:26:03 PM\n\nTo:   \"Don_Wright/Lex/Lexmark.LEXMARK\"@sweeper.lex.lexmark.com\ncc:   discuss%apps.ietf.org@interlock.lexmark.com (bcc: Don Wright/Lex/Lexmark)\nSubject:  Re: Two new drafts: Multipart/Interleaved and Application /BatchBeep\n\n\n\none reason I didn't suggest the \"printer fetches things on demand\" model\nmyself was that I didn't know your requirements - other than that you\nseemed to be assuming that the document would fit into a MIME message.\nthere are certainly conditions under which the \"on demand\" model would\nnot work - among them being long round-trip delay conditions and\nintermittent connectivity.\n\n(however I'll confess I'm intrigued - under what conditions does a cell\nphone need to send a complex document to a printer?  I can see how a\ncell phone might want to dump its address book, or forward an incoming\nfax, or some such.  but although these seem like potentially large\ndocuments, they don't seem like complex documents.  I can also see how\nI might want to transmit a complex document to a printer from my palm III\nto a cell phone - but the palm III is quite perfectly of speaking TCP and\nacting as a server for any document that is already stored in its memory.)\n\nBut I have to wonder about problem definitions that place so many\nconstraints on a solution that no reasonable solution seems possible.\nIt's not that such problems don't exist, it's that one gets the\nimpression that the problem definition raises the bar higher than\nnecessary or the solution set is constrained more than necessary.\n\nIn particular \"the resources necessary to support a server\" basically\nmeans the ability to multiplex and demultiplex data over a communications\nchannel, along with (perhaps) the ability to accept unanticipated\ninput.  I'm not claiming that all cell phones can do this, but a device\nthat cannot do this is limited indeed!  Surely the processing overhead\nassociated with handling complex documents far exceeds that required\nto do simple multiplexing and demultiplexing.  An environment that is so\nbandwidth constrained that base64 is an onerous amount of overhead\nprobably shouldn't be using either MIME or XML framing either - it should\nprobably be using some binary protocol that does framing, multiplexing,\nand lossless data compression all at the same time (since they interact\nwith one another).  And intuitively, trying to make a resource-poor client\ntransmit arbitrarily complex documents to a resource-poor printer sounds\nlike an unrealistically hard problem.  I'd be looking for ways to place\nfirm limits on the allowable size/complexity of the document.\n\nRealistically, unless you impose some such constraints, interoperability\nis just going to be a crap shoot anyway.\n\nKeitt\n\n\n\n", "id": "lists-007-13580037"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "> \"An environment that is so\n> bandwidth constrained that base64 is an onerous amount of overhead\n> probably shouldn't be using either MIME or XML framing either - it should\n> probably be using some binary protocol that does framing, multiplexing,\n> and lossless data compression all at the same time (since they interact\n> with one another).\"\n> \n> Tell me about it!!!!!  But if it doesn't use XML it isn't kewl and therefore\n> is unacceptable!  I proposed binary and was shot down immediately by the\n> \"politically correct\" XML!\n\nthe folks who blindly recommend XML for everything are the ones who should\nbe lined up and shot - perhaps not with lethal weapons (though it is\ntempting) but maybe with big darts that have \"stupid\" flags attached.\n(to warn everyone else of their presence)\n\n> \"(however I'll confess I'm intrigued - under what conditions does a cell\n> phone need to send a complex document to a printer?\"\n> \n> Imagine an address book with icons and background images within each \n> cell of an XHTML table.\n\na cell phone that can maintain separate icons and background images for\neach element of an address book is sophisticated enough to multiplex\ntraffic over a data stream.\n\nKeith\n\n\n\n", "id": "lists-007-13593304"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application  /BatchBee", "content": "don@lexmark.com wrote:\n\n> \n> Scott:\n> \n> 1) It is NOT for IPP clients\n> 2) It IS intended to help the printing of images on printers with little buffer\n> space\n> 3) It IS for clients that do not have \"server\" functionality.  The client opens\n> the connection, pushes the content and is done.\n\nOk.  In that case, I don't think that it actually solves the problem \nit is intended to solve (and perhaps that no solution exists for the \nproblem space in which both parties are so severely constrained).\n\n-- \nScott Lawrence      Architect            slawrence@virata.com\nVirata       Embedded Web Technology    http://www.emweb.com/\n\n\n\n", "id": "lists-007-13602708"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application  /BatchBee", "content": "Keith Moore said:\n\n\"the folks who blindly recommend XML for everything are the ones who should\nbe lined up and shot - perhaps not with lethal weapons (though it is\ntempting) but maybe with big darts that have \"stupid\" flags attached.\n(to warn everyone else of their presence)\"\n\nWe have succeeded in finding a point of complete agreement.\n\n**********************************************\n* Don Wright                 don@lexmark.com *\n* Chair, Printer Working Group               *\n* Chair, IEEE MSC                            *\n*                                            *\n* Director, Alliances & Standards            *\n* Lexmark International                      *\n* 740 New Circle Rd                          *\n* Lexington, Ky 40550                        *\n* 859-825-4808 (phone) 603-963-8352 (fax)    *\n**********************************************\n\n\n\n\nKeith Moore <moore%cs.utk.edu@interlock.lexmark.com> on 04/17/2001 03:40:29 PM\n\nTo:   \"Don_Wright/Lex/Lexmark.LEXMARK\"@sweeper.lex.lexmark.com\ncc:   Keith Moore <moore%cs.utk.edu@interlock.lexmark.com>,\n      discuss%apps.ietf.org@interlock.lexmark.com (bcc: Don Wright/Lex/Lexmark)\nSubject:  Re: Two new drafts: Multipart/Interleaved and Application /BatchBeep\n\n\n\n> \"An environment that is so\n> bandwidth constrained that base64 is an onerous amount of overhead\n> probably shouldn't be using either MIME or XML framing either - it should\n> probably be using some binary protocol that does framing, multiplexing,\n> and lossless data compression all at the same time (since they interact\n> with one another).\"\n>\n> Tell me about it!!!!!  But if it doesn't use XML it isn't kewl and therefore\n> is unacceptable!  I proposed binary and was shot down immediately by the\n> \"politically correct\" XML!\n\nthe folks who blindly recommend XML for everything are the ones who should\nbe lined up and shot - perhaps not with lethal weapons (though it is\ntempting) but maybe with big darts that have \"stupid\" flags attached.\n(to warn everyone else of their presence)\n\n> \"(however I'll confess I'm intrigued - under what conditions does a cell\n> phone need to send a complex document to a printer?\"\n>\n> Imagine an address book with icons and background images within each\n> cell of an XHTML table.\n\na cell phone that can maintain separate icons and background images for\neach element of an address book is sophisticated enough to multiplex\ntraffic over a data stream.\n\nKeith\n\n\n\n", "id": "lists-007-13611491"}, {"subject": "RE: Two new drafts: Multipart/Interleaved and Application/BatchBe e", "content": "Martin,\n\nCould you give more detail about how you envision using external entities in\nthe context of the example I include below?\n\nOne of the problem's requirements is that a producer must be able to start\nsending the data before it has produced all of the data.  So a solution\ncould not require that all entities be known and defined before transmission\nbegins.\n\nA typical example is a document that consists of XHTML plus many images\nwhere the XHTML is split into many chunks so that the images can be\ninterleaved among the XHTML chunks.  To provide something for our\nconversation, I have taken the example from section 5.2 of the\nmultipart/interleaved draft and converted it to Multipart/related with\n\"<fragment .../>\" elements which allow each XML fragment to reference the\nnext one. The question is whether there is an existing XML mechanism that\nbehaves like \"fragment\" element. Here is the example:\n\n---------------------------\n \nContent-Type: multipart/related; boundary=\"boundary-example\";\n              type=\"text/xhtml+xml\"\n\n--boundary-example\nContent-Id: \"49568.44343xxx@foo.com\"\nContent-Type: text/xhtml+xml;charset=\"us-ascii\"\nContent-Disposition: inline\n\n<?xml version=\"1.0\"?>\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n    \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n<html xmlns=\"http://www.w3.org/TR/xhtml1\">\n<body>\n<p>some text\n<img src=\"cid:49568.45876xxx@foo.com\"/>\n<img src=\"cid:49568.46000xxx@foo.com\"/>\nsome more text after the images\n</p>\n            <fragment ref=\"cid:49568.47456xxx@foo.com\"/>\n</body>\n</html>\n--boundary-example\nContent-ID: <49568.45876xxx @foo.com>\nContent-Type: image/gif\nContent-Transfer-Encoding: base64\nContent-Disposition: attachment\n\nR0lGODlhGAGgAPEAAP/////ZRaCgoAAAACH+PUNvcHlyaWdodCAoQykgMTk5\nNSBJRVRGLiBVbmF1dGhvcml6ZWQgZHVwbGljYXRpb24gcHJvaGliaXRlZC4A\netc...\n--boundary-example\nContent-ID: <49568.46000xxx@foo.com>\nContent-Type: image/gif\nContent-Transfer-Encoding: binary\nContent-Disposition: attachment\n\n<binary data>\n--boundary-example\nContent-Id: \"49568.47456xxx@foo.com\"\nContent-Type: text/xhtml+xml;charset=\"us-ascii\"\n\n<p>some more text without images\n</p>\n            <fragment ref=\"cid:49568.49333xxx@foo.com\"/>\n--boundary-example\nContent-ID: <49568.47333xxx@foo.com>\nContent-Type: image/gif\nContent-Transfer-Encoding: binary\nContent-Disposition: attachment\n\n<binary data>\n--boundary-example\nContent-Id: \"49568.49333xxx@foo.com\"\nContent-Type: text/xhtml+xml;charset=\"us-ascii\"\n\n<p>some more text\n<img src=\"cid:49568.47333xxx@foo.com\"/>\n</p>\n <p>some final text\n</p>\n--boundary-example--\n\n\n\n> -----Original Message-----\n> From: Martin Duerst [mailto:duerst@w3.org]\n> Sent: Monday, April 16, 2001 8:32 PM\n> To: Herriot, Robert; discuss@apps.ietf.org\n> Subject: Re: Two new drafts: Multipart/Interleaved and\n> Application/BatchBeep\n> \n> \n> One possible solution to the problem described would be to take\n> the XML document, cut out suitable pieces and put them into\n> separate external entities, change the remainder of the XML document\n> appropriately, and then use plain old Multipart/Related,\n> with the core XML document first, and then the separated-out\n> entities and the gifs interleaved as appropriate. For external\n> entities, see http://www.w3.org/TR/REC-xml#sec-external-ent.\n> \n> Regards,   Martin.\n> \n> \n> At 12:36 01/04/16 -0700, Herriot, Robert wrote:\n> >I recently published two drafts\n> >\n> >\n> >http://www.ietf.org/internet-drafts/draft-herriot-multipart-i\nnterleaved-00.t\n> >xt\n> >\n> >http://www.ietf.org/internet-drafts/draft-herriot-application\n> -batchbeep-00.t\n> >xt\n> >\n> >(Note that the first draft is not available via the Internet \n> Drafts Search\n> >engine, but is accessible via the URL supplied above).\n> >The problem that motivates these two proposals is the case of an XML\n> >document with attachments, such as gif images. Normally, a \n> Multipart/Related\n> >representation would suffice. The first body part would be \n> the XML and the\n> >remaining body parts would be gif images, each referenced \n> from the XML. But\n> >when a memory constrained printer encounters a reference to \n> a gif image body\n> >part in the XML, it might not have the space to hold the \n> remaining XML while\n> >it scans ahead for the gif image. This problem suggests the \n> need to be able\n> >to interleave chunks of XML and gif images. Each of the two \n> drafts provide a\n> >solution for interleaving chunks.\n> >Both drafts define new MIME types. The first draft defines\n> >Multipart/Interleaved and Application/Chunk content types, \n> which extend\n> >Multipart/Related for use with memory constrained devices. \n> The second draft\n> >defines Application/BatchBeep content type, which defines a \n> MIME type whose\n> >contents is the client-to-server portion of a BEEP session.  \n> Although the\n> >two drafts are based on two very different ideas, the \n> examples show that the\n> >two solutions are nearly byte-for-byte identical. The \n> primary difference is\n> >that the boundary string in the Multipart/Interleaved \n> solution is a trailer\n> >and/or header in the Application/BatchBeep solution.\n> >I would appreciate any comments on these drafts.\n> >Bob Herriot\n> \n\n\n\n", "id": "lists-007-13622644"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "> Sender: moore@cs.utk.edu\n> From: Keith Moore <moore@cs.utk.edu>\n> Date: Tue, 17 Apr 2001 15:40:29 -0400\n> To: don@lexmark.com\n> Cc: Keith Moore <moore@cs.utk.edu>, discuss@apps.ietf.org\n> Subject: Re: Two new drafts: Multipart/Interleaved and Application /BatchBeep\n> -----\n> > \"An environment that is so\n> > bandwidth constrained that base64 is an onerous amount of overhead\n> > probably shouldn't be using either MIME or XML framing either - it should\n> > probably be using some binary protocol that does framing, multiplexing,\n> > and lossless data compression all at the same time (since they interact\n> > with one another).\"\n> >\n> > Tell me about it!!!!!  But if it doesn't use XML it isn't kewl and therefore\n> > is unacceptable!  I proposed binary and was shot down immediately by the\n> > \"politically correct\" XML!\n> \n> the folks who blindly recommend XML for everything are the ones who should\n> be lined up and shot - perhaps not with lethal weapons (though it is\n> tempting) but maybe with big darts that have \"stupid\" flags attached.\n> (to warn everyone else of their presence)\n> \n>\n\nWhile I agree with your sentiments, remember that XML run through compression\nends up alot more compact than one naively thinks, as the tags compress\nvery well indeed.\n\nHaving dealt with both flavors of protocols, each have their place: the\nproblem is an education one to use the right tool in the right place.\n- Jim\n\n--\nJim Gettys\nTechnology and Corporate Development\nCompaq Computer Corporation\njg@pa.dec.com\n\n\n\n", "id": "lists-007-13640214"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application/BatchBee", "content": "At 16.54 -0700 01-04-16, <ned.freed@mrochek.com> wrote:\n>A better approach would be to use BEEP's multiple\n>session capability -- the client could send the control document over and the\n>server could request things from the client on a different channel.\n\nI have before not understood why there was interest in mapping\nBEEP on top of SMTP. Now I understand how this can be useful!\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-13651710"}, {"subject": "RE: LABEL request only allows one set, one add..", "content": "Yes, in RFC3253, \"at most one x, y, or z\" is (x | y | z).\nIf you were allowed to have an x and a y and a z, it uses\nand \"and\", e.g.: \"at most one x, at most one y, and at most\none z\".  So you can do an add, a set, or a remove, but not\nmore than one in the same request.  The \"sequence of elements\"\nis just there for extensibility.\n\nRFC-3253 has no restrictive DTD statements such as:\n <!ELEMENT label (add | set | remove)>\nsince if this DTD was used by a validating parser,\nit would violate WebDAV semantics, which requires that\nunknown element types be ignored, and not cause a parse\nerror.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Lisa Dusseault [mailto:ldusseault@xythos.com]\nSent: Saturday, June 15, 2002 10:10 AM\nTo: 'Clemm, Geoff'; 'DeltaV (E-mail)'\nSubject: RE: LABEL request only allows one set, one add...\n\n\nThat's a great point, but it makes me realize I may be reading the\ndefinition wrong.  I had assumed it to be possible to add one label, remove\na second and set a third, all in the same request. This assumption was based\non the following language:\n\n     The request body MUST be a DAV:label element.\n\n      <!ELEMENT label ANY>\n      ANY value: A sequence of elements with at most one DAV:add,\n      DAV:set, or DAV:remove element.\n\nPerhaps this is supposed to mean that only one child element can be inside\nlabel, but \"a sequence\" does imply more than one.  If you mean to restrict\nit to one only, then the definition should be:\n\n<!ELEMENT label (add | set | remove)>\n\nLisa\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, June 14, 2002 8:24 PM\n> To: DeltaV (E-mail)\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n>\n> I wouldn't say it was an oversight, but rather a use\n> case that wasn't sufficiently common to warrant making\n> the protocol more complicated to support it.\n> In particular, you would have to define the semantics\n> of what would happen if one part of the request would fail\n> and the other would succeed, and how to marshall that\n> error information.\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> Sent: Friday, June 14, 2002 9:31 PM\n> To: DeltaV (E-mail)\n> Subject: LABEL request only allows one set, one add...\n>\n>\n>\n>\n> Is it an oversight that the LABEL request only allows one\n> set, one add, or\n> one remove at a time (or one of each, but not two of any?)\n>\n> For example, say I wanted to add <label-name>foo</label-name> and\n> <label-name>bar</label-name> to a version in one request.\n> The definition of\n> the LABEL request body is:\n>\n>   <!ELEMENT label ANY>\n>   ANY value: A sequence of elements with at most one\n>   DAV:add, DAV:set, or DAV:remove element.\n>\n>   <!ELEMENT add (label-name)>\n>   <!ELEMENT set (label-name)>\n>   <!ELEMENT remove (label-name)>\n>\n>   <!ELEMENT label-name (#PCDATA)> PCDATA value: string\n>\n> Since <add> can only contain one label-name, only one label\n> can be added per\n> each request.  I would have to issue two LABEL requests to\n> add both foo and\n> bar labels.\n>\n> Lisa\n>\n\n\n\n", "id": "lists-007-1365561"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application  /BatchBee", "content": "At 15.30 -0400 01-04-17, <don@lexmark.com> wrote:\n>Tell me about it!!!!!  But if it doesn't use XML it isn't kewl and \n>therefore is\n>unacceptable!  I proposed binary and was shot down immediately by the\n>\"politically correct\" XML!\n\nI made a test, where I encoded the same information using ASN.1,\nABNF (RFC822 style) and XML.\n\nYou can find it at\nhttp://www.dsv.su.se/jpalme/abook/asn-1-xml-compare.pdf\n\nI compared how many octets had to be sent to transmit the\nsame information in some different formats:\n\nRelative\nSize       Encoding\n\n100        ASN.1-PER\n175        ASN.1-BER\n550        ABNF, RFC822 style\n830        XML\n\nWhen shown such results, people often say \"but XML can be packed\".\nSo I tried packing the XML using the ZIP format. Small blocks of data\nbecame longer, not shorter, when packed. So packing, at least\nusing ZIP, will not make XML more efficient except for rather\nlarge files.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-13659814"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application /BatchBee", "content": "At 15.40 -0400 01-04-17, Keith Moore wrote:\n>the folks who blindly recommend XML for everything are the ones who should\n>be lined up and shot - perhaps not with lethal weapons (though it is\n>tempting) but maybe with big darts that have \"stupid\" flags attached.\n>(to warn everyone else of their presence)\n\nI made a test, where I encoded the same information using ASN.1,\nABNF (RFC822 style) and XML.\n\nYou can find it at\nhttp://www.dsv.su.se/jpalme/abook/asn-1-xml-compare.pdf\n\nI compared how many octets had to be sent to transmit the\nsame information in some different formats:\n\nRelative\nSize       Encoding\n\n100        ASN.1-PER\n175        ASN.1-BER\n550        ABNF, RFC822 style\n830        XML\n\nAt 08.11 -0700 01-04-23, Jim Gettys wrote:\n>While I agree with your sentiments, remember that XML run through compression\n>ends up alot more compact than one naively thinks, as the tags compress\n>very well indeed.\n\nI tried packing the XML using the ZIP format. Small blocks of data\nbecame **longer**, not shorter, when packed. So packing, at least\nusing ZIP, will not make XML more efficient except for rather\nlarge files.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-13669168"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application   /BatchBee", "content": "Yes, you are correct for a small piece of XML: it is hideously expensive.\n\nThings don't do so badly when you get to longer documents.\n\nOf course, the same people only look at long documents, and ignore\nhuman latency (one of the reasons why I find HTTP ugly is that the\nverbosity even of RFC822 headers is adding large latency over low bandwidth\nlines).\n- Jim\n\n--\nJim Gettys\nTechnology and Corporate Development\nCompaq Computer Corporation\njg@pa.dec.com\n\n\n\n", "id": "lists-007-13678426"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "> 100        ASN.1-PER\n> 175        ASN.1-BER\n> 550        ABNF, RFC822 style\n> 830        XML\n\nSeems like your ASN.1 examples have implicit typing while your ABNF\nand XML examples use explicit tags for each element.  So it's \nhardly fair to say that you're comparing ASN.1 with ABNF or XML;\nyou're really comparing implicit to explicit tags.\n\nKeith\n\n\n\n", "id": "lists-007-13687140"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application /BatchBee", "content": "At 16.48 -0400 01-04-23, Keith Moore wrote:\n>  > 100        ASN.1-PER\n>>  175        ASN.1-BER\n>>  550        ABNF, RFC822 style\n>>  830        XML\n>\n>Seems like your ASN.1 examples have implicit typing while your ABNF\n>and XML examples use explicit tags for each element.  So it's\n>hardly fair to say that you're comparing ASN.1 with ABNF or XML;\n>you're really comparing implicit to explicit tags.\n>\n>Keith\n\nBy implicit typing in ASN.1-BER is meant that a single tag is used to\nindicate both the type in the actual application and the base type it\nis based on. With explicit typing, two tags are used. But the ABNF\nexamples do not use explicit typing. Explicit typing in ABNF would be\nfor something like:\n\n   Birthyear (INTEGER): 1958\n   Name (ISO-8859-1): Mary Smith\n\nwhich is not done in neither my ABNF nor my XML encoding.\n\nAnyway, explicit typing would only perhaps increase the size of the\nASN.1-BER encoding by about 10 %, that would not change the main\nresult of my comparison.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-13695318"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "there's more than one kind of typing.  in your ASN.1 examples, you don't\nappear to include the \"name\" of each datum, whereas in your ABNF and XML\nexamples, you do.\n\n\n\n", "id": "lists-007-13704726"}, {"subject": "I got i", "content": "Hey, lu\n\nSorry, it took longer than i expected but I found the site, it's\n\n http://www.multiopen.com\n \n the site will make your web surfing very convenient.\n \n \nAnd here goes one more, it's\n\n http://www.mysimon.com \n \n this one will help your online shopping    \n \n Get to the site and mail me after\n\n bye~\n \n\n\n\n", "id": "lists-007-13712897"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application /BatchBee", "content": "At 09.57 -0400 01-04-24, Keith Moore wrote:\n>there's more than one kind of typing.  in your ASN.1 examples, you don't\n>appear to include the \"name\" of each datum, whereas in your ABNF and XML\n>examples, you do.\n\nThe main principle of efficient coding of protocols is to only send \nthe information which varies over time. Information which is static, \nlike\nthe names of the fields, is either suppressed or compacted very strongly.\nIt is this compacting of this information which is a main reason why\nthe ASN.1 encoding got so compact. The disadvantage with this, of\ncourse, is that the encoded date is much more difficult to read\nfor a human not using a special program.\n\nDid you also look at my comparison between RFC822 and XML\n\nRFC822 example:\n     From: Father Christmas <fchristmas@northpole.arctic>\n\nXML encoding of the same information:\n\n     <from>\n       <user-friendly-name>Father Christmas</user-friendly-name>\n       <e-mail-address>\n         <localpart>fchristmas</localpart>\n         <domainpart>\n           <domainelement>northpole</domainelement>\n           <domainelement>arctic</domainelement>\n       </domainpart>\n     </from>\n\nThe XML encoding uses five times as many characters. It does\nhave, however, the advantage that you need not have special\nrules for each new punctuation character which occurs as in the\nRFC822 variant.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-13719511"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "> >there's more than one kind of typing.  in your ASN.1 examples, you don't\n> >appear to include the \"name\" of each datum, whereas in your ABNF and XML\n> >examples, you do.\n> \n> The main principle of efficient coding of protocols is to only send \n> the information which varies over time. Information which is static, \n> like the names of the fields, is either suppressed or compacted very \n> strongly.  It is this compacting of this information which is a main \n> reason why the ASN.1 encoding got so compact. \n\nThis isn't a feature of ASN.1.  It's a feature of encoding the \nfield names implicitly via their position in the data stream vs. \nencoding them explicitly with tags.  ASN.1 can do this either\nway.  For instance, SNMP uses ASN.1 but tags each datum with an OID.\n\nYou can also do positional encoding with RFC 822 headers or XML.\nIt's just a question of how much of the syntax of the underlying\ndata that you expose/export into the outer presentation syntax.\n\n> The disadvantage with this, of course, is that the encoded date is \n> much more difficult to read for a human not using a special program.\n\nThat's only one disadvantage of positional encoding.  You're making\nassumptions about which data is static and which data isn't static\nthat aren't even appropriate for the examples that you cite, much less \nin general.\n\n> Did you also look at my comparison between RFC822 and XML\n> \n> RFC822 example:\n>      From: Father Christmas <fchristmas@northpole.arctic>\n> \n> XML encoding of the same information:\n> \n>      <from>\n>        <user-friendly-name>Father Christmas</user-friendly-name>\n>        <e-mail-address>\n>          <localpart>fchristmas</localpart>\n>          <domainpart>\n>            <domainelement>northpole</domainelement>\n>            <domainelement>arctic</domainelement>\n>        </domainpart>\n>      </from>\n> \n> The XML encoding uses five times as many characters. \n\nyou could have as easily said:\n\n<from>Father Christmas &#60;fchristmas@northpole.arctic&#62;</from>\n\nand that would have been a more accurate comparison.  The XML version\nuses a few more characters, but it's not a huge difference overall. \n\nKeith\n\n\n\n", "id": "lists-007-13729707"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "And, of course, none of this has to do with ASN.1 but rather to do\nwith BER, PER, DER, etc., i.e., with particular ASN.1 Encoding\nRules. One could define a VER (Verbose Encoding Rules) for ASN.1 which\nwas worse than any of the compared alternatives. Similarly, one can\ndefine more compact XML encoding rules, e.g., WAP's Binary XML.\n\nDonald\n\nFrom:  Keith Moore <moore@cs.utk.edu>\nMessage-Id:  <200104241917.PAA17760@astro.cs.utk.edu>\nX-URI:  http://www.cs.utk.edu/~moore/\nTo:  Jacob Palme <jpalme@dsv.su.se>\ncc:  Keith Moore <moore@cs.utk.edu>, discuss@apps.ietf.org\nIn-reply-to:  Your message of \"Tue, 24 Apr 2001 20:29:50 +0200.\"\n                  <p05010407b70b755d01a3@[130.237.150.141]> \nDate:  Tue, 24 Apr 2001 15:17:54 -0400\nSender:  moore@cs.utk.edu\nList-Unsubscribe:  <mailto:discuss-request@apps.ietf.org?Subject=unsubscribe>\n>> >there's more than one kind of typing.  in your ASN.1 examples, you don't\n>> >appear to include the \"name\" of each datum, whereas in your ABNF and XML\n>> >examples, you do.\n>> \n>> The main principle of efficient coding of protocols is to only send \n>> the information which varies over time. Information which is static, \n>> like the names of the fields, is either suppressed or compacted very \n>> strongly.  It is this compacting of this information which is a main \n>> reason why the ASN.1 encoding got so compact. \n>\n>This isn't a feature of ASN.1.  It's a feature of encoding the \n>field names implicitly via their position in the data stream vs. \n>encoding them explicitly with tags.  ASN.1 can do this either\n>way.  For instance, SNMP uses ASN.1 but tags each datum with an OID.\n>\n>You can also do positional encoding with RFC 822 headers or XML.\n>It's just a question of how much of the syntax of the underlying\n>data that you expose/export into the outer presentation syntax.\n>\n>> The disadvantage with this, of course, is that the encoded date is \n>> much more difficult to read for a human not using a special program.\n>\n>That's only one disadvantage of positional encoding.  You're making\n>assumptions about which data is static and which data isn't static\n>that aren't even appropriate for the examples that you cite, much less \n>in general.\n>\n>> Did you also look at my comparison between RFC822 and XML\n>> \n>> RFC822 example:\n>>      From: Father Christmas <fchristmas@northpole.arctic>\n>> \n>> XML encoding of the same information:\n>> \n>>      <from>\n>>        <user-friendly-name>Father Christmas</user-friendly-name>\n>>        <e-mail-address>\n>>          <localpart>fchristmas</localpart>\n>>          <domainpart>\n>>            <domainelement>northpole</domainelement>\n>>            <domainelement>arctic</domainelement>\n>>        </domainpart>\n>>      </from>\n>> \n>> The XML encoding uses five times as many characters. \n>\n>you could have as easily said:\n>\n><from>Father Christmas &#60;fchristmas@northpole.arctic&#62;</from>\n>\n>and that would have been a more accurate comparison.  The XML version\n>uses a few more characters, but it's not a huge difference overall. \n>\n>Keith\n\n\n\n", "id": "lists-007-13740416"}, {"subject": "I got i", "content": "Hey, lu\n\nSorry, it took longer than i expected but I found the site, it's\n\n http://www.multiopen.com\n \n the site will make your web surfing very convenient.\n \n \nAnd here goes one more, it's\n\n http://www.mysimon.com \n \n this one will help your online shopping    \n \n Get to the site and mail me after\n\n bye~\n \n\n\n\n", "id": "lists-007-13753400"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application   /BatchBee", "content": "At 11:29 AM 4/24/2001, Jacob Palme wrote:\n>RFC822 example:\n>     From: Father Christmas <fchristmas@northpole.arctic>\n>\n>The XML encoding uses five times as many characters.\n\n>     <from>\n>       <user-friendly-name>Father Christmas</user-friendly-name>\n>       <e-mail-address>\n>         <localpart>fchristmas</localpart>\n>         <domainpart>\n>           <domainelement>northpole</domainelement>\n>           <domainelement>arctic</domainelement>\n>       </domainpart>\n>     </from>\n\nAlas, it uses far more than that...\n\n>     <from>\n>       <user-friendly-name>\n           <friendly-name-char>F</friendly-name-char>\n           <friendly-name-char>a</friendly-name-char>\n           <friendly-name-char>t</friendly-name-char>\n           <friendly-name-char>h</friendly-name-char>\n           <friendly-name-char>e</friendly-name-char>\n           <friendly-name-char>r</friendly-name-char>\n           <friendly-name-char> </friendly-name-char>\n           <friendly-name-char>C</friendly-name-char>\n           <friendly-name-char>h</friendly-name-char>\n           <friendly-name-char>r</friendly-name-char>\n           <friendly-name-char>i</friendly-name-char>\n           <friendly-name-char>s</friendly-name-char>\n           <friendly-name-char>t</friendly-name-char>\n           <friendly-name-char>m</friendly-name-char>\n           <friendly-name-char>a</friendly-name-char>\n           <friendly-name-char>s</friendly-name-char>\n         </user-friendly-name>\n>       <e-mail-address>\n>         <localpart>\n                 <localchar>f</localchar>\n                 <localchar>c</localchar>\n                 <localchar>h</localchar>\n                 <localchar>r</localchar>\n                 <localchar>i</localchar>\n                 <localchar>s</localchar>\n                 <localchar>t</localchar>\n                 <localchar>m</localchar>\n                 <localchar>a</localchar>\n                 <localchar>s</localchar>\n           </localpart>\n>         <domainpart>\n>           <domainelement>\n                 <domainchar>n</domainchar>\n                 <domainchar>O</domainchar>\n                 <domainchar>r</domainchar>\n                 <domainchar>t</domainchar>\n                 <domainchar>h</domainchar>\n                 <domainchar>p</domainchar>\n                 <domainchar>o</domainchar>\n                 <domainchar>l</domainchar>\n                 <domainchar>e</domainchar>\n             </domainelement>\n>           <domainelement>arctic</domainelement>\n                 <domainchar>a</domainchar>\n                 <domainchar>r</domainchar>\n                 <domainchar>c</domainchar>\n                 <domainchar>t</domainchar>\n                 <domainchar>i</domainchar>\n                 <domainchar>c</domainchar>\n             </domainelement>\n>       </domainpart>\n>     </from>\n\n>It does have, however, the advantage that you need not have special\n>rules for each new punctuation character which occurs as in the\n>RFC822 variant.\n\nEach of the strings has different permissible sets of characters, so in \nfact you do need to have special rules for each type of string.\n\nOf course, the real purpose of extending the example is to show that the \nexample can be biased at the whim of the writer, exactly as Keith has been \ntrying to explain.\n\nEfficiency vs. ease of use are a juggling act.  Note, for example, that \nRFC822 and domain parsers are plentiful, so calling for their use is \nreasonable.  Hence while the original XML is rationale, an equally \nplausible choice is:\n\n>     <from>\n>       <display-name>Father Christmas</display-name>\n>         <localpart></localpart>\n>         <addrspec>fchristmas@northpole.arctic</addrspec>\n>     </from>\n\nSerendipitous we have a real-world example of a design choice made for \nexactly this circumstance, from \n<draft-klyne-message-rfc822-xml-01.txt>.  It chose a somewhat different \nbalance from either example:\n\n\n>        <rfc822:from>\n>          <emx:Address>\n>            <emx:adrs>mailto:Pooh@PoohCorner.100Aker.org</emx:adrs>\n>            <emx:name>Winnie the Pooh</emx:name>\n>          </emx:Address>\n>        </rfc822:from>\n\nIt is still an early draft, so one might imagine some further optimization, \nfor improved conciseness...\n\nd/\n\n----------\nDave Crocker   <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking   <http://www.brandenburg.com>\ntel: +1.408.246.8253;   fax: +1.408.273.6464\n\n\n\n", "id": "lists-007-13760040"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "> And, of course, none of this has to do with ASN.1 but rather to do\n> with BER, PER, DER, etc., i.e., with particular ASN.1 Encoding\n> Rules.\n\nactually, I think it has more to do with the way you use ASN.1\n(i.e. the actual ASN.1 specification for your protocol)\nthan any of the ways of encoding ASN.1\n\nin other words, if you decide that your protocol will implicitly\ndetermine field tags by position then you use ASN.1 SEQUENCE\nbut if you decide that field tags should be explicit then you'll\nuse some sort of OPTIONAL structure that contains the tag and\nthe value [*]  and if you decide that your protocol will expose\n(say) the entire structure of an email address in the ASN.1 layer\nthen it will naturally take up more space than if you just encode\nthe entire email address as a single IA5STRING.\n\n[*] if memory serves... but I have done my best to forget how ASN.1\nworks.  so if you claim I've made errors I'll only congratulate\nmyself on how much I've forgotten.\n\nKeith\n\nlet's stamp out gratuitous use of *both* ASN.1 and XML in our lifetime!\n\n\n\n", "id": "lists-007-13773710"}, {"subject": "RE: LABEL request only allows one set, one add..", "content": "RFC2518 already established that validating parsers cannot strictly use the\nDTD in the specification but must allow unknown elements in any element.\n\nIf RFC3253 consistently followed what you suggest, then auto-version would\nalso take a value \"ANY\" rather than being defined properly.\n\n  <!ELEMENT auto-version (checkout-checkin | checkout-unlocked-checkin\n     | checkout | locked-checkout)? >\n\nRFC3253 has many such \"restrictive\" DTDs.\n\nLisa\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Saturday, June 15, 2002 3:28 PM\n> To: 'DeltaV (E-mail)'\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n>\n> Yes, in RFC3253, \"at most one x, y, or z\" is (x | y | z).\n> If you were allowed to have an x and a y and a z, it uses\n> and \"and\", e.g.: \"at most one x, at most one y, and at most\n> one z\".  So you can do an add, a set, or a remove, but not\n> more than one in the same request.  The \"sequence of elements\"\n> is just there for extensibility.\n>\n> RFC-3253 has no restrictive DTD statements such as:\n>  <!ELEMENT label (add | set | remove)>\n> since if this DTD was used by a validating parser,\n> it would violate WebDAV semantics, which requires that\n> unknown element types be ignored, and not cause a parse\n> error.\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> Sent: Saturday, June 15, 2002 10:10 AM\n> To: 'Clemm, Geoff'; 'DeltaV (E-mail)'\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n> That's a great point, but it makes me realize I may be reading the\n> definition wrong.  I had assumed it to be possible to add one\n> label, remove\n> a second and set a third, all in the same request. This\n> assumption was based\n> on the following language:\n>\n>      The request body MUST be a DAV:label element.\n>\n>       <!ELEMENT label ANY>\n>       ANY value: A sequence of elements with at most one DAV:add,\n>       DAV:set, or DAV:remove element.\n>\n> Perhaps this is supposed to mean that only one child element\n> can be inside\n> label, but \"a sequence\" does imply more than one.  If you\n> mean to restrict\n> it to one only, then the definition should be:\n>\n> <!ELEMENT label (add | set | remove)>\n>\n> Lisa\n>\n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Friday, June 14, 2002 8:24 PM\n> > To: DeltaV (E-mail)\n> > Subject: RE: LABEL request only allows one set, one add...\n> >\n> >\n> >\n> > I wouldn't say it was an oversight, but rather a use\n> > case that wasn't sufficiently common to warrant making\n> > the protocol more complicated to support it.\n> > In particular, you would have to define the semantics\n> > of what would happen if one part of the request would fail\n> > and the other would succeed, and how to marshall that\n> > error information.\n> >\n> > Cheers,\n> > Geoff\n> >\n> > -----Original Message-----\n> > From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> > Sent: Friday, June 14, 2002 9:31 PM\n> > To: DeltaV (E-mail)\n> > Subject: LABEL request only allows one set, one add...\n> >\n> >\n> >\n> >\n> > Is it an oversight that the LABEL request only allows one\n> > set, one add, or\n> > one remove at a time (or one of each, but not two of any?)\n> >\n> > For example, say I wanted to add <label-name>foo</label-name> and\n> > <label-name>bar</label-name> to a version in one request.\n> > The definition of\n> > the LABEL request body is:\n> >\n> >   <!ELEMENT label ANY>\n> >   ANY value: A sequence of elements with at most one\n> >   DAV:add, DAV:set, or DAV:remove element.\n> >\n> >   <!ELEMENT add (label-name)>\n> >   <!ELEMENT set (label-name)>\n> >   <!ELEMENT remove (label-name)>\n> >\n> >   <!ELEMENT label-name (#PCDATA)> PCDATA value: string\n> >\n> > Since <add> can only contain one label-name, only one label\n> > can be added per\n> > each request.  I would have to issue two LABEL requests to\n> > add both foo and\n> > bar labels.\n> >\n> > Lisa\n> >\n>\n\n\n\n", "id": "lists-007-1377738"}, {"subject": "We all want to be better parents.....don't we??", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-13782302"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application /BatchBee", "content": "At 15.17 -0400 01-04-24, Keith Moore wrote:\n>  > Did you also look at my comparison between RFC822 and XML\n>>\n>>  RFC822 example:\n>>       From: Father Christmas <fchristmas@northpole.arctic>\n>>\n>>  XML encoding of the same information:\n>>\n>>       <from>\n>>         <user-friendly-name>Father Christmas</user-friendly-name>\n>>         <e-mail-address>\n>>           <localpart>fchristmas</localpart>\n>>           <domainpart>\n>>             <domainelement>northpole</domainelement>\n>>             <domainelement>arctic</domainelement>\n>>         </domainpart>\n>>       </from>\n>>\n>>  The XML encoding uses five times as many characters.\n>\n>you could have as easily said:\n>\n><from>Father Christmas &#60;fchristmas@northpole.arctic&#62;</from>\n>\n>and that would have been a more accurate comparison.  The XML version\n>uses a few more characters, but it's not a huge difference overall.\n\nBut then you are combining XML with other encoding. &#60 and\n@ are framing constructs from RFC822 which in your example\nare combined with XML. So your example is a mixture of two\ndifferent encoding methods, XML and RFC822, which is not\nvery neat. You miss the main advantage of XML (and ASN.1/BER),\nthat one single syntactical method is used for all encoding,\nand that the same framing rules can be used everywhere.\nIn RFC822, there are different framing rules for different\nplaces in the encoded information, and different rules for\nallowed characters and special encoding of non-allowed\ncharacters in different parts of the message header.\nIn XML, you get a single, unified method of framing,\nbut at the expense of a much more verbose encoding.\nThat is the point I wanted to make with my example.\n\nIn the case of RFC822, it has solved the problems with use\nof framing characters in encoded data by some very archaic\nrules, such that spaces are (in practice, even if not according\nto the standards text) not allowed in e-mail addresses and\nthat special characters have to be encoded in special ways.\nWe are so accustomed to RFC822 that we do not think of the\nrestrictions it imposes. But non-Internet experts do not\nlike the RFC822 rules for what is allowed and not allowed\nin the elementary parts of e-mail addresses, even if\nnowadays almost everyone in high-technology countries\nare so accustomed to Internet rules that they do not\ncomplain about them anymore.\n\nXML also has special rules for encoding of special characters,\nbut they are the same rules everywhere, because a unified\nmethod is used for all the framing.\n\nThe XML encoding has another advantage: If the keywords\nare chosen well, you can read the XML data and understand\nit even if you do not know the encoding rules. In the\nRFC822 example, you have to know what is user-friendly\nname and what is e-mail address, what is local part\nand what is domain name, how a domain name can be\nhierarchical by the use of \".\". This is of course of\nmost value when the data transmitted has a syntax\nwith which the reader is not already familiar. In the\ncase of RFC822, we are so accustomed to its special\nusage of \"<\", \"@\" and \".\", that this is no problem to\nan Internet-savvy person.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-13788691"}, {"subject": "Fw: Chenille Jigs The secert is out ", "content": "      CHENILLE RATTLING JIGS will put Bigger fish in your boat. 100% Guaranteed.\n      www.chenillejig.com\n      Our Baits are softer than any other on the market, and deliver INCREDIBLY NATURAL ACTION along with a compact profile that's perfectly suited for BIG BASS  You will quickly discover, these baits move like no other on the market. As an added benefit, this soft formula feels VERY natural to the fish. They REALLY DO hold on longer, giving you more time to detect the strike and set the hook.\n\n      Our unique, natural color combinations give you a great advantage. Thoroughly tested and proven, our colors give YOU a very effective solution for unlocking the jaws of those finicky bass. At times, color alone is often the solution to tough conditions. Designed to appear natural and appealing to bass, our colors and bait styles are a valuable tool, sure to put more fish in your boat. Make these YOUR go-to baits..\n\n      All baits offered to YOU are SCENTED  the most effective fish attractant on the market. This scent alone has been proven time and time again to draw strikes from otherwise inactive fish.\n\n      Our combination of COLOR, ACTION, SOUND, and SCENT delivers a DEADLY PUNCH, sure to catch YOU more fish. All baits offered to YOU have been thoroughly FIELD TESTED by our talented PRO STAFF. \n      In addition to our regular colors, we also offer a custom mixing service. If you have a favorite color  send us a sample and we will match it for you. WE MUST HAVE A SAMPLE TO MATCH\n     \n      Chenille Jigs are not sold in some states. \n     \n      COLORS : ORANGE  CHARTREUSE PURPLE YELLOW GREEN BUBBLEGUM  BLUE RED WHITE BROWN BLACK \n     \n\n   Pro Pack SIX Jigs per order  $ 24.00 SHIPPING INCLUDED  USA. Comes in a Plano specialty box. \n\n\n\n", "id": "lists-007-13800028"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "> At 15.17 -0400 01-04-24, Keith Moore wrote:\n> >  > Did you also look at my comparison between RFC822 and XML\n> >>\n> >>  RFC822 example:\n> >>       From: Father Christmas <fchristmas@northpole.arctic>\n> >>\n> >>  XML encoding of the same information:\n> >>\n> >>       <from>\n> >>         <user-friendly-name>Father Christmas</user-friendly-name>\n> >>         <e-mail-address>\n> >>           <localpart>fchristmas</localpart>\n> >>           <domainpart>\n> >>             <domainelement>northpole</domainelement>\n> >>             <domainelement>arctic</domainelement>\n> >>         </domainpart>\n> >>       </from>\n> >>\n> >>  The XML encoding uses five times as many characters.\n> >\n> >you could have as easily said:\n> >\n> ><from>Father Christmas &#60;fchristmas@northpole.arctic&#62;</from>\n> >\n> >and that would have been a more accurate comparison.  The XML version\n> >uses a few more characters, but it's not a huge difference overall.\n> \n> But then you are combining XML with other encoding. &#60 and\n> @ are framing constructs from RFC822 which in your example\n> are combined with XML. So your example is a mixture of two\n> different encoding methods, XML and RFC822, which is not\n> very neat. \n\nI disagree in the strongest possible terms.  Different layers have\ndifferent needs in a presentation encoding; neither XML nor any other \nencoding scheme is suitable for use at every layer.  Not only that, but \nit is sometimes quite desirable for the encoding at one layer to be \nopaque to other layers.\n\n> You miss the main advantage of XML (and ASN.1/BER),\n> that one single syntactical method is used for all encoding,\n> and that the same framing rules can be used everywhere.\n\njust because ASN.1 or XML can be used everywhere doesn't mean it's\na good idea.\n\nyes, RFC 822 would have been better if it were a bit more regular,\nbut X.400 is even less regular - precisely because it makes too\nmuch use of the expressive power of ASN.1.\n\n> In RFC822, there are different framing rules for different\n> places in the encoded information, and different rules for\n> allowed characters and special encoding of non-allowed\n> characters in different parts of the message header.\n> In XML, you get a single, unified method of framing,\n> but at the expense of a much more verbose encoding.\n> That is the point I wanted to make with my example.\n\nright, but you're presuming that XML is misused.  you might be\npresuming the very kind of misuse that the \"use XML for everything\"\nproponents are advocating, but such misuse is not inherent with XML.\nnor is XML the only presentation layer to witness this degree of misuse.\n\n> In the case of RFC822, it has solved the problems with use\n> of framing characters in encoded data by some very archaic\n> rules, such that spaces are (in practice, even if not according\n> to the standards text) not allowed in e-mail addresses and\n> that special characters have to be encoded in special ways.\n\nin any protocol, regardless of what framing method it uses,\nseldom-used features are often mis-implemented.\n\n> We are so accustomed to RFC822 that we do not think of the\n> restrictions it imposes. \n\nimplementors are aware of them.\n\n> But non-Internet experts do not\n> like the RFC822 rules for what is allowed and not allowed\n> in the elementary parts of e-mail addresses, even if\n> nowadays almost everyone in high-technology countries\n> are so accustomed to Internet rules that they do not\n> complain about them anymore.\n\nCould it be that some of those restrictions exist for other reasons?\nX.400 also has its share of restrictions on the format of addresses,\neven though it uses ASN.1, which would otherwise allow those addresses\nto be transparent.\n\nsince email addresses get used in a wide variety of contexts other \nthan email protocols, it's hardly surprising that there are \n(both practical and imposed) constraints on their use. \n\n> The XML encoding has another advantage: If the keywords\n> are chosen well, you can read the XML data and understand\n> it even if you do not know the encoding rules. In the\n> RFC822 example, you have to know what is user-friendly\n> name and what is e-mail address, what is local part\n> and what is domain name, how a domain name can be\n> hierarchical by the use of \".\". \n\nthat depends on who \"you\" are.  users just have to be able to\nrecognize the pattern xxx@yyy.zzz as an email address.  this \nis actually easier for a human than having to look through \nthe XML and try to figure out which sub-fields are part of an\naddress and which ones are part of a message.\n\n> This is of course of\n> most value when the data transmitted has a syntax\n> with which the reader is not already familiar. In the\n> case of RFC822, we are so accustomed to its special\n> usage of \"<\", \"@\" and \".\", that this is no problem to\n> an Internet-savvy person.\n\nas far as I can tell, people adapted to this rather quickly.\nemail addresses are a lot easier to use (and to prononuce)\nthan URLs, but people have even adapted to URLs.\n\nKeith\n\n\n\n", "id": "lists-007-13808266"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application   /BatchBee", "content": "(This is a re-posting, because I did not get a copy of the first posting \nfrom the re-mailer.  /d)\n\n\nAt 11:29 AM 4/24/2001, Jacob Palme wrote:\n>RFC822 example:\n>     From: Father Christmas <fchristmas@northpole.arctic>\n>\n>The XML encoding uses five times as many characters.\n\n>     <from>\n>       <user-friendly-name>Father Christmas</user-friendly-name>\n>       <e-mail-address>\n>         <localpart>fchristmas</localpart>\n>         <domainpart>\n>           <domainelement>northpole</domainelement>\n>           <domainelement>arctic</domainelement>\n>       </domainpart>\n>     </from>\n\nAlas, it uses far more than that...\n\n>     <from>\n>       <user-friendly-name>\n           <friendly-name-char>F</friendly-name-char>\n           <friendly-name-char>a</friendly-name-char>\n           <friendly-name-char>t</friendly-name-char>\n           <friendly-name-char>h</friendly-name-char>\n           <friendly-name-char>e</friendly-name-char>\n           <friendly-name-char>r</friendly-name-char>\n           <friendly-name-char> </friendly-name-char>\n           <friendly-name-char>C</friendly-name-char>\n           <friendly-name-char>h</friendly-name-char>\n           <friendly-name-char>r</friendly-name-char>\n           <friendly-name-char>i</friendly-name-char>\n           <friendly-name-char>s</friendly-name-char>\n           <friendly-name-char>t</friendly-name-char>\n           <friendly-name-char>m</friendly-name-char>\n           <friendly-name-char>a</friendly-name-char>\n           <friendly-name-char>s</friendly-name-char>\n         </user-friendly-name>\n>       <e-mail-address>\n>         <localpart>\n                 <localchar>f</localchar>\n                 <localchar>c</localchar>\n                 <localchar>h</localchar>\n                 <localchar>r</localchar>\n                 <localchar>i</localchar>\n                 <localchar>s</localchar>\n                 <localchar>t</localchar>\n                 <localchar>m</localchar>\n                 <localchar>a</localchar>\n                 <localchar>s</localchar>\n           </localpart>\n>         <domainpart>\n>           <domainelement>\n                 <domainchar>n</domainchar>\n                 <domainchar>O</domainchar>\n                 <domainchar>r</domainchar>\n                 <domainchar>t</domainchar>\n                 <domainchar>h</domainchar>\n                 <domainchar>p</domainchar>\n                 <domainchar>o</domainchar>\n                 <domainchar>l</domainchar>\n                 <domainchar>e</domainchar>\n             </domainelement>\n>           <domainelement>arctic</domainelement>\n                 <domainchar>a</domainchar>\n                 <domainchar>r</domainchar>\n                 <domainchar>c</domainchar>\n                 <domainchar>t</domainchar>\n                 <domainchar>i</domainchar>\n                 <domainchar>c</domainchar>\n             </domainelement>\n>       </domainpart>\n>     </from>\n\n>It does have, however, the advantage that you need not have special\n>rules for each new punctuation character which occurs as in the\n>RFC822 variant.\n\nEach of the strings has different permissible sets of characters, so in \nfact you do need to have special rules for each type of string.\n\nOf course, the real purpose of extending the example is to show that the \nexample can be biased at the whim of the writer, exactly as Keith has been \ntrying to explain.\n\nEfficiency vs. ease of use are a juggling act.  Note, for example, that \nRFC822 and domain parsers are plentiful, so calling for their use is \nreasonable.  Hence while the original XML is rationale, an equally \nplausible choice is:\n\n>     <from>\n>       <display-name>Father Christmas</display-name>\n>         <localpart></localpart>\n>         <addrspec>fchristmas@northpole.arctic</addrspec>\n>     </from>\n\nSerendipitous we have a real-world example of a design choice made for \nexactly this circumstance, from \n<draft-klyne-message-rfc822-xml-01.txt>.  It chose a somewhat different \nbalance from either example:\n\n\n>        <rfc822:from>\n>          <emx:Address>\n>            <emx:adrs>mailto:Pooh@PoohCorner.100Aker.org</emx:adrs>\n>            <emx:name>Winnie the Pooh</emx:name>\n>          </emx:Address>\n>        </rfc822:from>\n\nIt is still an early draft, so one might imagine some further optimization, \nfor improved conciseness...\n\nd/\n\n----------\nDave Crocker   <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking   <http://www.brandenburg.com>\ntel: +1.408.246.8253;   fax: +1.408.273.6464\n\n\n\n", "id": "lists-007-13821243"}, {"subject": "Vocabulary Considered Harmfu", "content": "All,\n\nThe new practice of using the word \"crazies\" to describe contributors who\nare working on utf8 as an IDN mechanism can't be helpful.  I didn't feel\ncomfortable with this, so I left this morning's Open Apps meeting.\n\nIn the interests of full disclosure, I am working on utf8 as an IDN mechanism.\n\nEric\n\n\n\n", "id": "lists-007-13891992"}, {"subject": "Re: Vocabulary Considered Harmfu", "content": "At 6:54 AM -0400 8/6/01, Eric Brunner-Williams in Portland Maine wrote:\n>The new practice of using the word \"crazies\" to describe contributors who\n>are working on utf8 as an IDN mechanism can't be helpful.\n\nIt is hopefully not a new practice. It was a rude error on my part, \none for which I apologize. If other people want to turn this into a \nnew practice based on my statement yesterday: please don't.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-13898999"}, {"subject": "Use ofHTTP to pass firewall", "content": "A protocol technique which is becoming more and more common is\nto tunnel other protocols over HTTP, or to use special variants\nor usages of HTTP, in order to pass firewalls. Since firewalls\nalso often only allow connections to certain ports, this\ntechnique often means that port 80 is used for a number of\ndifferent protocols.\n\nThe HTTP server, in such a case, works as a kind of multiplexing\nagent, which distributes the incoming HTTP requests to different\napplications.\n\nI have some questions regarding this practice:\n\n(1) Am I correct in describing the practice above?\n\n(2) Does this practice lead to reduced or increased security,\n     compared to the alternative of using special port numbers\n     for each application and changing the firewalls when\n     necessary?\n\n(3) Is this a good practice? Should IETF do something to\n     favor or disfavor this practive?\n\nMy feeling is that it is against the whole idea of port numbers to\nmultiplex lots of different applications to a single port 80, just in\norder to cheat firewalls. And that security will be reduced by this\npractice, since dangerous things may be able to pass the firewall by\nusing HTTP and port 80 and then forwarding the result to an insecure\nprogram.\n\nOn the other hand, the HTTP server on port 80, which handles such\nrequests, may be more secure against various security holes, such\nas the well-known buffer overflow, than particular servers for\nparticular port numbers. But of course the data which the HTTP\nserver forwards to the application program may cause buffer over-\nflow in the application program, even if this data arrived indi-\nrectly via the HTTP server on port 80?\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-13906625"}, {"subject": "RE: LABEL request only allows one set, one add..", "content": "Good point ... I should have been more specific.\n\nRFC-3253 uses \"ANY\" as the DTD for all method request\nand response bodies, as we believed that was where\nextensibility was most required, and so we wanted\nto emphasize this fact in the protocol.\n\nProperties and nested request/response elements \nwithin method request/response bodies are defined with\nthe standard DTD's.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Lisa Dusseault [mailto:ldusseault@xythos.com]\nSent: Saturday, June 15, 2002 7:49 PM\nTo: 'Clemm, Geoff'; 'DeltaV (E-mail)'\nSubject: RE: LABEL request only allows one set, one add...\n\n\nRFC2518 already established that validating parsers cannot strictly use the\nDTD in the specification but must allow unknown elements in any element.\n\nIf RFC3253 consistently followed what you suggest, then auto-version would\nalso take a value \"ANY\" rather than being defined properly.\n\n  <!ELEMENT auto-version (checkout-checkin | checkout-unlocked-checkin\n     | checkout | locked-checkout)? >\n\nRFC3253 has many such \"restrictive\" DTDs.\n\nLisa\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Saturday, June 15, 2002 3:28 PM\n> To: 'DeltaV (E-mail)'\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n>\n> Yes, in RFC3253, \"at most one x, y, or z\" is (x | y | z).\n> If you were allowed to have an x and a y and a z, it uses\n> and \"and\", e.g.: \"at most one x, at most one y, and at most\n> one z\".  So you can do an add, a set, or a remove, but not\n> more than one in the same request.  The \"sequence of elements\"\n> is just there for extensibility.\n>\n> RFC-3253 has no restrictive DTD statements such as:\n>  <!ELEMENT label (add | set | remove)>\n> since if this DTD was used by a validating parser,\n> it would violate WebDAV semantics, which requires that\n> unknown element types be ignored, and not cause a parse\n> error.\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> Sent: Saturday, June 15, 2002 10:10 AM\n> To: 'Clemm, Geoff'; 'DeltaV (E-mail)'\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n> That's a great point, but it makes me realize I may be reading the\n> definition wrong.  I had assumed it to be possible to add one\n> label, remove\n> a second and set a third, all in the same request. This\n> assumption was based\n> on the following language:\n>\n>      The request body MUST be a DAV:label element.\n>\n>       <!ELEMENT label ANY>\n>       ANY value: A sequence of elements with at most one DAV:add,\n>       DAV:set, or DAV:remove element.\n>\n> Perhaps this is supposed to mean that only one child element\n> can be inside\n> label, but \"a sequence\" does imply more than one.  If you\n> mean to restrict\n> it to one only, then the definition should be:\n>\n> <!ELEMENT label (add | set | remove)>\n>\n> Lisa\n>\n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Friday, June 14, 2002 8:24 PM\n> > To: DeltaV (E-mail)\n> > Subject: RE: LABEL request only allows one set, one add...\n> >\n> >\n> >\n> > I wouldn't say it was an oversight, but rather a use\n> > case that wasn't sufficiently common to warrant making\n> > the protocol more complicated to support it.\n> > In particular, you would have to define the semantics\n> > of what would happen if one part of the request would fail\n> > and the other would succeed, and how to marshall that\n> > error information.\n> >\n> > Cheers,\n> > Geoff\n> >\n> > -----Original Message-----\n> > From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> > Sent: Friday, June 14, 2002 9:31 PM\n> > To: DeltaV (E-mail)\n> > Subject: LABEL request only allows one set, one add...\n> >\n> >\n> >\n> >\n> > Is it an oversight that the LABEL request only allows one\n> > set, one add, or\n> > one remove at a time (or one of each, but not two of any?)\n> >\n> > For example, say I wanted to add <label-name>foo</label-name> and\n> > <label-name>bar</label-name> to a version in one request.\n> > The definition of\n> > the LABEL request body is:\n> >\n> >   <!ELEMENT label ANY>\n> >   ANY value: A sequence of elements with at most one\n> >   DAV:add, DAV:set, or DAV:remove element.\n> >\n> >   <!ELEMENT add (label-name)>\n> >   <!ELEMENT set (label-name)>\n> >   <!ELEMENT remove (label-name)>\n> >\n> >   <!ELEMENT label-name (#PCDATA)> PCDATA value: string\n> >\n> > Since <add> can only contain one label-name, only one label\n> > can be added per\n> > each request.  I would have to issue two LABEL requests to\n> > add both foo and\n> > bar labels.\n> >\n> > Lisa\n> >\n>\n\n\n\n", "id": "lists-007-1391510"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "See draft-moore-using-http-01.txt\n\nAt 03:33 AM 8/9/2001, Jacob Palme wrote:\n>A protocol technique which is becoming more and more common is\n>to tunnel other protocols over HTTP, or to use special variants\n>or usages of HTTP, in order to pass firewalls. Since firewalls\n>also often only allow connections to certain ports, this\n>technique often means that port 80 is used for a number of\n>different protocols.\n>\n>The HTTP server, in such a case, works as a kind of multiplexing\n>agent, which distributes the incoming HTTP requests to different\n>applications.\n>\n>I have some questions regarding this practice:\n>\n>(1) Am I correct in describing the practice above?\n>\n>(2) Does this practice lead to reduced or increased security,\n>     compared to the alternative of using special port numbers\n>     for each application and changing the firewalls when\n>     necessary?\n>\n>(3) Is this a good practice? Should IETF do something to\n>     favor or disfavor this practive?\n>\n>My feeling is that it is against the whole idea of port numbers to\n>multiplex lots of different applications to a single port 80, just in\n>order to cheat firewalls. And that security will be reduced by this\n>practice, since dangerous things may be able to pass the firewall by\n>using HTTP and port 80 and then forwarding the result to an insecure\n>program.\n>\n>On the other hand, the HTTP server on port 80, which handles such\n>requests, may be more secure against various security holes, such\n>as the well-known buffer overflow, than particular servers for\n>particular port numbers. But of course the data which the HTTP\n>server forwards to the application program may cause buffer over-\n>flow in the application program, even if this data arrived indi-\n>rectly via the HTTP server on port 80?\n>--\n>Jacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\n>for more info see URL: http://www.dsv.su.se/jpalme/\n\nMichael W. Condry\nDirector,  Network Edge Technology\n\n\n\n", "id": "lists-007-13917424"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "Jacob:\n\n>I have some questions regarding this practice:\n>\n>(1) Am I correct in describing the practice above?\n\nYou are absolutely right, you \"hit the nail to the head\". This is one of\nthe most common\nhackers' practices and network vulnerabilities today (cf. Code Red and IIS\nserver).\n\n\n>\n>(2) Does this practice lead to reduced or increased security,\n>     compared to the alternative of using special port numbers\n>     for each application and changing the firewalls when\n>     necessary?\n\nReduced, since with different ports you may configure firewall to those\nports, here all\nrequests are transperent.\n\n>\n>(3) Is this a good practice? Should IETF do something to\n>     favor or disfavor this practice?\n\nFirst, you may \"disfavour\" this practice only if you limit the\nfunctionality of the Web server, so you\ndo not allow Web servers to be used as portals, you prevent ASPs, etc.\nwhich is probably not a realistic\nassumption.\n\n>\n>My feeling is that it is against the whole idea of port numbers to\n>multiplex lots of different applications to a single port 80, just in\n>order to cheat firewalls. \n\nThe purpose of multiplexing to port 80 is not \"to cheat firewalls\" (that is\nthe consequence),\nthe purpose is nice (GUI) interface of the Web to many background\napplication servers.\n\n\n>On the other hand, the HTTP server on port 80, which handles such\n>requests, may be more secure against various security holes, such\n>as the well-known buffer overflow, than particular servers for\n>particular port numbers. But of course the data which the HTTP\n>server forwards to the application program may cause buffer over-\n>flow in the application program, even if this data arrived indirectly \n>via the HTTP server on port 80?\n\n\nWeb server can not be more secure, it is as secure as it is, (since it is\nstandardized !).\nTherefore, one method of enhancing this \"multiplexing on port 80\" protocol\nis to put \nsome kind of the Security Proxy (at the application level ! not firewall at\nthe IP level)\nin front of the port 80. Such proxy can take care of\n\n   - standard Web IP level security (SSL),\n   - application level Web security (s-http),\n   - additional multi-application security (S/MIME),\n   - security against active contents,\n   - etc.\n\nI'd like to mention that here in the States I have an on-going research\nproject dealing exactly\nwith these problems that you've indicated and creating solutions which I've\nbriefly described.\n\nRegards,\n\nSead\n\n\n\n", "id": "lists-007-13928859"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "in a nutshell, my view is that if people are using a web browser \non the client end to view the content, then it's reasonable to use \nport 80 on the server end.   \n\notherwise, it's probably not reasonable to use port 80.\n\nKeith\n\n\n\n", "id": "lists-007-13939973"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "On Thu, Aug 09, 2001 at 01:39:00PM -0400, Keith Moore wrote:\n> in a nutshell, my view is that if people are using a web browser \n> on the client end to view the content, then it's reasonable to use \n> port 80 on the server end.   \n> \n> otherwise, it's probably not reasonable to use port 80.\n\nRight.  Port 80 is reserved for the Web, not HTTP.\n\nThe notion that a firewall is any more or less secure because of\npeople promoting pseudo-standards that tunnel over HTTP is missing a bit\nof common sense.  Someone trying to break through a firewall isn't going\nto obey IANA port reservations, let alone protocol standards.\n\nSecurity will depend on how the firewall has been configured and will\nrequire some level of content filtering on any ports that it exposes to\nthe outside world.  HTTP makes that a bit easier than most protocols,\nbut only when it is used appropriately.  People installing software on\nthe firewall that allows inappropriate use of HTTP to pass through\nwill be reducing the security of that firewall.\n\n....Roy\n\n\n\n", "id": "lists-007-13949327"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "> > in a nutshell, my view is that if people are using a web browser\n> > on the client end to view the content, then it's reasonable to use\n> > port 80 on the server end.\n> > \n> > otherwise, it's probably not reasonable to use port 80.\n> \n> Right.  Port 80 is reserved for the Web, not HTTP.\n\nwell, I'm assuming that they're using something that resembles HTTP.\n\nI don't think it's reasonable to use port 80 for arbitrary protocols,\nwhether or not you can consider such protocols part of \"the web\".\n\nKeith\n\np.s. does \"the web\" have a definition?  In my mind \"the web\" includes\nanything that can be named with a URI, which is most of the Internet...\n\n\n\n", "id": "lists-007-13959217"}, {"subject": "Snowhite and the Seven Dwarfs - The REAL story", "content": "Today, Snowhite was turning 18. The 7 Dwarfs always where very educated and\npolite with Snowhite. When they go out work at mornign, they promissed a \n*huge* surprise. Snowhite was anxious. Suddlently, the door open, and the Seven\nDwarfs enter...\n\n\n\n\n\napplication/octet-stream attachment: midgets.scr\n\n\n\n\n", "id": "lists-007-13969061"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "--On 08/09/2001 3:29 PM -0400 Keith Moore <moore@cs.utk.edu> wrote:\n\n>> Right.  Port 80 is reserved for the Web, not HTTP.\n> \n> well, I'm assuming that they're using something that resembles HTTP.\n> \n> I don't think it's reasonable to use port 80 for arbitrary protocols,\n> whether or not you can consider such protocols part of \"the web\".\n> \n> Keith\n> \n> p.s. does \"the web\" have a definition?  In my mind \"the web\" includes\n> anything that can be named with a URI, which is most of the Internet...\n\nHmmm....I only use the wording \"the web\" is only used for the subset of\nwhat is transported over the http protocol, can be named with a http URI,\nand accessed with a \"web browser\" -- PLUS \"embedded content\" in the\nwebpages which the user is accessing -- PLUS accompanying things like\nWEBDAV abilities to edit that data documents.\n\nI.e. \"the web\" is for me a subset of what you think is the web.\n\nInteresting...\n\n   paf\n\n\n\n", "id": "lists-007-13975342"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "RE: In addition: IDSs and Intranet servers.\n\nInteresting discussion. And to add to the insecurity many \"high-security\"\norganizations are using intrusion detection systems (IDS) without any\npattern matching on port 80 - they're just set the IDS to allow almost\nanything to happen through port 80 - no alarm will ever ring. To add further\nto that - all the ill-constructed intranet servers with global read as\ndefault for all databases...makes the world less secure. Just as examples:\n1) Lotus Notes Domino Web Server (many versions) with global read for all\nnew created databases and even write in some cases (yes, via a browser) to\nsetup and\nconfiguration areas.(setup.nsf and domcfg.nsf). 2) Centrinity First Class\nIntranet Server with global read to lists of all conferences and users.\nAnd global write to all intranet conferences via other routes (such as\nwriting an email over port25 to the conference.name@server). The list goes\non and on... It just surprises me that very few organizations seem to\nacknowledge the problem. Maybe now in these times of slow economic growth,\nthere's more time to think it over.\n\n/Fredrik Bjorck (Stockholm University / KTH)\n\nOn Thu, 9 Aug 2001, Jacob Palme wrote:\n\n> At 08.14 -0700 01-08-09, Michael W. Condry wrote:\n> >See draft-moore-using-http-01.txt\n>\n> One should distinguish between use of HTTP as a transfer protocol\n> for other applications than web server-web client-communication,\n> and use of port 80 to bypass firewalls.\n>\n> draft-moore-using-http-01.txt is to a large extent a warning\n> against using HTTP as a transfer protocol. However, there are\n> valid reasons why people want to use HTTP, in particular that\n> existing software can be reused. And use of HTTP does not mean\n> that one has to use port 80 in order to bypass firewalls. It was\n> that practice which my message was mainly asking about.\n> --\n> Jacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\n> for more info see URL: http://www.dsv.su.se/jpalme/\n>\n\n\n\n", "id": "lists-007-13985728"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "On Fri, Aug 10, 2001 at 07:53:58AM +0100, Patrik F?ltstr?m wrote:\n> --On 08/09/2001 3:29 PM -0400 Keith Moore <moore@cs.utk.edu> wrote:\n> \n> >> Right.  Port 80 is reserved for the Web, not HTTP.\n> > \n> > well, I'm assuming that they're using something that resembles HTTP.\n> > \n> > I don't think it's reasonable to use port 80 for arbitrary protocols,\n> > whether or not you can consider such protocols part of \"the web\".\n> > \n> > p.s. does \"the web\" have a definition?  In my mind \"the web\" includes\n> > anything that can be named with a URI, which is most of the Internet...\n> \n> Hmmm....I only use the wording \"the web\" is only used for the subset of\n> what is transported over the http protocol, can be named with a http URI,\n> and accessed with a \"web browser\" -- PLUS \"embedded content\" in the\n> webpages which the user is accessing -- PLUS accompanying things like\n> WEBDAV abilities to edit that data documents.\n> \n> I.e. \"the web\" is for me a subset of what you think is the web.\n\nThe Web is an information space, not limited to any protocol or\nformat (so, URI is closer to the definition than HTTP). As I\nunderstand it, this is more or less the W3C definition.\n\n\nI know that wiser heads than mine will consider this incorrect, but\nmy belief is that a port allocation's semantics are limited to a\nreasonable expectation that a particular wire protocol will be\nspoken.\n\nIt may be operationally convenient to make assumptions about what\nservices are used over a particular protocol, but imposing policy,\napplying heuristics or inferring security based on port is unwise at\nbest, as has been noted.\n\nThis, IMHO, is especially true for generalised transfer protocols\n(*TPs). Do we consider valid users of the FTP ports to only be\nhuman-driven FTP clients? May only MUAs or MTAs acting on their\nbehalf use port 25?\n\nIt's certainly true that people do impose policy, apply heuristics\nand infer security from port 80, but I don't think this should be\nencouraged or codified. If we went down that path, it would restrict\nthe 'valid' uses of HTTP, somewhat paradoxically (based on the\ndefinition above) limiting the uses of the Web as well.\n\n(Note the fine line being walked - I agree with Kieth's motivation to\nwarn people about the possibility of these things when they use HTTP\nas a substrate).\n\nNow to catch up on the jetlag...\n\n-- \nMark Nottingham, Research Scientist\nAkamai Technologies (San Mateo, CA USA)\n\n\n\n", "id": "lists-007-13997293"}, {"subject": "Open App Area meeting:  notes from URN presentatio", "content": "A couple of folks asked if the slide I used in the open applications area \nmeeting for talking about the registration of URN namespaces for protocol \nparameters were online.  They're now at:\n\n   http://public.research.mimesweeper.com/IETF/URIs/ApplicationProtocolElementURIs/\n\n#g\n\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-14009182"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "Jacob,\n\nI don't plan on following this thread in discuss@apps.ietf.org.\n\nIt was the subject of discussion at the Apps Area Open at IETF-44,\nat least in its transport aspect.\n\nFrom the end2end-interest list, with permission of the author.\n\nEric\n\n------- Forwarded Message\n\nThread-Topic: [e2e] Fwd: Camel's nose in the tent\nThread-Index: AcEkQAUWrIV+7hbwSeOw5h++zDr35AAA9ZLw\nFrom: \"Christian Huitema\" <huitema@windows.microsoft.com>\nTo: <end2end-interest@postel.org>\nList-Archive: <http://www.postel.org/pipermail/end2end-interest/>\nDate: Mon, 13 Aug 2001 15:08:30 -0700\n\nThe business of filtering based on port numbers is rapidly getting\ninsane: blocking incoming 80, \"transparent proxy\" of outgoing 80,\nblocking 25... I think we should rewrite the browsers and SMTP agents to\nuse alternate ports, picked more or less at random. In fact, we already\nhave the tools to do that with the SRV records. I can think of a\nfilter-breaker that will first try to access www.example.com:80, and if\nthat breaks for any reason, try to resolve \"_http._tcp.www.example.com\nIN SRV\" -- et voila, alternate port number, filtering is defeated...\nSame could work for mail, etc.\n\n- -- Christian Huitema\n\n------- End of Forwarded Message\n\n\n\n", "id": "lists-007-14016962"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "If we used SRV records to pick ports then the firewalls would just\nintercept DNS queries to know which ports to intercept, and this\nwould just create a bigger mess.  Especially given that NATs do \nsomething like this already.\n\nend-to-end IPsec would help, but it's really difficult to deploy.\n\nit would also help if software vendors stopped shipping apps \nthat were vulnerable to network-borne viruses.\n\nIMHO, standards should say that an app MUST NOT present downloaded\ncontent unless the security considerations for that content-type\nand application had been studied and any known threats ameilorated.\n\nKeith\n\n\n\n", "id": "lists-007-14026046"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "--On 01-08-14 12.40 -0400 Keith Moore <moore@cs.utk.edu> wrote:\n\n> If we used SRV records to pick ports then the firewalls would just\n> intercept DNS queries to know which ports to intercept, and this\n> would just create a bigger mess.  Especially given that NATs do \n> something like this already.\n\nLet me ask you if you think a variant of this is ok:\n\n(1) Let's say we have a DNS server which when it gets a DNS query\n_requests_ an ip address and port number combination, just like you can\nrequest an IP address from a DHCP server. After getting the data back, that\nip-address/port number is given back in DNS.\n\n(2) Let's say the application on the inside of the firewall is requesting\nan IP-address / port number from a firewall, and when the data is returned,\ndynamic update in DNS is used to update the SRV which is given back to the\nrequesting client.\n\nIs (1) and/or (2) ok?\n\nI.e. I feel the real question is how one in a legitimate way can request a\n(virtual) portnumber and ip address can be requested from for example a\nfirewall, NAT box or whatever.\n\n  paf\n\n\n\n", "id": "lists-007-14034235"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "> Is (1) and/or (2) ok?\n\nno.  the last thing we need is to legitimize things that put brittle \nper-flow state inside the network, intercept traffic for third parties,\nincrease the dependence on DNS reliability (making the network less reliable),\nbreak existing applications, and reduce the flexibility of new applications.\n\nyou can't fix the NAT problem with hacks like this.  it only makes it worse.\n\nKeith\n\n\n\n", "id": "lists-007-14043145"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "--On 01-08-22 11.23 -0400 Keith Moore <moore@cs.utk.edu> wrote:\n\n>> Is (1) and/or (2) ok?\n> \n> no.  the last thing we need is to legitimize things that put brittle \n> per-flow state inside the network, intercept traffic for third parties,\n> increase the dependence on DNS reliability (making the network less\n> reliable), break existing applications, and reduce the flexibility of new\n> applications.\n> \n> you can't fix the NAT problem with hacks like this.  it only makes it\n> worse.\n\nI was not talking about NAT's, but things that block traffic on certain\nports, like normal firewalls, but you are completely right that this can be\nused for NAT purposes aswell.\n\nBut, I get your point. Doing DHCP request, pppoe authentication etc when a\nhost \"wakes up\" and get's an IP address is one thing. Doing the same or\nsimilar things when it for example starts it's \"SIP telephony listener\" or\ninitiates some other flow is not good.\n\nThat is what I read in your message.\n\n   paf\n\n\n\n", "id": "lists-007-14051560"}, {"subject": "Re: Use ofHTTP to pass firewall", "content": "> I was not talking about NAT's, but things that block traffic on certain\n> ports, like normal firewalls, but you are completely right that this can be\n> used for NAT purposes aswell.\n> \n> But, I get your point. Doing DHCP request, pppoe authentication etc when a\n> host \"wakes up\" and get's an IP address is one thing. Doing the same or\n> similar things when it for example starts it's \"SIP telephony listener\" or\n> initiates some other flow is not good.\n> \n> That is what I read in your message.\n\nThat's true, but there's more to it than that.  Yes, doing a dynamic DNS update\non a per-flow (rather than just a per-login) basis is a pain. But more generally,\nexpecting all apps to use SRV on a per-connection basis is a bad idea.  DNS names\nare ill-suited as endpoint identifiers for a variety of reasons, including that  \nDNS lookups are slow (often taking several seconds to complete), they're not \nterribly reliable (servers often falsely report errors and/or are misconfigured)\nPutting SRV lookups in the path slows things down and makes the overall app\nless reliable.  Port-hopping also makes it more difficult to diagnose and fix \nproblems. \n\nYou might get this to work for specific applications, but it's not a general\npurpose solution.    And the last thing we need is for the network to become\nmore application-aware and application-specific.\n\nKeith\n\n\n\n", "id": "lists-007-14060676"}, {"subject": "RFC3253 XML extensibility, was: LABEL request only allows one set, one add..", "content": "Geoff,\n\ndoes this basically mean that, for instance, the auto-version property is\n*not* meant to be extensible with new protocol elements?\n\nAs RFC3253 has no specific wording about what the DTD fragments mean, but\nthe DTD fragments *by definition* cannot be normative (for instance, because\nof namespace requirements), I was under the impression that RFC2518's\nextensibility rules apply to RFC3253 as well. Was I wrong?\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Sunday, June 16, 2002 3:54 PM\n> To: 'DeltaV (E-mail)'\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n>\n> Good point ... I should have been more specific.\n>\n> RFC-3253 uses \"ANY\" as the DTD for all method request\n> and response bodies, as we believed that was where\n> extensibility was most required, and so we wanted\n> to emphasize this fact in the protocol.\n>\n> Properties and nested request/response elements\n> within method request/response bodies are defined with\n> the standard DTD's.\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> Sent: Saturday, June 15, 2002 7:49 PM\n> To: 'Clemm, Geoff'; 'DeltaV (E-mail)'\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n> RFC2518 already established that validating parsers cannot\n> strictly use the\n> DTD in the specification but must allow unknown elements in any element.\n>\n> If RFC3253 consistently followed what you suggest, then auto-version would\n> also take a value \"ANY\" rather than being defined properly.\n>\n>   <!ELEMENT auto-version (checkout-checkin | checkout-unlocked-checkin\n>      | checkout | locked-checkout)? >\n>\n> RFC3253 has many such \"restrictive\" DTDs.\n>\n> Lisa\n>\n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Saturday, June 15, 2002 3:28 PM\n> > To: 'DeltaV (E-mail)'\n> > Subject: RE: LABEL request only allows one set, one add...\n> >\n> >\n> >\n> > Yes, in RFC3253, \"at most one x, y, or z\" is (x | y | z).\n> > If you were allowed to have an x and a y and a z, it uses\n> > and \"and\", e.g.: \"at most one x, at most one y, and at most\n> > one z\".  So you can do an add, a set, or a remove, but not\n> > more than one in the same request.  The \"sequence of elements\"\n> > is just there for extensibility.\n> >\n> > RFC-3253 has no restrictive DTD statements such as:\n> >  <!ELEMENT label (add | set | remove)>\n> > since if this DTD was used by a validating parser,\n> > it would violate WebDAV semantics, which requires that\n> > unknown element types be ignored, and not cause a parse\n> > error.\n> >\n> > Cheers,\n> > Geoff\n> >\n> > -----Original Message-----\n> > From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> > Sent: Saturday, June 15, 2002 10:10 AM\n> > To: 'Clemm, Geoff'; 'DeltaV (E-mail)'\n> > Subject: RE: LABEL request only allows one set, one add...\n> >\n> >\n> > That's a great point, but it makes me realize I may be reading the\n> > definition wrong.  I had assumed it to be possible to add one\n> > label, remove\n> > a second and set a third, all in the same request. This\n> > assumption was based\n> > on the following language:\n> >\n> >      The request body MUST be a DAV:label element.\n> >\n> >       <!ELEMENT label ANY>\n> >       ANY value: A sequence of elements with at most one DAV:add,\n> >       DAV:set, or DAV:remove element.\n> >\n> > Perhaps this is supposed to mean that only one child element\n> > can be inside\n> > label, but \"a sequence\" does imply more than one.  If you\n> > mean to restrict\n> > it to one only, then the definition should be:\n> >\n> > <!ELEMENT label (add | set | remove)>\n> >\n> > Lisa\n> >\n> > > -----Original Message-----\n> > > From: ietf-dav-versioning-request@w3.org\n> > > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > > Sent: Friday, June 14, 2002 8:24 PM\n> > > To: DeltaV (E-mail)\n> > > Subject: RE: LABEL request only allows one set, one add...\n> > >\n> > >\n> > >\n> > > I wouldn't say it was an oversight, but rather a use\n> > > case that wasn't sufficiently common to warrant making\n> > > the protocol more complicated to support it.\n> > > In particular, you would have to define the semantics\n> > > of what would happen if one part of the request would fail\n> > > and the other would succeed, and how to marshall that\n> > > error information.\n> > >\n> > > Cheers,\n> > > Geoff\n> > >\n> > > -----Original Message-----\n> > > From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> > > Sent: Friday, June 14, 2002 9:31 PM\n> > > To: DeltaV (E-mail)\n> > > Subject: LABEL request only allows one set, one add...\n> > >\n> > >\n> > >\n> > >\n> > > Is it an oversight that the LABEL request only allows one\n> > > set, one add, or\n> > > one remove at a time (or one of each, but not two of any?)\n> > >\n> > > For example, say I wanted to add <label-name>foo</label-name> and\n> > > <label-name>bar</label-name> to a version in one request.\n> > > The definition of\n> > > the LABEL request body is:\n> > >\n> > >   <!ELEMENT label ANY>\n> > >   ANY value: A sequence of elements with at most one\n> > >   DAV:add, DAV:set, or DAV:remove element.\n> > >\n> > >   <!ELEMENT add (label-name)>\n> > >   <!ELEMENT set (label-name)>\n> > >   <!ELEMENT remove (label-name)>\n> > >\n> > >   <!ELEMENT label-name (#PCDATA)> PCDATA value: string\n> > >\n> > > Since <add> can only contain one label-name, only one label\n> > > can be added per\n> > > each request.  I would have to issue two LABEL requests to\n> > > add both foo and\n> > > bar labels.\n> > >\n> > > Lisa\n> > >\n> >\n>\n>\n>\n\n\n\n", "id": "lists-007-1406590"}, {"subject": "Re: Open App Area meeting:  notes from URN presentatio", "content": "Hello Graham\n\nMany thanks for your notes. What kind of application did you use to draw \nthe mindmaps? (I'm challenged with an Apple computer, any chance?)\n\nKind regards,\n\nUrs.\n\n\n\n", "id": "lists-007-14069619"}, {"subject": "We are exporting PE(X)-AL-PE(x) composite pipe for underfloor heating syste", "content": "Plypipe Manufacture Co Ltd.\n6-10F,16 Zumiao Road\nFoshan, 528000\nGuangdong, China\n\nTel:(86)757 2301712 / 2302816\nFax:(86)757 2302879\n\nEmail: pipesales@163.com & plypipesale@sina.com\n\nWebsite: http://www.plypipe.com\n\nDear Sir/Madam\n\nIf your company is in the line of pipe, plumbing or faucet materials, we would \nbe very keen to establish a long term business relationship with you.\n\nWe are the largest manufacturer Asia of PE(X)-AL-PE(X) composite pipe and faucet \n(47 production lines) which is the most advanced pipe system in the world. With \nthe advantages of both plastic and metal pipe, its simple to install, hygienic, \ncorrosive-free, non-toxic, hi-temperature & pressure resistant with a very long \nworking life (more than 50 years)\n\nPlease visit our recently launched website of www.plypipe.com for detailed information.\n\nEstablished in 1994, Plypipe is widely used throughout Europe, US, Russia and \nAsia in applications such as underfloor heating system and in both residential \nand commercial plumbing systems among others.\n\nWith buoyant sales on both the domestic and international markets, we invite \nyou to consider acting as our agent in your country to share in our worldwide \nsales success story.\n\nThanks for your time in reading this email.\nIf you have any questions or suggestions please let me know.\n\nYours sincerely,\n\nRobert Chen\nInternatial Trade Dept. Manager\n\n\n\n", "id": "lists-007-14076838"}, {"subject": "urn:ietf:params and an IETF XML registr", "content": "Hi all,\n  Graham mentioned these documents during his discussion at the apps open\narea meeting in London. They have been updated based on comments heard\nafter that discussion and some discussions with the IANA. The two documents\nare:\n\nAn IETF URN Sub-namespace for Registered Protocol Parameters\ndraft-mealling-iana-urn-01.txt\n\nThe IETF XML Registry\ndraft-mealling-iana-xmlns-registry-02.txt\n\nIf you haven't already reviewed these please do so. I intend on asking\nthe RFC Editor to publish these sometime next week. One question I have\nis what status should they be. BCP? \n\n-MM\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | urn:pin:1\nmichael@neonym.net      |                              | http://www.neonym.net\n\n\n\n", "id": "lists-007-14085396"}, {"subject": "Re: Requirements for reliable message deliver", "content": "> what happened exactly in 93? in general, once you start winning, it's hard\n> to stop winning...\n\nIn 1993 I started working on what became Spec 1170, with Locus, for IBM and\nHP. This was driven by the loss of share to Microsoft, and a realignment of\nthe vendors from their prior constallatons (X/Open vs UI, Hamilton Group vs\nAT&T+SMI, NFS vs AFS, ...), to their with- or against-Redmond (modern) set\nof alignments (and consolidations).\n\nWe (the Unix industry) had stopped winning, by 1993 IBM was in serious\ndifficulty, and both IBM and HP were forward-minded about the conversion\nof their core businesses to hardware plus Windows aftermarkets. We killed\nSunWin and some other good ideas, established CDE, tried for shrinkwrap\n(via ANDF), and failed.\n\nI concure with Jim that the instutionalization of X in '88 (of \"Unix\" in '85)\ninto vendor consortia was marred by insufficient \"enlightened self-interest\"\nby the vendor consortia members, most of whom are now trading at pennies on\nthe dollar. \n\nEric\n\n\n\n", "id": "lists-007-14125147"}, {"subject": "Re: Requirements for reliable message deliver", "content": "                                                                                                              \n                    John Ibbotson                                                                             \n                                         To:     Keith Moore <moore@cs.utk.edu>                               \n                    12/04/2001           cc:                                                                  \n                    08:29 AM             From:   John Ibbotson/UK/IBM@IBMGB                                   \n                                         Subject:     Re: Requirements for reliable message delivery(Document \n                                         link: John Ibbotson)                                                 \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n\n\n\nKeith,\nThe customers that have requested reliability are the large scale users of\nour proprietary messaging middleware MQSeries. They rely on the product for\nmoving high value transactions (milions of USD) in the financial and other\nareas. For the reasons of opening firewall ports (amongst others), they'd\nlike to see a more general purpose and standardised way of achieving the\nsame degree of reliability on the internet. Hence the comment on customer\nrequirements.\nJohn\n\nXML Technology and Messaging,\nIBM UK Ltd, Hursley Park,\nWinchester, SO21 2JN\n\nTel: (work) +44 (0)1962 815188        (home) +44 (0)1722 781271\nFax: +44 (0)1962 816898\nNotes Id: John Ibbotson/UK/IBM\nemail: john_ibbotson@uk.ibm.com\n\n\n\n                                                                                                              \n                    Keith Moore                                                                               \n                    <moore@cs.utk.       To:     Brian E Carpenter <brian@hursley.ibm.com>                    \n                    edu>                 cc:     Keith Moore <moore@cs.utk.edu>, Mark Baker                   \n                    Sent by:              <distobj@acm.org>, John Ibbotson/UK/IBM@IBMGB, Discuss Apps         \n                    moore@cs.utk.e        <discuss@apps.ietf.org>, Richard P King/Watson/IBM@IBMUS            \n                    du                   Subject:     Re: Requirements for reliable message delivery          \n                                                                                                              \n                                                                                                              \n                    11/26/2001                                                                                \n                    03:55 PM                                                                                  \n                                                                                                              \n                                                                                                              \n\n\n\n\n> But that's a solution, and we have to look for the requirements that\n> have generated that solution, so that we can create a better solution.\n\nthat's fine.  but simply citing 'customer feedback' as the justification\nfor HTTP doesn't illuminate the underlying requirements that caused\ncustomers to request that.\n\nKeith\n\n\n\n", "id": "lists-007-14134907"}, {"subject": "Re: Requirements for reliable message deliver", "content": "                                                                                                              \n                    John Ibbotson                                                                             \n                                         To:     Graham Klyne <GK@ninebynine.org>                             \n                    12/04/2001           cc:                                                                  \n                    08:17 AM             From:   John Ibbotson/UK/IBM@IBMGB                                   \n                                         Subject:     Re: Requirements for reliable message delivery(Document \n                                         link: John Ibbotson)                                                 \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n\n\n\nGraham,\nSome comments inline:\nJohn\n\nXML Technology and Messaging,\nIBM UK Ltd, Hursley Park,\nWinchester, SO21 2JN\n\nTel: (work) +44 (0)1962 815188        (home) +44 (0)1722 781271\nFax: +44 (0)1962 816898\nNotes Id: John Ibbotson/UK/IBM\nemail: john_ibbotson@uk.ibm.com\n\n\n\n                                                                                                              \n                    Graham Klyne                                                                              \n                    <GK@ninebynine       To:     John Ibbotson/UK/IBM@IBMGB                                   \n                    .org>                cc:     Brian E Carpenter <brian@hursley.ibm.com>, Discuss Apps      \n                                          <discuss@apps.ietf.org>, Richard P King/Watson/IBM@IBMUS            \n                    11/26/2001           Subject:     Re: Requirements for reliable message delivery          \n                    11:15 AM                                                                                  \n                                                                                                              \n                                                                                                              \n\n\n\n\nJohn,\n\nThanks for your clarifications, though I must confess I am still struggling\nto understand the rationale for what you seem to be describing:\n\n(1) Complexity of distributed commit:  it seems to me that the simplest\noption would be if the \"reliable message transfer\" were just a single\nend-to-end hop, without the issues of cascading.  This suggests that\nintermediate hops may be best effort if the message-passing endpoint has\nthe recovery logic.\n\n<JBI> Sure, If life was so simple :-) Most B2B types of transfer assume an\napplication generating a message <JBI> sits within some firewall and is\ncommunicating with another application within some other business <JBI>\n<JBI> firewall. That immediately gives three hops App1 -> gateway1 ->\ngateway2 -> App2 (I'm assuming the App <JBI> talks to some messaging\nmiddleware maybe via JMS). The internal messaging middleware in each\nbusiness <JBI> infrastructure may be different so that adds the complexity\nof different transports to the equation. If <JBI> you now consider a\ntransaction from App1 to App2, then resources have to be locked over the\n<JBI> <JBI> <JBI> request/response path between App1 and App2 to ensure\ncorrect commit/rollback. This is not what we want. <JBI> The Business\nhosting App2 does not want its resources locked by a supplier or purchaser\nrunning App1. <JBI> That's why breaking the transaction down to smaller\nunits of work at the messaging level simplifies <JBI> matters. Now the\nbusiness hosting App2 only has to consider transactions scoped between its\ngateway and <JBI> applications - much more manageable.\n\n(2) Achieving reliability:  it is my view that reliability is mostly\nachieved by strong implementation and operational deployment, not protocol\ndesign.  But however good a system is, there is still a possibility of\nfailure.  I think the challenge for protocol design is to make the\nbehaviour deterministic, in the sense that the sender of a message has a\nreliable indication of the eventual outcome of message transfer (or, in a\ntransactional context, I suppose it would be better to say that the two\nendpoints have a reliable way to synchronize their record of state).\n\n<JBI> No matter how robust the implementation and deployment is, there will\nstill be failures. A reliable <JBI> protocol design will provide\ndeterministic behaviour as seen by an application that uses the reliable\n<JBI> delivery service defined by the protocol.\n\nI see a problem with this scenario, which I must assume you've considered,\nso I hope it will flush out any misunderstandings:\n\n      +------+     +------------+     +--------+\n      |Sender|-->--|Intermediary|-->--|Receiver|\n      +------+     +------------+     +--------+\n\n   (a) First hop:  sender hands off to intermediate.\n       On completion, assumes that delivery is (or will be) done.\n<JBI> No - it is known that delivery is done since the protocol tells him\nthat it has been done. Suppose\n<JBI> message M1 is to be sent. There is a stored copy of M1 at the sender.\nThe sender sends M1 to the\n<JBI> Intermediary which stores it persistently. Persistently means that\nthe copy will survive a recycling of <JBI> the intermediary so the message\nhas to be stored on disk (database, filesystem etc). The intermediary <JBI>\nthen responds to the Sender telling it that M1 has been stored. The Sender\ncan then delete its local <JBI> copy of M1. In the case of the intermediary\nfailing before M1 is stored, the sender will not be told <JBI> that the\nintermediary copy of M1 is stored. Therefore the transaction of sending M1\nis in doubt. It can <JBI> then resynchronise with the intermediary and\nresend M1.\n\n   (b) Intermediary falls over.  Message (or record of state) held at\nintermediary is lost.\n<JBI> The Intermediary MUST make a local copy of the message. If it then\nfalls over, it can recover. If it <JBI> falls over before storing it, there\nis a local copy still at the sender and the endpoints can still <JBI>\nrecover and resend the message.\n   (c) Sender and Receiver are now out of sync, with no outstanding\nunresolved state\n<JBI> First hop actions are repeated between the intermediary and reveiver\nfor reliable delivery.\n\n(3) You talk about transferring state information with the message;  it\nseems to me that such state information can only ever be partial with\nrespect to whatever function it is that the endpoint applications are\ntrying to perform.  So the need for some kind of end-to-end synchronization\ndoesn't go away.\n<JBI> Hopefully, what I've described above shows how the end-to-end\nsynchronisation can be implemented using\n<JBI> cascaded single hops. There are still end-to-end issues such as\nauthentication, non-repudiation etc that <JBI> are the responsibility of\nthe business process using the  reliable delivery. I believe those kinds of\n<JBI> issues are strictly the responsibility of the business applications\nand not the messaging layer.\n#g\n--\n\n\nAt 03:27 PM 11/22/01 +0000, John Ibbotson wrote:\n> >From our experience with reliable transactional messaging, we believe\nthat\n>a single hop approach is the starting point. Certainly end-to-end\n>reliability is required at an application level, but we believe this\nshould\n>be built on a single-hop model with multiple hops being considered as\n>cascaded single hops. An important consideration here is transactionality.\n>The complexity of distributed 2 phase commit can be simplified by adopting\n>the single hop model. A unidirectional message over a single hop can be\n>managed as a single unit of work with commit/rollback being applied when a\n>message is reliably delivered to the endpoint. Therefore in an\nasynchronous\n>request/response single hop model, there are three units of work - the\n>request, the processing and the response. This extends to the multi hop\n>case so for N hops, there are 2N +1 units of work. Issues such as\n>end-to-end security, authentication, non-repudiation etc can then be\n>implemented at the application layer on top of the messaging.\n>\n>A reliable messaging protocol requires the definition of \"state machines\"\n>at the endpoints of the single hop together with state information\n>transferred as part of the message between the endpoints. These may be\n>abstracted to a set of operations that we have briefly described in the\n>requirements document. Separation of the state machines from the state\n>information means that alternative bindings of the state information to\n>different transports can be implemented.\n[...]\n\n\n------------\nGraham Klyne\nGK@NineByNine.org\n\n\n\n", "id": "lists-007-14148187"}, {"subject": "Re: Requirements for reliable message deliver", "content": "                                                                                                              \n                    John Ibbotson                                                                             \n                                         To:     Brian E Carpenter <brian@hursley.ibm.com>                    \n                    12/04/2001           cc:                                                                  \n                    08:24 AM             From:   John Ibbotson/UK/IBM@IBMGB                                   \n                                         Subject:     Re: Requirements for reliable message delivery(Document \n                                         link: John Ibbotson)                                                 \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n\n\n\nAgree, HTTP won't go away in the near (or not so near) future. I believe\nthere is the opportunity for the IETF to develop the kind of reliable\nprotocol our requirements draft addresses. However, we can't ignore HTTP in\nthe near term and adding reliability to it with relatively few changes\nwould be a pragmatic solution - certainly labeling users of HTTP as\nignorant is probably not the way to go :-)\nJohn\n\nXML Technology and Messaging,\nIBM UK Ltd, Hursley Park,\nWinchester, SO21 2JN\n\nTel: (work) +44 (0)1962 815188        (home) +44 (0)1722 781271\nFax: +44 (0)1962 816898\nNotes Id: John Ibbotson/UK/IBM\nemail: john_ibbotson@uk.ibm.com\n\n\n\n                                                                                                              \n                    Brian E                                                                                   \n                    Carpenter            To:     Keith Moore <moore@cs.utk.edu>                               \n                    <brian@hursley       cc:     Mark Baker <distobj@acm.org>, John Ibbotson/UK/IBM@IBMGB,    \n                    .ibm.com>             Discuss Apps <discuss@apps.ietf.org>, Richard P                     \n                                          King/Watson/IBM@IBMUS                                               \n                    11/26/2001           Subject:     Re: Requirements for reliable message delivery          \n                    03:52 PM                                                                                  \n                                                                                                              \n                                                                                                              \n\n\n\n\nKeith Moore wrote:\n>\n> > I don't think the real world has shown much respect for the\n> > restricted application model either. Hence the argument for more\n> > ambitious requirements.\n>\n> I guess the question is whether the IETF should follow the \"real world\"\n> when the \"real world\" demands things (like layering messaging over HTTP)\n> that are technically unsound.\n\nBut that's a solution, and we have to look for the requirements that\nhave generated that solution, so that we can create a better solution.\nThat's how I understand the draft.\n\n  Brian\n\n\n\n", "id": "lists-007-14166470"}, {"subject": "Re: Requirements for reliable message deliver", "content": "Guys,\nI agree - HTTP is something that needs to be done in the near term but that\ndoesn't stop a proper solution being developed in the medium/longer term.\nJohn\n\nXML Technology and Messaging,\nIBM UK Ltd, Hursley Park,\nWinchester, SO21 2JN\n\nTel: (work) +44 (0)1962 815188        (home) +44 (0)1722 781271\nFax: +44 (0)1962 816898\nNotes Id: John Ibbotson/UK/IBM\nemail: john_ibbotson@uk.ibm.com\n\n\n\n                                                                                                              \n                    Brian E                                                                                   \n                    Carpenter            To:     Keith Moore <moore@cs.utk.edu>                               \n                    <brian@hursley       cc:     Jim Gettys <jg@pa.dec.com>, Claudio Allocchio                \n                    .ibm.com>             <Claudio.Allocchio@garr.it>, Mark Baker <distobj@acm.org>, John     \n                                          Ibbotson/UK/IBM@IBMGB, Discuss Apps <discuss@apps.ietf.org>,        \n                    11/28/2001            Richard P King/Watson/IBM@IBMUS                                     \n                    04:29 PM             Subject:     Re: Requirements for reliable message delivery          \n                                                                                                              \n                                                                                                              \n                                                                                                              \n\n\n\n\nKeith, layering over *something* seems to be the only solution...\nit certainly doesn't have to be HTTP and that isn't at all\nwhat John Ibbotson's draft is saying, unless I've misread\nit badly.\n\n  Brian\n\nKeith Moore wrote:\n>\n> > > > Exactly. We can all agree on this. So given that fact, and the fact\nthat\n> > > > people do want to reliably transfer hypertext across unreliable,\n> > > > non-transparent and intermittently connected networks, what should\nwe do?\n> > >\n> > > We should explain why it doesn't make good sense to do these things,\n> > > and provide alternatives that do make sense.\n> >\n> > Wait a minute. I'd love it if the network was reliable, transparent\n> > and connected 100% of the time, but it isn't. We have to deal with\nthat.\n>\n> so how does layering over HTTP help this situation?  it certainly\n> doesn't add reliability or transparency, nor does it help fix\n> broken connections.  you can provide reliability and transparency\n> over HTTP, but you have to work harder to do this than to provide\n> the same services over IP.\n>\n> even if you use HTTP as a means to get through firewalls, this is a short\n> term fix at best.  because the fact that traffic is tunnelled over HTTP\n> doesn't mean that it's any more suitable to pass through the firewall\n> than raw IP traffic.\n>\n> what we need are better means to provide security than our current\n> firewalls, with fine-grained access control that is based on other\n> properties than just the network locations of the participants, with\n> the ability to specify access control centrally (within a domain).\n> but enforcement done by the hosts and servers.   firewalls should\n> also be able to examine credentials and provide coarse filtering of\n> traffic to protect the network and to provide security in depth.\n> and the credentials need to be usable in multiple security domains.\n\n\n\n", "id": "lists-007-14179272"}, {"subject": "Re: Requirements for reliable message deliver", "content": "                                                                                                              \n                    John Ibbotson                                                                             \n                                         To:     \"Marshall T. Rose\" <mrose+mtr.netnews@dbc.mtview.ca.us>      \n                    12/04/2001           cc:                                                                  \n                    08:42 AM             From:   John Ibbotson/UK/IBM@IBMGB                                   \n                                         Subject:     Re: Requirements for reliable message delivery(Document \n                                         link: John Ibbotson)                                                 \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n                                                                                                              \n\n\n\nMarshall,\nComments below:\nJohn\n\nXML Technology and Messaging,\nIBM UK Ltd, Hursley Park,\nWinchester, SO21 2JN\n\nTel: (work) +44 (0)1962 815188        (home) +44 (0)1722 781271\nFax: +44 (0)1962 816898\nNotes Id: John Ibbotson/UK/IBM\nemail: john_ibbotson@uk.ibm.com\n\n\n\n                                                                                                                          \n                    \"Marshall T. Rose\"                                                                                    \n                    <mrose+mtr.netnews@dbc.mtv       To:     John Ibbotson/UK/IBM@IBMGB                                   \n                    iew.ca.us>                       cc:     \"Discuss Apps\" <discuss@apps.ietf.org>, \"Marshall Rose\"      \n                                                      <mrose@dbc.mtview.ca.us>                                            \n                    11/28/2001 05:17 AM              Subject:     Re: Requirements for reliable message delivery          \n                                                                                                                          \n                                                                                                                          \n                                                                                                                          \n\n\n\n\nguys - help me out with something. after reading your I-D, i can't help but\nthink that you can meet your requirements by:\n\n1. shifting more responsibility (e.g., loss detection) to the endpoints.\n<JBI> Absolutely. From a reliability point of view, the responsibility is\nnot to lose the message at\n<JBI> the endponts. In this case, the sending endpoint must have a stored\ncopy available until it knows\n<JBI> unambiguously that the receiving endpoint has successfully stored the\nreceived message persistently.\n<JBI> It can then delete its copy. In cases of failure, it can retry and\nsynchronise with the receiving\n<JBI> endpoint.\n2. using an application-layer relaying service with deterministic delivery\nsemantics (e.g., apex with some of the party pack options).\n<JBI> I need to read more on APEX before commenting authoritatively on this\n:-) But having seen your\n<JBI> presentation to the XML Protocol WG in Boston I think APEX could\nprovide the basis for a reliable\n<JBI> protocol. There is still the question as to what is to be done in the\nshort term and the feedback we get <JBI> from our customers is that HTTP\nwill be around for a long time and they'd like to make that reliable -\n<JBI> warts and all !\nwhat am i missing here?\n\n/mtr\n\n\n\n", "id": "lists-007-14193996"}, {"subject": "Re: Requirements for reliable message deliver", "content": "And there are many exchange models other than RPC ......\nJohn\n\nXML Technology and Messaging,\nIBM UK Ltd, Hursley Park,\nWinchester, SO21 2JN\n\nTel: (work) +44 (0)1962 815188        (home) +44 (0)1722 781271\nFax: +44 (0)1962 816898\nNotes Id: John Ibbotson/UK/IBM\nemail: john_ibbotson@uk.ibm.com\n\n\n\n                                                                                                              \n                    Brian E                                                                                   \n                    Carpenter            To:     Eliot Lear <lear@cisco.com>                                  \n                    <brian@hursley       cc:     Bill Janssen <bill@janssen.org>, Jim Gettys <jg@pa.dec.com>, \n                    .ibm.com>             \"Marshall T. Rose\" <mrose+mtr.netnews@dbc.mtview.ca.us>, Discuss    \n                                          Apps <discuss@apps.ietf.org>                                        \n                    11/29/2001           Subject:     Re: Requirements for reliable message delivery          \n                    12:16 PM                                                                                  \n                                                                                                              \n                                                                                                              \n\n\n\n\nEliot Lear wrote:\n>\n> In the vast volume o this discussion I lost something somewhere.  Why\nisn't\n> BEEP a good college try at a decent baseline upon which strong RPC could\nbe\n> written?\n\nWell, the draft we were originally discussing attempts to answer this.\n>\n> And why are we pissing and moaning rather than either fixing SOAP or\ncoming\n> up with an alternative?\n\nThe draft attempts to list requirements, not exactly for fixing SOAP,\nbut making it unnecessary to fix it. [i.e. fix the Post Office rather\nthan the envelope.]\n\n  Brian\n\n\n\n", "id": "lists-007-14206651"}, {"subject": "Re: Requirements for reliable message deliver", "content": "> However, we can't ignore HTTP in\n> the near term and adding reliability to it with relatively few changes\n> would be a pragmatic solution -\n\nI disagree that it is pragmatic.  In practice HTTP implementations often\ndo not follow finer points of the current specifications, much less any\nextensions necessary for reliable messaging.  Users will have a difficult \ntime distinguishing garden-variety HTTP from the versions of HTTP that \nsupport messaging.  And firewalls are even worse than clients and servers\nabout following the specifications, and they are harder to replace.\n\nIn practice, HTTP is optimized for casual web browsing.  Trying to get\nit to do something else is an exercise in futility.\n\nI don't disagree with the idea that a reliable messaging protocol and\ninfrastructure would be useful, just that layering it on top of HTTP\nis a good first step.\n\nKeith\n\n\n\n", "id": "lists-007-14219650"}, {"subject": "Re: Requirements for reliable message deliver", "content": "John,\n\nI'd like to phrase my concerns about HTTPR (recognizing that this draft\nis likely a prelude to its submission) in the form of an example.\n\nSuppose I've got a resource, say my thermostat, that I want to interact\nwith via HTTP.  I can send it a PUT message, explicitly setting the\ntarget temperature of the thermostat to 21C, like so;\n\nPUT http://example.org/mythermostat/\nContent-Type: application/xml\n<temperature type=\"absolute\" units=\"celsius\">21</temperature>\n\nIn this context, reliability means ensuring that my thermostat is set\nto 21C.  As HTTP is a state coordination language, even if my PUT\nrequest lost the connection after the PUT was performed, I have choices.\nI can check the state of the thermostat with a GET to see if it's set to\n21C, or I can re-invoke the PUT, which works because PUT is idempotent.\n\nThat was partly for context, to show that HTTP has its own reliability\ncharacteristics that have to be considered.  Non-idempotent methods such\nas POST are the tough ones, so let's look at it.\n\nLet's say I want to bump up the current temperature of the thermostat by\none degree C, for whatever temperature it's currently set at.  I can do\nthat with;\n\nPOST http://example.org/mythermostat/\nContent-Type: application/xml\n<temperature type=\"relative\" units=\"celsius\">1</temperature>\n\nYou're entirely right that there is currently no way for the sender to\nknow if the recipient processed that message, in the case where the\nconnection drops after the message is processed.  But consider a small\nextension;\n\nPOST http://example.org/mythermostat/\nContent-Type: application/xml\nMessage-Id: 74293847298374\n<temperature type=\"relative\" units=\"celsius\">1</temperature>\n\nHere, \"Message-Id\" uniquely identifies an instance of a message, and\ncan be used by consenting parties to add idempotency to POST ...\nthough, without prior agreement, you'd want to use a mandatory extension\nfeature such as that provided by M-POST in RFC 2774 to ensure that\nMessage-Id isn't ignored.  With this, I can simply re-POST the message\nuntil I get a 2xx response.\n\nThis example doesn't draw a complete picture of what reliability means\nin the context of HTTP, but hopefully it's enough to describe why I\nbelieve HTTPR is taking the wrong approach.\n\nMB\n-- \nMark Baker, Chief Science Officer, Planetfred, Inc.\nOttawa, Ontario, CANADA.      mbaker@planetfred.com\nhttp://www.markbaker.ca   http://www.planetfred.com\n\n\n\n", "id": "lists-007-14227807"}, {"subject": "Re: Requirements for reliable message deliver", "content": "Mark,\n\nWhy not just use the system described in RFC 1831, ONC RPC?\n\nBill\n\n\n\n", "id": "lists-007-14238273"}, {"subject": "binding-names of members of working-collectio", "content": "Hi,\nWorking-collections contain binding to version-histories. But what is not\nclear, is the binding-name of such bindings. \n\nTo illustrate, take a collection hierarchy:\n/coll/\n     |\n     +- /a\n     |\n     +- /b\n     |\n     +- /c\n\nThe binding-names in the version-controlled-collection \"coll\" would be \"a\",\n\"b\" and \"c\".\nAssume that the version-history of /coll/a is at URL /vh/vh20. Since the\nversion-history is a DAV resource, it can have the name \"vh20\". Similar\nversion-histories for /coll/b and /coll/c are at /vh/vh21 and /vh/22.\n\nWhen we CHECKOUT \"coll\", we get the working-collection \"/wr/wr123\". \nWhat should the PROPFIND on /wr/wr123 return?\na) /wr/wr123/vh20 (binding-name is the 'name' of the version-history),\n/wr/wr123/vh21 and /wr/wr123/vh22\nOR\nb) /wr/wr123/a (binding-name is still the same as the binding-name in the\nversion-controlled-collection), /wr/wr123/b and /wr/wr123/c\n\nCertainly the latter is more convenient. However, is this specifically\nmentioned in the spec?\n\nThanks,\nGirish\n\n\n\n", "id": "lists-007-1424240"}, {"subject": "[????] ?????? ?????????? ????", "content": "Untitled Document                        ???? ???? ???????? ????????  ????????. ???????? ???? ???? ?????? \n ???? ???????? ???????? ???????? ???????? ???????? ??????????. \n ???????? ???? ???? ???????? ?????? ?????????? \n ???????? ???? ?????? ???? ??????????.                                                       \n             ?????????? ??????  DB?????? ???? ?????????? ?????? ??????????.\n ???????? ???????? ?????????? ???????? ????????!!\n ?? ?????? ?????????? ?????? ????????.             \n       ??????????  ???????? ????????????!            \n  \n\n\n", "id": "lists-007-14246007"}, {"subject": "Re: Requirements for reliable message deliver", "content": "On Tue, Dec 04, 2001 at 08:45:56AM +0000, John Ibbotson wrote:\n> The customers that have requested reliability are the large scale\n> users of our proprietary messaging middleware MQSeries. They rely\n> on the product for moving high value transactions (milions of USD)\n> in the financial and other areas. For the reasons of opening\n> firewall ports (amongst others), they'd like to see a more general\n> purpose and standardised way of achieving the same degree of\n> reliability on the internet. Hence the comment on customer\n> requirements.\n\nSurely, if that much money incentive is involved, your customers can\nbeat their firewall admins over the heads to get that hole punched?\nIt's in everyone's interests to separate mission-critical traffic\nfrom casual Web browsing. HTTPR's reliability won't do much good when\nthe proxy is down for maintainence, or Web browsing is filtered, or\nthe ISP two hops up installs a transparent proxy overnight, and the\ninfrastructure admins don't realise that they're losing x million\ndollars a minute as a result. The people managing the infrastructure\nneed to know about mission-critical apps in order to support them.\n\nMy last job happened to be administering firewalls in what I would\nimagine is one of their most paranoid contexts; at a Fortune 25\nfinancial services firm. There were clear and not terribly onerous\n(considering the risk) proceedures for opening a port on the firewall\nif you had an application that needed exposure. Yes, the developers\nbitched about it, and yes, risk protection's job was to say \"no\",\nwhich is what I imagine you're hearing about, but escalating the war\nbetween risk protection and developers doesn't seem like a great\nidea, IMHO.\n\nJust my .02...\n\n\n-- \nMark Nottingham, Research Scientist\nAkamai Technologies (San Mateo, CA USA)\n\n\n\n", "id": "lists-007-14252834"}, {"subject": "Re: Requirements for reliable message deliver", "content": "At 08:19 AM 12/4/01 +0000, John Ibbotson wrote:\n>John,\n>\n>Thanks for your clarifications, though I must confess I am still struggling\n>to understand the rationale for what you seem to be describing:\n>\n>(1) Complexity of distributed commit:  it seems to me that the simplest\n>option would be if the \"reliable message transfer\" were just a single\n>end-to-end hop, without the issues of cascading.  This suggests that\n>intermediate hops may be best effort if the message-passing endpoint has\n>the recovery logic.\n>\n><JBI> Sure, If life was so simple :-) Most B2B types of transfer assume an\n>application generating a message <JBI> sits within some firewall and is\n>communicating with another application within some other business <JBI>\n><JBI> firewall. That immediately gives three hops App1 -> gateway1 ->\n>gateway2 -> App2 (I'm assuming the App <JBI> talks to some messaging\n>middleware maybe via JMS). The internal messaging middleware in each\n>business <JBI> infrastructure may be different so that adds the complexity\n>of different transports to the equation.\n\nAh, are we talking about requirements for a reliable messaging *protocol* \nstandard, or something else?  I think I'm beginning to see what you're \nafter, and need think about this some more.\n\nMeanwhile...\n\n>(2) Achieving reliability:  it is my view that reliability is mostly\n>achieved by strong implementation and operational deployment, not protocol\n>design.  But however good a system is, there is still a possibility of\n>failure.  I think the challenge for protocol design is to make the\n>behaviour deterministic, in the sense that the sender of a message has a\n>reliable indication of the eventual outcome of message transfer (or, in a\n>transactional context, I suppose it would be better to say that the two\n>endpoints have a reliable way to synchronize their record of state).\n>\n><JBI> No matter how robust the implementation and deployment is, there will\n>still be failures. A reliable <JBI> protocol design will provide\n>deterministic behaviour as seen by an application that uses the reliable\n><JBI> delivery service defined by the protocol.\n\nGood.  We agree on that much.\n\n>I see a problem with this scenario, which I must assume you've considered,\n>so I hope it will flush out any misunderstandings:\n>\n>       +------+     +------------+     +--------+\n>       |Sender|-->--|Intermediary|-->--|Receiver|\n>       +------+     +------------+     +--------+\n>\n>    (a) First hop:  sender hands off to intermediate.\n>        On completion, assumes that delivery is (or will be) done.\n><JBI> No - it is known that delivery is done since the protocol tells him\n>that it has been done. Suppose\n><JBI> message M1 is to be sent. There is a stored copy of M1 at the sender.\n>The sender sends M1 to the\n><JBI> Intermediary which stores it persistently. Persistently means that\n>the copy will survive a recycling of <JBI> the intermediary so the message\n>has to be stored on disk (database, filesystem etc). The intermediary <JBI>\n>then responds to the Sender telling it that M1 has been stored. The Sender\n>can then delete its local <JBI> copy of M1. In the case of the intermediary\n>failing before M1 is stored, the sender will not be told <JBI> that the\n>intermediary copy of M1 is stored. Therefore the transaction of sending M1\n>is in doubt. It can <JBI> then resynchronise with the intermediary and\n>resend M1.\n\nMy fundamental problem here is that simply having the intermediary store \nthe message before indicating acceptance is not, of itself, a guarantee of \nfinal delivery.  SMTP semantics effectively require this much.  Suppose a \nrelay hosting centre suffers a disk failure after a message has been \naccepted.  Or a flood.  Or...\n\nAlso, I note that the intermediary->sender confirmation you describe is a \nconfirmation of *storage*, not confirmation of delivery.  Now, that is \nfine, but I don't think it's sufficient.  I think the message \ninfrastructure should also be able to supply the sender a confirmation of \nfinal delivery, OR an indication that final delivery was not achieved, OR \nfor there to be a presumption that if such confirmation is not achieved \nwithin a defined interval then the final delivery was not achieved.\n\nMeanwhile, the sender may be free to delete its copy of the message when \nthe intermediary has accepted it, but should not assume that any associated \ntransaction has been completed/committed by its ultimate recipient.  This \nis (part of) what I meant by suggesting that hop-by-hop reliability may be \na useful performance enhancement but not of itself sufficient for \nend-to-end reliability.\n\n>    (b) Intermediary falls over.  Message (or record of state) held at\n>intermediary is lost.\n><JBI> The Intermediary MUST make a local copy of the message. If it then\n>falls over, it can recover.\n\nAssuming the copy survives the \"falling over\" ... see above.\n\n>    (c) Sender and Receiver are now out of sync, with no outstanding\n>unresolved state\n><JBI> First hop actions are repeated between the intermediary and reveiver\n>for reliable delivery.\n>\n>(3) You talk about transferring state information with the message;  it\n>seems to me that such state information can only ever be partial with\n>respect to whatever function it is that the endpoint applications are\n>trying to perform.  So the need for some kind of end-to-end synchronization\n>doesn't go away.\n><JBI> Hopefully, what I've described above shows how the end-to-end\n>synchronisation can be implemented using\n><JBI> cascaded single hops. There are still end-to-end issues such as\n>authentication, non-repudiation etc that <JBI> are the responsibility of\n>the business process using the  reliable delivery. I believe those kinds of\n><JBI> issues are strictly the responsibility of the business applications\n>and not the messaging layer.\n\nI guess I'm arguing that ultimate responsibility for reliability also needs \nto be responsibility of the business application (or some layer at the \nendpoint closely tied to the business application).\n\n#g\n\n\n------------\nGraham Klyne\nGK@NineByNine.org\n\n\n\n", "id": "lists-007-14261880"}, {"subject": "[????] ?????? ?????????? ????!", "content": "Untitled Document                        ???? ???? ???????? ????????  ????????. ???????? ???? ???? ?????? \n ???? ???????? ???????? ???????? ???????? ???????? ??????????. \n ???????? ???? ???? ???????? ?????? ?????????? \n ???????? ???? ?????? ???? ??????????.                                                       \n             ?????????? ??????  DB?????? ???? ?????????? ?????? ??????????.\n ???????? ???????? ?????????? ???????? ????????!!\n ?? ?????? ?????????? ?????? ????????.             \n       ??????????  ???????? ????????????!            \n  \n\n\n", "id": "lists-007-14276132"}, {"subject": "[????]???? ?????", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-14282892"}, {"subject": "Re: Requirements for reliable message deliver", "content": "[hmm, just checked the archives and my reply to Bill wasn't there.\nMust have sent it to him directly.  Here it is again with a minor mod.]\n\nHi Bill,\n\n> Mark,\n>\n> Why not just use the system described in RFC 1831, ONC RPC?\n\nThat's a big question that a single email can't answer.  The best I can\ndo in a pinch is to reference Roy Fielding's dissertation;\n\nhttp://www.ebuilt.com/fielding/pubs/dissertation/rest_arch_style.htm#sec_5_1_5\n\nBut as a quick-and-practical answer, because I want my thermostat to be\na first class resource on the Web.  This is what the Web was designed\nto be and do.\n\nMB\n-- \nMark Baker, Chief Science Officer, Planetfred, Inc.\nOttawa, Ontario, CANADA.      mbaker@planetfred.com\nhttp://www.markbaker.ca   http://www.planetfred.com\n\n\n\n", "id": "lists-007-14289117"}, {"subject": "Re: Requirements for reliable message deliver", "content": "> But as a quick-and-practical answer, because I want my thermostat to be\n> a first class resource on the Web.  This is what the Web was designed\n> to be and do.\n\nif the design of the web is to coerce everything into one protocol,\nit's fundamentally broken.    perhaps that was the intent, but \nI'm happy that things didn't work out that way.\n\n\n\n", "id": "lists-007-14297741"}, {"subject": "Re: Requirements for reliable message deliver", "content": "> if the design of the web is to coerce everything into one protocol,\n> it's fundamentally broken.    perhaps that was the intent, but \n> I'm happy that things didn't work out that way.\n\nNot \"everythng\", just \"lots of things\".\n\nDo you see a problem with my example?\n\nMB\n-- \nMark Baker, Chief Science Officer, Planetfred, Inc.\nOttawa, Ontario, CANADA.      mbaker@planetfred.com\nhttp://www.markbaker.ca   http://www.planetfred.com\n\n\n\n", "id": "lists-007-14305964"}, {"subject": "Re: Requirements for reliable message deliver", "content": "Mark Baker wrote:\n> \n> > if the design of the web is to coerce everything into one protocol,\n> > it's fundamentally broken.    perhaps that was the intent, but\n> > I'm happy that things didn't work out that way.\n> \n> Not \"everythng\", just \"lots of things\".\n> \n> Do you see a problem with my example?\n\nI can't see any basic reason why a thermostat should be accessed as if\nit was a hypertext document. I would expect building-services control\nmessages to get layered directly over a transport protocol in due \ncourse. I certainly want thermostats to be accessed by a highly reliable\nmechanism that survives disconnected operation, which is where this\nthread started.\n\n  Brian\n\n\n\n", "id": "lists-007-14314484"}, {"subject": "Why the Web", "content": "> I can't see any basic reason why a thermostat should be accessed as if\n> it was a hypertext document.\n\nI would do it for the same reason that anything ends up on the Web;\n\n- I can manipulate it from the same app I use to manipulate so much of\nmy life already; the browser\n- it can leverage existing and yet-to-be-developed extensions such as\nWebDAV so that access to it can be locked, versioned, etc..\n- if I forget its URL, Google can find it for me\n- if my house network is unreliable, an existing cache on the network\ncan let me know what the last cached state of my thermostat is, and\nwhen that state snapshot was taken\n- authentication for free\n- content negotiation permits my french-speaking serviceman to\nalso manipulate and debug it remotely through the same URL\n\netc..\n\nIf that isn't reason enough for you, then do it just to prevent the\nAPPS area from needing 10 area directors by the end of the decade. 8-)\n\n> I would expect building-services control\n> messages to get layered directly over a transport protocol in due \n> course. I certainly want thermostats to be accessed by a highly reliable\n> mechanism that survives disconnected operation, which is where this\n> thread started.\n\nYou didn't think my explanation of reliability in the context of\nthermostat control was sufficient?  Can you elaborate on what else\nyou'd think would be needed?\n\nMB\n-- \nMark Baker, Chief Science Officer, Planetfred, Inc.\nOttawa, Ontario, CANADA.      mbaker@planetfred.com\nhttp://www.markbaker.ca   http://www.planetfred.com\n\n\n\n", "id": "lists-007-14323197"}, {"subject": "RE: binding-names of members of working-collectio", "content": "   From: B H, Girish [mailto:g.b.h@sap.com]\n\n   When we CHECKOUT \"coll\", we get the working-collection \"/wr/wr123\". \n   What should the PROPFIND on /wr/wr123 return?\n   a) /wr/wr123/vh20 (binding-name is the 'name' of the version-history),\n   /wr/wr123/vh21 and /wr/wr123/vh22\n   OR\n   b) /wr/wr123/a (binding-name is still the same as the binding-name in the\n   version-controlled-collection), /wr/wr123/b and /wr/wr123/c\n\nThe latter, (b).\n\n   Certainly the latter is more convenient. However, is this specifically\n   mentioned in the spec?\n\nGood point!  This is not stated explicitly in the spec, and should be.\nI'll add this to the errata list.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1432594"}, {"subject": "Re: Why the Web", "content": "Mark,\n\nI worked in process control systems for ten years or so, and\nmy answer is: no, mechanisms such as you describe aren't\ngood enough. You need transactional reliability.\n\n   Brian\n\nMark Baker wrote:\n> \n> > I can't see any basic reason why a thermostat should be accessed as if\n> > it was a hypertext document.\n> \n> I would do it for the same reason that anything ends up on the Web;\n> \n> - I can manipulate it from the same app I use to manipulate so much of\n> my life already; the browser\n> - it can leverage existing and yet-to-be-developed extensions such as\n> WebDAV so that access to it can be locked, versioned, etc..\n> - if I forget its URL, Google can find it for me\n> - if my house network is unreliable, an existing cache on the network\n> can let me know what the last cached state of my thermostat is, and\n> when that state snapshot was taken\n> - authentication for free\n> - content negotiation permits my french-speaking serviceman to\n> also manipulate and debug it remotely through the same URL\n> \n> etc..\n> \n> If that isn't reason enough for you, then do it just to prevent the\n> APPS area from needing 10 area directors by the end of the decade. 8-)\n> \n> > I would expect building-services control\n> > messages to get layered directly over a transport protocol in due\n> > course. I certainly want thermostats to be accessed by a highly reliable\n> > mechanism that survives disconnected operation, which is where this\n> > thread started.\n> \n> You didn't think my explanation of reliability in the context of\n> thermostat control was sufficient?  Can you elaborate on what else\n> you'd think would be needed?\n> \n> MB\n> --\n> Mark Baker, Chief Science Officer, Planetfred, Inc.\n> Ottawa, Ontario, CANADA.      mbaker@planetfred.com\n> http://www.markbaker.ca   http://www.planetfred.com\n\n\n\n", "id": "lists-007-14332799"}, {"subject": "Re: Requirements for reliable message deliver", "content": "The Web is fundamentally designed for person-to-person communication,\nnot program-to-program.  It works OK for device-to-person as well\n(viewing/setting your home thermostat over the Web, for example), but\nonly because there's a person in the loop to handle exceptions.\n\nBill\n\n> > But as a quick-and-practical answer, because I want my thermostat to be\n> > a first class resource on the Web.  This is what the Web was designed\n> > to be and do.\n> \n> if the design of the web is to coerce everything into one protocol,\n> it's fundamentally broken.    perhaps that was the intent, but \n> I'm happy that things didn't work out that way.\n\n\n\n", "id": "lists-007-14342429"}, {"subject": "Re: Why the Web", "content": "This reminds me of the folks who built RPC systems by setting properties\non the root window of a specified X Window System server.  It was the\nonly piece of software they had that was reasonably well implemented...\n\nBill\n\n> I would do it for the same reason that anything ends up on the Web;\n> \n> - I can manipulate it from the same app I use to manipulate so much of\n> my life already; the browser\n> - it can leverage existing and yet-to-be-developed extensions such as\n> WebDAV so that access to it can be locked, versioned, etc..\n> - if I forget its URL, Google can find it for me\n> - if my house network is unreliable, an existing cache on the network\n> can let me know what the last cached state of my thermostat is, and\n> when that state snapshot was taken\n> - authentication for free\n> - content negotiation permits my french-speaking serviceman to\n> also manipulate and debug it remotely through the same URL\n> \n> etc..\n\n\n\n", "id": "lists-007-14351107"}, {"subject": "Re: Why the Web", "content": "> Mark,\n> \n> I worked in process control systems for ten years or so, and\n> my answer is: no, mechanisms such as you describe aren't\n> good enough. You need transactional reliability.\n\nIf you mean that an HTTP operation needs to occur within the context of\na larger transaction, HTTP can do that so long as the interaction\nremains stateless (see [1]).\n\nBut I question whether this is needed in the use case I provided.\nPerhaps if you're controlling a thermostat used in some chemical\nengineering plant you'd need it, but not in a house.\n\n [1] http://www1.ics.uci.edu/pub/ietf/http/hypermail/2001/0044.html\n\nMB\n-- \nMark Baker, Chief Science Officer, Planetfred, Inc.\nOttawa, Ontario, CANADA.      mbaker@planetfred.com\nhttp://www.markbaker.ca   http://www.planetfred.com\n\n\n\n", "id": "lists-007-14359755"}, {"subject": "Re: Requirements for reliable message deliver", "content": "On Fri, Dec 14, 2001 at 09:28:22AM -0800, Bill Janssen wrote:\n> The Web is fundamentally designed for person-to-person communication,\n> not program-to-program.  It works OK for device-to-person as well\n> (viewing/setting your home thermostat over the Web, for example), but\n> only because there's a person in the loop to handle exceptions.\n\nThat is _not_ the view held by the entire W3C and most of the people\nworking on web based software these days. Many web applications work very\nwell with no human involvement at all....\n\nBesides, what are you calling the 'web'? Tim and most of the W3C have\nroughly defined it as the set of things identifiable via URIs...\n\n-MM\n\n> > > But as a quick-and-practical answer, because I want my thermostat to be\n> > > a first class resource on the Web.  This is what the Web was designed\n> > > to be and do.\n> > \n> > if the design of the web is to coerce everything into one protocol,\n> > it's fundamentally broken.    perhaps that was the intent, but \n> > I'm happy that things didn't work out that way.\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | urn:pin:1\nmichael@neonym.net      |                              | http://www.neonym.net\n\n\n\n", "id": "lists-007-14368141"}, {"subject": "RE: Requirements for reliable message deliver", "content": "Michael Mealling wrote,\n> Besides, what are you calling the 'web'? Tim and most of the W3C \n> have roughly defined it as the set of things identifiable via \n> URIs...\n\nYes, but that's a pretty imperialist definition given that *anything*\ncan be identified by a URI (for suitable readings of 'can'). I don't \nsee any good reason to accept it.\n\nCheers,\n\n\nMiles\n\n-- \nMiles Sabin                                     InterX\nInternet Systems Architect                      27 Great West Road\n+44 (0)20 8817 4030                             Middx, TW8 9AS, UK\nmsabin@interx.com                               http://www.interx.com/\n\n\n\n", "id": "lists-007-14377716"}, {"subject": "Re: Requirements for reliable message deliver", "content": "On Fri, Dec 14, 2001 at 06:24:14PM -0000, Miles Sabin wrote:\n> Michael Mealling wrote,\n> > Besides, what are you calling the 'web'? Tim and most of the W3C \n> > have roughly defined it as the set of things identifiable via \n> > URIs...\n> \n> Yes, but that's a pretty imperialist definition given that *anything*\n> can be identified by a URI (for suitable readings of 'can'). I don't \n> see any good reason to accept it.\n\nAccept whatever you want. But the Apps area, the industry and most other \nstandards bodies accept that definition. The web is much more than\nyour browser....\n\n-MM\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | urn:pin:1\nmichael@neonym.net      |                              | http://www.neonym.net\n\n\n\n", "id": "lists-007-14387267"}, {"subject": "RE: Requirements for reliable message deliver", "content": "Michael Mealling wrote,\n> Miles Sabin wrote,\n> > Yes, but that's a pretty imperialist definition given that \n> > *anything* can be identified by a URI (for suitable readings of \n> > 'can'). I don't see any good reason to accept it.\n>\n> Accept whatever you want. But the Apps area, the industry and most \n> other standards bodies accept that definition. The web is much more \n> than your browser....\n\nI don't disagree, but there's a world of difference (literally) \nbetween \"not just a browser\" and \"everything that could conceivably be \naddressed via some URI scheme or other\".\n\nGiven the RFC 2396 definition,\n\n  A resource can be anything that has identity.  Familiar examples \n  include an electronic document, an image, a service (e.g., \"today's \n  weather report for Los Angeles\"), and a collection of other \n  resources.  Not all resources are network \"retrievable\"; e.g., human \n  beings, corporations, and bound books in a library can also be \n  considered resources.\n\nthat's potentially everything, period, at which point the term\nbecomes useless.\n\nSince when did the definition of the web stretch so wide that things \nwhich aren't even network retrievable are considered to be part of it?\n\nCheers,\n\n\nMiles\n\n-- \nMiles Sabin                                     InterX\nInternet Systems Architect                      27 Great West Road\n+44 (0)20 8817 4030                             Middx, TW8 9AS, UK\nmsabin@interx.com                               http://www.interx.com/\n\n\n\n", "id": "lists-007-14396843"}, {"subject": "Re: Requirements for reliable message deliver", "content": "> The Web is fundamentally designed for person-to-person communication,\n> not program-to-program.\n\nThis is a common misconception.  It was designed for both.  It just\nhappens to be used primarily for human communication today.\n\n>  It works OK for device-to-person as well\n> (viewing/setting your home thermostat over the Web, for example), but\n> only because there's a person in the loop to handle exceptions.\n\nHave you been following the \"Semantic Web\"?\n\nhttp://www.scientificamerican.com/2001/0501issue/0501berners-lee.html\n\nMB\n-- \nMark Baker, Chief Science Officer, Planetfred, Inc.\nOttawa, Ontario, CANADA.      mbaker@planetfred.com\nhttp://www.markbaker.ca   http://www.planetfred.com\n\n\n\n", "id": "lists-007-14407449"}, {"subject": "versioned collections vs. delete on VH", "content": "Consider the following scenario:\n\nversioned collection \"/a\" with versioned plain resource \"/a/b\".\n\n\"/a\" gets checked out and it's DAV:checked-out property points to\n\"/versions/120\".\n\nDAV:version-history of \"/a/b\" points to \"/vhr/123\".\n\nDAV:version-controlled-binding-set of \"/versions/120\" maps the internal\nmember name \"a\" to \"/vhr/123\".\n\nNow, \"/vhr/123\" gets deleted (server decides that it allows deletion of\nVHRs, un-version-controls \"/a/b\" and removes versions).\n\nDoes this change the DAV:version-controlled-binding-set of \"/versions/120\"?\n\nIf it doesn't (which I assume), the user has lost the ability to access the\nversion history. So, to find and retrieve an old version of \"/a/b\", it will\nhave to revive the version history using UNCHECKOUT or UPDATE, or to create\na working collection. Right?\n\nJulian\n\n\n\n", "id": "lists-007-1441007"}, {"subject": "Re: Requirements for reliable message deliver", "content": "> Since when did the definition of the web stretch so wide that things \n> which aren't even network retrievable are considered to be part of it?\n\nIf I recall Roy correctly, 1993.\n\nI'm not personally retrievable over a network, but I assert that\n\"http://www.markbaker.ca\" identifies me uniquely on the Web.\nInvoking a GET on that will return an HTML representation of me,\nincluding a description of my work, family, affiliations, etc..\n\nMB\n-- \nMark Baker, Chief Science Officer, Planetfred, Inc.\nOttawa, Ontario, CANADA.      mbaker@planetfred.com\nhttp://www.markbaker.ca   http://www.planetfred.com\n\n\n\n", "id": "lists-007-14415785"}, {"subject": "Re: Why the Web", "content": "> This reminds me of the folks who built RPC systems by setting properties\n> on the root window of a specified X Window System server.  It was the\n> only piece of software they had that was reasonably well implemented...\n\nI don't understand this.  HTTP was designed to support this type of\ncoarse grained interaction style that involves transferring\nrepresentations of resources around the network.  In my thermostat\nexample, I was using it *exactly* as it was designed to be used.\nThere is simply no comparison to that hack job you described.\n\nMB\n-- \nMark Baker, Chief Science Officer, Planetfred, Inc.\nOttawa, Ontario, CANADA.      mbaker@planetfred.com\nhttp://www.markbaker.ca   http://www.planetfred.com\n\n\n\n", "id": "lists-007-14424760"}, {"subject": "Re: Requirements for reliable message deliver", "content": "On Fri, Dec 14, 2001 at 06:48:16PM -0000, Miles Sabin wrote:\n> Michael Mealling wrote,\n> > Miles Sabin wrote,\n> > Accept whatever you want. But the Apps area, the industry and most \n> > other standards bodies accept that definition. The web is much more \n> > than your browser....\n> \n> I don't disagree, but there's a world of difference (literally) \n> between \"not just a browser\" and \"everything that could conceivably be \n> addressed via some URI scheme or other\".\n> \n> Given the RFC 2396 definition,\n> \n>   A resource can be anything that has identity.  Familiar examples \n>   include an electronic document, an image, a service (e.g., \"today's \n>   weather report for Los Angeles\"), and a collection of other \n>   resources.  Not all resources are network \"retrievable\"; e.g., human \n>   beings, corporations, and bound books in a library can also be \n>   considered resources.\n> \n> that's potentially everything, period, at which point the term\n> becomes useless.\n\nActually no it isn't. RDF uses that basic notion plus an assertion\nframework together to build a very robust knowlege description framework.\nURIs are to the Web what IP is to the Internet. You could just as\neasily say that since everything on the Internet runs over IP that\nthe point that it does is useless...\n\n> Since when did the definition of the web stretch so wide that things \n> which aren't even network retrievable are considered to be part of it?\n\nSince 1991 when Tim brought the entire lot to the IETF. At the time\nthere wasn't an HTTP protocol and the major consumer of URIs was gopher...\n\n-MM\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | urn:pin:1\nmichael@neonym.net      |                              | http://www.neonym.net\n\n\n\n", "id": "lists-007-14433084"}, {"subject": "Re: Requirements for reliable message deliver", "content": "\"The enemy of the good is the perfect\"....\n\nI'll take a thermostat with a web page interface this year over one with\nsome fancy protocol interface several years later, at least in my house...\n\nWhether such fancyness is needed is precisely dependent on the\nconsequences of failure.  I can tolerate my thermostat being set wrong\nfor a while....\n\nDoesn't mean I want that for a nuclear power plant, however :-).\n                                - Jim\n\n--\nJim Gettys\nCambridge Research Laboratory\nCompaq Computer Corporation\njg@pa.dec.com\n\n\n\n", "id": "lists-007-14443449"}, {"subject": "Re: Why the Web", "content": "> > I can't see any basic reason why a thermostat should be accessed as if\n> > it was a hypertext document.\n> \n> I would do it for the same reason that anything ends up on the Web;\n> \n> - I can manipulate it from the same app I use to manipulate so much of\n> my life already; the browser\n> - it can leverage existing and yet-to-be-developed extensions such as\n> WebDAV so that access to it can be locked, versioned, etc..\n> - if I forget its URL, Google can find it for me\n> - if my house network is unreliable, an existing cache on the network\n> can let me know what the last cached state of my thermostat is, and\n> when that state snapshot was taken\n> - authentication for free\n> - content negotiation permits my french-speaking serviceman to\n> also manipulate and debug it remotely through the same URL\n> \n> etc..\n\nthough you might like them for your thermostat, you're making a false \nassumption that such things are desirable for thermostats, or any\nother application, in general .\n\n> If that isn't reason enough for you, then do it just to prevent the\n> APPS area from needing 10 area directors by the end of the decade. 8-)\n\ngiven the complexity and weaknesses of HTTP and the wide variety of\nbehavior in the deployed HTTP infrastructure, it's often more work \nto figure out and specify how to use HTTP to do something, than it \nis to design your own protocol.\n\nHTTP often works okay on a small scale.  But I have yet to see someone \nsuggest using HTTP for a widely-used protocol who truly understood \nthe implications of that design choice.\n\nKeith\n\n\n\n", "id": "lists-007-14452460"}, {"subject": "Re: Why the Web", "content": "> given the complexity and weaknesses of HTTP and the wide variety of\n> behavior in the deployed HTTP infrastructure, it's often more work \n> to figure out and specify how to use HTTP to do something, than it \n> is to design your own protocol.\n\nNo.  It is hard to use HTTP to do something for which it was specifically\ndesigned not to do well.  All protocols have trade-offs in order to\nmatch the efficiencies of the requirements at the time they were designed,\nand much of HTTP's requirements centered around deployability in a\nheterogeneous, multi-organizational environment.  To consider a protocol's\ndesign in isolation of its context is a poor way to create systems.\n\nAlmost all of HTTP's complexity is due to two things: MIME syntax and\nthe optional features of content/encoding negotiation.  The only thing\nhard about building an HTTP service is dealing with the raw TCP socket\nhandling bugs in operating systems and browsers.\n\n> HTTP often works okay on a small scale.  But I have yet to see someone \n> suggest using HTTP for a widely-used protocol who truly understood \n> the implications of that design choice.\n\nHTTP is still better than any other published protocol for what it is\nintended to do.  Mark's point, which I think he is belaboring, is that\nthe same application can be designed in many ways, some of which will\nwork well with the Web paradigm and some of which will work against it.\nThat doesn't mean HTTP is the best way of implementing all applications.\nIt simply means that there are good uses of HTTP and bad uses of HTTP.\nI'd rather burn time on replacing HTTP with something more efficient,\nbut for the same architecture, than waste it trying to make HTTP\nefficient for all architectures.\n\nIn any case, HTTPR is a silly idea because it attempts to use HTTP as\na transport protocol, which is a total waste of bits.  Firewalls exist\nfor a reason, and that reason won't change just because more companies\ntry to wedge their protocols through TCP 80.  The firewalls will just\nadapt to block them by content, and the resulting systems will fail in\nways that will be a customer-service nightmare.  DOA, just like DCOM\nover HTTP, but it will keep happening over and over again as long as\npeople fail to understand the reasons HTTP is not a transport protocol\n(beyond the simple notion of efficiency).\n\n....Roy\n\n\n\n", "id": "lists-007-14461784"}, {"subject": "Re: Requirements for reliable message deliver", "content": "> That is _not_ the view held by the entire W3C and most of the people\n> working on web based software these days. Many web applications work very\n> well with no human involvement at all....\n\nYes, I know, but it's still *my* view.\n\n> Besides, what are you calling the 'web'? Tim and most of the W3C have\n> roughly defined it as the set of things identifiable via URIs...\n\nThat's a good point.  I was referring to things reachable with HTTP.\n\nBill\n\n\n\n", "id": "lists-007-14471890"}, {"subject": "Re: Why the Web", "content": "\"Roy T. Fielding\" wrote:\n...\n> In any case, HTTPR is a silly idea because it attempts to use HTTP as\n> a transport protocol, which is a total waste of bits.  \n\nThis started as a convsersation about requirements, not solutions.\n\nHowever, since you mention a solution: as far as I know, the\nlayering of HTTPR over HTTP/POST is a pragmatic choice and it could\nbe layered over a real transport just as well. But real transports\naren't known for penetrating firewalls either.\n\n   Brian\n\n\n\n", "id": "lists-007-14480295"}, {"subject": "Need some help on Apach", "content": "Dear Friends,\n\nI'm a novice who is trying hands on apache web server.\nRecently, I \ntried fortifying my web server using the .htacess\nfeature... I \ncreated the .htaccess and the .htpasswd files as per\nthe instructions \nand the syntax is error free. Unfortunately this is\nnot working. Do i \nneed to change any other settings? Surprisingly the\nsame feature \nworked on another apache server. I donno what to do.\nCan any of you \nfolks help me? \n\nplease reply to no1kole@yahoo.com or\nbapubalu@utdallas.edu\n\nRegards,\n\nBalaji\n\n\n=====\nBalaji B. G\n2200 Waterview Parkway, Apt # 1521, Richardson, Texas 75080\nPhone: 972-699-7341 (Res), 972-883-6290 (Lab)\nEmail: no1koole@yahoo.com  bapubalu@vsnl.com\nURL: http://www.utdallas.edu/~bapubalu\n************************************************************\nHappiness is not in belongings, but is in belonging...\n\n__________________________________________________\nDo You Yahoo!?\nSend your FREE holiday greetings online!\nhttp://greetings.yahoo.com\n\n\n\n", "id": "lists-007-14487667"}, {"subject": "[????]??????,?????? ????  ??/????????  ?????? ?????????? ????..!", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-14495979"}, {"subject": "Can there be multiple BINDs to a VCR", "content": "Hi,\n\ngiven a resource with the distinct URLs \"/a1\" and \"/a2\" (so both URLs\nidentify the same resource).\n\n1) Is it allowed to VERSION-CONTROL this resource?\n\n2) If yes and assuming that the VCR is checked out, what is the\nDAV:checkout-set of the \"current\" version (the version identified by the\nVCR's checked-out property)? Does it contain DAV:href elements for both\nURLs?\n\nJulian\n\n\n\n", "id": "lists-007-1449617"}, {"subject": "Buying a home?  Self employed?  Hard to qualify?126", "content": "WE SOLVE MORTGAGE PROBLEMS !!!\n\nSpecializing in loans for exceptional people\n\n     Self-Employed Borrowers\n     No Income or Asset Verification\n     All Levels of Credit Quality\n     Up to 100% Financing\n     High Debt Ratios\n     Non-Owner Occupied Properties\n     Renovation Plus Purchase and Refinance\n\n$UPER $OLUTION$ ......... $UPER RE$ULT$\n\nIf you would like additional information \nplease email us at wed1111@excite.com?Subject=MoreInformation\n\nHelp a family member or a friend with their home loan needs by \nFORWARDING THIS EMAIL TO THEM!\n\nAn Equal Housing Opportunity Lender\n\n\n\nIf you wish to be removed from this advertiser's future mailings, please reply \nwith the subject \"Remove\" and this software will automatically block you \nfrom their future mailings.\n\n\n\n", "id": "lists-007-14544127"}, {"subject": "Brand New E-Mail pager for FR-EE", "content": "Brand New E-Mail pager for FREE!\n\n   No long term contract\n   No activation fee\n   No big prepayment of airtime\n   No credit check\n\n   PAGING AMERICA is going to give you absolutely Free the Brand new Motorola\n   Accessmate E-Mail display pager. This is the top of the line PCS technology\n   pager made today. This side viewable display pager has a retail value of\n   $189.00and comes with its own e-mail address so you can receive your e-mails\n   as well as alpha-numeric and numeric messages instantly where ever you are.\n   Your new e-mail pager has features like 50,000 character memory, message time\n   stamping, automatic garbled message correction, beeps or vibrates,\n   incandescent backlight, saved message folder, a unique never out of range\n   feature that allows your pager to retrieve messages sent earlier when your\n   pager was out of range or turned completely off. You can also receive\n   weather, news and sports .The Motorola e-mail pager is very small and uses\n   only a single double A battery. All we ask before we ship you your Free pager\n   is for you to allow us to provide the airtime for you. There is no long term\n   contract or credit check. Airtime is month to month and can be cancelled at\n   any time. This pager will comes pre-programmed with its own e-mail address as\n   well as a local telephone number to receive numeric pages. This pager comes\n   with a complete 30 day money back guarantee, if after receiving this pager\n   you're not completely happy, send it back and receive a full refund.\n\n   For immediate delivery call Paging America at toll free at 877-699-8545\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrand New E-Mail pager for FREE!\n\n\n\n", "id": "lists-007-14551105"}, {"subject": "Separate discussion list for IDN", "content": "Paul Hoffman and I have created a mailing list for discussions of \nonly the IDNA algorithm described in draft-ietf-idn-idna-00.txt. The \nreason for a separate mailing list for this discussion is because it \notherwise the discussion of IDNA will otherwise get bogged down with \narguments whether IDNA is the correct way to do IDN. Those discussion \nshould instead be on the IDN WG mailing list (although the protocol \ndesign team report concluded that an ACE-based solution in the \napplication is the right way to go for the short term). Paul and I \nhave not got many comments, but we feel that the document and \ndescription, as well as the algorithm, might be made better.\n\nFurther, this message is sent to the apps-discuss list aswell as to \nthe IDN mailing list as the IDNA algorithm can be used for domain \nname protocol components regardless of what protocol is using it.\n\nThe name of the mailing list is ietf-idna@mail.apps.ietf.org.\nSubscribe by sending request to ietf-idna-request@mail.apps.ietf.org.\n\n    paf\n\n-- \nPatrik F?ltstr?m <paf@cisco.com>                         Cisco Systems\nConsulting Engineer                                  Office of the CSO\nPhone: (Stockholm) +46-8-4494212            (San Jose) +1-408-525-0940\n        PGP: 2DFC AAF6 16F0 F276 7843  2DC1 BC79 51D9 7D25 B8DC\n\n\n\n", "id": "lists-007-14558991"}, {"subject": "Brand New E-Mail pager for FR-EE", "content": "Brand New E-Mail pager for FREE!\n\n   No long term contract\n   No activation fee\n   No big prepayment of airtime\n   No credit check\n\n   PAGING AMERICA is going to give you absolutely Free the Brand new Motorola\n   Accessmate E-Mail display pager. This is the top of the line PCS technology\n   pager made today. This side viewable display pager has a retail value of\n   $189.00and comes with its own e-mail address so you can receive your e-mails\n   as well as alpha-numeric and numeric messages instantly where ever you are.\n   Your new e-mail pager has features like 50,000 character memory, message time\n   stamping, automatic garbled message correction, beeps or vibrates,\n   incandescent backlight, saved message folder, a unique never out of range\n   feature that allows your pager to retrieve messages sent earlier when your\n   pager was out of range or turned completely off. You can also receive\n   weather, news and sports .The Motorola e-mail pager is very small and uses\n   only a single double A battery. All we ask before we ship you your Free pager\n   is for you to allow us to provide the airtime for you. There is no long term\n   contract or credit check. Airtime is month to month and can be cancelled at\n   any time. This pager will comes pre-programmed with its own e-mail address as\n   well as a local telephone number to receive numeric pages. This pager comes\n   with a complete 30 day money back guarantee, if after receiving this pager\n   you're not completely happy, send it back and receive a full refund.\n\n   For immediate delivery call Paging America at toll free at 877-699-8545\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrand New E-Mail pager for FREE!\n\n   No long term contract\n   No activation fee\n   No big prepayment of airtime\n   No credit check\n\n\n\n", "id": "lists-007-14566977"}, {"subject": "Standards for machine translation in e-mail and  netnew", "content": "Work on standards for language-translation in e-mail and netnews can\ntake place in the mailing list LANGTRANS@SU.SE.\n\nTo subscribe to this mailing list, send a message to LISTSERV@SU.SE\nwhich contains the text SUB[SCRIBE] LANGTRANS\n\nWhen your subscription has been accepted, please write a short message\nto the list describing yourself and your interest in languate \ntranslation standards.\n\nMore information and the present IETF drafts can be downloaded from\nhttp://dsv.su.se/jpalme/ietf/jp-ietf-home.html#translation\n\nThe web page above earlier gave an incorrect description of how\nto join the mailing list. This has been corrected.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-14575012"}, {"subject": "RE: Can there be multiple BINDs to a VCR", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   given a resource with the distinct URLs \"/a1\" and \"/a2\" (so both URLs\n   identify the same resource).\n\n   1) Is it allowed to VERSION-CONTROL this resource?\n\nYes.\n\n   2) If yes and assuming that the VCR is checked out, what is the\n   DAV:checkout-set of the \"current\" version (the version identified by the\n   VCR's checked-out property)? Does it contain DAV:href elements for both\n   URLs?\n\nThat's up to your server.  It must at least have the request-URL\nof the CHECKOUT request.  A client cannot count on having both URLs\nin the DAV:checkout-set, because that is not required by the protocol.\nNote that in general, there will not be a list of all URLs, because\nthere can be an infinite number of URLs that identify a resource when\na collection that contains the resource also contains a binding to\nitself.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1457680"}, {"subject": "Re: Standards for machine translation in e-mail andnetnew", "content": "Hello Jacob,\n\nI have just had a short look at this. A few comments.\n\nI don't understand what multipart/choices is for. There are\nimplementation problems for multipart/alternative, but they\ndon't get fixed by proposing something new. They can (and\nshould) just be fixed asap, which is easier than to implement\nsomething new.\n\nPlease also note that the 'selector' parameter is very similar\nto the 'differences' parameter proposed in RFC 1766\n(e.g. http://www.innosoft.com/rfc/rfc1766.html), which yet\nhas to take on. It would at least be worthwhile to use the\nsame name.\n\nFor ftp://ftp.dsv.su.se/users/jpalme/draft-palme-email-translation-02.txt,\nit says \"All of these methods of transmitting information is based on the\nassumption that all language versions are ready and available when a\nmessage is sent.\". This is clearly wrong, because it doesn't\napply to http. It may also be worth mentioning that some formats,\nin particular SVG (http://www.w3.org/TR/SVG/struct.html#SwitchElement)\nand SMIL (http://www.w3.org/TR/REC-smil/#switch), have a <switch>\nconstruct that allows to display one of the languages contained\nin the document.\n\nThe provisions regarding the \"Content-Translator\" header field:\n >>>>\n   The \"Content-Translator\" header field indicates who made the\n   translation. When a translation is submitted, the \"From\" header field\n   should still indicate the original author, but the \"Content-Translator\"\n   header field can indicate who made the translation.\n >>>>\nare very scary, because they will produce very misleading impression\non user agents that don't understand Content-Translator (namely\nthat the mail came from the original sender). Things should be\nturned around, so that such an impression is not possible.\n\nIn general, I think that translations, in particular incremental\nones, fit much better with the Web paradigm than with the message\nparadigm. It might be better to get some more actual experience\non the Web side rather than to try to force things into messaging.\n\n\nRegards,   Martin.\n\n\nAt 11:09 01/02/13 +0100, Jacob Palme wrote:\n>Work on standards for language-translation in e-mail and netnews can\n>take place in the mailing list LANGTRANS@SU.SE.\n>\n>To subscribe to this mailing list, send a message to LISTSERV@SU.SE\n>which contains the text SUB[SCRIBE] LANGTRANS\n>\n>When your subscription has been accepted, please write a short message\n>to the list describing yourself and your interest in languate translation \n>standards.\n>\n>More information and the present IETF drafts can be downloaded from\n>http://dsv.su.se/jpalme/ietf/jp-ietf-home.html#translation\n>\n>The web page above earlier gave an incorrect description of how\n>to join the mailing list. This has been corrected.\n>--\n>Jacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\n>for more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-14587845"}, {"subject": "Re: Standards for machine translation in e-mail  andnetnew", "content": "I suggest that further discussion of this is done in the\n\"langtrans\" mailing list. To subscribe to this list,\nsend a message containing the text\n\nsub langtrans your name, not your e-mail address\n\nto listserv@su.se\n\nI have written a more complete reply to Martin's message\nin that mailing list. For those who have not yet subscribed\nto the list, you can read my more complete replies to the\nmessages from Martin and Keith at:\nhttp://salut.nu/forum/uno/6/1/17/ and\nhttp://salut.nu/forum/uno/6/1/19/\nThe full archives of the mailing list can be read at\nhttp://salut.nu/forum/uno/6/1/;allmessages\n\n\nAt 12.20 +0900 01-02-14, Martin Duerst wrote:\n>I don't understand what multipart/choices is for. There are\n>implementation problems for multipart/alternative, but they\n>don't get fixed by proposing something new. They can (and\n>should) just be fixed asap, which is easier than to implement\n>something new.\n\nAt 01.04 -0500 01-02-14, Keith Moore wrote:\n>I would further argue that \"something new\" in this space which is\n>so similar to multipart/alternative serves merely to increase the\n>number of implementation options, and thus, to decrease the\n>liklihood of interoperability.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-14604125"}, {"subject": "Bankruptcy", "content": "Have you been considering filing\n \nBancruptcy?\n \nDon't do it until you read this information\n \n  THE REAL TRUTH ABOUT WHETHER FILING\nBANKRUPTCY IS YOUR BEST ALTERNATIVE!\n \nYou may be shocked by all the phony information that is \ncirculating about the\npros and cons of bancruptcy (some spread by credit card \ncompanies).\n \nHere is a small sample of the secrets you will learn:\nDiscover why bankruptcy may actually improve your credit rating!\n\nLearn to Restart your life Completely Debt-Free.\n\nLearn when a Chapter 13 is a better choice than a Chapter 7 \nbankruptcy.\n\nHow to stop your creditors dead in their tracks! How to \nimmediately stop:\n\nForeclosures\nEvictions\nWage Garnishments\nSeizures\nLiens\nCreditor lawsuits\nLearn to identify when there are better solutions to your \nfinancial problems than bankruptcy\n\nHow to know if you need a lawyer to help you.\n\nHow to identify which debts ARE eliminated in bankruptcy and \nwhich ARE NOT! (Key)\n\nWhat if you charged up your credit card(s) just before filing! \n(Key)\n\nHOW TO SAVE $1,000 OR MORE IN BANKRUPTCY LAWYER FEES\n\nI'm going to reveal two closely guarded secrets of the legal \nprofession:\n \n1) The law does not require that you retain a lawyer to help you \nfile bankruptcy in ANY state.\n2) The vast majority of personal bankruptcy cases are highly \nroutine and could easily be handled\nwithout paying unnecessary lawyer fees.\n \nCLICK HERE FOR MORE INFORMATION\nhttp://www.newcreditworthiness.com/11/bancruptcy/ \n\nTo be removed, go to \nhttp://www.newcreditworthiness.com/remove.html\n\n  \n \n \n \n \n \n \n \n \n \n \n\n\n\n", "id": "lists-007-14617029"}, {"subject": "Filters Please! was: Re: Bankruptcy", "content": "Isn't there a filter preventing spam on the list... something like if you\nare not a member you cannot send the list email??\n\n-al\n\n-----------------------------------------------------\nBest Internet Services - Web Hosting $10.00 a month\nhttp://www.akc.com\n\n----- Original Message -----\nFrom: <lister278@lycos.com>\nTo: <discuss@apps.ietf.org>\nSent: Thursday, February 15, 2001 2:34 AM\nSubject: Bankruptcy?\n\n\n> Have you been considering filing\n>\n> Bancruptcy?\n>\n> Don't do it until you read this information\n>\n>   THE REAL TRUTH ABOUT WHETHER FILING\n> BANKRUPTCY IS YOUR BEST ALTERNATIVE!\n>\n> You may be shocked by all the phony information that is\n> circulating about the\n> pros and cons of bancruptcy (some spread by credit card\n> companies).\n>\n> Here is a small sample of the secrets you will learn:\n> Discover why bankruptcy may actually improve your credit rating!\n>\n> Learn to Restart your life Completely Debt-Free.\n>\n> Learn when a Chapter 13 is a better choice than a Chapter 7\n> bankruptcy.\n>\n> How to stop your creditors dead in their tracks! How to\n> immediately stop:\n>\n> Foreclosures\n> Evictions\n> Wage Garnishments\n> Seizures\n> Liens\n> Creditor lawsuits\n> Learn to identify when there are better solutions to your\n> financial problems than bankruptcy\n>\n> How to know if you need a lawyer to help you.\n>\n> How to identify which debts ARE eliminated in bankruptcy and\n> which ARE NOT! (Key)\n>\n> What if you charged up your credit card(s) just before filing!\n> (Key)\n>\n> HOW TO SAVE $1,000 OR MORE IN BANKRUPTCY LAWYER FEES\n>\n> I'm going to reveal two closely guarded secrets of the legal\n> profession:\n>\n> 1) The law does not require that you retain a lawyer to help you\n> file bankruptcy in ANY state.\n> 2) The vast majority of personal bankruptcy cases are highly\n> routine and could easily be handled\n> without paying unnecessary lawyer fees.\n>\n> CLICK HERE FOR MORE INFORMATION\n> http://www.newcreditworthiness.com/11/bancruptcy/\n>\n> To be removed, go to\n> http://www.newcreditworthiness.com/remove.html\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n\n\n\n", "id": "lists-007-14625084"}, {"subject": "Re: Filters Please! was: Re: Bankruptcy", "content": "Al,\n\nThis is an application of the NAT service model to ... uh ... Layer 11\nin the Extended ISO Reference Model (xISORM).\n\nRenumbering and cash-exhaustion solved in one handy package.\n\nEric\n\n\n\n", "id": "lists-007-14635593"}, {"subject": "Re: Filters Please! was: Re: Bankruptcy", "content": "> Isn't there a filter preventing spam on the list... something like if you\n> are not a member you cannot send the list email??\n\nyes, there are filters in place.  until very recently they were almost\n100% effective.  better filters have been written, and will be installed\nas soon as they are tested for reliability.\n\nI've been swamped in my day job for the past few weeks and haven't\nhad time to get back to them.\n\nKeith\n\n\n\n", "id": "lists-007-14643288"}, {"subject": "Your Account Approva", "content": "Dear Customer,\n\nWe Are Pleased To Inform You That Your Application Has Been \nAccepted.\nYou Should Now Go To The Following Url And Complete The \nApplication Process,\n\nhttp://www.evidence-eliminator.com/go.shtml?A653465\n\nPlease Be Sure To Copy And Paste The EXACT Code Into Your Browser \nWindow Otherwise It May Result In Your Application Being Voided.\n\nOnce You Have Completed The Next Stage In Your Application We \nWill Mail Your Unique User Code And, You May Then Take Advantage \nOf Our Exclusive Program.\n\nThank You For Your Interest In Our Program.\n\nApplications@Evidence-Eliminator.Com\n \n \n \n \n \n \n \n \n\n\n\n", "id": "lists-007-14650537"}, {"subject": "Software enginee", "content": "Hi:\n\nI have got your email from the Web site and I am very interested in working for your company. I \nhave a BS in Electrical Engineering and computer science and worked on my Master degree \nin Telecommunication engineering (not finished due to the lucrative market!). I have also 7++ \nyears of experience with software development, Internet development and hardware. I have \nworked for many companies both in Iran and in the United States using different development \nenvironments.\nI am looking for a position which utilizes my experience. I am open to both Permanent position \nor contract to permanent positions.\n\nI am Canadian resident and have permission to work in Canada.\nI have attached my resume and sincerely appreciate your attention, thank you.\n\nSincerely,\n\nKian Haghdad\n\nHere is my resume:\nKian Haghdad\n8 Kingsbridge Crt., Apt. 508 \nToronto, Ontario M2R 1L5\nHome: (416) 630-7066\nFax:  (416) 630-7991\nEmail: khaghdad27@yahoo.com\n\nI have more than 7+ years of experience in application development, Database Management, \nInternet development. I have also been involved in hardware design. My software \ndevelopment experience is mainly in Visual Basic, Visual C++, Visual J++, Visual InterDev, \nCOM, DCOM, MFC, SDKs, MS-Access, MS-SQL, FoxPro,\nJava script and VB script. Over the years I have been responsible for the \nDevelopment of many applications from design to commercial release.\n\nEDUCATION:\n\nSharif University OF Technology, Tehran (The best technical school in Iran)9/87-6/92\nB.S. Degree: Electrical Engineering and computer science\nWorked on M.S. degree in Telecommunication engineering\n\nEXPERIENCE:\n\n01Communique, Mississauga, Ontario12/00-Present\nInvolved in the development of a web supported version of the communicating Interface\nusing Active Server Pages, JavaScript, VB Script and browser compatibility, Visual C++6.0,\nBorland C++, MSMQ, TCP/IP. \nApplication increases the Modem compatibility for the wide variety of connections.\nIt also provides additional capabilities for the desktop version on the web.\n\nAmerican SkySat, Walnut Creek, California5/00-Present\n* Involved in the development of a web application in Visual InterDev 6.0 using Active Server \nPages (ASP), Microsoft E-Commerce, SQL 7.0, XML, Visual C++ 6.0 and Visual Basic 6.0, \nVisual J++ 6.0, COM (ATL), DCOM, JavaScript and VB Script. The web server was Microsoft \nInternet Information Server (IIS), Microsoft site server 3.0, with Microsoft E-Commerce edition \n3.0 and FrontPage extension running under the NT Server The web application provides NT \nrelated services online. The user can register and buy services and also allows the user to \ntroubleshoot and configure a system at real time online. The web site also provides the \ncapability of chatting online, customer support online, statistical analysis online and transaction \nonline.\n\n* Developed a database management application for a medical health care center, using \nVisual Basic 6.0, SQL 7.0, Crystal report and Access 2000. (Windows 98 and NT)\n\nAmerican Computech, Pleasanton, California3/98-5/00\nDeveloped different applications using Visual C++, Visual J++, and Access.\n\n* Involved in the development of a CRM (Customer Relation Management)web application in \nVisual InterDev 6.0 using Active Server Pages (ASP), Microsoft E-Commerce, SQL 7.0, XML, \nVisual Basic 6.0, Visual J++ 6.0, COM, DCOM, JavaScript and VB Script. (Windows 98 and \nNT)\n\nDeveloped an application in Visual Basic 5.0, Access 97 and Crystal reports (using ODBC) for \nfinancial analyses department of FHP (Concord, California). The application is capable of \nimporting data from other systems, analyzing and processing the data and generating hundreds \nof reports base on the original data.\n\n*Developed an MDI application in Visual C++5,0 and Access 97 for windows called ID maker. \nThe application is designed to drive a digital camera, capture a picture and generate different \nID cards using OLE (marketing for schools and clubs). The Cannon digital camera is controlled \nvia DLL functions calls to the camera's driver. The camera is connected via a parallel port. I \nhave also developed several OCXs for this project.\n\nDeveloped an application in Visual Basic 5.0, Access 97 and Crystal reports (using ODBC). \nThe application is a very large information management system for CBI (City Building Inc. in \nSan Francisco). The application contains 28 relational tables large number of queries forms \nand reports.\n\nTavanir Co., Tehran, Iran9/95-3/98\n*Developed an application in Visual C++ 5.0 intended for network control managements. The \napplication is able to get information such as voltage, active and reactive power from power \nplants and transmission stations and specifies transmission state using power flow method after \na fault occurs on the transmission line. \n\n* Developed an application for voltage drop on the net. The application was developed in \nVisual Basic 5.0 using graphical OCXs.\n\n* Developed hardware for the high voltage network.\n\n*Developed an application in Visual C++ 4.0. The application checks the transmitting power on \nthe lines and controls the system's steady state by alarm system.\n\n*Developed an application in Visual C++ 4.0 set the protection relays in substations to protect \nthe network's reliability.\n\nPishro Co., Tehran, Iran11/94-6/95\nDesigned, developed and implemented electrical systems using computer aided software. The \nelectrical systems were intended for both indoors (Buildings) and outdoors (Airports and \nTerminals).\nThe systems were designed and based on the standard and regulation of electrical system.\n\nPardis Tower Co, Tehran, Iran1/93-11/94\nDesigned simulators for training purpose.\n*Developed an application in  C++ for  cycloconvertor simulator. The  \ncycloconvertor is used in the starters of synchronous motors.\n*Developed application using C++  for control speed of  DC motors. The application\n gets input voltage to the motor, speed of motor and rotor's current. It can control\n the motor speed based on requested speed.\n*Developed application using C++ for step motor's control speed. In order to change the angle \nof dish antenna, the application orders to step motor to change the rotor's situation.\n\nSKILLS:\nSoftware development\nVisual C++, Visual Basic, Visual InterDev, Visual J++, MFC, SDKs, COM, DCOM, ATL ActiveXs \n, C++, Fortran, Intel  8085 Assembler Access.\nInternet development\nVisual InterDev 6.0, Active Server Pages (ASP), SQL 7.0, COM, DCOM, Java script. \nDatabase development\nMS-SQL, Access, FoxPro\nOperating System Used\nNT, MS-Win, UNIX, VAX, MS-DOS\n\n\n\n\n\napplication/msword attachment: kian_Resume_U_C.doc\n\n\n\n\n", "id": "lists-007-14657652"}, {"subject": "RE: versioned collections vs. delete on VH", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   Consider the following scenario:\n\n   versioned collection \"/a\" with versioned plain resource \"/a/b\".\n\n   \"/a\" gets checked out and it's DAV:checked-out property points to\n   \"/versions/120\".\n\n   DAV:version-history of \"/a/b\" points to \"/vhr/123\".\n\n   DAV:version-controlled-binding-set of \"/versions/120\" maps the internal\n   member name \"a\" to \"/vhr/123\".\n\n   Now, \"/vhr/123\" gets deleted (server decides that it allows deletion of\n   VHRs, un-version-controls \"/a/b\" and removes versions).\n\n   Does this change the DAV:version-controlled-binding-set of\n\"/versions/120\"?\n\nThat's up to the server.  There's nothing in the protocol that\nrequires this to be done, but I'm sure there will be implementations\nthat do update the DAV:version-controlled-binding-set in this case.\n\n   If it doesn't (which I assume), the user has lost the ability to access\nthe\n   version history.\n\nIt doesn't matter what the server does with the\nversion-controlled-binding-set.  If the version history has been\ndeleted, the user has lost the ability to access the version history.\nOr maybe I've misunderstood you here.\n\n   So, to find and retrieve an old version of \"/a/b\", it will\n   have to revive the version history using UNCHECKOUT or UPDATE, or to\ncreate\n   a working collection. Right?\n\nYou can't use UNCHECKOUT or UPDATE to retrieve versions from a \ndeleted version history.  Or maybe again I've misunderstood you here.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1466270"}, {"subject": "FREE 2001 NEW CAR QUOT", "content": "The Easiest Way to Get Low Prices on Cars\nDon't make life a hassle by going from dealer to dealer for your \nnext car.\nTake the stress out of it by making the Internet work for you.\nJust click on the link below to get low prices on all makes and \nmodels, new and used.\nIt's FREE, FAST and the EASIEST way to get a great deal on your \nnext car.\n\nhttp://www.getmetheinfo.com/\n\n\nTo be removed from future mailings, please send an email to: \nmailto:remlist003@lycos.com\n \n \n \n \n \n \n \n \n \n \n \n \n \n\n\n\n", "id": "lists-007-14698811"}, {"subject": "Re: OPES Draft Charter and Mailing INfo, please commen", "content": "While I think the goals of OPES are valuable, I have concerns about using \nICAP as a starting point for the HTTP-related work.\n\nWhen I looked, a couple of months ago, ICAP seemed to me to exhibit the \ncharacteristics of a protocol hacked together in a closed group (which the \nICAP forum was) -- lacking awareness of a wider range of protocol design \nissues and concerns.  I think the most productive way forward would be to \nisolate the goals of the protocol, and revisit the overall design.\n\nIn my opinion, the ICAP specification is architecturally weak.  It lacks a \nclear separation between the ICAP protocol elements and HTTP protocol \nelements that are the subject of ICAP protocol actions.  It is also unclear \nwhether the protocol is intended to be an extension of HTTP (i.e. defines \nnew HTTP headers) or is a protocol that happens to look like HTTP.  Is ICAP \nintended to run on port 80?\n\nWhen passing about HTTP protocol units for examination or modification, I \nthink the protocol should be designed to clearly separate the HTTP protocol \nelements from the ICAP protocol elements; e.g. by wrapping in a \nmessage/http MIME structure.  In addition to architectural cleanliness, \nthis has the following specific advantages:  (a) it provides some \ninsulation from possible future changes to HTTP;  (b) it is more likely to \nbe usable if a new generation of web access protocol is deployed;  (c) it \nis more likely to have elements that are usable with other protocols (such \nas SMTP suggested in the charter).\n\nTherefore, my comments on the charter come down to this:\n\nRather than defining different protocols for different kinds of auxiliary \nserver, I think it would be better to design some common protocol elements \nthat can be used over a variety of underlying transfer services, and carry \ninformation _about_ different protocols;  i.e. common protocol elements to \ndeal with the common framework.  Specific service definitions can then be \nadded to deal with specific protocol usage such as HTTP.\n\n#g\n--\n\n\nAt 07:18 PM 12/17/00 -0800, Michael W. Condry wrote:\n\n\n\n>Orthogonal Protocol Extension Services(opes)\n>\n>\n>Co-chairs:\n>    Michael Condry <condry@intel.com>\n>    Hilarie Orman <HORMAN@novell.com>\n>\n>Mailing Lists:\n>    General Discussion: ietf-openproxy@imc.org\n>    To Subscribe: ietf-openproxy-request@imc.org\n>    Web: http://www.extproxy.org\n>    Archive: ftp://ftp.ietf.org/ietf-mail-archive/opes\n>\n>Description of Working Group:\n>\n>The Orthogonal Protocol Extension Services architecture (OPES) enables \n>construction of services executed on application data by participating \n>transit intermediaries.  Caching is the most basic intermediary service, \n>one that requires a basic understanding of application semantics by the \n>cache server.  Because intermediaries divert data temporarily over a \n>pathway different from the transit pathway, one can think of the service \n>path as being orthogonal to the main transit path.  The purpose of this \n>working group is to define the protocols and API's for a broad set of \n>services that facilitate efficient delivery of complex content or services \n>related to content.  The advantage of standardizing these protocols and \n>API's is that the services can be re-used across vendor products without \n>modifying the transit intermediaries or services.\n>\n>The architecture supports services that are either co-located with the \n>transit intermediary or located on other servers (referred to as auxiliary \n>servers in this charter).  The ICAP protocol is being developed for \n>carrying HTTP headers and data to cooperating servers; other protocols for \n>carrying SMTP or other protocols to cooperating servers will be supported \n>by the framework, as they exist or become available.  This working group \n>defines the supporting configuration data and protocols for configuring \n>services on the transit intermediaries; this configuration makes it \n>possible to administer collections of transit intermediaries and content \n>services as a coherent system.\n>\n>There are four parts of a good service definition for transit-based \n>extensions to an application protocol.  The first part defines the \n>protocol processing point or points in the intermediary that could detect \n>an application data event of interest to the auxiliary service.  The \n>second part defines the server, the access method for the server, and the \n>marshaled form for arguments added when delivering the application data to \n>the auxiliary server.  The third defines the post processing of the data \n>returned by the auxiliary.  The fourth element of the definition is an \n>encoding of the above information combined with the service extension \n>itself, defined as some form of loadable code or access method for \n>invoking the code.  The working group will define an information model and \n>realization of the model into repository and protocol elements.\n>\n>These service definitions must be standardized in ways that are compatible \n>with the policy framework of the Policy working group. The definitions \n>constitute configuration information that can come from repositories or \n>runtime protocols; for example, and ICAP server coming on-line can notify \n>its clients of the services it offers, and it can update their status \n>(\"up\", \"changed\", \"suspended\", \"moved\") while it is running.  A namespace \n>for services and a means for registering names will be considered.\n>\n>Some crucial data must be communicated from the intermediary to the \n>auxiliary server in standardized semantics.  Identification and \n>authentication information for the application connection may be important \n>to the auxiliary processing, for example.  The working group will define a \n>core set of information necessary for supporting generic application needs.\n>\n>Postprocessing the result from the auxiliary processor is done at the \n>option of the intermediary, but instructions from the auxiliary server \n>must be communicated in a standardized manner.  Generic directives \n>(\"drop\", \"hold\", \"assign attribute\", are examples.  The working group will \n>define postprocessing directives and the rules for their interaction with \n>the configuration policy.\n>\n>The security model for intermediary services involves defining the \n>administrator roles and privileges for the application client, application \n>server, intermediary, and auxiliary server.  The working group will use \n>the Policy Configuration Information Model to define the security \n>attributes and the enforceable policy.\n>\n>The working group items for delivery are\n>1.      A \"side transit\" protocol (ICAP) for use with HTTP\n>2.      A policy-based configuration and definition model for orthogonal \n>service extensions\n>a.      To include representation of conditions leading to invocation of \n>extension services, common data items (identities, authentication state, \n>etc.), postprocessing directives, and the access method for the service or \n>a representation of a loadable service (URL or encoded executable or \n>interpretable code, for example).\n>b.      A specific repository-based embodiment of the model\n>c.      A delivery protocol embodying the elements of the model as a \n>language; the protocol may be embedded in HTTP and/or ICAP.\n>d.      Recommended procedures for registering service names and \n>repositories for extensions\n>3.      A security model and security configuration policy definitions, \n>i.e. roles, privileges, and enforcement point responsibilities.\n>\n>After these items have been delivered, the working group can examine the \n>progress in this area and, if appropriate, re-charter to with more\n>general work items in the OPES framework.\n>\n>Existing Internet-Drafts\n>Basic Requirements:\n>         http://draft-tomlinson-epsfw-00.txt\n>Initial iCAP Callout Server:\n>         http://draft-elson-opes-icap-00.txt\n>A Rule Specification Language for Proxy Services:\n>         http://draft-beck-opes-psrl-00.txt\n>General Use Cases:\n>         http://draft-beck-opes-esfnep-01.txt\n>\n>\n>Goals and Milestones:\n>\n>Feb 01: Requirements and roadmap documents for WG\n>Feb 01: First draft of HTTP orthogonal protocol; first draft of policy \n>information model\n>Mar 01: Meet at Minneapolis IETF\n>Mar 01: OPES architecture and requirements documents\n>Jun 01: Submission of security model and configuration policy to IETF\n>Jul 15: Draft of policy rules, enforcement semantics, standard data items, \n>and post processing\n>Aug 01: Meet at London IETF\n>Aug 01: Final submission of HTTP orthogonal protocol.\n>Oct 01: Submission of repository specific and ICAP-based policy rule \n>deliver protocol\n>Dec 01: Salt Lake City IETF.\n>Dec 01: Review charter, if necessary, amend for additional orthogonal \n>protocol definitions, standard data items, postprocessing directives.\n>\n>\n>\n>\n>\n>\n>\n>Michael W. Condry\n>Director, Internet Strategy\n>2111 N.E. 25th Ave.\n>JF3-206\n>Hillsboro, OR 97124-5961\n>\n>Phone: (503) 264-9019\n>FAX: (503) 264-3483\n>Email: condry@intel.com\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-14705274"}, {"subject": "Buying a home?  Self employed?  Hard to qualify?127", "content": "WE SOLVE MORTGAGE PROBLEMS !!!\n\nSpecializing in loans for exceptional people\n\n     Self-Employed Borrowers\n     No Income or Asset Verification\n     All Levels of Credit Quality\n     Up to 100% Financing\n     High Debt Ratios\n     Non-Owner Occupied Properties\n     Renovation Plus Purchase and Refinance\n\n$UPER $OLUTION$ ......... $UPER RE$ULT$\n\n\nFOR ADDITIONAL INFORMATION PLEASE REQUEST MORE \nINFORMATION BY CLICKING ON THE LINK WHICH FOLLOWS:\n\nmailto:mon1110@excite.com?Subject=More_Information_SEHCNIT\n\nHelp a family member or a friend with their home loan needs by \nFORWARDING THIS EMAIL TO THEM!\n\nAn Equal Housing Opportunity Lender\n\n\n\nIf you wish to be removed from this advertiser's future mailings, please reply \nwith the subject \"Remove\" and this software will automatically block you \nfrom their future mailings.\n\n\n\n", "id": "lists-007-14724361"}, {"subject": "[ietf-discuss] &lt;none&gt", "content": "WOULD YOU STUFF\nENVELOPES FOR\n$1,000'S WEEKLY?\n\n$2 For Each Envelope You Stuff\nSIMPLE, PLEASANT WORK YOU CAN DO AT HOME!!!\n\nHELP SOLVE YOUR MONEY PROBLEMS.  No more worries over\ninflation, recession, bills, rising gasoline and other\ncosts.  If you are looking for easy extra income, to\nrelieve financial pressures, you owe it to yourself to\ninvestigate our offer.\n\nHERE IS YOUR CHANCE to earn extra money working at\nhome by becoming an active participant of our\nsuccessful mailing association.  You receive cash\ndaily for the envelopes you stuff.  There is no limit.\n You stuff as many as you wish.\n\nNO EXPERIENCE OR SPECIAL SKILLS REQUIRED.  Our\nHOMEMAILER'S PROGRAM is designed especially for people\nwith little or no business experience and provides\nstep-by step instructions.\n\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n\nWHY IS THIS POSSIBLE?\nThere are many mail-order companies who want to expand\ntheir business, but do not want to hire more people. \nIf they hired more employees, they would have to\nsupervise them, rent more office space, pay more taxes\nand insurance, all involving more paperwork.  It is\nmuch easier for them to set it up so that independent\nhomeworkers can earn money doing the work themselves.\n\nThis program is designed to help people cash in with a\ncompany who needs homeworkers.  Each member is an\nindependent homeworker. You serve a company that pays\ngood commissions to have their circulars mailed.  This\nprogram has been perfected so that it has become one\nof the most successful and profitable ones ever.\n\nWe invite you to take part in our success.  The money\nyou earn is up to you.  We do not require that you\nmail a certain number of pieces each week.  You can\ntake on whatever amount of business that fits your\nschedule, and you can quit whenever you want, there\nare no obligations. This work mainly consists of the\nsecuring of envelopes.\n\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n\nYou may work in the comfort of your own home, choose\nyour own hours, and set your own pace.  No need to\nleave your present job.  The possibilities are\nunlimited - get the whole family to join in.  Form\nworkshops with your friends.  We will further show you\nhow to expand your operation and boost your new income\nas high as you wish to go.\n\nNOW, IT'S ALL UP TO YOU!\nThe opportunity for the better life is here - it's\nwaiting!  But only YOU can take that all-important\nstep that separates the achievers from the dreamers! \nOrder NOW!\n\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n\nALL BUSINESS can be done by MAIL and we give you\ncomplete assistance at every step to insure your\nsuccess. You can START THE SAME DAY you receive the\ninstructions and begin RECEIVING MONEY WITHIN TWO\nWEEKS and every week from then on, as long as you\ndesire.\n\nYou will be supplied with the materials to be stuffed.\n Envelopes will be already stamped and addressed.\n\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n\nGUARANTEE:  We welcome you to this program and extend\nto you our unconditional guarantee that everything we\nhave said about this program is true and that you will\nbe delighted with the money you make.  Our goals and\ncontinued success depends on your 100% satisfaction\nwith the HOMEMAILER'S PROGRAM.\n\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n\nDON'T BE FOOLED\nThere are many fraudulent envelope addressing and\nchain letter schemes being sold today.  We recommend\nthat you avoid them.  Why fool with some questionable\nscheme when our program enables you to earn so much\nmoney legally.  This is not an offer of employment. \nIt is an opportunity to become an independent\ncommission mailer for our company. Remember, unlike\nthe others, this is not a get-rich-quick scheme.  It\nis a proven program for making money while filling the\nneeds of a company who need people to mail their\ncirculars.\n\nIN ORDER TO GET YOU STARTED IMMEDIATELY, we must\nrequire a one-time fee of only $13.95.  This covers\nour expense in showing you what to do and guarantees\nyou can work with us as long as desired.  You will not\nbe required or asked to pay for any additional\ninformation or manuals.  Inasmuch as we would like to\nsend you our program with the small charge, we must\nprotect ourselves from those who are not serious and\nhave no intention other than to satisfy their own\ncuriosity.  Naturally, no business can afford to send\nout costly material to everyone who writes in asking\nfor it.  This small charge assures us that you are\nserious about wanting to earn money at home.\n\nDON'T DELAY - START IMMEDIATELY!!!\nThis is money.  You can begin now by putting your time\nto the best of use. The next few minutes can literally\nchange your life.  Don't let this extraordinary\nopportunity pass.\n\nYOUR REGISTRATION FEE REFUNDED\nas soon as you submit your first 100 envelopes.\n\nSend a check or money order in the amount of  $13.95\nto:\n\n\nX V A    International\n11948,    207th Street, Suite 309\nMaple Ridge, BC, Canada\nV2X 1X7\n\nDon?t forget to include your name, address, and an\nemail address.\n\nNever send cash through the mail. \n\nXVA International is a licensed business operating in\nBC, Canada; license #14126.\n\nPlease allow 4 to 6 weeks for delivery of your starter\nkit.\n \nThis message is sent in compliance of the new e-mail\nbill: SECTION 301. Per Section 301, Paragraph\n(a)(2)(C) of S. 1618.  Further transmissions to you by\nthe sender of this email may be stopped at no cost to\nyou by sending a reply to this email with the word\n\"remove\" in the subject line.\n\n\n__________________________________________________\nDo You Yahoo!?\nGet email at your own domain with Yahoo! Mail. \nhttp://personal.mail.yahoo.com/\n\n\n\n", "id": "lists-007-14731796"}, {"subject": "Obtain Biotech IPOs!    15", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-14743915"}, {"subject": "Wg's which have not made progress latel", "content": "We have in Apps Area a number of groups which want to have working \ngroups. The line is getting longer and longer, and that is NOT FUN.\n\nReason for not \"just\" creating new wg's is that we have limited \nresources in various places, and resources are held up by old wg's \nwhich move forward very slowly -- if moving at all, and not always in \nthe correct direction maybe?\n\nI will as Area Director start forcing wg's to decide to be closed, \nand documents moved to personal contributions.\n\nNote that this doesn't prohibit the documents to be published as an \nRFC in the future, but as individual contributions.\n\nIf people have any problem with this, or other ideas on how to free \nresources, let me and Ned know.\n\n     paf\n\n-- \nPatrik F?ltstr?m <paf@cisco.com>       Internet Engineering Task Force\nArea Director, Applications Area                   http://www.ietf.org\nPhone: (Stockholm) +46-8-4494212            (San Jose) +1-408-525-0940\n        PGP: 2DFC AAF6 16F0 F276 7843  2DC1 BC79 51D9 7D25 B8DC\n\n\n\n", "id": "lists-007-14750081"}, {"subject": "RE: Can there be multiple BINDs to a VCR", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Wednesday, June 26, 2002 11:20 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: Can there be multiple BINDs to a VCR?\n>\n>\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    given a resource with the distinct URLs \"/a1\" and \"/a2\" (so both URLs\n>    identify the same resource).\n>\n>    1) Is it allowed to VERSION-CONTROL this resource?\n>\n> Yes.\n>\n>    2) If yes and assuming that the VCR is checked out, what is the\n>    DAV:checkout-set of the \"current\" version (the version\n> identified by the\n>    VCR's checked-out property)? Does it contain DAV:href elements for both\n>    URLs?\n>\n> That's up to your server.  It must at least have the request-URL\n> of the CHECKOUT request.  A client cannot count on having both URLs\n\nIf a server supports \"real\" bindings, it would be hard to guarantee this.\n\nIn particular, what about if \"/a1\" is checked out, then deleted. What would\nbe the DAV:checkout-set of the checked out version?\n\n> in the DAV:checkout-set, because that is not required by the protocol.\n\nThat's right. I think the only thing that the protocol requires is that for\neach checked out resource, one (of possibly many) resource URIs is reported.\n\n> Note that in general, there will not be a list of all URLs, because\n> there can be an infinite number of URLs that identify a resource when\n> a collection that contains the resource also contains a binding to\n> itself.\n\nRight -- that would be the case discussed in [1]. This is a problem\neverytime a method needs to generate \"a\" URI for a given resource (same for\nmany REPORTs...).\n\n\n\n[1]\n<http://greenbytes.de/tech/webdav/draft-ietf-webdav-binding-protocol-02.html\n#rfc.section.5.2>\n\n\n\n", "id": "lists-007-1475047"}, {"subject": "draft-carlberg-ieps-framework-00.tx", "content": "Can I have some people looking at \ndraft-carlberg-ieps-framework-00.txt for \"Application Area Issues\" \nplease?\n\nI.e. Area Directors have got a question from the IETF Chair to please \nlook at Area Dependencies.\n\n    Regards, Patrik\n\n-- \nPatrik F?ltstr?m <paf@cisco.com>       Internet Engineering Task Force\nArea Director, Applications Area                   http://www.ietf.org\nPhone: (Stockholm) +46-8-4494212            (San Jose) +1-408-525-0940\n        PGP: 2DFC AAF6 16F0 F276 7843  2DC1 BC79 51D9 7D25 B8DC\n\n\n\n", "id": "lists-007-14758338"}, {"subject": "Re: Wg's which have not made progress latel", "content": "Patrik,\n\nMaybe there are cases where the topic is important and extra\neffort would appear if people (other than the chairs and current\nparticipants) knew the WG was under threat. \n\nI understand that you may hesitate to name-and-shame in public,\nbut a list of the WGs you consider to be stuck would be interesting.\n\n   Brian\n\nPatrik F?ltstr?m wrote:\n> \n> We have in Apps Area a number of groups which want to have working\n> groups. The line is getting longer and longer, and that is NOT FUN.\n> \n> Reason for not \"just\" creating new wg's is that we have limited\n> resources in various places, and resources are held up by old wg's\n> which move forward very slowly -- if moving at all, and not always in\n> the correct direction maybe?\n> \n> I will as Area Director start forcing wg's to decide to be closed,\n> and documents moved to personal contributions.\n> \n> Note that this doesn't prohibit the documents to be published as an\n> RFC in the future, but as individual contributions.\n> \n> If people have any problem with this, or other ideas on how to free\n> resources, let me and Ned know.\n> \n>      paf\n> \n> --\n> Patrik F?ltstr?m <paf@cisco.com>       Internet Engineering Task Force\n> Area Director, Applications Area                   http://www.ietf.org\n> Phone: (Stockholm) +46-8-4494212            (San Jose) +1-408-525-0940\n>         PGP: 2DFC AAF6 16F0 F276 7843  2DC1 BC79 51D9 7D25 B8DC\n\n\n\n", "id": "lists-007-14765740"}, {"subject": "Re: Wg's which have not made progress latel", "content": "At 10.11 -0600 01-01-18, Brian E Carpenter wrote:\n>I understand that you may hesitate to name-and-shame in public,\n>but a list of the WGs you consider to be stuck would be interesting.\n\nI don't want to do this now, but first talk with Ned (which is \nhappily unaware of me wanting to do this _NOW_), so we have a \ncoherent picture of the state we belive the wg's are in.\n\nMy mail might have been possible to read in a more negative way than \nwhat was intended. The main point was that people interested in a \ntopic should NOT be afraid of having a wg closed, because the work \ncan continue anyway -- especially if the number of people is small. \nThe mailing list can continue to exist, the RFC's can still be \nproduced etc.\n\nThe point was that I feel that we should try to use the IETF \nresources for the discussions which do need the really wide review \nthe IETF can provide in a wg, and not only through a last call.\n\nAnd, I do have the names of wg's which WANT to close but are not able \nto do that because I personally have their last documents on my \nplate. I am cleaning up that in parallell.\n\nNed is working with a new apps-area web-page, and more status reports \nwill be given, and my goal is that WE in the apps area should have a \ncommon view on:\n\n  - What we are working on in general\n  - What we need to concentrate on\n  - What is out of scope\n\nI hope we together can communicate more in all directions on status \netc, and that hopefully will give people the extra energy which is \nneeded to push I-D's over the last doorstep to become RFC's \n(including myself, I am not blaming anyone!!)\n\nThat said, I expect that Ned and I can start having a list of wg's \nand documents shortly -- but the expectation is NOT that the \ninformation there should be a surprise for anyone, and especially not \nthe wg (chair).\n\nI have already had email exchange with one chair in one wg today, and \njust exchanging those two messages made me understand more what is \nactually going on.\n\nSo easy, and I probably do not do it often enough.\n\n     paf\n\n\n-- \nPatrik F?ltstr?m <paf@cisco.com>       Internet Engineering Task Force\nArea Director, Applications Area                   http://www.ietf.org\nPhone: (Stockholm) +46-8-4494212            (San Jose) +1-408-525-0940\n        PGP: 2DFC AAF6 16F0 F276 7843  2DC1 BC79 51D9 7D25 B8DC\n\n\n\n", "id": "lists-007-14774986"}, {"subject": "Re: Wg's which have not made progress latel", "content": "patrik - thanks for the thoughtful note.\n\nmay i ask that you and ned send email to each of the WGs in question,\ncomparing their progress to their charter, and giving them a short amount of\ntime to show progress or be nuke'd.\n\na charter represents a contract between the ADs and a WG. the reasons that\ncharters have milestones with dates is so that everyone can understand the\ntimeliness and metabolism of the project and principals.\n\nin research, you can't schedule innovation; but, the ietf isn't a research\norganization, it's an engineering organization. in engineering, scheduling\nis one of the most important things to get right.\n\nwhen WGs go stale but don't die, they prevent other WGs from being formed.\nthis is plainly unfair...\n\n/mtr\n\n\n\n", "id": "lists-007-14784916"}, {"subject": "Re: Wg's which have not made progress latel", "content": "At 09.15 -0800 01-01-18, Marshall T. Rose wrote:\n>may i ask that you and ned send email to each of the WGs in question,\n>comparing their progress to their charter, and giving them a short amount of\n>time to show progress or be nuke'd.\n\nWe are NOT after killing things because it is fun.\n\nWe want progress. If either this mail from me, or a future ping from \nme and Ned make the wg start work again, fine.\n\n>a charter represents a contract between the ADs and a WG. the reasons that\n>charters have milestones with dates is so that everyone can understand the\n>timeliness and metabolism of the project and principals.\n\nExactly!\n\n>when WGs go stale but don't die, they prevent other WGs from being formed.\n>this is plainly unfair...\n\nExactly my point in my initial message. wg's _DO_ use resources just \nby existing.\n\n   paf\n\n\n\n-- \nPatrik F?ltstr?m <paf@cisco.com>       Internet Engineering Task Force\nArea Director, Applications Area                   http://www.ietf.org\nPhone: (Stockholm) +46-8-4494212            (San Jose) +1-408-525-0940\n        PGP: 2DFC AAF6 16F0 F276 7843  2DC1 BC79 51D9 7D25 B8DC\n\n\n\n", "id": "lists-007-14793582"}, {"subject": "Re: Wg's which have not made progress latel", "content": "> >may i ask that you and ned send email to each of the WGs in question,\n> >comparing their progress to their charter, and giving them a short amount\nof\n> >time to show progress or be nuke'd.\n>\n> We are NOT after killing things because it is fun.\n\nand i hope you didn't think i was implying otherwise...\n\n\n> We want progress. If either this mail from me, or a future ping from\n> me and Ned make the wg start work again, fine.\n>\n> >a charter represents a contract between the ADs and a WG. the reasons\nthat\n> >charters have milestones with dates is so that everyone can understand\nthe\n> >timeliness and metabolism of the project and principals.\n>\n> Exactly!\n>\n> >when WGs go stale but don't die, they prevent other WGs from being\nformed.\n> >this is plainly unfair...\n>\n> Exactly my point in my initial message. wg's _DO_ use resources just\n> by existing.\n\nwe are certainly in agreement.\n\n/mtr\n\n\n\n", "id": "lists-007-14802897"}, {"subject": "Re: Wg's which have not made progress latel", "content": "At 10.38 -0800 01-01-18, Marshall T. Rose wrote:\n>  > We are NOT after killing things because it is fun.\n>\n>and i hope you didn't think i was implying otherwise...\n\nDefinitly not.\n\nI just thought it was extemely important to make the point extremely explicit!\n\n    paf\n\n\n\n", "id": "lists-007-14811800"}, {"subject": "Re: Wg's which have not made progress latel", "content": "> >and i hope you didn't think i was implying otherwise...\n>\n> Definitly not.\n>\n> I just thought it was extemely important to make the point extremely\nexplicit!\n\nhistorically, when this approach is taken (a warning shot to the wg), the\nsuccess ratio is 50%. (for the amusement of this list, i'll let each\nsubscriber figure out what is meant by \"success\").\n\n/mtr\n\n\n\n", "id": "lists-007-14819977"}, {"subject": "Daytona Thunderwear Specials!! by Becker Designs In", "content": "Text/Html attachment: stored\n\n\n\n\n", "id": "lists-007-14833869"}, {"subject": "Win a top of the range iMac, Palm Pilot or Discma", "content": "      Connect to your future and start 2001 as a winner\n      Win a top of the range iMac, Palm Pilot or Discman\n\n      All you have to do to win is register with planetgraduate, the new\ninternational site for students, graduates and employers.\n      Simply click here to get started\n\n      Take just a few seconds to register and enter our draw to win either a\nPalm Pilot or Sony Discman. Take a few minutes more and enter your CV with\nplanetgraduate's CV Builder and you could win the incredibly cool iMac and\nbe connected to the Internet in a couple of clicks.\n\n\n      Enter our prize draw today to win one of these top prizes:-\n      A top of the range iMac\n      One of two Palm Pilots\n      One of three Portable CD players\n\n\n        Discman  iMac Palm Pilot\n\n        PS Double your chances of winning a Discman or Palm Pilot by helping\nus let your friends know about this great competition.\n\n     The draw will take place on Friday 23rd February 2001\n\n     Prizes may differ from models shown\n\n      To unsubscribe from this email, reply to this email with the word\n'unsubscribe' only in the subject line\n      or send an email to unsubscribe@planetgraduate.com\n\n\n              get a job now  |  study net  .  the village  |  relax & enjoy\n.  top deals  |  behind the scenes\n\n             contact us  .  privacy policy  .  terms of use  .  copyright\n\n\n\n", "id": "lists-007-14840343"}, {"subject": "Update to OPES Workgroup Charter Reques", "content": "Open Pluggable Extension Services(opes)\n\nCo-chairs:\n    Michael Condry <condry@intel.com>\n    Hilarie Orman <HORMAN@novell.com>\n\nMailing Lists:\n    General Discussion: ietf-openproxy@imc.org\n    To Subscribe: ietf-openproxy-request@imc.org\n    Web: http://www.ietf-opes.org and http://www.extproxy.org (same sites)\n    Archive: ftp://ftp.ietf.org/ietf-mail-archive/opes\n\nDescription of Working Group:\n\nThe Open Pluggable Extension Services architecture (OPES) enables construction\nof services executed on application data by participating transit\nintermediaries.  Caching is the most basic intermediary service, one that\nrequires a basic understanding of application semantics by the cache server.\nBecause intermediaries divert data temporarily over a pathway different \nfrom the\ntransit pathway, one can think of the service path as being orthogonal to the\nmain transit path.  The purpose of this working group is to define the \nprotocols\nand, if appropriate, API's for a broad set of services that facilitate \nefficient\ndelivery of complex content or services related to content.  The advantage of\nstandardizing these protocols is that the services can be re-used across \nvendor\nproducts without modifying the transit intermediaries or services.\n\nThe architecture supports services that are either co-located with the transit\nintermediary or located on other cooperating servers.  There is a protocol \nthat\nconnects the OPES service device and cooperating services. The ICAP \nprotocol is\nbeing developed as one option for carrying HTTP headers and data to \ncooperating\nservers; the framework will support other protocols to cooperating servers, as\nthey exist or become available.  This working group defines the supporting\nconfiguration data and protocols for configuring services on the transit\nintermediaries; this configuration makes it possible to administer collections\nof transit intermediaries and content services as a coherent system.\n\nThere are protocols and policies to define the applications that are plugged\ninto the OPES server. The working group must define these as well.\n\nThe security model for intermediary services involves defining the \nadministrator\nroles and privileges for the application client, application server,\nintermediary, and auxiliary server.\n\nThe working group items for delivery are\n1.      A \"side transit\" protocol (e.g., ICAP) for use with HTTP\n2.      A \"service delivery\" protocol for delivering the services or service\ndescriptions to be preformed by the OPES facility or/and its\ncooperating servers.\n3.      A configuration and definition model for service extensions\na.      To include representation of conditions leading to invocation of\nintermediary-based services, common data items (identities,\nauthentication state, etc.), postprocessing directives, and the\naccess method for the service or a representation of a loadable\nservice (URL or encoded executable or interpretable code, for\nexample).\nb.      Other policy recommendations observed by having an intermediary be\nthe central point of service extensions.\n4.      A trust model and security configuration policy definitions, i.e.\nroles, privileges, and enforcement point responsibilities.\n\nAfter these items have been delivered, the working group can examine the\nprogress in this area and, if appropriate, re-charter to with more\ngeneral work items in the OPES framework.\n\nExisting Internet-Drafts\nBasic Requirements:\n         http://draft-tomlinson-epsfw-00.txt\nInitial iCAP Callout Server:\n         http://draft-elson-opes-icap-00.txt\nA Rule Specification Language for Proxy Services:\n         http://draft-beck-opes-psrl-00.txt\nGeneral Use Cases:\n         http://draft-beck-opes-esfnep-01.txt\n\n\nGoals and Milestones:\n\nFeb 01: Workshop to discuss OPES issues\nMar 01: First draft of a OPES-device-to-OPES-servers protocol.\nMar 01: Meet at Minneapolis IETF\nMar 01: Requirements gathering and document update plans.\nMay 01: First draft of policy information model\nJun 01: Submission of security model and configuration policy to IETF\nJul 15: Draft of service dispatch rules, enforcement semantics, standard data\nitems, and post processing\nAug 01: Meet at London IETF\nAug 01: Final submission of callout protocol(s).\nNov 01: Draft of \"service specification\" protocol\nDec 01: Salt Lake City IETF.\nMar 02: Review charter, if necessary, amend for additional definitions, \nstandard\ndata items, postprocessing directives.\n\n\n\nMichael W. Condry\nDirector, Network Edge Technology\n\n\n\n", "id": "lists-007-14848690"}, {"subject": "RE: Can there be multiple BINDs to a VCR", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > From: Clemm, Geoff\n   >\n   >    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n   >\n   >    2) ... assuming that the VCR is checked out, what is the\n   >    DAV:checkout-set of the \"current\" version (the version\n   >    identified by the VCR's checked-out property)? Does it contain\n   >    DAV:href elements for both URLs?\n   >\n   > That's up to your server.  It must at least have the request-URL\n   > of the CHECKOUT request.  A client cannot count on having both\n   > URLs\n\n   If a server supports \"real\" bindings, it would be hard to guarantee\n   this.  In particular, what about if \"/a1\" is checked out, then\n   deleted. What would be the DAV:checkout-set of the checked out\n   version?\n\nActually, I retract my comment above (i.e. \"It must at least have the\nrequest-URL of the CHECKOUT request\").  The protocol only requires\nthat the DAV:checkout-set \"identifies each checked-out resource whose\nDAV:checked-out property identifies this version\", and says nothing\nabout which URL should be used to do so.\n\n   > in the DAV:checkout-set, because that is not required by the protocol.\n\n   That's right. I think the only thing that the protocol requires is\n   that for each checked out resource, one (of possibly many) resource\n   URIs is reported.\n\nI agree.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1485865"}, {"subject": "$6,000 In 30 Days / $60,000 In 3 Months - Doing ONLY What YO", "content": "-------------------------------------------------------------\nThis is a NetDOMINATION Ezine Exclusive Ad Mailing. \nThis mail is never sent unsolicited.  This is not \"spam\". \nYou agreed to receive this email by signing up to our \nezine list either by our online signup form or by using \nour FFA Links Page which has terms of use which \nexplicity state you will receive this email.\n-------------------------------------------------------------\n\n\nDo you feel like you're the ONLY one working hard to make money on the net....the poeple you sign up do nothing? That is if you sign them up at all.\n\nWe have sponsors who teach you all the things that work the best and are always there for you to answer questions and help whenever you need them. \n\nIf you are really SERIOUS about being successful in Internet marketing, you can be on our winning TEAM.  \n\nWe'll tell you how to make $6,000 in 30 days and how to make AT LEAST $60,000 in the NEXT 3 months - WITHOUT selling, motivating, or \"baby-sitting\". \n\nYOU will work with QUALIFIED people who are just as committed as YOU are to succeeding without spending most of your day working online to get to the top. \n\nClick on:  http://twi.bizzycom.com \nPartner name: sailor\n\nRead the information and take the first step toward \nworking with people who do THEIR part and let you \ndo what YOU do best. \n\nLets go to the top! With a TEAM that does allthe marketing and selling FOR US!!\n\nAli Newell\n\n\n------------------------------------------------------------\nThis email is NEVER sent unsolicited.  THIS IS NOT \"SPAM\". \nYou are receiving this email because you EXPLICITLY signed\nyourself up to our list with our online signup form or\nthrough use of our FFA Links Page and E-MailDOM systems, \nwhich have EXPLICIT terms of use which state that through \nits use you agree to receive our emailings.  You may also \nbe a member of a ZineDOM list or one of many numerous\nNetDOMINATION FREE Marketing Services and as such you \nagreed when you signed up for such list that you would \nalso be receiving this emailing.\n\nDue to the above, this email message cannot be considered \nunsolicitated, or spam.\n\n\n\n", "id": "lists-007-14892174"}, {"subject": "Appllications Area Open Meetin", "content": "--On 01-07-05 17.44 -0400 agenda@ietf.org wrote:\n\n> MONDAY, August 6, 2001\n> 0900-1130 Morning Sessions \n> APPappareaApplications Open Area Meeting\n\nNed and myself are happy receiving suggestions on what main topic to have\non the agenda (part from the walkthrough of wg's and bof's).\n\n   Patrik\n\n\n\n", "id": "lists-007-14900534"}, {"subject": "Re: Appllications Area Open Meetin", "content": "Discussion of application \"support\" activities, like OPES, might be useful.\n\n(Useful, that is, if we can refrain from religious overtones.)\n\nd/\n\nAt 02:49 PM 7/5/2001, Patrik F?ltstr?m wrote:\n>--On 01-07-05 17.44 -0400 agenda@ietf.org wrote:\n>\n> > MONDAY, August 6, 2001\n> > 0900-1130 Morning Sessions\n> > APP   apparea         Applications Open Area Meeting\n>\n>Ned and myself are happy receiving suggestions on what main topic to have\n>on the agenda (part from the walkthrough of wg's and bof's).\n>\n>    Patrik\n\n----------\nDave Crocker  <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking  <http://www.brandenburg.com>\ntel +1.408.246.8253;  fax +1.408.273.6464\n\n\n\n", "id": "lists-007-14909279"}, {"subject": "????? ?? ?????? -&quot;??????? ????????????&quot", "content": "????? ????                                                                                                       ????????? ???????!\n ?????????? ??????? ? ???????????? ?? ??????????? ?????????? ???????????\n\n                                           ??? ?????????? ????????? ? ? WAN ????? .\n\nCisco Sistems ??? ???????? ?????? ? ??????? ??????? ??????????, ??????????????? ??? ???? ????????\n\n\n  a.. ?????????????????????? ?????????????? ????? -12000 ,-7500 ,-7200 ? ??.\n  b.. ??????????? LAN ????? -Catalist\n  c.. ??????????? WAN ????? -IGX 8400,BPX8600,MGX8800\n  d.. ?????????? ??????? ????? ?1000,1600,2500,2600/3600,3800,4000\n\nEICON Technology\n\n\n  a.. ???????????????? ??????????? ??? ????? Frame Relay/X25/SDLS\n  b.. EICONCard?????C20/21,C30/31/S50/S51/S52/S90/S91/S94/P62/P92/C90/C91\n  c.. ??????? ???????????? ??? ??????? ISDN ? ADSL ???????????? ?????, ??????????????.\n  d.. EICON DIVA T/A , ISD modem ,ISDN USB ,ISDN Card,ISDN PRO Card ,Server BRI ,Server 4BRI ,Server Voice 4BRI ,Server PRI ,Mobile V.90 PC Card ,LAN ISDN Modem ,ASDL USB ,1830 ISDN Router ,2430 Eternet ,USB ADSL Modem\n  e.. ??????? ??? SNA:\n  f.. AVIVA Mainframe Edition (?????? ? ????-?????????? ??? WINDOWS NT ? WINDOWS 95) , Enterprise Access Server\nMotorolla\n\n\n  a.. ??????????????? ??????????? Frame Relay ?????\n  b.. Vanguard 8500, 6560/6520, 6425/6430/6450, 305/320, 311/312, 200, 100, Remote VU ,6500 Plus Regional Concentrator\n  c.. ??????? ??????????: 9000 Open Management System\n  d.. ???????????????? ????????????: Codex 326x ????? , 3460 Fast*R\n\nPAIRGAIN\n\n            Campus , Megabit Access ,Megabit-CRA modems ,Megabit 300 series ,Megabit modems 700F/600L/500L ,\n\n            AVIDIA Systems ,High Gain ETSI , HighGain  *98 ,PG-2/PG-Plus/PG-Flex\n\nZYXEL\n\n\n  a.. ????????????? ? DSL-??????????????\n  b.. Prestige 681 , Prestige 128L ,Prestige 153X\n????? - ??????????? ?????????? ????????????????????? ????????????\n\n  a.. IDSL ?????? ??? ?????????? ?????????? ?????:\n  b.. ?-144 , ?-144? , ?-64 .\n  c.. ?????? ??? ?????????? ?????????? ????? ? ?????????? ???????????\n  d.. ?-160 ,?-1 ,?-2 ,?-200 ,?-115? ,?-713? ,??????????? ????? PC-2 ,????????? ??????????? EM-2\nRAD\n           ??????????????? TDM-?????????????? ? ?????????????.\n               RAD Megaplex 2100/2104 , RAD Kilomux 2000/2100 ,RAD DXC-30/10A/8R ,RAD Optimux - XLE1 ,RAD Optimux - 4E1 ,RAD HSM-4\n\n  a.. ?????????? ??????? ? ??????? ???????? ?????\n  b.. RAD FCD-E1 , RAD FCD-2 ,RAD FCD-24\n  c.. ???????????? Frame relay/X.25\n  d.. RAD MAXcess 3000/3004 , RAD MAXcess 300/30 ,RAD APD-/2HS/8 , RAD APS-8/16/24 , SPS-2/2HS/3/3HS/3S/6/12\n  e.. ??????????????? ????, ????????? ? ???????????\n  f.. RAD AMC-101 , RAD AMC-1 ,?????????? ?????????? ????????? ??????????? RAD VSC, VSC-X\n  g.. ?????? ? ???:RAD ACE-101\n  h.. ????????? ?????? ? ??? ? Internet.\n  i.. RAD WebRanger , RAD Tiny Bridge, Tiny Bridge - 4W ,RAD TinyRouter\n  j.. ?????? \"????????? ????\"??????????? ? ?????????? ?????? ??? ?????????? ????? .?????????????? ??????\nCICLADES\n\n  a.. ????????????? ????? Cyclades Y-series , Cyclades Z-series\n  b.. ??????? ?????????? ??????? Cyclades PR4000\n  c.. ??????????????: Cyclades PR3000/TS , Cyclades PathRouter\nTAINET\n???????????????? ???????????? ??? ?????????? ????? ???????? ??????:??inet T-288C V.34+ ,Tainet T-336Cx/Nx/NDx V.34+ ,Tainet DT-128 ,Tainet TRS-32 SUPER SHELF , Tainet DT-2000 HDSL Series ,Tainet Xstream 1300/1320/1310/1330 ,Tainet Mars 9000 DSL Concentrator ,Tainet Mercury 3600 ,Tainet MUXpro 7100 ,Tainet WANpro 2000.\n???????? ????? ????????????????? ???????????? ? ??? ????? ???????????? ?????????.\n?? ?????? ?????? ???????? ?? ??? ???? ???????, ????????? ? ????????????? ???????????? ? ?????????? ??? ???????????? ? ????????????. ????????? - ??????? ? ?????? ???!\n\nE ? mail:           v_potechin@diamond.ru\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "lists-007-14918700"}, {"subject": "Give it a Tr", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-14929485"}, {"subject": "test - please ignor", "content": "just testing out the new list software.  sorry to bother you.\n\n\n\n", "id": "lists-007-14935563"}, {"subject": "Publication of SOAP Version 1.2 and XML Protocol Abstract Model  drafts (fwd", "content": "---------- Forwarded Message ----------\nDate: m?ndag 9 juli 2001 21.33 +0200\nFrom: Yves Lafon <ylafon@w3.org>\nTo: w3c-policy@apps.ietf.org\nSubject: Publication of SOAP Version 1.2 and XML Protocol Abstract Model\ndrafts\n\nAs part of the XML Protocol Activity, the two following drafts were\npublished today:\n\nSOAP Version 1.2 is available from\n  http://www.w3.org/TR/2001/WD-soap12-20010709/\n\nXML Protocol Abstract Model is available from\n  http://www.w3.org/TR/2001/WD-xmlp-am-20010709/\n\nComments on this documents should be addressed at <xmlp-comments@w3.org>,\nthe main discussion mailing list being <xml-dist-app@w3.org>. Both are\npublic and publicly archived mailing lists.\nRegards,\n\n-- \nYves Lafon - W3C\n\"Baroula que barouleras, au ti?u toujou t'entourneras.\"\n \n\n---------- End Forwarded Message ----------\n\n\n\n", "id": "lists-007-14941915"}, {"subject": "Re: Appllications Area Open Meetin", "content": "Hello Patrik.  I know you typically have a meeting on Thursday for the WG \nchairs.  Do you know what time that will be yet?  I will be attending this \none (finally) and then taking a train out afterwards.  Since I'm checking \ntrain schedules, I thought I would find out what time you thought you \nmight hold the meeting.  Thanks.\n\n\n\n", "id": "lists-007-14950439"}, {"subject": "activity-set and new members of a working collectio", "content": "Hi,\nA working-collection can have non-versioned-resources as its members. And\nwhen the working-collection is checked in, these non-versioned-members are\nautomatically version-controlled.\n\nIf the working-collection has a non-empty DAV:activity-set, then would it\nnot make sense to copy this activity-set to each of the\nnon-versioned-members which have been automatically version-controlled? This\nis especially meaningful when we consider the activity as a 'change set'.\nSurely the newly added resources are part of the same 'logical change' as\ntheir parent collection.\n\nRegards,\nGirish\n\n\n\n", "id": "lists-007-1495056"}, {"subject": "Re: Appllications Area Open Meetin", "content": "Dear group. I apologize that everyone got a copy of my note to Patrik.  I \nthought my email app had left them off (especially since I said reply to \nsender only).  8-)\n___________________\nPatricia Egen Consulting\nwww.egenconsulting.com\n423-875-2652\n\n\n\n", "id": "lists-007-14959175"}, {"subject": "Re: Appllications Area Open Meetin", "content": "--On 01-07-18 11.18 -0400 pregen@egenconsulting.com wrote:\n\n>  I know you typically have a meeting on Thursday for the WG chairs.  Do\n> you know what time that will be yet?\n\nTo the audience: This is about a closed meeting for BOF and WG chairs in\nthe applications area.\n\nLast year we had a meeting 7-8PM if I remember correctly. I don't mind\nhaving it earlier, but that will mean that dinner will be delayed.\n\nI am happy to hear what you think. I am happy to have the meeting directly\nafter the sessions end. One hour should be enough, and we do have things to\ntalk about this time.\n\n   paf\n\n\nPatrik F?ltstr?m <paf@cisco.com>                         Cisco Systems\nConsulting Engineer                                  Office of the CSO\nPhone: (Stockholm) +46-8-6859131            (San Jose) +1-408-525-8509\n        PGP: 2DFC AAF6 16F0 F276 7843  2DC1 BC79 51D9 7D25 B8DC\n \n\n\n\n", "id": "lists-007-14968032"}, {"subject": "SOAP bar bof", "content": "Would anyone be interested in getting together during London to talk\ninformally about the status and progress of SOAP? (I am a member of\nthe W3C XML Protocol WG)\n\nDespite the perceptions of some, the WG is very interested in IETF\ninput and feedback on SOAP issues. Current discussions are revolving\naround defining the nature of bindings and general, and in specific\nthe binding to HTTP, so it's an excellent time to discuss this.\n\n-- \nMark Nottingham, Research Scientist\nAkamai Technologies (San Mateo, CA USA)\n\n\n\n", "id": "lists-007-14977202"}, {"subject": "Re: Appllications Area Open Meetin", "content": "I would much perfer a 5:30-6:30 meeting.\n\nAt 11:37 AM 7/19/2001 +0200, Patrik F?ltstr?m wrote:\n>--On 01-07-18 11.18 -0400 pregen@egenconsulting.com wrote:\n>\n> >  I know you typically have a meeting on Thursday for the WG chairs.  Do\n> > you know what time that will be yet?\n>\n>To the audience: This is about a closed meeting for BOF and WG chairs in\n>the applications area.\n>\n>Last year we had a meeting 7-8PM if I remember correctly. I don't mind\n>having it earlier, but that will mean that dinner will be delayed.\n>\n>I am happy to hear what you think. I am happy to have the meeting directly\n>after the sessions end. One hour should be enough, and we do have things to\n>talk about this time.\n>\n>    paf\n>\n>\n>Patrik F?ltstr?m <paf@cisco.com>                         Cisco Systems\n>Consulting Engineer                                  Office of the CSO\n>Phone: (Stockholm) +46-8-6859131            (San Jose) +1-408-525-8509\n>         PGP: 2DFC AAF6 16F0 F276 7843  2DC1 BC79 51D9 7D25 B8DC\n>\n\nMichael W. Condry\nDirector,  Network Edge Technology\n\n\n\n", "id": "lists-007-14984125"}, {"subject": "SOAP bar bof - Monda", "content": "I've gotten a pretty good response to this, so I'm going to try to do\nit Monday night at about 6 (between the last afternoon session and\nthe evening session).\n\nIf you're interested and this doesn't work for you, please drop me a\nline.\n\nTentatively, we'll meet in the lobby (I've never been to the site)\nand move on to a site with appropriate supplies (London is a\ntarget-rich environment for Bar BoFs). Final details will be posted\non the notice board and this list.\n\nCheers,\n\nP.S. - to clarify, this is NOT an effort to bring SOAP\nstandardization into the IETF, compete with the W3C, or review the\nstatus of W3C/IETF coordination. It is an unofficial\nupdate/discussion of the current status of the XMLP WG in regards to\nissues that are interesting to IETF'ers, and an informal solicitation\nfor (hopefully constructive) feedback.\n\n\n\nOn Thu, Jul 19, 2001 at 11:49:06AM -0700, Mark Nottingham wrote:\n> Would anyone be interested in getting together during London to talk\n> informally about the status and progress of SOAP? (I am a member of\n> the W3C XML Protocol WG)\n> \n> Despite the perceptions of some, the WG is very interested in IETF\n> input and feedback on SOAP issues. Current discussions are revolving\n> around defining the nature of bindings and general, and in specific\n> the binding to HTTP, so it's an excellent time to discuss this.\n> \n> -- \n> Mark Nottingham, Research Scientist\n> Akamai Technologies (San Mateo, CA USA)\n> \n\n-- \nMark Nottingham, Research Scientist\nAkamai Technologies (San Mateo, CA USA)\n\n\n\n", "id": "lists-007-14993864"}, {"subject": "RE: activity-set and new members of a working collectio", "content": "Yes, I agree that this would make sense.\n\nCheers,\nGeoff \n\n-----Original Message-----\nFrom: B H, Girish [mailto:g.b.h@sap.com]\nSent: Thursday, June 27, 2002 10:09 AM\nTo: ietf-dav-versioning@w3.org\nSubject: activity-set and new members of a working collection\n\n\n\nHi,\nA working-collection can have non-versioned-resources as its members. And\nwhen the working-collection is checked in, these non-versioned-members are\nautomatically version-controlled.\n\nIf the working-collection has a non-empty DAV:activity-set, then would it\nnot make sense to copy this activity-set to each of the\nnon-versioned-members which have been automatically version-controlled? This\nis especially meaningful when we consider the activity as a 'change set'.\nSurely the newly added resources are part of the same 'logical change' as\ntheir parent collection.\n\nRegards,\nGirish\n\n\n\n", "id": "lists-007-1502946"}, {"subject": "XML Protocol: Proposals to address SOAPAction heade", "content": "The W3C XML Protocol Working Group is attempting to address perceived\nand reported problems with the \"SOAPAction\" mechanism in the HTTP\nbinding (see SOAP 1.1 Section 6.1.1 [1]). As part of this process,\nthe WG wishes to solicit comments and guidence on two proposals it\nhas generated, as below.\n\nComments must go to xmlp-comments@w3.org by 2001-06-18, and should\naddress the proposals as they sit, and may optionally make general\ncomments on resolution of issues with SOAPAction. Those representing\nthe positions of particular groups or organisations are requested to\nclearly identify themselves as such. The WG encourages additional\ndiscussion on the xml-dist-app@w3.org mailing list.\n\nNeither of the following options precludes equivalent functionality\nelsewhere.\n\nProposal A:\nUse of SOAPAction is discouraged. SOAPAction is an optional part of\nXMLP, supported but not required. Services MAY require SOAPAction and\nany software wishing to access those services MUST be able to send\nit.\n\nProposal B:\nUse of SOAPAction is deprecated. Senders SHOULD NOT send SOAPAction.\nReceivers MUST NOT accept or reject messages on the basis of the\npresense, absence, or value of the SOAPAction header.\n\nRegards,\n\nMark Nottingham\nfor the W3C XML Protocol Working Group\n\n\n[1] http://www.w3.org/TR/SOAP/#_Toc478383528\n\n\n-- \nMark Nottingham, Research Scientist\nAkamai Technologies (San Mateo, CA USA)\n\n\n\n", "id": "lists-007-15029465"}, {"subject": "[ietf-discuss] &lt;none&gt", "content": "text/htmlSUBJECT: (None) attachment: stored\n\n\n\n\n", "id": "lists-007-15037434"}, {"subject": "We are Manufacturer and Exporter of Hi-Fi Loudspeaker Manufacturer and Exporte", "content": "Dear Sir,\n\nWe come cross to see your company on  the internet. If you are still dealing \nwith the Hi-Fi loudspeaker, we hope we can built up a relations with your company.\n\nAoning Electronics Co. Ltd., Foshan City is a branch of Macao Jinhua Trading \nGroup in Foshan City. It has introduced loudspeaker production equipment from \nabroad, equipped with a complete set of B & K electroacoustics measuring instrument \nfrom Denmark and modernized professional listening room, with abundant technical \nforce and advanced equipment. \n\nAoning Electronics Co. Ltd. has cooperated with Nanjing Electroacoustics Co. \nLtd. which has nearly forty years experiences in loudspeaker design and production, \nto develop different kinds of loudspeaker, frequency divider and Hi-Fi loudspeaker \nsystem, which are well recommended and chosen by both domestic and overseas consumers, \nadopting fittings from famous manufacturers and under the introduction of novel \ndesign and modernized production technology. Among these products, the JM-6502 \nloudspeaker system was granted the title of \"most received product\" in \"the first \nnational sound equipment exhibition\" in 1995, the AN-5003 loudspeaker system \nand AV-1 home cinema system were granted the title of \"well received product\" \nin 'the second national sound equipment exhibition\" in 1996. The JK-6506 and \nJK-8007 loudspeaker system of the JK series were granted the title of \"well received \nproduct\" in \"the third national sound equipment exhibition\" in the end of 1997. \nThe Hi-Fi No.8 super sound enclosure was granted the title of \"the super worthy \nloudspeaker with the best sound\" in the Fourth Sound Equipment Exhibition by \nthe professional appraisers unanimously. \n\nWith the above rewards, the company has made unremitting efforts to produce JV \nserial loudspeakers, SP series loudspeakers and Duite series loudspeakers which \nare welcome by consumers. Two novel sound enclosure as Aoning No.8 and Aojing \nNo.1 are introduced recently. Taking \"quality first, rapid delivery, consumer \nsupreme\" as the service aim of our company, we sincerely look forward to establishing \nbusiness relations with customers at home and abroad. \n\nShould you have any questions, Please don't hesitate to contact immediately.\n\nSincerely yours,\n\nSimon Lee\n\nInternational Sales / Aoning Electronics Co., Ltd.\n\nWebsite: http://www.bosunco.com/aoning/index.htm\nEmail: aroning@sina.com\n       aronings@sina.com\n\n\n\n", "id": "lists-007-15043149"}, {"subject": "CUSTOM ASSOCIATION WEBSITE CREATED INSTANTLY FOR YOU", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-15052950"}, {"subject": "We are Manufacturer and Exporter of Hi-Fi Loudspeaker Manufacturer and Exporte", "content": "Dear Sir,\n\nWe come cross to see your company on  the internet. If you are still dealing \nwith the Hi-Fi loudspeaker, we hope we can built up a relations with your company.\n\nAoning Electronics Co. Ltd., Foshan City is a branch of Macao Jinhua Trading \nGroup in Foshan City. It has introduced loudspeaker production equipment from \nabroad, equipped with a complete set of B & K electroacoustics measuring instrument \nfrom Denmark and modernized professional listening room, with abundant technical \nforce and advanced equipment. \n\nAoning Electronics Co. Ltd. has cooperated with Nanjing Electroacoustics Co. \nLtd. which has nearly forty years experiences in loudspeaker design and production, \nto develop different kinds of loudspeaker, frequency divider and Hi-Fi loudspeaker \nsystem, which are well recommended and chosen by both domestic and overseas consumers, \nadopting fittings from famous manufacturers and under the introduction of novel \ndesign and modernized production technology. Among these products, the JM-6502 \nloudspeaker system was granted the title of \"most received product\" in \"the first \nnational sound equipment exhibition\" in 1995, the AN-5003 loudspeaker system \nand AV-1 home cinema system were granted the title of \"well received product\" \nin 'the second national sound equipment exhibition\" in 1996. The JK-6506 and \nJK-8007 loudspeaker system of the JK series were granted the title of \"well received \nproduct\" in \"the third national sound equipment exhibition\" in the end of 1997. \nThe Hi-Fi No.8 super sound enclosure was granted the title of \"the super worthy \nloudspeaker with the best sound\" in the Fourth Sound Equipment Exhibition by \nthe professional appraisers unanimously. \n\nWith the above rewards, the company has made unremitting efforts to produce JV \nserial loudspeakers, SP series loudspeakers and Duite series loudspeakers which \nare welcome by consumers. Two novel sound enclosure as Aoning No.8 and Aojing \nNo.1 are introduced recently. Taking \"quality first, rapid delivery, consumer \nsupreme\" as the service aim of our company, we sincerely look forward to establishing \nbusiness relations with customers at home and abroad. \n\nShould you have any questions, Please don't hesitate to contact immediately.\n\nSincerely yours,\n\nSimon Lee\n\nInternational Sales / Aoning Electronics Co., Ltd.\n\nWebsite: http://www.bosunco.com/aoning/index.htm\nEmail: aroning@sina.com\n       aronings@sina.com\n\n\n\n", "id": "lists-007-15059541"}, {"subject": "Standard format for health informational page", "content": "Funded by the EU, we are going to develop a standard format\nfor health informational pages. The intention with this\nformat is to allow different health informational systems\non the Internet to exchange and re-use each other's web\npages.\n\nThe format will probably be based on XML, with the text\nitself in XHMTL, possibly a restricted XHTML with certain\nguidelines on how to use the HTML tags.\n\nIs there anything special I should think about when doing\nthis. I am already aware of Dublin Core and will look at it.\n-- \n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-15069395"}, {"subject": "common carriers", "content": "Recently I read that internet service providers have been increasingly \nlosing status as common carriers, because, for example, there have \nbeen a lot of continuing attempts at legislation requiring \ncontent-based filtering.\n\nIn fact, someone has apparently written a worm (or \"implemented an \nactive network,\" in the words of the apologists) which scans the \nhard drives of its hosts, and sends mail of \"suspicious\" activity \nto authorities, along with everyone in the host's local address book.\n\nPerhaps the OPES group will be able to scan network traffic on those \nISPs who choose to give up their common carrier status (and its \nimmunization against suits steming from, for example, the Electronic \nComminucations Privacy Act), so that whenever anyone sends an email \nwhich is objectionable to the FCC, they can immediatly alert the \nlocal police department, or the host's office of intellectual \nproperty control.\n\nThe alternative, common carrier status, which is preserved by other, \nolder, legislation in contexts involving IP telephony, at least \nin the United States, requires preservation of the end-to-end model.\n\nBenjamin Franklin knew this, as did Jefferson.  John Stewart Mill\nwrote about it, too, more than 100 years before the first e-mail.\n\nCheers,\nJames\n\nP.S.  Since I mentioned IP telephony, I am sure Lloyd would be \ndisappointed if I failed to point out that here in the U.S., the \nuse of asynchronous voice messaging (such as the excellent work \nbeing done by the IETF's Voice Profile for Internet Mail Working\nGroup) is protected by both the Electronic Communications Privacy \nAct and older telephony common-carrier requirements in U.S. law.\nMoreover, it is firmly rooted in end-to-end requirements.\n\n\n\n", "id": "lists-007-15076963"}, {"subject": "Scheduling for Londo", "content": "There are the slots we have scheduled so far.\n\nAPPLICATION AREA\n1. (apparea) Applications Open Area Meeting WG\n2. (deltav) Web Versioning and Configuration Management WG\n3. (fax) Internet Fax WG\n4. (ldapbis)  LDAP (v3) Revision WG\n5. (provreg) Provisioning Registry Protocol WG\n6. (simple) SIP for Instant Messaging and Presence Leveraging Extensions WG\n7. (trade) Internet Open Trading Protocol WG\n8. (vpim) Voice Profile for Internet Mail WG\n9. (webdav) WWW Distributed Authoring and Versioning WG\n\n\nShould I take this as a sign that the rest of the wg's are done modulo work\nwe AD's should do to get groups closed?\n\n   paf\n\n\n\n", "id": "lists-007-15085183"}, {"subject": "Re: Scheduling for Londo", "content": "On 6/18/01 at 3:57 PM +0200, Patrik F?ltstr?m wrote:\n\n>Should I take this as a sign that the rest of the wg's are done modulo work\n>we AD's should do to get groups closed?\n\nFor my WGs: This is pretty much true of BEEP; some cleanup and we're \non our way. APEX is not meeting, but that's only because work is \nprogressing and the document editors don't feel like they need \nface-to-face time at the moment. IMAPEXT will probably meet and I \nwill get the request in before the 7/16 deadline if so, but the group \nis not being very motivated at the moment. I am attempting motivation \nnow, which will be followed by threat, and then followed by the \nspecter of IESG threat.\n\npr\n-- \nPete Resnick <mailto:presnick@qualcomm.com>\nQUALCOMM Incorporated - Direct phone: (858)651-4478, Fax: (858)651-1102\n\n\n\n", "id": "lists-007-15092800"}, {"subject": "Re: Scheduling for Londo", "content": "--On 01-06-18 11.06 -0500 Pete Resnick <presnick@qualcomm.com> wrote:\n\n> On 6/18/01 at 3:57 PM +0200, Patrik F?ltstr?m wrote:\n> \n>> Should I take this as a sign that the rest of the wg's are done modulo\n>> work we AD's should do to get groups closed?\n\nBy the way, for those of you who doesn't know me...I should have used a\nsmiley after my statement. Both because I know many groups are waiting for\nme personally as I have had one of the worst work-loads ever the last two\nmonths, secondly because I know your workload is not the best either.\n\nI.e. this is my way of asking all of us if it is not the case that people\nwhich do want meetings really should send in their request asap, or there\nwill not be any slot in London.\n\nAt the same time ask everyone to think about the status of their groups.\n\nThanks you all for understanding and not misunderstanding me too much.\n\n   paf\n\n\n\n", "id": "lists-007-15100951"}, {"subject": "***Atenci?n a Todos los Usarios de Computadoras**", "content": "***Atenci?n a Todos los Usarios de Computadoras***\n\n?Cansado de pagar $200, $300, $400 ? Incluso $500 pesos por \nlos cartuchos de Inyecci?n?\n\n?Cansado de que tu Impresora gaste tinta una y otra vez?\n\n?Cansado de correr a la tienda en busca de tu cartucho?\n\n?Cansado de tener que esperar hasta la ma?ana siguiente para \nque la Impresora funcione?\n\n===================================================\n==============================\n\nAqui est? la soluci?n no reemplaces tus Cartuchos...Rellenalos \ncon Nuestros kits de Relleno-F?cil\n\n===================================================\n==============================\n\nNo Importa que tipo de Impresora tengas o con que colores \nquieras Imprimir\n\nNuestros kits trabajan en calquier marca de Impresora.. Con los \nkits de relleno usted obtiene toda la tinta y \n\nherramientas que necesita para  rellenar sus cartuchos de \nInyecci?n m?s de 10 veces\n\nRellenarar sus cartuchos es r?pido barato y f?cil de hacer - \n?Rellena tu Cartucho Inkjet por menos de $50 pesos!\n\nTodo lo que necesitas est? Incluido en Nuestros kits con \nInstrucciones  \n\nLas Primeras 200 ?rdenes recibidas durante durante ?sta \npromocion recibir?n una botella extra de tinta negra \nabsolutamente GR?TIS!!!!!!\n\n??Envio Gratis a Toda de Republica Mexicana con Multi-Pack!!\n\nLLAMA AHORA  (016) 6-31-83-62  o  (016) 6-31-86-39       \n\nHaz click aqui para tinta gratis     \nwww.jrinkjet.com.mx/promoforDF.htm\n\nPara m?s informaci?n acerca de Tintas Universal haz click aqui  \nwww.jrinkjet.com.mx\n\nGracias,\n\nTintas Universal de M?xico S.A. de C.V.***Atenci?n a Todos los \nUsarios de Computadoras***\n\n?Cansado de pagar $200, $300, $400 ? Incluso $500 pesos por \nlos cartuchos de Inyecci?n?\n\n?Cansado de que tu Impresora gaste tinta una y otra vez?\n\n?Cansado de correr a la tienda en busca de tu cartucho?\n\n?Cansado de tener que esperar hasta la ma?ana siguiente para \nque la Impresora funcione?\n\n===================================================\n==============================\n\nAqui est? la soluci?n no reemplaces tus Cartuchos...Rellenalos \ncon Nuestros kits de Relleno-F?cil\n\n===================================================\n==============================\n\nNo Importa que tipo de Impresora tengas o con que colores \nquieras Imprimir\n\nNuestros kits trabajan en calquier marca de Impresora.. Con los \nkits de relleno usted obtiene toda la tinta y \n\nherramientas que necesita para  rellenar sus cartuchos de \nInyecci?n m?s de 10 veces\n\nRellenarar sus cartuchos es r?pido barato y f?cil de hacer - \n?Rellena tu Cartucho Inkjet por menos de $50 pesos!\n\nTodo lo que necesitas est? Incluido en Nuestros kits con \nInstrucciones  \n\nLas Primeras 200 ?rdenes recibidas durante durante ?sta \npromocion recibir?n una botella extra de tinta negra \nabsolutamente GR?TIS!!!!!!\n\n??Envio Gratis a Toda de Republica Mexicana con Multi-Pack!!\n\nLLAMA AHORA  (016) 6-31-83-62  o  (016) 6-31-86-39       \n\nHaz click aqui para tinta gratis     \nwww.jrinkjet.com.mx/promoforDF.htm\n\nPara m?s informaci?n acerca de Tintas Universal haz click aqui  \nwww.jrinkjet.com.mx\n\nGracias,\n\nTintas Universal de M?xico S.A. de C.V.\nNEVER SEND SPAM. IT IS BAD.\n\n\n\n", "id": "lists-007-15108960"}, {"subject": "***Atenci?n a Todos los Usarios de Computadoras**", "content": "***Atenci?n a Todos los Usarios de Computadoras***\n\n?Cansado de pagar $200, $300, $400 ? Incluso $500 pesos por \nlos cartuchos de Inyecci?n?\n\n?Cansado de que tu Impresora gaste tinta una y otra vez?\n\n?Cansado de correr a la tienda en busca de tu cartucho?\n\n?Cansado de tener que esperar hasta la ma?ana siguiente para \nque la Impresora funcione?\n\n===================================================\n==============================\n\nAqui est? la soluci?n no reemplaces tus Cartuchos...Rellenalos \ncon Nuestros kits de Relleno-F?cil\n\n===================================================\n==============================\n\nNo Importa que tipo de Impresora tengas o con que colores \nquieras Imprimir\n\nNuestros kits trabajan en calquier marca de Impresora.. Con los \nkits de relleno usted obtiene toda la tinta y \n\nherramientas que necesita para  rellenar sus cartuchos de \nInyecci?n m?s de 10 veces\n\nRellenarar sus cartuchos es r?pido barato y f?cil de hacer - \n?Rellena tu Cartucho Inkjet por menos de $50 pesos!\n\nTodo lo que necesitas est? Incluido en Nuestros kits con \nInstrucciones  \n\nLas Primeras 200 ?rdenes recibidas durante durante ?sta \npromocion recibir?n una botella extra de tinta negra \nabsolutamente GR?TIS!!!!!!\n\n??Envio Gratis a Toda de Republica Mexicana con Multi-Pack!!\n\nLLAMA AHORA  (016) 6-31-83-62  o  (016) 6-31-86-39       \n\nHaz click aqui para tinta gratis     \nwww.jrinkjet.com.mx/promoforDF.htm\n\nPara m?s informaci?n acerca de Tintas Universal haz click aqui  \nwww.jrinkjet.com.mx\n\nGracias,\n\nTintas Universal de M?xico S.A. de C.V.***Atenci?n a Todos los \nUsarios de Computadoras***\n\n?Cansado de pagar $200, $300, $400 ? Incluso $500 pesos por \nlos cartuchos de Inyecci?n?\n\n?Cansado de que tu Impresora gaste tinta una y otra vez?\n\n?Cansado de correr a la tienda en busca de tu cartucho?\n\n?Cansado de tener que esperar hasta la ma?ana siguiente para \nque la Impresora funcione?\n\n===================================================\n==============================\n\nAqui est? la soluci?n no reemplaces tus Cartuchos...Rellenalos \ncon Nuestros kits de Relleno-F?cil\n\n===================================================\n==============================\n\nNo Importa que tipo de Impresora tengas o con que colores \nquieras Imprimir\n\nNuestros kits trabajan en calquier marca de Impresora.. Con los \nkits de relleno usted obtiene toda la tinta y \n\nherramientas que necesita para  rellenar sus cartuchos de \nInyecci?n m?s de 10 veces\n\nRellenarar sus cartuchos es r?pido barato y f?cil de hacer - \n?Rellena tu Cartucho Inkjet por menos de $50 pesos!\n\nTodo lo que necesitas est? Incluido en Nuestros kits con \nInstrucciones  \n\nLas Primeras 200 ?rdenes recibidas durante durante ?sta \npromocion recibir?n una botella extra de tinta negra \nabsolutamente GR?TIS!!!!!!\n\n??Envio Gratis a Toda de Republica Mexicana con Multi-Pack!!\n\nLLAMA AHORA  (016) 6-31-83-62  o  (016) 6-31-86-39       \n\nHaz click aqui para tinta gratis     \nwww.jrinkjet.com.mx/promoforDF.htm\n\nPara m?s informaci?n acerca de Tintas Universal haz click aqui  \nwww.jrinkjet.com.mx\n\nGracias,\n\nTintas Universal de M?xico S.A. de C.V.\nNEVER SEND SPAM. IT IS BAD.\n\n\n\n", "id": "lists-007-15118107"}, {"subject": "error condition for delete of VHR when VCR is in checked-in collectio", "content": "Hi,\n\nconsidering:\n\n- a versioned controlled checked-in collection /a\n- a version controlled resource /a/b with a version history resource of\n/vhr/123\n- a server that handles deletion of version histories as request to\nun-version-control the VCR\n\nWhat should happen upon a DELETE on /vhr/123?\n\n- this would be considered to change the state of /a/b from being\nversion-controlled to not being version-controlled, however the parent\ncollection isn't checked out\n\n- returning Conflict with error condition\nDAV:cannot-modify-checked-in-parent seems to be a valid approach, however\ndoesn't fit optimally (because the request was sent to /vhr/123, and /a --\nwhich causes the error as not bein checked out -- isn't a parent collection\nof the request URI).\n\nJulian\n\n\n\n", "id": "lists-007-1512084"}, {"subject": "PRO Marketing Program FREE - NOW!", "content": "Hello Friend, \nNetwork marketing can be so fun, and so exciting. I love it! \nNetwork marketing can also be a huge disapointment, and Heartache. \nI hate it!\nDoes this sound familiar? You have been working diligently on a \nprogam for six months. You are just about to experience that \nexponential growth that you keep hearing about, then suddenly WHAM!, the company is out of business. It was a well intentioned company, they had a good product, but for what ever reason, GONE! \nNow what? You just spent six months bringing people in to a business. You told them how great it was, and believed it. Now, you have just lost face. You never lied, or cheated anyone, but nontheless, they were let down. Friend, I am here to tell you, that it does not have to be that way.\nSurely by now, you have heard of a new company called \nNetmark Pro. With this company, you join at no cost, and give away these great recruiting, and selling systems. While you do this, you build up a frienship that lasts. You are just giving away something that everyone in this business needs, and it works!!\nThat bond lasts, and no matter what business you may get into in the future, and you know there will be more, your gang will be there with you. \nEver wish you had a bunch of people with you right from the start? \nWell, this is one way to do just that. \nThe other day, I was offered an opportunity to get into a pre-launch business that I believe is going to rock this world. Who do you think I told about this business first? That's right. Who do you suppose they told? \nIf you can see the whole picture here, please visit this site to get your no cost Netmark Pro system - AT NO COST! \n<http://www.netmarkpro.net/kvmartin>\nIt makes Network marketing a whole new ball game. More fun, and the bottom line friend, MORE MONEY! Netmark Pro also pays for referrals on two levels. NO NEED TO UPGRADE TO BE PAID. \n\nKathrn Martin \n(Subject Line : NMP) <kvmartin@money-income.com>\n\nThis email is never sent unsolicited. This is not spam. You are receiving this email because you explicitly and expressly signed yourself up to our list with our online signup form or \nthrough use of our MyListmaker Page, FFA Links Page, Links2U Page, WorldGlobeEzine, ReferralWare, Small Biz FFA Page or our many Megaresponse Pages (matching my search criteria of \"part time income\") which have EXPLICIT terms of use that state that through use of these pages you \"opt-in\" and therefore you agree \nto receive our periodic e-mails. This also applies to email address obtained from 3rd Parties via \"safe lists.\n\n\n\n\nHere's some ADDITIONAL GREAT WAYS to help your Marketing Efforts and further your Marketing Success.\nhttp://www.mysimplesystem.com/d.cgi/147182 \nIt's working for me ... it WILL work for YOU!!\nWant to earn a SIX FIGURE INCOME???\nhttp://www.ezinfocenter.com/1338434\nALREADY an \"SFI Affiliate\"? This one is FOR YOU!\nhttp://www.wildfireco-op.net/a.asp?70043613\n(SPECIFICALLY DESIGNED FOR SFI Affiliates & Members)\n\n\n\n__________________________________________________\nD O T E A S Y - \"Join the web hosting revolution!\"\n             http://www.doteasy.com\n\n\n\n", "id": "lists-007-15127269"}, {"subject": "Re: Scheduling for Londo", "content": "Patrik,\n\nI suggest we (again) attempt something in the whois-space, with clear\ndemarkations between\n:43 massage (presentation issues),\n:xx structure (centralized, collaborative/delegated/...\npost-43 mega-massage (the whole xml opera)\n\nEric\n\n\n\n", "id": "lists-007-15137303"}, {"subject": "Re: Scheduling for Londo", "content": "--On 01-06-20 09.57 -0400 Eric Brunner-Williams in Portland Maine\n<brunner@nic-naa.net> wrote:\n\n> I suggest we (again) attempt something in the whois-space, with clear\n> demarkations between\n> :43 massage (presentation issues),\n> :xx structure (centralized, collaborative/delegated/...\n> post-43 mega-massage (the whole xml opera)\n\n\nI am happy to do that.\n\nWill you take the lead and come up with an agenda for the BOF?\n\n  paf\n\n\n\n", "id": "lists-007-15145320"}, {"subject": "Re: Scheduling for Londo", "content": "At 06:57 AM 6/20/2001, Eric Brunner-Williams in Portland Maine wrote:\n>I suggest we (again) attempt something in the whois-space, with clear\n>demarkations between\n>         :43 massage (presentation issues),\n>         :xx structure (centralized, collaborative/delegated/...\n>         post-43 mega-massage (the whole xml opera)\n\n(patrik's confirmation is happily noted, however...)\n\nGiven that we have had two false starts on this topic, already, I'd like to \nraise the concern that the previous false start seemed -- to me, at least \n-- pretty clearly to be focused ONLY on creation of a data structure \nstandard for :43 responses.\n\nHowever the discussion got sidetracked with other, larger and more \ndifficult issues.\n\nPerhaps the agenda was not as clear as I thought it was.  Hence, being more \nclear this time will suffice (he said, optimistically.)\n\nPerhaps something deeper is at issue.  If so, can we try to surface it and \ndispatch it?\n\nd/\n\n----------\nDave Crocker   <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking   <http://www.brandenburg.com>\ntel: +1.408.246.8253;   fax: +1.408.273.6464\n\n\n\n", "id": "lists-007-15153325"}, {"subject": "Re: Scheduling for Londo", "content": "--On 01-06-20 10.14 -0700 Dave Crocker <dcrocker@brandenburg.com> wrote:\n\n> Perhaps the agenda was not as clear as I thought it was.  Hence, being\n> more  clear this time will suffice (he said, optimistically.)\n> \n> Perhaps something deeper is at issue.  If so, can we try to surface it\n> and  dispatch it?\n\nThat's why I wanted someone to take the lead. I.e. my positive reaction was\nbecause (a) something _has_ to be done, especially with the port 43\nprotocol, and for other things we have the LDAP proposal from Verisign/NSI\nand (b) given an agenda which all of us with knifes in our backs is happy\nwith, I will schedule the BOF.\n\nBut, as Dave says, this is not a walk in the park. Significant work is\nneeded before a meeting will be fruitful.\n\n  paf\n\n\n\n", "id": "lists-007-15162690"}, {"subject": "RE: Scheduling for Londo", "content": "> -----Original Message-----\n> From: Patrik F?ltstr?m [mailto:paf@cisco.com]\n> Sent: Wednesday, June 20, 2001 3:47 PM\n> To: Dave Crocker; Eric Brunner-Williams in Portland Maine\n> Cc: discuss@apps.ietf.org; ietf-whois@imc.org; brunner@nic-naa.net\n> Subject: Re: Scheduling for London \n \n\n> But, as Dave says, this is not a walk in the park. Significant work is\n> needed before a meeting will be fruitful.\n\nHow relevant do folks see the work previously agreed to within ICANN circles\nto prescribe the info that must be returned in response to a domain name\nquery?  Good building block, or still too muddled to form the basis of\nsomething to work from?\n\n<Scott/>\n\n\n\n", "id": "lists-007-15171195"}, {"subject": "RE: Scheduling for Londo", "content": "ahhh.  yes.  Thanks, Scott.\n\nNOW I remember why things got bogged down:\n\n         The problem is with needing to distinguish mechanism from policy.\n\nThe constrained IETF efforts needs to specify mechanism only.  If possible, \nit should \"require\" no specific data in a response.  Any that it DOES \nrequire should be very minimal and utterly essential to operational \nrequirements.\n\nThe real policy work, for deciding what to put in a response, can be \ndebated elsewhere.\n\nd/\n\n\nAt 01:58 PM 6/20/2001, Hollenbeck, Scott wrote:\n> > -----Original Message-----\n> > From: Patrik F?ltstr?m [mailto:paf@cisco.com]\n> > Sent: Wednesday, June 20, 2001 3:47 PM\n> > To: Dave Crocker; Eric Brunner-Williams in Portland Maine\n> > Cc: discuss@apps.ietf.org; ietf-whois@imc.org; brunner@nic-naa.net\n> > Subject: Re: Scheduling for London\n>\n>\n> > But, as Dave says, this is not a walk in the park. Significant work is\n> > needed before a meeting will be fruitful.\n>\n>How relevant do folks see the work previously agreed to within ICANN circles\n>to prescribe the info that must be returned in response to a domain name\n>query?  Good building block, or still too muddled to form the basis of\n>something to work from?\n>\n><Scott/>\n\n----------\nDave Crocker   <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking   <http://www.brandenburg.com>\ntel: +1.408.246.8253;   fax: +1.408.273.6464\n\n\n\n", "id": "lists-007-15180607"}, {"subject": "RE: Scheduling for Londo", "content": "> How relevant do folks see the work previously agreed to within ICANN circles\n> to prescribe the info that must be returned in response to a domain name\n> query?\n\nnot to port 43 whois.  but we've had this discussion before, have we not?\n\nrandy\n\n\n\n", "id": "lists-007-15190990"}, {"subject": "RE: Scheduling for Londo", "content": "> -----Original Message-----\n> From: Randy Bush [mailto:randy@psg.com]\n> Sent: Wednesday, June 20, 2001 5:15 PM\n> To: Hollenbeck, Scott\n> Cc: discuss@apps.ietf.org; ietf-whois@imc.org\n> Subject: RE: Scheduling for London \n> \n> \n> > How relevant do folks see the work previously agreed to within ICANN\ncircles\n> > to prescribe the info that must be returned in response to a domain name\n> > query?\n> \n> not to port 43 whois.  but we've had this discussion before, \n> have we not?\n\nIndeed we have, with the chaotic results described earlier on this thread.\nNow that Dave's question regarding how we managed to get bogged down has\nbeen partially answered, we should carefully consider the scope of a BoF\nagenda to make sure that we don't resurrect this topic again -- with the\npossible exception of being very clear that it's _not_ relevant.\n\n<Scott/>\n\n\n\n", "id": "lists-007-15198327"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "If you are going to allow deletion of version histories, your best\nbet is to \"clean up\" (at least, from the protocol perspective).\nThis means you should remove all references (or act as if you have\nremoved all references) to /vhr/123.  In particular, you would remove\nreferences from the version-controlled-binding-set of any collection\nversion.  The result is that from the perspective of /a, there no longer\nis a version-controlled binding to /a/b, so /a/b is just a\nnon-version-controlled member from /a's perspective (i.e. no error).\n\nCheers,\nGeoff\n\n   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   considering:\n\n   - a versioned controlled checked-in collection /a\n   - a version controlled resource /a/b with a version history resource of\n   /vhr/123\n   - a server that handles deletion of version histories as request to\n   un-version-control the VCR\n\n   What should happen upon a DELETE on /vhr/123?\n\n   - this would be considered to change the state of /a/b from being\n   version-controlled to not being version-controlled, however the parent\n   collection isn't checked out\n\n   - returning Conflict with error condition\n   DAV:cannot-modify-checked-in-parent seems to be a valid approach, however\n   doesn't fit optimally (because the request was sent to /vhr/123, and /a\n--\n   which causes the error as not bein checked out -- isn't a parent\ncollection\n   of the request URI).\n\n\n\n", "id": "lists-007-1520232"}, {"subject": "Re: Scheduling for Londo", "content": "On 2001-06-20 16:58:29 -0400, Hollenbeck, Scott wrote:\n> \n> > -----Original Message-----\n> > From: Patrik F?ltstr?m [mailto:paf@cisco.com]\n> > Sent: Wednesday, June 20, 2001 3:47 PM\n> > To: Dave Crocker; Eric Brunner-Williams in Portland Maine\n> > Cc: discuss@apps.ietf.org; ietf-whois@imc.org; brunner@nic-naa.net\n> > Subject: Re: Scheduling for London \n> \n> > But, as Dave says, this is not a walk in the park. Significant work\n> > is needed before a meeting will be fruitful.\n> \n> How relevant do folks see the work previously agreed to within ICANN\n> circles to prescribe the info that must be returned in response to a\n> domain name query?  Good building block, or still too muddled to form\n> the basis of something to work from?\n\nWhile I may not be \"relevant\", could you please point me and any other\nfolks who might not be part of the ICANN circles to some place we could\nfind out what the info that must be returned is?\n\n(FWIW, while the RIPE NCC is an RIR, we do domain name queries on the\nside.)\n\nThanks!\n\n-- \nShane\n\n\n\n", "id": "lists-007-15207427"}, {"subject": "email list and Drop Shipper lis", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-15216604"}, {"subject": "Communication between applications and networ", "content": "Recently a new Internet draft has been submitted\n(draft-pham-triggers-and-handles-00.txt, downloadable from\nhttp://www.ietf.org/internet-drafts/draft-pham-triggers-and-handles-00.txt),\nwhich introduces a new concept for communication between applications\nand network \nelements. The document defines triggers and handles exchanged between\napplications and network elements, and introduces associated\ncommunication mechanisms such as subscription to triggers from a network\nelement, and discovery of network element interfaces.\n\nThis communication interface and framework will allow applications to be\ndeployed on heterogeneous networks in a vendor-independent way but still\nbeing aware of network events by the mechanism of triggers and being\nable to control network resources by the mechanism of handles, i.e.\nnetwork awareness of applications will be improved. The work will aim at\nreusing as much as possible existing protocols and will \ndefine extensions or new protocols only when necessary. The targeted\nnetwork environment is primarily the broadband access network (user\nterminal - DSL modem - DSLAM - BRAS), although also other networks can\nbe envisaged.\n\nThe purpose of this Internet Draft is to stimulate discussion on this\nconcept. Therefore an associated mailinglist has been created where you\ncan send your comments and reactions:\nAddress: triggershandles@public.alcatel.com\nTo subscribe, send an email to majordomo@public.alcatel.com with in the\nbody \"subcribe triggershandles\"\n\nIf discussions raise enough interests, a BOF will be requested to\nfurther work on the subject in IETF. Indeed, the topic is today not\nreally covered in a charter of any working group. Nevertheless, it has\nclear links with following areas and working groups:\n- the applications area: since the I-D deals with mechanisms to make\napplications more network aware.\n- the operations and management area: since the mechanism are based on\nor similar to concepts used in AAA, in policy framework, etc.\n- the resource allocation protocol WG (rap): since the COPS protocol is\ncurrently envisaged to be one of the major cornerstones of the triggers\n& handles framework.\n- the middlebox communication WG (midcom): as this WG deals with\nmechanisms for applications to be able to communicate their needs to the\ndevices in the network that provide transport policy enforcement. in\nother words, very similar to the idea of handles in the I-D.\n\nLooking forward to receiving your comments,\n\nDominique Chantrain & Hien-Thong Pham\n\n\n\n", "id": "lists-007-15223020"}, {"subject": "Re: Scheduling for Londo", "content": "    \n    The real policy work, for deciding what to put in a response, can be \n    debated elsewhere.\n\nI believe that the DNSO is trying to so, see: DNSO Names Council\nWhois Survey, http://www.icann.org/dnso/whois-survey-en-10jun01.htm\nfor details.\n\nPolicy is starting to be the big thing. The Dutch registration\nchamber (a kinf of privacy in database protection agency) planning\nto look into what a whois service might provide and what not. And\nthis is of course not only for domain related data, but also for\nthe adress people, such as the RIPE NCC whois service.\n\n\njaap\n\n\n\n", "id": "lists-007-15234789"}, {"subject": "Re: Scheduling for Londo", "content": "On 2001-06-27 15:20:58 +0200, Jaap Akkerhuis wrote:\n> \n>     \n>     The real policy work, for deciding what to put in a response, can be \n>     debated elsewhere.\n> \n> I believe that the DNSO is trying to so, see: DNSO Names Council Whois\n> Survey, http://www.icann.org/dnso/whois-survey-en-10jun01.htm\n> for details.\n> \n> Policy is starting to be the big thing. The Dutch registration chamber\n> (a kinf of privacy in database protection agency) planning to look\n> into what a whois service might provide and what not. And this is of\n> course not only for domain related data, but also for the adress\n> people, such as the RIPE NCC whois service.\n\nIndeed.  We have been contacted by the Dutch information authority\nconcerning the information in our Whois database, and are working with\nthem on this issue.\n\n-- \nShane Kerr\nRIPE NCC\n\n\n\n", "id": "lists-007-15243079"}, {"subject": "Are international characters allowed in email addresses", "content": "Hello,\n\nI'm researching an issue regarding whether international characters are\nallowed in email addresses. Through the research that I've conducted thus\nfar I've seen contradictory information.\n\nIn looking at RFC-822 it only specifies ASCII characters being allowed,\nhowever I have actually seen a few email addresses that do in fact have\ninternational characters in them. For example, jos?.berm?dez@xxxxxx.com --\nnote the accented 'e' and 'u'.\n\nIf anyone has any more definitive information regarding what is and what is\nnot supported in respect to international characters in email addresses, I\nwould be greatly appreciative.\n\nThanks in advance.\n\nRegards,\nJohn\n\n__________________________________________\nJohn Harrison\n@Once, Director of Product Management\n309 SW 6th Avenue, Suite 900, Portland, OR 97204\ndirect: 503.419.0552 / cell: 503.804.2161\nmain: 503.241/4185 / fax: 503.241.4279\nemail: jharrison@once.com\n\n\n\n", "id": "lists-007-15251233"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "- there is no support right now for an internationalized left part of an \nemail address.\n- there is current work for the right part (the domain name) in the ietf \nidn wg.\n\nMarc.\n\nAt/? 11:57 2001-06-27 -0700, John Harrison you wrote/vous ?criviez:\n>Hello,\n>\n>I'm researching an issue regarding whether international characters are\n>allowed in email addresses. Through the research that I've conducted thus\n>far I've seen contradictory information.\n>\n>In looking at RFC-822 it only specifies ASCII characters being allowed,\n>however I have actually seen a few email addresses that do in fact have\n>international characters in them. For example, jos?.berm?dez@xxxxxx.com --\n>note the accented 'e' and 'u'.\n>\n>If anyone has any more definitive information regarding what is and what is\n>not supported in respect to international characters in email addresses, I\n>would be greatly appreciative.\n>\n>Thanks in advance.\n>\n>Regards,\n>John\n>\n>__________________________________________\n>John Harrison\n>@Once, Director of Product Management\n>309 SW 6th Avenue, Suite 900, Portland, OR 97204\n>direct: 503.419.0552 / cell: 503.804.2161\n>main: 503.241/4185 / fax: 503.241.4279\n>email: jharrison@once.com\n\n\n\n", "id": "lists-007-15261786"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "> I'm researching an issue regarding whether international characters are\n> allowed in email addresses.\n\nno, they're not.  in all current mail standards email addresses must\nbe entirely in ASCII.\n\n\n\n", "id": "lists-007-15271735"}, {"subject": "RE: Are international characters allowed in email addresses", "content": "Thanks, Keith.\n\nSo if I received an email address with the following:\n\ndavid.garc?a.arregui@xxxx.com\n\nit would be incorrect?\n\nThe accented ? is in fact an ASCII character, it is included in ASCII 8 I\nbelieve and definitely ISO Latin 1 (ISO-8859-1), not ASCII 7. The example\nabove is a real email address that I received from someone -- thus my state\nof confusion.\n\nThanks for your assistance.\n\n-John\n\n-----Original Message-----\nFrom: Keith Moore [mailto:moore@cs.utk.edu]\nSent: Wednesday, June 27, 2001 1:04 PM\nTo: John Harrison\nCc: 'discuss@apps.ietf.org'\nSubject: Re: Are international characters allowed in email addresses? \n\n\n> I'm researching an issue regarding whether international characters are\n> allowed in email addresses.\n\nno, they're not.  in all current mail standards email addresses must\nbe entirely in ASCII.\n\n\n\n", "id": "lists-007-15279948"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "At 04:04 PM 6/27/2001, Keith Moore wrote:\n> > I'm researching an issue regarding whether international characters are\n> > allowed in email addresses.\n>\n>no, they're not.  in all current mail standards email addresses must\n>be entirely in ASCII.\n\nwell, we can be a bit friendlier to the topic, I think.  Only ASCII \n\"characters\" are permitted, however there is a standard that permits \nencoding international characters into an ASCII form.\n\nSo the pure negative is:  raw (binary) international characters are not \npermitted.\nThe positive is:  Encoded international characters are permitted.\n\nd/\n\n\n----------\nDave Crocker  <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking  <http://www.brandenburg.com>\ntel +1.408.246.8253;  fax +1.408.273.6464\n\n\n\n", "id": "lists-007-15289649"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "Geoff,\n\ndid you possibly miss the part about the collection \"/a\" being checked-in?\nOtherwise this sounds as if deleting the VHR may have the side effect of\nun-version-controlling a resource which is member of a version-controlled\nchecked-in collection...\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, June 28, 2002 2:43 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: error condition for delete of VHR when VCR is in checked-in\n> c ollection\n>\n>\n>\n> If you are going to allow deletion of version histories, your best\n> bet is to \"clean up\" (at least, from the protocol perspective).\n> This means you should remove all references (or act as if you have\n> removed all references) to /vhr/123.  In particular, you would remove\n> references from the version-controlled-binding-set of any collection\n> version.  The result is that from the perspective of /a, there no longer\n> is a version-controlled binding to /a/b, so /a/b is just a\n> non-version-controlled member from /a's perspective (i.e. no error).\n>\n> Cheers,\n> Geoff\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    considering:\n>\n>    - a versioned controlled checked-in collection /a\n>    - a version controlled resource /a/b with a version history resource of\n>    /vhr/123\n>    - a server that handles deletion of version histories as request to\n>    un-version-control the VCR\n>\n>    What should happen upon a DELETE on /vhr/123?\n>\n>    - this would be considered to change the state of /a/b from being\n>    version-controlled to not being version-controlled, however the parent\n>    collection isn't checked out\n>\n>    - returning Conflict with error condition\n>    DAV:cannot-modify-checked-in-parent seems to be a valid\n> approach, however\n>    doesn't fit optimally (because the request was sent to /vhr/123, and /a\n> --\n>    which causes the error as not bein checked out -- isn't a parent\n> collection\n>    of the request URI).\n>\n>\n\n\n\n", "id": "lists-007-1529671"}, {"subject": "RE: Are international characters allowed in email addresses", "content": "Thanks, Dave,\n\nWhere might I go to find more information on the standard you mentioned\nbelow?\n\nThanks,\nJohn\n\n-----Original Message-----\nFrom: Dave Crocker [mailto:dcrocker@brandenburg.com]\nSent: Wednesday, June 27, 2001 1:15 PM\nTo: Keith Moore\nCc: John Harrison; 'discuss@apps.ietf.org'\nSubject: Re: Are international characters allowed in email addresses? \n\n\nAt 04:04 PM 6/27/2001, Keith Moore wrote:\n> > I'm researching an issue regarding whether international characters are\n> > allowed in email addresses.\n>\n>no, they're not.  in all current mail standards email addresses must\n>be entirely in ASCII.\n\nwell, we can be a bit friendlier to the topic, I think.  Only ASCII \n\"characters\" are permitted, however there is a standard that permits \nencoding international characters into an ASCII form.\n\nSo the pure negative is:  raw (binary) international characters are not \npermitted.\nThe positive is:  Encoded international characters are permitted.\n\nd/\n\n\n----------\nDave Crocker  <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking  <http://www.brandenburg.com>\ntel +1.408.246.8253;  fax +1.408.273.6464\n\n\n\n", "id": "lists-007-15299404"}, {"subject": "RE: Are international characters allowed in email addresses", "content": "I guess Dave was referring to RFC2047.\n\nHowever, RFC2047 expressly forbids using the encoded strings in address\nspecifications.\n\n-d\n\n> -----Original Message-----\n> From: John Harrison [mailto:jharrison@once.com]\n> Sent: Wednesday, June 27, 2001 1:18 PM\n> To: 'Dave Crocker'; Keith Moore\n> Cc: 'discuss@apps.ietf.org'\n> Subject: RE: Are international characters allowed in email addresses?\n>\n>\n> Thanks, Dave,\n>\n> Where might I go to find more information on the standard you mentioned\n> below?\n>\n> Thanks,\n> John\n>\n> -----Original Message-----\n> From: Dave Crocker [mailto:dcrocker@brandenburg.com]\n> Sent: Wednesday, June 27, 2001 1:15 PM\n> To: Keith Moore\n> Cc: John Harrison; 'discuss@apps.ietf.org'\n> Subject: Re: Are international characters allowed in email addresses?\n>\n>\n> At 04:04 PM 6/27/2001, Keith Moore wrote:\n> > > I'm researching an issue regarding whether international characters are\n> > > allowed in email addresses.\n> >\n> >no, they're not.  in all current mail standards email addresses must\n> >be entirely in ASCII.\n>\n> well, we can be a bit friendlier to the topic, I think.  Only ASCII\n> \"characters\" are permitted, however there is a standard that permits\n> encoding international characters into an ASCII form.\n>\n> So the pure negative is:  raw (binary) international characters are not\n> permitted.\n> The positive is:  Encoded international characters are permitted.\n>\n> d/\n>\n>\n> ----------\n> Dave Crocker  <mailto:dcrocker@brandenburg.com>\n> Brandenburg InternetWorking  <http://www.brandenburg.com>\n> tel +1.408.246.8253;  fax +1.408.273.6464\n\n\n\n", "id": "lists-007-15310042"}, {"subject": "RE: Are international characters allowed in email addresses", "content": "At 04:30 PM 6/27/2001, Dan Wing wrote:\n>I guess Dave was referring to RFC2047.\n>\n>However, RFC2047 expressly forbids using the encoded strings in address\n>specifications\n\nright.  it only applies to the \"display name\" string.\n\nso, the added constraint is a) no international characters in the mailbox \nstring, and b) encoding of international strings in the domain name is \nforthcoming.\n\nd/\n\n\n----------\nDave Crocker  <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking  <http://www.brandenburg.com>\ntel +1.408.246.8253;  fax +1.408.273.6464\n\n\n\n", "id": "lists-007-15321762"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "> > > I'm researching an issue regarding whether international characters are\n> > > allowed in email addresses.\n\n> > no, they're not.  in all current mail standards email addresses must\n> > be entirely in ASCII.\n\n> well, we can be a bit friendlier to the topic, I think.  Only ASCII\n> \"characters\" are permitted, however there is a standard that permits\n> encoding international characters into an ASCII form.\n\nDave, this is being friendly at the expense of accuracy. While it is true\nthat there are various standards for encoding international characters\nin ASCII, at present none of them are applicable to email addresses.\n\nPhrases and comments in message headers are another matter. There are\nstandards for internationalizing those (RFC 2047 in particular).\nBut they don't apply to addresses themselves.\n\n> So the pure negative is:  raw (binary) international characters are not\n> permitted.\n> The positive is:  Encoded international characters are permitted.\n\nYou certainly can perform such an encoding and produce a valid address, but\nthere's no encoding that is standardized for email addresses so don't\nanyone else to reverse the encoding and display the result.\n\nNed\n\n\n\n", "id": "lists-007-15331113"}, {"subject": "RE: Are international characters allowed in email addresses", "content": "> At 04:30 PM 6/27/2001, Dan Wing wrote:\n> >I guess Dave was referring to RFC2047.\n> >\n> >However, RFC2047 expressly forbids using the encoded strings in address\n> >specifications\n\n> right.  it only applies to the \"display name\" string.\n\n> so, the added constraint is a) no international characters in the mailbox\n> string, and b) encoding of international strings in the domain name is\n> forthcoming.\n\nMaybe. It is also possible, although IMO not likely, that another\nsort of solution will deploy instead.\n\nNed\n\n\n\n", "id": "lists-007-15340877"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "> >no, they're not.  in all current mail standards email addresses must\n> >be entirely in ASCII.\n> \n> well, we can be a bit friendlier to the topic, I think.  \n\nI thought a succinct, complete, and accurate answer was the friendliest\npossible.\n\n> Only ASCII\n> \"characters\" are permitted, however there is a standard that permits\n> encoding international characters into an ASCII form.\n\nonly in human-readable text.  not in email addresses. \n\nKeith\n\n\n\n", "id": "lists-007-15349950"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "The discussion thus far has employed terms like \"address\" and \"domain\".\n\nIn general, sendmail (a MTA with a modest deployment) is 8-bit encoding \nindifferent.\nThe only interesting issue is can sendmail handle 8-bit headers?\n\nCurrently, the answer is \"no\".\n\nThe IETF has not yet scheduled a transition plan to 8-bit clean header \nprocessing,\nnor an EHLO extension specification and a way to do 8->7 bit encoding when \nsending\nto a system that didn't announce the extension.\n\n[My thanks to the private correspondent, however any errors or omissions \nare mine,\nor artifacts of a bogus MUA].\n\nEric\n\nAt 6/27/01 11:57 AM, John Harrison wrote:\n>Hello,\n>\n>I'm researching an issue regarding whether international characters are\n>allowed in email addresses. Through the research that I've conducted thus\n>far I've seen contradictory information.\n>\n>In looking at RFC-822 it only specifies ASCII characters being allowed,\n>however I have actually seen a few email addresses that do in fact have\n>international characters in them. For example, jos?.berm?dez@xxxxxx.com --\n>note the accented 'e' and 'u'.\n>\n>If anyone has any more definitive information regarding what is and what is\n>not supported in respect to international characters in email addresses, I\n>would be greatly appreciative.\n>\n>Thanks in advance.\n>\n>Regards,\n>John\n>\n>__________________________________________\n>John Harrison\n>@Once, Director of Product Management\n>309 SW 6th Avenue, Suite 900, Portland, OR 97204\n>direct: 503.419.0552 / cell: 503.804.2161\n>main: 503.241/4185 / fax: 503.241.4279\n>email: jharrison@once.com\n\n\n\n", "id": "lists-007-15358851"}, {"subject": "RE: Are international characters allowed in email addresses", "content": "Thanks everyone for your assistance today. The level of detail in the\nresponses has been very much appreciated!\n\n-John\n\n-----Original Message-----\nFrom: Eric Brunner-Williams [mailto:wampum@maine.rr.com]\nSent: Wednesday, June 27, 2001 4:47 PM\nTo: John Harrison; 'discuss@apps.ietf.org'\nSubject: Re: Are international characters allowed in email addresses?\n\n\nThe discussion thus far has employed terms like \"address\" and \"domain\".\n\nIn general, sendmail (a MTA with a modest deployment) is 8-bit encoding \nindifferent.\nThe only interesting issue is can sendmail handle 8-bit headers?\n\nCurrently, the answer is \"no\".\n\nThe IETF has not yet scheduled a transition plan to 8-bit clean header \nprocessing,\nnor an EHLO extension specification and a way to do 8->7 bit encoding when \nsending\nto a system that didn't announce the extension.\n\n[My thanks to the private correspondent, however any errors or omissions \nare mine,\nor artifacts of a bogus MUA].\n\nEric\n\nAt 6/27/01 11:57 AM, John Harrison wrote:\n>Hello,\n>\n>I'm researching an issue regarding whether international characters are\n>allowed in email addresses. Through the research that I've conducted thus\n>far I've seen contradictory information.\n>\n>In looking at RFC-822 it only specifies ASCII characters being allowed,\n>however I have actually seen a few email addresses that do in fact have\n>international characters in them. For example, jos?.berm?dez@xxxxxx.com --\n>note the accented 'e' and 'u'.\n>\n>If anyone has any more definitive information regarding what is and what is\n>not supported in respect to international characters in email addresses, I\n>would be greatly appreciative.\n>\n>Thanks in advance.\n>\n>Regards,\n>John\n>\n>__________________________________________\n>John Harrison\n>@Once, Director of Product Management\n>309 SW 6th Avenue, Suite 900, Portland, OR 97204\n>direct: 503.419.0552 / cell: 503.804.2161\n>main: 503.241/4185 / fax: 503.241.4279\n>email: jharrison@once.com\n\n\n\n", "id": "lists-007-15369311"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "> The only interesting issue is can sendmail handle 8-bit headers?\n\nno, that's not the only interesting issue.  not by a longshot.\n\n\n\n", "id": "lists-007-15380840"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "What other parts of sendmail have sub-8-bit-semantics?\n\n  At 6/28/01 12:24 AM, Keith Moore wrote:\n> > The only interesting issue is can sendmail handle 8-bit headers?\n>\n>no, that's not the only interesting issue.  not by a longshot.\n\n\n\n", "id": "lists-007-15389361"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "> What other parts of sendmail have sub-8-bit-semantics?\n\nnope, you're missing the boat entirely.\n\nthe point is that you need a lot more than 8-bit cleanliness\nto support 8-bit email addresses.\n\nto argue the other way is both naive and irresponsible.\n\n\n\n", "id": "lists-007-15398158"}, {"subject": "Where is Content-language defined these days", "content": "As far as I can tell, the most recent document defining the \nContent-language header is RFC1766.  But, according to the RFC index:\n\n1766 Tags for the Identification of Languages. H. Alvestrand. March\n      1995. (Format: TXT=16966 bytes) (Obsoleted by RFC3066) (Status:\n      PROPOSED STANDARD)\n\nBut RFC3066 says nothing about Content-language, other than it being moved \nto another document.  I have failed to discover what other document.\n\n#g\n\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-15407116"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c  ollectio", "content": "If you've deleted the version history, you have effectively\ntrashed any historical references (e.g. in collection versions)\nto that version history.  If you are going to let that deletion\nhappen even when there is a VCR for that version history in\nsome workspace, I don't see that it makes any sense to worry\nabout whether or not the collection containing that VCR is\nchecked in or checked out.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Friday, June 28, 2002 8:59 AM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: error condition for delete of VHR when VCR is in checked-in\nc ollection\n\n\nGeoff,\n\ndid you possibly miss the part about the collection \"/a\" being checked-in?\nOtherwise this sounds as if deleting the VHR may have the side effect of\nun-version-controlling a resource which is member of a version-controlled\nchecked-in collection...\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, June 28, 2002 2:43 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: error condition for delete of VHR when VCR is in checked-in\n> c ollection\n>\n>\n>\n> If you are going to allow deletion of version histories, your best\n> bet is to \"clean up\" (at least, from the protocol perspective).\n> This means you should remove all references (or act as if you have\n> removed all references) to /vhr/123.  In particular, you would remove\n> references from the version-controlled-binding-set of any collection\n> version.  The result is that from the perspective of /a, there no longer\n> is a version-controlled binding to /a/b, so /a/b is just a\n> non-version-controlled member from /a's perspective (i.e. no error).\n>\n> Cheers,\n> Geoff\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    considering:\n>\n>    - a versioned controlled checked-in collection /a\n>    - a version controlled resource /a/b with a version history resource of\n>    /vhr/123\n>    - a server that handles deletion of version histories as request to\n>    un-version-control the VCR\n>\n>    What should happen upon a DELETE on /vhr/123?\n>\n>    - this would be considered to change the state of /a/b from being\n>    version-controlled to not being version-controlled, however the parent\n>    collection isn't checked out\n>\n>    - returning Conflict with error condition\n>    DAV:cannot-modify-checked-in-parent seems to be a valid\n> approach, however\n>    doesn't fit optimally (because the request was sent to /vhr/123, and /a\n> --\n>    which causes the error as not bein checked out -- isn't a parent\n> collection\n>    of the request URI).\n>\n>\n\n\n\n", "id": "lists-007-1541127"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "Well thanks for the boost Keith, I can put that next to my James Seng\n(idn@ops.ietf.org) note comparing me to Jeff Williams and depositing my\naddress in his killfile, or my Gordon Cook (nanog@merit.edu) note also\ndepositing my address in his killfile after discoursing on my ancestry\nor ...\n\nDo you have anything other than attitude to share concerning the\nrequirements for header processing? Concerning an implementation\nof (sendmail) the requirements for header processing? Concering MTAs\ngenerally and 8-bit processing?\n\nDo you have anything other than attitude to share concerning the\nprocess for making progress upon a set of problems Leslie suggested\nin rfc2825?\n\nThere really has to be more to list interaction than pissing distance\ncontests, and so much, much more to seniority and experience than\nshallow curmudgeonery.\n\nIn November of 1981, five years before I got to the point of reading\nthe work-product of the IETF, Jon wrote during an earlier moment of\nprofound change that:\n\n   As with all new systems, there will be some aspects which are not as \n   robust and efficient as we would like (just as with the initial\n   ARPANET).  But with your help, these problems can be solved and we  \n   can move into an environment with significantly broader communication\n   services.\n\nI _know_ who Jon was addressing, who he expected to help, it was who we\nwere then, and now.\n\nPut the \"you are an idiot\" in all of its vitriolic variations in private\nmail, or in discuss@apps.ietf.org, but _please_ put technical content in\ndiscuss@apps.ietf.org -- the subject might be more important than anyone's\nego or claim-2-clue.\n\nCheers,\nEric\n\n\n\n", "id": "lists-007-15415455"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "> Do you have anything other than attitude to share concerning the\n> requirements for header processing? \n\nyes.  but there's lots of material about it, I'm tired of writing\nsuch things over and over, mail experts will already be aware of \nthe issues (or if not, can figure it out with a moment's thought), \nand you've been in the IDN discussion so you should also be familiar \nwith those issues.\n\nso I'm not going to waste my time trying to re-familiarize you with\nthem. \n\nKeith\n\n\n\n", "id": "lists-007-15426390"}, {"subject": "Re: Where is Content-language defined these days", "content": "> As far as I can tell, the most recent document defining the\n> Content-language header is RFC1766.  But, according to the RFC index:\n\n> 1766 Tags for the Identification of Languages. H. Alvestrand. March\n>       1995. (Format: TXT=16966 bytes) (Obsoleted by RFC3066) (Status:\n>       PROPOSED STANDARD)\n\n> But RFC3066 says nothing about Content-language, other than it being moved\n> to another document.  I have failed to discover what other document.\n\ndraft-alvestrand-content-language-02.txt.\n\nNed\n\n\n\n", "id": "lists-007-15435391"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "--On 01-06-28 10.15 -0400 Eric Brunner-Williams in Portland Maine\n<brunner@nic-naa.net> wrote:\n\n> Concerning an implementation\n> of (sendmail) the requirements for header processing? Concering MTAs\n> generally and 8-bit processing?\n\nYou at least need to either agree on a charset to use, or negotiation of\ncharset. Compare MIME spec with current IDN discussions. And, 8 bits are\nnot enough today for many charsets (including UTF-8).\n\n paf\n\nPatrik F?ltstr?m <paf@cisco.com>                         Cisco Systems\nConsulting Engineer                                  Office of the CSO\nPhone: (Stockholm) +46-8-6859131            (San Jose) +1-408-525-8509\n        PGP: 2DFC AAF6 16F0 F276 7843  2DC1 BC79 51D9 7D25 B8DC\n\n\n\n", "id": "lists-007-15443611"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "...\n> and you've been in the IDN discussion so you should also be familiar \n> with those issues.\n\nThe IDN discussion has produced a requirements memo that states, inter\nalia, that\n\nThe intended scope of this document is to explore requirements\nfor the internationalization of domain names ...\n\nThis isn't header processing, and it isn't 8-bit clean processing, and\nthe use of \"internationalization\" here differs fundamentally from industry\nand academic i18n usages.\n\nIn the same statement of scope, the requirements memo even constains\na recommendation, viz,\n\nIt is recommended that solutions not necessarily be within the\nDNS itself, but could be a layer interjected between the\napplication and the DNS.\n\nThis is somewhat unique to the IDN WG's Requirements Draft editors, a\nrecommendation in lieu of a, and before, a requirement.\n\nIt is within reason that Apps area ADs, former and current, could want to\nsolve a problem which could be stated as infrastructural, or as application\nspecific, in the latter form.\n\nIt is within reason that the application-specific problem statement is not\nthe unique means to identify the mechanism or set of mechanisms which form\na solvable problem.\n\nThe majority of the IDN poll participants have expressed some form of\ninterest in an application solution for extending the set of 63 (only\n37 unique) values available for composing dns labels. These all involve\nencoding a larger set of values on the unchanged (though tagged) set of\n63 (or 37) values, and some heuristics about the larger set of values.\nThere are the predicable distractions when someone mentions \"language\"\nor \"script\" or \"search\" or \"friendly\" or ... but these are distractions,\nthe only dns issue is the label space, 4-bits-plus-5, or greater.\n\nThat doesn't make the proposal correct or best or anything but one with\nsome interest (mine included, but not in an exhaustive \"ACE ONLY\" context).\nIt does suggest that the discourse on the issue could be improved by moving\nthe WG into the Apps Area, since its co-chairs, requirements editors, and\nmore popular proposals favor application-specific mechanisms.\n\nIn a nutshell, the discussion of 8-bit transparency, in SMTP, or in any\nother part of the problem space, in the IDN list, has been a little less\nthan professional.\n\nThis isn't about Eric's time or Keith's, availability or valuation.\n\nCheers,\nEric\n\n\n\n", "id": "lists-007-15453273"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "> > and you've been in the IDN discussion so you should also be familiar\n> > with those issues.\n> \n> The IDN discussion has produced a requirements memo that states, inter\n> alia, that\n\nthe IDN requirements memo is irrelevant.  the discussions on the IDN \nlist have repeatedly focused on the problems of names in multiple\ncharacter sets, translation of those names to a common format, \ncanonicalization of those names, encoding of those names in ASCII to \nmake them safe for existing applications, comparison of those names,\netc.  the notion that an application that actually uses domain names\nas protocol elements can be fixed by simply making it 8bit clean has \nbeen soundly and repeatedly refuted.\n\nthe issues for email addresses are not identical, but are quite similar.\nI'm sure they will be revisited in due time by applications area groups, \nbut that time is after the IDN group has finished its work.\nwe'll have to have those discussions then anyway, just to bring everybody\nup to speed.  so there's no sense in our having them now.  folks who\nare interested are welcome to read the IDN list archives or join that\ndiscussion.\n\nKeith\n\n\n\n", "id": "lists-007-15464424"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "Patrik, (non-AD hat noted)\n\n> You at least need to either agree on a charset to use, or negotiation of\n> charset. Compare MIME spec with current IDN discussions. And, 8 bits are\n> not enough today for many charsets (including UTF-8).\n\nOr use unknown-8bit (RFC 1428 section 3).\n\nI honestly don't know how to compare anything useful with \"current IDN\ndiscussions\", the list is all over the place, anything other than ACE\nis as popular as djb-advocacy on namedroppers, with my-dog-is-bigger\nbehavior the norm, and periodically a \"technical advisor\" blows by with\nhelpful notes of the form \"it-can't-be-solved-use-ldap\".\n\nThank heavens we didn't decide we simply had to add \"+\" to the set of\ncharacters we use for names, or authoritative root would be divided into\nmonotheists (of the negative, or \"hypenated\" form) and +/- dualists by\nsundown.\n\nI don't get the point of your final sentence.\n\nEric Brunner+/-Williams\narchitect, utf8-based code-set independence, solaris, 1995\nimplementor, utf8-based code-set independence, hpux, 1996\n\nQuoting myself (headers), before Keith's commentary on my comment.\n> The discussion thus far has employed terms like \"address\" and \"domain\".\n> \n> In general, sendmail (a MTA with a modest deployment) is 8-bit encoding \n> indifferent. The only interesting issue is can sendmail handle 8-bit headers?\n> \n> Currently, the answer is \"no\".\n> \n> The IETF has not yet scheduled a transition plan to 8-bit clean header \n> processing, nor an EHLO extension specification and a way to do 8->7 bit\n> encoding when sending to a system that didn't announce the extension.\n\n\n\n", "id": "lists-007-15474106"}, {"subject": "Re: Are international characters allowed in email addresses", "content": ">etc.  the notion that an application that actually uses domain names\n>as protocol elements can be fixed by simply making it 8bit clean has\n>been soundly and repeatedly refuted.\n\nWas that claim ever offered by anyone? As rhetoric it may suffice to\npreclude work clearly identified in rfc2825 and elsewhere, but rhetoric\nisn't a substitute for a restatement of the problem as infrastructural.\n\nAs Fred Baker remarked when opening his for-and-against discussion\n(unique dns root) with Karl Auerbach at the ISOC-MINC Workshop in\nStockholm earlier this month, unfortunate rhetoric drives discourse to\nless than productive ends.\n\nI do make the claim that there are several places where sub-8-bit\nprocessing takes place, e.g., sendmail header processing, and each\ncan be fixed, e.g., 8-bit clean plus a transition mechanism (EHLO) for\n8-to-7 down-conversion, as well as dns label processing. These can\nbe viewed as \"infrastructure\" or as \"applications\".\n\nCan you suggest how these two statements can be reconcilled?\n1. the IDN requirements memo is irrelevant.\nand\n2. the issues ... will be revisited in due time ... but that time is after the\nIDN group has finished its work.\n\nRequirements Considered Optional is not something I look forward to.\n\nEric\n\nAt 6/28/01 01:05 PM, Keith Moore wrote:\n> > > and you've been in the IDN discussion so you should also be familiar\n> > > with those issues.\n> >\n> > The IDN discussion has produced a requirements memo that states, inter\n> > alia, that\n>\n>the IDN requirements memo is irrelevant.  the discussions on the IDN\n>list have repeatedly focused on the problems of names in multiple\n>character sets, translation of those names to a common format,\n>canonicalization of those names, encoding of those names in ASCII to\n>make them safe for existing applications, comparison of those names,\n>etc.  the notion that an application that actually uses domain names\n>as protocol elements can be fixed by simply making it 8bit clean has\n>been soundly and repeatedly refuted.\n>\n>the issues for email addresses are not identical, but are quite similar.\n>I'm sure they will be revisited in due time by applications area groups,\n>but that time is after the IDN group has finished its work.\n>we'll have to have those discussions then anyway, just to bring everybody\n>up to speed.  so there's no sense in our having them now.  folks who\n>are interested are welcome to read the IDN list archives or join that\n>discussion.\n>\n>Keith\n\n\n\n", "id": "lists-007-15484857"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "Eric,\n\nyou are making no sense at all, and I refuse to waste my time trying\nto get you to make sense.\n\nKeith\n\n\n\n", "id": "lists-007-15496057"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "--On 01-06-28 13.18 -0400 Eric Brunner-Williams in Portland Maine\n<brunner@nic-naa.net> wrote:\n\n> I don't get the point of your final sentence.\n\nQuite a number of charsets (including UTF-8) use more than 8 bit per\ncharacter. Because of that, the protocol and the applications which use a\ntextual based protocol need to operate on characters, and not 8-bit blocks,\nand because of this understand the (variable?) size of a character.\n\nThis is one of the reasons why the encoding MIME uses works well for\n\"comments\" but very badly for other data in headers in email messages.\n\n   paf\n\n\n\n", "id": "lists-007-15504576"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "Sigh. Back to the level we started at.\n\nWas it:\n         a) observing that the problem may be viewed as infrastructural?\n         b) discussion of header processing and EHLO?\n         c) paraphrasing Fred?\n         d) asking for an explanation of two phrases?\n\nA letter will suffice and I can pay you for your time.\n\nEric\n  At 6/28/01 02:09 PM, Keith Moore wrote:\n>Eric,\n>\n>you are making no sense at all, and I refuse to waste my time trying\n>to get you to make sense.\n>\n>Keith\n\n\n\n", "id": "lists-007-15514341"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "Patrik,\n\nSo the point of your comment is that you think I need to know this fact.\n\nOK. If I didn't know it previously, say at any time since 1988, I know it\nnow. I know I knew it then, the 8859-*/2022 mess was so close to being\nreal I almost had to stuff it or its premature antecedent into X/Open's\nfirst UNIX standard. A chararacter != a byte.\n\nNow if we were having a discussion about process vs file encodings,\nas OS implementors (which only one of us is, to my knowledge), then\nwe could segue tothe sub-7-bit processing model of some application(s),\nand the multi-byte processing model of some (other) application(s), their\nfile encoding requirements, and our (the OS weenies owning the bottom-\nhalf-of-the-tty display-width problem, the lib{c,mb,w} APIs, collation orders,\netc.) studied indifference to these application-specific ephemera.\n\nWe could marvel that some apps dorks were imposing a 6-bit-minus-one\ncode-space restriction on an 8-bit organized i/o and memory system [1],\nor a must-be-stateless octet processing semantic as the sole means of\ngetting a more-than-8-bit code-space on an 8-bit memory type.\n\nHaving done the ASCII-to-UTF-8 transformation twice in two similar host\nsource bases (solaris and hpux) and knowing how the equivalent work\nwas done in some other hosts (aix, same for all intents and purposes), I'm\nreally at a loss to understand something here.\n\nEric\n[1] rfc761 (tcp) and rfc768 (udp) are 8-bit transparent transport protocols.\n\nAt 6/28/01 11:11 AM, Patrik F?ltstr?m wrote:\n>--On 01-06-28 13.18 -0400 Eric Brunner-Williams in Portland Maine\n><brunner@nic-naa.net> wrote:\n>\n> > I don't get the point of your final sentence.\n>\n>Quite a number of charsets (including UTF-8) use more than 8 bit per\n>character. Because of that, the protocol and the applications which use a\n>textual based protocol need to operate on characters, and not 8-bit blocks,\n>and because of this understand the (variable?) size of a character.\n>\n>This is one of the reasons why the encoding MIME uses works well for\n>\"comments\" but very badly for other data in headers in email messages.\n>\n>    paf\n\n\n\n", "id": "lists-007-15523203"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "> > Do you have anything other than attitude to share concerning the\n> > requirements for header processing?\n\n> yes.  but there's lots of material about it, I'm tired of writing\n> such things over and over, mail experts will already be aware of\n> the issues (or if not, can figure it out with a moment's thought),\n> and you've been in the IDN discussion so you should also be familiar\n> with those issues.\n\n> so I'm not going to waste my time trying to re-familiarize you with\n> them.\n\nKeith, I could not agree more. Mail experts are already well aware of the\nissues and have discussed them over and over and over. Now is not the time to\nrepeat all that.\n\nAdditionally, internationalization of message headers started with RFC 1342/RFC\n1522/RFC 2047 and continues with internationalization of domains, and\ninternationalization of domains is being done by the IDN WG. Any issues you\nhave with the work that's underway need to be discussed on the IDN mailing\nlist, not on the apps area list or the ietf-822 list.\n\nIt is vital that people interested in the internationalization of message\nheaders focus first on domains so we get the right solution in that space,\nsince any more general solution has to take the work done for domains into\naccount. And as I've said before, while I think some of the more radical IDN\nproposals aren't likely to be adopted, if they are they will change the\ncharacter of the message header problem completely, so until it is clear which\nway the wind is blowing it is very foolish to start in on message headers.\n\nAnd if anyone is just getting started on this whole topic, you really need to\nread the IDN requirements draft and review the list traffic before jumping in\nwith a topic that more likely than not has already been discussed past the\npoint of exhaustion in that forum.\n\nNed\n\n\n\n", "id": "lists-007-15534661"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c  ollectio", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, June 28, 2002 3:18 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: error condition for delete of VHR when VCR is in checked-in\n> c ollection\n>\n>\n>\n> If you've deleted the version history, you have effectively\n> trashed any historical references (e.g. in collection versions)\n> to that version history.  If you are going to let that deletion\n\nNope. I have deleted the binding to the version history, not necessarily the\ninformation itself. In particular, my server may be able to reconstruct it\nupon UNCHECKOUT of the versioned collection \"/a\" (using the same URI).\n\n> happen even when there is a VCR for that version history in\n> some workspace, I don't see that it makes any sense to worry\n> about whether or not the collection containing that VCR is\n> checked in or checked out.\n\nThe issue is that RFC3253 doesn't define a method to switch off version\ncontrol on a resource, and therefore people are using deletion on VHRs to\nswitch off versioning (I couldn't find any mention of this in the spec,\nthough). This conflates to separate things, but there doesn't seem to be\nbetter way to do it (please don't say COPY/DELETE/MOVE, because this creates\na *new* resource).\n\n\n\n", "id": "lists-007-1553730"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "Ned,\n\nGoing back to Mr. Harrison's original question, could you offer him a\nsensible answer that made a contrary assertion to the one I made, and\nKeith took exception to, and explain that no header processing issues\nare involved, only \"domain\" and \"address\" issues?\n\nSince I have been participating in the IDN list most of this year, your\nclosing para(s) were for someone else's benefit, right? You did read\nKeith's comment that the IDN requirements draft is irrelevant, so as\nyou both agree with Keith completely _and_ recommend people read\nthe requirements draft, your point is ... what?\n\nThis is heading towards interesting territory -- don't use apps, don't\nuse 822, don't use ... and don't complain about IDN.\n\nNot what I expected.\n\nEric\n\nAt 6/28/01 02:00 PM, ned.freed@mrochek.com wrote:\n> > > Do you have anything other than attitude to share concerning the\n> > > requirements for header processing?\n>\n> > yes.  but there's lots of material about it, I'm tired of writing\n> > such things over and over, mail experts will already be aware of\n> > the issues (or if not, can figure it out with a moment's thought),\n> > and you've been in the IDN discussion so you should also be familiar\n> > with those issues.\n>\n> > so I'm not going to waste my time trying to re-familiarize you with\n> > them.\n>\n>Keith, I could not agree more. Mail experts are already well aware of the\n>issues and have discussed them over and over and over. Now is not the time to\n>repeat all that.\n>\n>Additionally, internationalization of message headers started with RFC \n>1342/RFC\n>1522/RFC 2047 and continues with internationalization of domains, and\n>internationalization of domains is being done by the IDN WG. Any issues you\n>have with the work that's underway need to be discussed on the IDN mailing\n>list, not on the apps area list or the ietf-822 list.\n>\n>It is vital that people interested in the internationalization of message\n>headers focus first on domains so we get the right solution in that space,\n>since any more general solution has to take the work done for domains into\n>account. And as I've said before, while I think some of the more radical IDN\n>proposals aren't likely to be adopted, if they are they will change the\n>character of the message header problem completely, so until it is clear which\n>way the wind is blowing it is very foolish to start in on message headers.\n>\n>And if anyone is just getting started on this whole topic, you really need to\n>read the IDN requirements draft and review the list traffic before jumping in\n>with a topic that more likely than not has already been discussed past the\n>point of exhaustion in that forum.\n>\n>                                 Ned\n\n\n\n", "id": "lists-007-15545335"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "> Going back to Mr. Harrison's original question, could you offer him a\n> sensible answer that made a contrary assertion to the one I made, and\n> Keith took exception to, and explain that no header processing issues\n> are involved, only \"domain\" and \"address\" issues?\n\nIn other words, you want me to argue Keith's points for him. Thanks but no\nthanks.\n\nFor my part I never said that \"no header processing issues are involved\". What\nI did say is that until it is clear what direction IDN is going we cannot work\nusefully on things like \"header processing issues\". For all we know at this\npoint we'll end up with some directory solution layred on top of existing\nservices that argues strongly for something akin to X.400's\nORAddressAndDirectoryName construct. (And no, I'm not saying that I think such\nan outcome is likely or that it appeals to me. All I'm saying is that anything\nis possible at this point.)\n\n> Since I have been participating in the IDN list most of this year, your\n> closing para(s) were for someone else's benefit, right? You did read\n> Keith's comment that the IDN requirements draft is irrelevant, so as\n> you both agree with Keith completely _and_ recommend people read\n> the requirements draft, your point is ... what?\n\nEric, this is flummery and you know it. Shame on you. I responded to one\nmessage of Keith's by saying I agreed with everything he said in it. Then Keith\nsaid in a separate, subsequent message that he believes the IDN requirements\ndraft is irrelevant. Agreeing with what Keith said in one message doesn't mean\nthat I agree with everything he says in subsequent messages. The very notion\nthat this would be so is absurd.\n\n> This is heading towards interesting territory -- don't use apps, don't\n> use 822, don't use ... and don't complain about IDN.\n\n> Not what I expected.\n\nI have no idea what your expectations are, and after what you said in this\nmessage, I frankly don't care.\n\nEven if I were interested in discussing header processing issues at this\npoint (I'm not), it is now clear that you have no intention in engaging in\na sensible or reasonable discussion. So as far as I'm concerned this\ndiscussion is now terminated.\n\nNed\n\n\n\n", "id": "lists-007-15557164"}, {"subject": "Re: Are international characters allowed in email addresses", "content": "Ned,\n\nI accept that you belive that I act in bad faith. I don't seek to change\nyour beliefs.\n\nI don't understand that something as central to the purpose and process\nof a working group as its requirements gathering can be both irrelevant\nand recommended reading.\n\nI don't think Mr. Harrison was asking a question that shouldn't have been\nasked in discuss@apps.ietf.org. I don't think discussing the underlying\nbyte processing is uninteresting, or something that should not have been\nmade in discuss@apps.ietf.org. At Minneapolis (previous time) the Apps\nOpen meeting resulted in a (very) modest attempt to ask or even answer\nsome common architectural problems in the Apps area. You should recall\nthis, you were present.\n\nHaving done two i18n OS upgrades, which touched everything from sort to\nsccs to csh and ksh in apps, and lib{c,w} in the system libraries, and \nthe locale definitions, and display width in the tty subsystem, from an\nexplicit ASCII and an explicit ASCII+HP15 process and file encoding to a\ncode set independent (implicit UTF-8) process and file encoding, I'm not\nseeing the width and depth of engineering experience on this problem now\nin the IDN WG. It isn't present in Keith alone, or you alone, or both of\nyou together.\n\nI don't understand that something as broadly consequental as implicit\n(and subsetted) ASCII can't be discussed except in a working group with\nutterly asbysmal process and progress, and where things need fixing.\nI can understand that over the past year the IETF has become a meaner,\neven nastier milieu in which to attempt to work. I hope it is a local\nproblem.\n\nAs to my expectations, they are that technical discussion prevail. Having\nsome experience designing and implementing system-wide expansions of the\nbase character handling from ASCII to a larger range of functionality, I\nam at a loss to understand the uncivil, even abusive, conduct that passes\nfrequently without comment when the issue of i18n arises in an IETF context.\n2026, 2282, ...\n\nIt isn't necessary to conclude anything about dns labels (see bcp42) to\nlook at the utility for changing sendmail.\n\nKeith's note was previous, not subsequent.\n\n> Even if I were interested in discussing header processing issues at this\n> point (I'm not), it is now clear that you have no intention in engaging in\n> a sensible or reasonable discussion. So as far as I'm concerned this\n> discussion is now terminated.\n\nYes, an end has been reached. I am glad I didn't write that paragraph.\n\nEric\n\n\n\n", "id": "lists-007-15568314"}, {"subject": "Re: Where is Content-language defined these days", "content": "Graham - Harald is working on that document. Draft at\nhttp://www.ietf.org/internet-drafts/draft-alvestrand-content-language-02.txt\n\n\nRegards,   Martin.\n\nAt 14:12 01/06/28 +0100, Graham Klyne wrote:\n>As far as I can tell, the most recent document defining the \n>Content-language header is RFC1766.  But, according to the RFC index:\n>\n>1766 Tags for the Identification of Languages. H. Alvestrand. March\n>      1995. (Format: TXT=16966 bytes) (Obsoleted by RFC3066) (Status:\n>      PROPOSED STANDARD)\n>\n>But RFC3066 says nothing about Content-language, other than it being moved \n>to another document.  I have failed to discover what other document.\n>\n>#g\n>\n>\n>------------\n>Graham Klyne\n>(GK@ACM.ORG)\n>\n\n\n\n", "id": "lists-007-15579262"}, {"subject": "Humidity &amp; moisture problems in Hi-Tech industr", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-15587983"}, {"subject": "Re: Bankruptcy", "content": "I have been trying to find a site that will explain how to file for personal \nbankruptcy without an attorney.  Can you help me out?\nMy Mother has terminal cancer, can no longer work, gets only SS, and her \nmonthly obligations are 3 times that amt., but she needs to keep her car for \ntransportation to and from hospital, etc..\n\nAny info you could send me would be greatly appreciated.\n\nS. Guthrie\n\n\n\n", "id": "lists-007-15594485"}, {"subject": "resource-types of working resources/collection", "content": "Hi,\nThe specification does not give clarity on the resource type for\nworking-resources and working-collections. My guess is that it does not\nintroduce any new resource types (just as it does not for VCRs and\nversions). If this is so, then I think this should be explicitly mentioned.\n\nThanx,\nGirish\n\n\n\n", "id": "lists-007-1563989"}, {"subject": "Recognizing search engine spider", "content": "Is there any standard which search engines use when sending\nHTTP requests during spidering, in order to tell the\nreceipient HTTP server that they are search engines.\n\nI can see multiple uses of this. In our particular case,\nwe sometimes intentionally create slightly varying URLs\nof the same document, in order to stop an old version\nin the cache to be used. (Yes, I know there are cache\ncontrol standards, but they do not seem to work in all\ncases.) This might mean that a search engine would\nstore multiple copies of nearly the same document,\nand would not recognize that a new version replaces an\nold version of the same document.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-15658397"}, {"subject": "Re: Recognizing search engine spider", "content": "On Sat, Mar 03, 2001 at 10:31:02AM +0100, Jacob Palme wrote:\n> Is there any standard which search engines use when sending\n> HTTP requests during spidering, in order to tell the\n> receipient HTTP server that they are search engines.\n\nNo. Some try to use a heuristic, with varying success (the big ones\nare pretty easy to get).\n\n> I can see multiple uses of this. In our particular case,\n> we sometimes intentionally create slightly varying URLs\n> of the same document, in order to stop an old version\n> in the cache to be used. (Yes, I know there are cache\n> control standards, but they do not seem to work in all\n> cases.) This might mean that a search engine would\n> store multiple copies of nearly the same document,\n> and would not recognize that a new version replaces an\n> old version of the same document.\n\nThere are ways to assure cache freshness. See\n  http://www.mnot.net/cache_docs/\nIf that isn't good enough, vary the reference's query string, most\nsearch engines will understand.\n\nAlso, you might try using robots.txt to shape which documents will be\nfetched.\n\n\n-- \nMark Nottingham, Research Scientist\nAkamai Technologies (San Mateo, CA USA)\n\n\n\n", "id": "lists-007-15665869"}, {"subject": "Re: Recognizing search engine spider", "content": "At 08.56 -0800 01-03-03, Mark Nottingham wrote:\n>There are ways to assure cache freshness. See\n>   http://www.mnot.net/cache_docs/\n>If that isn't good enough, vary the reference's query string, most\n>search engines will understand.\n\nAfter experimentation, we found the best success with\nadding \";12345678, where 12345678 is a number which\nchanges every time the document is modified, at\nthe end of those URLs which refer to pages which are\nfrequently updated.\n\nYou can look at for example http://salut.nu/forum/uno/2/\nto see how our pages look like. If you click on a\nlink in those pages, \";12345678\" with a new\nnumber is added at the end of most of the pages\nwhenever the page is changed, in order to avoid\nusers getting old, cached versions of the document\nthey ask for.\n\nBut the document you referenced might teach us a method\nof avoiding stale pages to user without adding ;12345678\nat the end of our URLs. It seems like a very comprehensive\ntutorial on how to get your documents to be handled correctly\nby caches.\n\n>Also, you might try using robots.txt to shape which documents will be\n>fetched.\n\nAt present we are also using robots.txt to suppress\nsearch engines. Some of our content might however\nbe suitable for search engines, and then we must\nensure that we do not send the \";12345\" URL-s to\nthem, because this would cause them to store\nmultiple references to almost the same document\n(something which already is a big problem for\nsearch engine implementors), and which all would\nin reality refer users to the same document.\n\nI can guess that a standard method of recognizing\nwhen a HTTP client is a search engine might be\ncontroversial, since spammers would of course be\nvery happy to be able to deliver different content\nto search engines than to ordinary users in order\nto pull users to their sites. But they probably\nalready have learned to do that using various\nheuristics, as you suggest.\n\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-15674366"}, {"subject": "Personal notes from the Minneapolis meetin", "content": "My personal notes from the IETF meeting in Minneapolis\nlast week can be found at\n\nhttp://dsv.su.se/jpalme/ietf/ietf-mar-01-notes.html\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-15683362"}, {"subject": "RE: MP4 Player Available for Downloa", "content": "I've hesitated from joining this conversation because it was pointed out \nthat it's \"off-topic\".  Since everyone has been dying to get the last word \nin on this thread, and since I do think this is an important discussion to \nhave, I'm requesting that we move it to the Apps area discussion list \nrather than end the thread altogether (hence the addition of \n\"discuss@apps.ietf.org\" to the cc line...please send followups to this \nalias instead of rem-conf).\n\nFor those in the apps area, a brief introduction.  Someone posted a note to \nrem-conf (the IETF AVT working group mail alias) on the topic of two \nplayers that support the \".mp4\" file extension which don't \ninteroperate.  The discussion turned toward the issue of whether or not \ngenuine interoperability is possible, due to patent licensing restrictions, \nto which several people made statements to the effect of \"oh, that's just a \nred herring\".\n\nWell, I disagree.  MPEG-4 licensing is still very murky.  Here's the \nstatement in the M4IF FAQ (see http://www.m4if.org):\n\n     Based on the information that M4IF has received, the situation\n     is as follows:\n\n     MPEG-4 Systems: A call for essential patents was issued at the\n     beginning of September. Licensing is expected to start in\n     Spring 2001, and should encompass all of MPEG-4 version 1 and\n     version 2 technology\n\n     MPEG-4 Visual: portfolios are under development for the Simple\n     and Core Visual Profiles. Patents are currently being evaluated,\n     and a meeting will be called in October. It is expected that\n     licensing will begin in the beginning of 2001.\n\n     MPEG-4 Audio: A Call for essential patents is expected by the\n     end of October. Licensing should start in 2001.  Details are\n     still being worked out.\n\nIn other words, there's still a bunch of people talking in smoke filled \nrooms about what the licensing terms are.  Fine....just don't push this as \na standard that's ready for prime time.\n\nHaving seen the hue and cry in IETF plenary meetings when *one* company \nholds an essential patent, I shudder to think how a discussion of MPEG-4 \nlicensing would play out if done in the IETF, where my understanding is \nthat there are dozens of rights holders involved in the essential \ntechnology.  Perhaps that's why it's never been brought up.....   :)\n\nSo, I'm at a loss.  The MPEG4 group hasn't been very vigilant in ensuring \nthat the technology that they are standardizing is practical to implement, \nfrom a technology perspective or from a business perspective. On the \ntechnology front, the specification is a sprawling set of documents from \nwhich only a small portion is useful for the nuts-and-bolts of \ninteroperability, and even then it's not complete and is still a \nwork-in-progress. On the business side, there are dozens of companies \nclaiming to own intellectual property associated with essential technology \nin the specification, and the group responsible for working out a licensing \npool (the MPEG-4 Industry Forum, M4IF) is long overdue in its attempts to \nwork out the first of many pieces necessary for a complete end-to-end\nsystem.\n\nWould it be useful for the IETF to engage in standardization of audio/video \nfile formats?  If not the IETF, then who?\n\nRob\n\nAt 09:12 AM 3/27/01 +0200, Olivier Avaro wrote:\n>Hi all,\n>\n>For clarification on some questions raised by the original mail from Hari.\n>\n>1- mp4 is the file format of MPEG-4. If you comply to the mp4 spec., you can\n>parse any mp4 stream. The ability to play the stream is another dimension\n>covered by the signaling of the audio, video, graphics and scene description\n>profiles contained in the file.\n>\n>2- Because it would be nice when opening an mp4 file to know what bundles of\n>codecs you need, the mp4 file format contains specific tags to signal this.\n>As decided in the last MPEG meeting, these tags will be in part managed by a\n>registration authority outside MPEG. Industry fora, like ISMA, 3GPP, ... can\n>therefore defined the specific flavor of the MP4 file and signal it in a\n>clean way.\n>\n>3- It's great to see the MPEG-4 wave happening now, with new MPEG-4 products\n>released regularly (and not only audio and video !).Still, I am also\n>concerned about the confusion created when people do not announce to what\n>part of MPEG-4 they comply. It would be interesting to have this information\n>from the technology provider, otherwise the products are pretty useless, and\n>even more, they do not serve neither themselves nor the standard.\n>\n>4- I join Philippe regarding patents issues. I am also surprised by the kind\n>of naive questions raised and therefore am inclined to doubt their true\n>naivity. Quoting Leonardo : \"Of course getting things for free is nice, but\n>wise buyers know that a \"free\" price tag on something that is known to be\n>valuable means that the cost of that particular \"free\" item is just folded\n>into another cost item. The particular cost item that remunerates those who\n>have developed Intellectual Property applies to the MPEG standard solution\n>as much as to a proprietary solution. The fact that there is no explicit\n>price tag for the Intellectual Property of proprietary solutions does not\n>mean there there is no cost associated with it, it just means that it is\n>hidden. And this is not necessarily a good feature for a wise buyer.\". I\n>would add to this that before considering developing another solution,\n>possibly free of IP, maybe wise buyers should consider the cost of doing so,\n>including the extra cost of navigating between the existing patents.\n>\n>Kind regards,\n>\n>Olivier\n>\n> > > >> Flavor Software is proud to release the first commercial\n> > > MPEG-4 player\n> > > >> and authoring software. The Mild Flavor(tm) player and\n> > > sample MP4 files\n> > > >> featuring New York City indi bands \"The Pasties\", \"Brave\n> > > New Girl\", and\n> > > >> \"The Rosenbergs\" are available for download from the\n> > > Flavor Software web\n> > > >> site.\n> > > >>\n> > > >> Go to http://www.flavorsoftware.com and click on downloads.\n> > > >>\n> > > >> Spread the joy... tell your friends to go to the Flavor\n> > > web site and get\n> > > >> into MP4! Even better... create your own MP4 files and\n> > > send them to your\n> > > >> friends!  -- The Flavor Team\n\n\n\n", "id": "lists-007-15690564"}, {"subject": "RE: MP4 Player Available for Downloa", "content": "Dear Colleagues\nI do not know for the IETF email address that appears in Cc:, but as far as\nMPEG is concerned discussions about patents are not allowed by the ISO/IEC\ndirectives.\nI can understand that it may suit some parties to state that \"MPEG-4\nlicensing is still very murky\" and I will make no efforts to convince such\nparties that its is not, for the very simple reason that I do not know\nwhether this is true or not and I do not want to know.\nI will simply point out these two very simple and incontrovertible facts:\n1. the number of MP3 processors (encoders, decoders etc.) can be counted by\nthe tens of millions (at least 60 million Napster users :-)\n2. the number of MPEG-2 processors is well above 100 million (50 million\ndigital television set top boxes, 30 million hardware-based DVDs, 10 million\nPlaystation 2, an unknown number of software DVD decoders, an unknown number\nof DviX converters :-).\nI hear reports that implementation of these two standards requires the use\nof patented technologies (I have been told about 100 patents for MPEG-2).\nIt may suit some parties to run down MPEG-4, but the power of standard\ntechnologies demonstrated by the two cases above stays unchallenged. Patent\nissues may be complex, but so are business decisions for which patents are\njust one element. That is why I am sure that, as for the past, wise people\nwill make wise decisions.\nIn any case, please do not make further discussions about patents on MPEG\nreflectors.\nKind regards\nLeonardo Chiariglione\nConvenor, ISO/IEC JTC1/SC29/WG11 (MPEG)\n\n-----Original Message-----\nFrom: Rob Lanphier [mailto:robla@real.com]\nSent: 2001 marzo venerd? 22:26\nTo: olivier.avaro@francetelecom.com; 'Hari Kalva'; rem-conf@es.net\nCc: gen-sys@advent. ee. columbia. edu (E-mail); discuss@apps.ietf.org\nSubject: RE: MP4 Player Available for Download\n\n\nI've hesitated from joining this conversation because it was pointed out \nthat it's \"off-topic\".  Since everyone has been dying to get the last word \nin on this thread, and since I do think this is an important discussion to \nhave, I'm requesting that we move it to the Apps area discussion list \nrather than end the thread altogether (hence the addition of \n\"discuss@apps.ietf.org\" to the cc line...please send followups to this \nalias instead of rem-conf).\n\nFor those in the apps area, a brief introduction.  Someone posted a note to \nrem-conf (the IETF AVT working group mail alias) on the topic of two \nplayers that support the \".mp4\" file extension which don't \ninteroperate.  The discussion turned toward the issue of whether or not \ngenuine interoperability is possible, due to patent licensing restrictions, \nto which several people made statements to the effect of \"oh, that's just a \nred herring\".\n\nWell, I disagree.  MPEG-4 licensing is still very murky.  Here's the \nstatement in the M4IF FAQ (see http://www.m4if.org):\n\n     Based on the information that M4IF has received, the situation\n     is as follows:\n\n     MPEG-4 Systems: A call for essential patents was issued at the\n     beginning of September. Licensing is expected to start in\n     Spring 2001, and should encompass all of MPEG-4 version 1 and\n     version 2 technology\n\n     MPEG-4 Visual: portfolios are under development for the Simple\n     and Core Visual Profiles. Patents are currently being evaluated,\n     and a meeting will be called in October. It is expected that\n     licensing will begin in the beginning of 2001.\n\n     MPEG-4 Audio: A Call for essential patents is expected by the\n     end of October. Licensing should start in 2001.  Details are\n     still being worked out.\n\nIn other words, there's still a bunch of people talking in smoke filled \nrooms about what the licensing terms are.  Fine....just don't push this as \na standard that's ready for prime time.\n\nHaving seen the hue and cry in IETF plenary meetings when *one* company \nholds an essential patent, I shudder to think how a discussion of MPEG-4 \nlicensing would play out if done in the IETF, where my understanding is \nthat there are dozens of rights holders involved in the essential \ntechnology.  Perhaps that's why it's never been brought up.....   :)\n\nSo, I'm at a loss.  The MPEG4 group hasn't been very vigilant in ensuring \nthat the technology that they are standardizing is practical to implement, \nfrom a technology perspective or from a business perspective. On the \ntechnology front, the specification is a sprawling set of documents from \nwhich only a small portion is useful for the nuts-and-bolts of \ninteroperability, and even then it's not complete and is still a \nwork-in-progress. On the business side, there are dozens of companies \nclaiming to own intellectual property associated with essential technology \nin the specification, and the group responsible for working out a licensing \npool (the MPEG-4 Industry Forum, M4IF) is long overdue in its attempts to \nwork out the first of many pieces necessary for a complete end-to-end\nsystem.\n\nWould it be useful for the IETF to engage in standardization of audio/video \nfile formats?  If not the IETF, then who?\n\nRob\n\nAt 09:12 AM 3/27/01 +0200, Olivier Avaro wrote:\n>Hi all,\n>\n>For clarification on some questions raised by the original mail from Hari.\n>\n>1- mp4 is the file format of MPEG-4. If you comply to the mp4 spec., you\ncan\n>parse any mp4 stream. The ability to play the stream is another dimension\n>covered by the signaling of the audio, video, graphics and scene\ndescription\n>profiles contained in the file.\n>\n>2- Because it would be nice when opening an mp4 file to know what bundles\nof\n>codecs you need, the mp4 file format contains specific tags to signal this.\n>As decided in the last MPEG meeting, these tags will be in part managed by\na\n>registration authority outside MPEG. Industry fora, like ISMA, 3GPP, ...\ncan\n>therefore defined the specific flavor of the MP4 file and signal it in a\n>clean way.\n>\n>3- It's great to see the MPEG-4 wave happening now, with new MPEG-4\nproducts\n>released regularly (and not only audio and video !).Still, I am also\n>concerned about the confusion created when people do not announce to what\n>part of MPEG-4 they comply. It would be interesting to have this\ninformation\n>from the technology provider, otherwise the products are pretty useless,\nand\n>even more, they do not serve neither themselves nor the standard.\n>\n>4- I join Philippe regarding patents issues. I am also surprised by the\nkind\n>of naive questions raised and therefore am inclined to doubt their true\n>naivity. Quoting Leonardo : \"Of course getting things for free is nice, but\n>wise buyers know that a \"free\" price tag on something that is known to be\n>valuable means that the cost of that particular \"free\" item is just folded\n>into another cost item. The particular cost item that remunerates those who\n>have developed Intellectual Property applies to the MPEG standard solution\n>as much as to a proprietary solution. The fact that there is no explicit\n>price tag for the Intellectual Property of proprietary solutions does not\n>mean there there is no cost associated with it, it just means that it is\n>hidden. And this is not necessarily a good feature for a wise buyer.\". I\n>would add to this that before considering developing another solution,\n>possibly free of IP, maybe wise buyers should consider the cost of doing\nso,\n>including the extra cost of navigating between the existing patents.\n>\n>Kind regards,\n>\n>Olivier\n>\n> > > >> Flavor Software is proud to release the first commercial\n> > > MPEG-4 player\n> > > >> and authoring software. The Mild Flavor(tm) player and\n> > > sample MP4 files\n> > > >> featuring New York City indi bands \"The Pasties\", \"Brave\n> > > New Girl\", and\n> > > >> \"The Rosenbergs\" are available for download from the\n> > > Flavor Software web\n> > > >> site.\n> > > >>\n> > > >> Go to http://www.flavorsoftware.com and click on downloads.\n> > > >>\n> > > >> Spread the joy... tell your friends to go to the Flavor\n> > > web site and get\n> > > >> into MP4! Even better... create your own MP4 files and\n> > > send them to your\n> > > >> friends!  -- The Flavor Team\n\n\n\n", "id": "lists-007-15706534"}, {"subject": "RE: resource-types of working resources/collection", "content": "Yes, the spec should explicitly state that the DAV:resourcetype\nof a working-resource and working-collection is that of the\nversion being checked out.  I'll add this to the Errata document.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: B H, Girish [mailto:g.b.h@sap.com]\nSent: Friday, June 28, 2002 6:07 AM\nTo: ietf-dav-versioning@w3.org\nSubject: resource-types of working resources/collections\n\n\n\nHi,\nThe specification does not give clarity on the resource type for\nworking-resources and working-collections. My guess is that it does not\nintroduce any new resource types (just as it does not for VCRs and\nversions). If this is so, then I think this should be explicitly mentioned.\n\nThanx,\nGirish\n\n\n\n", "id": "lists-007-1571573"}, {"subject": "RE: MP4 Player Available for Downloa", "content": "Leonardo,\n\nThank you for your reply.  I would like to respond to some of your points:\n\nAt 11:37 PM 3/30/01 +0200, Chiariglione Leonardo wrote:\n>I do not know for the IETF email address that appears in Cc:, but as far \n>as MPEG is concerned discussions about patents are not allowed by the \n>ISO/IEC directives. [...]\n>In any case, please do not make further discussions about patents on MPEG\n>reflectors.\n\nMy apologies.  I didn't realize that there was any reflector other than the \ntwo IETF lists (rem-conf@es.net and discuss@apps.ietf.org)  I'm assuming \ngen-sys@advent.ee.columbia.edu is the ISO reflector?  It's no longer listed \nas a recipient in my reply.\n\n>I can understand that it may suit some parties to state that \"MPEG-4\n>licensing is still very murky\" and I will make no efforts to convince such \n>parties that its is not, for the very simple reason that I do not know \n>whether this is true or not and I do not want to know.\n\nHey, if you can find someone who's willing to make a non-murky public \nstatement on this issue, I'm all ears.  It may seem to you like I'm being \ndisingenuous and that I really don't want the answer, but nothing could be \nfurther from the truth.  I'd like to hear what the straight answer is from \nsomeone who's willing to state it publicly.  Since there's no shortage of \npeople who will hound RealNetworks publicly about not yet supporting \nMPEG-4, I'm sure there's someone who can give a good answer to this.  :)\n\n>I will simply point out these two very simple and incontrovertible facts:\n>1. the number of MP3 processors (encoders, decoders etc.) can be counted \n>by the tens of millions (at least 60 million Napster users :-)\n\nYes, but over the years, as MP3 has gotten more popular, Thomson has \nchanged the terms on MP3 to be more restrictive (from what I \nunderstand).  This is very reminiscent of what happened with GIF...which \nwould lead one to think that maybe a PNG effort is in order.  For example, \nthe Vorbis project has a good start on an audio codec:\n\nhttp://www.wired.com/news/culture/0,1284,37538,00.html\n\n...but alas, there's a lot more to doing full-blown multimedia than \naudio.  That's not a slam on the Vorbis people; they recognize it too and \nhave a very nascent video format and other elements of a complete \nsystem.  But I guess I'm tired of hearing that MPEG-4 is the undisputed \nstandard here, and I'm frustrated that I encounter so many people who \naren't even aware that there are licensing issues at all with MPEG-4.\n\n>2. the number of MPEG-2 processors is well above 100 million (50 million\n>digital television set top boxes, 30 million hardware-based DVDs, 10 \n>million Playstation 2, an unknown number of software DVD decoders, an \n>unknown number of DviX converters :-).\n\nAs they say in the stock market:  \"Past results are no indication of future \nperformance\"   :)\n\nMPEG-4 is a very different technology than MPEG-2, and \"licensable\" is very \ndifferent than openly available.\n\nI'd also note that DivX files are not .mp4, but are .avi, right?  I think \nthat speaks to the heart of the issue.\n\n>I hear reports that implementation of these two standards requires the use\n>of patented technologies (I have been told about 100 patents for MPEG-2).\n>It may suit some parties to run down MPEG-4, but the power of standard\n>technologies demonstrated by the two cases above stays unchallenged. \n>Patent issues may be complex, but so are business decisions for which \n>patents are just one element. That is why I am sure that, as for the past, \n>wise people will make wise decisions.\n\nI'm not arguing against standards (that'd be pretty stupid in general, and \n*really* stupid given this audience).  I'm saying that there doesn't \nexist  multimedia standard with the stated goal of being royalty-free.\n\nI guess it would be nice to redirect the efforts of the IETF toward truly \nopen formats, since most of the effort thus far has been toward things like \ndocumenting the .wav file format (as VPIM has been doing), or defining the \npacketization formats for MPEG-4 (as AVT is doing).\n\nRob\n\n-----Original Message-----\n>From: Rob Lanphier [mailto:robla@real.com]\n>Sent: 2001 marzo venerd? 22:26\n>To: olivier.avaro@francetelecom.com; 'Hari Kalva'; rem-conf@es.net\n>Cc: gen-sys@advent. ee. columbia. edu (E-mail); discuss@apps.ietf.org\n>Subject: RE: MP4 Player Available for Download\n>\n>\n>I've hesitated from joining this conversation because it was pointed out\n>that it's \"off-topic\".  Since everyone has been dying to get the last word\n>in on this thread, and since I do think this is an important discussion to\n>have, I'm requesting that we move it to the Apps area discussion list\n>rather than end the thread altogether (hence the addition of\n>\"discuss@apps.ietf.org\" to the cc line...please send followups to this\n>alias instead of rem-conf).\n>\n>For those in the apps area, a brief introduction.  Someone posted a note to\n>rem-conf (the IETF AVT working group mail alias) on the topic of two\n>players that support the \".mp4\" file extension which don't\n>interoperate.  The discussion turned toward the issue of whether or not\n>genuine interoperability is possible, due to patent licensing restrictions,\n>to which several people made statements to the effect of \"oh, that's just a\n>red herring\".\n>\n>Well, I disagree.  MPEG-4 licensing is still very murky.  Here's the\n>statement in the M4IF FAQ (see http://www.m4if.org):\n>\n>      Based on the information that M4IF has received, the situation\n>      is as follows:\n>\n>      MPEG-4 Systems: A call for essential patents was issued at the\n>      beginning of September. Licensing is expected to start in\n>      Spring 2001, and should encompass all of MPEG-4 version 1 and\n>      version 2 technology\n>\n>      MPEG-4 Visual: portfolios are under development for the Simple\n>      and Core Visual Profiles. Patents are currently being evaluated,\n>      and a meeting will be called in October. It is expected that\n>      licensing will begin in the beginning of 2001.\n>\n>      MPEG-4 Audio: A Call for essential patents is expected by the\n>      end of October. Licensing should start in 2001.  Details are\n>      still being worked out.\n>\n>In other words, there's still a bunch of people talking in smoke filled\n>rooms about what the licensing terms are.  Fine....just don't push this as\n>a standard that's ready for prime time.\n>\n>Having seen the hue and cry in IETF plenary meetings when *one* company\n>holds an essential patent, I shudder to think how a discussion of MPEG-4\n>licensing would play out if done in the IETF, where my understanding is\n>that there are dozens of rights holders involved in the essential\n>technology.  Perhaps that's why it's never been brought up.....   :)\n>\n>So, I'm at a loss.  The MPEG4 group hasn't been very vigilant in ensuring\n>that the technology that they are standardizing is practical to implement,\n>from a technology perspective or from a business perspective. On the\n>technology front, the specification is a sprawling set of documents from\n>which only a small portion is useful for the nuts-and-bolts of\n>interoperability, and even then it's not complete and is still a\n>work-in-progress. On the business side, there are dozens of companies\n>claiming to own intellectual property associated with essential technology\n>in the specification, and the group responsible for working out a licensing\n>pool (the MPEG-4 Industry Forum, M4IF) is long overdue in its attempts to\n>work out the first of many pieces necessary for a complete end-to-end\n>system.\n>\n>Would it be useful for the IETF to engage in standardization of audio/video\n>file formats?  If not the IETF, then who?\n>\n>Rob\n>\n>At 09:12 AM 3/27/01 +0200, Olivier Avaro wrote:\n> >Hi all,\n> >\n> >For clarification on some questions raised by the original mail from Hari.\n> >\n> >1- mp4 is the file format of MPEG-4. If you comply to the mp4 spec., you\n>can\n> >parse any mp4 stream. The ability to play the stream is another dimension\n> >covered by the signaling of the audio, video, graphics and scene\n>description\n> >profiles contained in the file.\n> >\n> >2- Because it would be nice when opening an mp4 file to know what bundles\n>of\n> >codecs you need, the mp4 file format contains specific tags to signal this.\n> >As decided in the last MPEG meeting, these tags will be in part managed by\n>a\n> >registration authority outside MPEG. Industry fora, like ISMA, 3GPP, ...\n>can\n> >therefore defined the specific flavor of the MP4 file and signal it in a\n> >clean way.\n> >\n> >3- It's great to see the MPEG-4 wave happening now, with new MPEG-4\n>products\n> >released regularly (and not only audio and video !).Still, I am also\n> >concerned about the confusion created when people do not announce to what\n> >part of MPEG-4 they comply. It would be interesting to have this\n>information\n> >from the technology provider, otherwise the products are pretty useless,\n>and\n> >even more, they do not serve neither themselves nor the standard.\n> >\n> >4- I join Philippe regarding patents issues. I am also surprised by the\n>kind\n> >of naive questions raised and therefore am inclined to doubt their true\n> >naivity. Quoting Leonardo : \"Of course getting things for free is nice, but\n> >wise buyers know that a \"free\" price tag on something that is known to be\n> >valuable means that the cost of that particular \"free\" item is just folded\n> >into another cost item. The particular cost item that remunerates those who\n> >have developed Intellectual Property applies to the MPEG standard solution\n> >as much as to a proprietary solution. The fact that there is no explicit\n> >price tag for the Intellectual Property of proprietary solutions does not\n> >mean there there is no cost associated with it, it just means that it is\n> >hidden. And this is not necessarily a good feature for a wise buyer.\". I\n> >would add to this that before considering developing another solution,\n> >possibly free of IP, maybe wise buyers should consider the cost of doing\n>so,\n> >including the extra cost of navigating between the existing patents.\n> >\n> >Kind regards,\n> >\n> >Olivier\n> >\n> > > > >> Flavor Software is proud to release the first commercial\n> > > > MPEG-4 player\n> > > > >> and authoring software. The Mild Flavor(tm) player and\n> > > > sample MP4 files\n> > > > >> featuring New York City indi bands \"The Pasties\", \"Brave\n> > > > New Girl\", and\n> > > > >> \"The Rosenbergs\" are available for download from the\n> > > > Flavor Software web\n> > > > >> site.\n> > > > >>\n> > > > >> Go to http://www.flavorsoftware.com and click on downloads.\n> > > > >>\n> > > > >> Spread the joy... tell your friends to go to the Flavor\n> > > > web site and get\n> > > > >> into MP4! Even better... create your own MP4 files and\n> > > > send them to your\n> > > > >> friends!  -- The Flavor Team\n\n\n\n", "id": "lists-007-15725323"}, {"subject": "RE: MP4 Player Available for Downloa", "content": "Rob\n\nyou may be right about the licensing of MPEG-4 in general;  but I \nbelieve I have told this group already the best of my knowledge on \nthe licensing of the file format, so I am a little disappointed that \nyou should end up on that particular subject.\n\n\n\nAt 12:25 PM -0800 3/30/01, Rob Lanphier wrote:\n>I've hesitated from joining this conversation because it was pointed \n>out that it's \"off-topic\".  Since everyone has been dying to get the \n>last word in on this thread, and since I do think this is an \n>important discussion to have, I'm requesting that we move it to the \n>Apps area discussion list rather than end the thread altogether \n>(hence the addition of \"discuss@apps.ietf.org\" to the cc \n>line...please send followups to this alias instead of rem-conf).\n>\n>For those in the apps area, a brief introduction.  Someone posted a \n>note to rem-conf (the IETF AVT working group mail alias) on the \n>topic of two players that support the \".mp4\" file extension which \n>don't interoperate.  The discussion turned toward the issue of \n>whether or not genuine interoperability is possible, due to patent \n>licensing restrictions, to which several people made statements to \n>the effect of \"oh, that's just a red herring\".\n>\n>Well, I disagree.  MPEG-4 licensing is still very murky.  Here's the \n>statement in the M4IF FAQ (see http://www.m4if.org):\n>\n>     Based on the information that M4IF has received, the situation\n>     is as follows:\n>\n>     MPEG-4 Systems: A call for essential patents was issued at the\n>     beginning of September. Licensing is expected to start in\n>     Spring 2001, and should encompass all of MPEG-4 version 1 and\n>     version 2 technology\n>\n>     MPEG-4 Visual: portfolios are under development for the Simple\n>     and Core Visual Profiles. Patents are currently being evaluated,\n>     and a meeting will be called in October. It is expected that\n>     licensing will begin in the beginning of 2001.\n>\n>     MPEG-4 Audio: A Call for essential patents is expected by the\n>     end of October. Licensing should start in 2001.  Details are\n>     still being worked out.\n>\n>In other words, there's still a bunch of people talking in smoke \n>filled rooms about what the licensing terms are.  Fine....just don't \n>push this as a standard that's ready for prime time.\n>\n>Having seen the hue and cry in IETF plenary meetings when *one* \n>company holds an essential patent, I shudder to think how a \n>discussion of MPEG-4 licensing would play out if done in the IETF, \n>where my understanding is that there are dozens of rights holders \n>involved in the essential technology.  Perhaps that's why it's never \n>been brought up.....   :)\n>\n>So, I'm at a loss.  The MPEG4 group hasn't been very vigilant in \n>ensuring that the technology that they are standardizing is \n>practical to implement, from a technology perspective or from a \n>business perspective. On the technology front, the specification is \n>a sprawling set of documents from which only a small portion is \n>useful for the nuts-and-bolts of interoperability, and even then \n>it's not complete and is still a work-in-progress. On the business \n>side, there are dozens of companies claiming to own intellectual \n>property associated with essential technology in the specification, \n>and the group responsible for working out a licensing pool (the \n>MPEG-4 Industry Forum, M4IF) is long overdue in its attempts to work \n>out the first of many pieces necessary for a complete end-to-end\n>system.\n>\n>Would it be useful for the IETF to engage in standardization of \n>audio/video file formats?  If not the IETF, then who?\n>\n>Rob\n>\n>At 09:12 AM 3/27/01 +0200, Olivier Avaro wrote:\n>>Hi all,\n>>\n>>For clarification on some questions raised by the original mail from Hari.\n>>\n>>1- mp4 is the file format of MPEG-4. If you comply to the mp4 spec., you can\n>>parse any mp4 stream. The ability to play the stream is another dimension\n>>covered by the signaling of the audio, video, graphics and scene description\n>>profiles contained in the file.\n>>\n>>2- Because it would be nice when opening an mp4 file to know what bundles of\n>>codecs you need, the mp4 file format contains specific tags to signal this.\n>>As decided in the last MPEG meeting, these tags will be in part managed by a\n>>registration authority outside MPEG. Industry fora, like ISMA, 3GPP, ... can\n>>therefore defined the specific flavor of the MP4 file and signal it in a\n>>clean way.\n>>\n>>3- It's great to see the MPEG-4 wave happening now, with new MPEG-4 products\n>>released regularly (and not only audio and video !).Still, I am also\n>>concerned about the confusion created when people do not announce to what\n>>part of MPEG-4 they comply. It would be interesting to have this information\n>>from the technology provider, otherwise the products are pretty useless, and\n>>even more, they do not serve neither themselves nor the standard.\n>>\n>>4- I join Philippe regarding patents issues. I am also surprised by the kind\n>>of naive questions raised and therefore am inclined to doubt their true\n>>naivity. Quoting Leonardo : \"Of course getting things for free is nice, but\n>>wise buyers know that a \"free\" price tag on something that is known to be\n>>valuable means that the cost of that particular \"free\" item is just folded\n>>into another cost item. The particular cost item that remunerates those who\n>>have developed Intellectual Property applies to the MPEG standard solution\n>>as much as to a proprietary solution. The fact that there is no explicit\n>>price tag for the Intellectual Property of proprietary solutions does not\n>>mean there there is no cost associated with it, it just means that it is\n>>hidden. And this is not necessarily a good feature for a wise buyer.\". I\n>>would add to this that before considering developing another solution,\n>>possibly free of IP, maybe wise buyers should consider the cost of doing so,\n>>including the extra cost of navigating between the existing patents.\n>>\n>>Kind regards,\n>>\n>>Olivier\n>>\n>>>  > >> Flavor Software is proud to release the first commercial\n>>>  > MPEG-4 player\n>>>  > >> and authoring software. The Mild Flavor(tm) player and\n>>>  > sample MP4 files\n>>>  > >> featuring New York City indi bands \"The Pasties\", \"Brave\n>>>  > New Girl\", and\n>>>  > >> \"The Rosenbergs\" are available for download from the\n>>>  > Flavor Software web\n>>>  > >> site.\n>>>  > >>\n>>>  > >> Go to http://www.flavorsoftware.com and click on downloads.\n>>>  > >>\n>>>  > >> Spread the joy... tell your friends to go to the Flavor\n>>>  > web site and get\n>>>  > >> into MP4! Even better... create your own MP4 files and\n>>>  > send them to your\n>>>  > >> friends!  -- The Flavor Team\n\n-- \nDavid Singer\nApple Computer/QuickTime\n\n\n\n", "id": "lists-007-15746701"}, {"subject": "RE: MP4 Player Available for Downloa", "content": "Rob,\nMy answers below\n\n>I'd like to hear what the straight answer is from \n>someone who's willing to state it publicly. \n\nUnfortunately that is not me. This is because I keep myself deliberately\nunaware of \"what is happening in smoke filled rooms where a bunch of people\nare talking about what the licensing terms are\".\nThe reason why I brought the MP3 and MPEG-2 examples was to show that it is\npossible to implement a virtuous circle in standards that require IPR.\nTherefore the people who own the IPR that makes MPEG-4 possible have an\nincentive to agree on \"good\" licensing terms, if they do not want to lose\nrevenues and \"fast\" if they do not want to lose the opportunity all\ntogether.\n\n>Since there's no shortage of \n>people who will hound RealNetworks publicly about not yet supporting \n>MPEG-4, \n\nI do not see why they should. RealNetworks is a quoted company that responds\nto its shareholders. If the current management of RealNetworks think that\nthey serve the company shareholders' interests better by not adopting\nMPEG-4, one of the two things can happen\n1. RealNetworks thrives. The policy is shown to be sound. Shareholders are\nhappy. The management is confirmed\n2. RealNetworks sinks. The policy is shown not to be sound. Shareholders are\nunhappy. The management is fired.\nPeople who \"hound RealNetworks publicly about not yet supporting MPEG-4\" can\ngo to a supplier of MPEG-4 solution. This is the good side of competition,\nparticularly when the alternative is a standard solution with many competing\nsuppliers.\n\n>As they say in the stock market:  \"Past results are no indication of future\n\n>performance\"   :)\n\nThe alternative to studying the past is divination. This does not seem to\nwork so weel these days in the stock market :-)\n\n>MPEG-4 is a very different technology than MPEG-2, and \"licensable\" is very\n\n>different than openly available.\n\nIs RealNetworks technology licensable or openly available?\n\n>I'd also note that DivX files are not .mp4, but are .avi, right?  I think \n>that speaks to the heart of the issue.\n\nNo, it does not. It just means that these people were contented with a\nsingle MPEG-4 \"tool\" - something that is perfectly legitimate with MPEG\nstandards - and thought that another, non-MPEG, technology suited their\nneeds better.\n\n>I'm saying that there doesn't \n>exist  multimedia standard with the stated goal of being royalty-free.\n\nStated by whom?\n\nLeonardo Chiariglione\n\n\n\n-----Original Message-----\nFrom: Rob Lanphier [mailto:robla@real.com]\nSent: 2001 marzo sabato 04:03\nTo: Chiariglione Leonardo\nCc: discuss@apps.ietf.org\nSubject: RE: MP4 Player Available for Download\n\n\nLeonardo,\n\nThank you for your reply.  I would like to respond to some of your points:\n\nAt 11:37 PM 3/30/01 +0200, Chiariglione Leonardo wrote:\n>I do not know for the IETF email address that appears in Cc:, but as far \n>as MPEG is concerned discussions about patents are not allowed by the \n>ISO/IEC directives. [...]\n>In any case, please do not make further discussions about patents on MPEG\n>reflectors.\n\nMy apologies.  I didn't realize that there was any reflector other than the \ntwo IETF lists (rem-conf@es.net and discuss@apps.ietf.org)  I'm assuming \ngen-sys@advent.ee.columbia.edu is the ISO reflector?  It's no longer listed \nas a recipient in my reply.\n\n>I can understand that it may suit some parties to state that \"MPEG-4\n>licensing is still very murky\" and I will make no efforts to convince such \n>parties that its is not, for the very simple reason that I do not know \n>whether this is true or not and I do not want to know.\n\nHey, if you can find someone who's willing to make a non-murky public \nstatement on this issue, I'm all ears.  It may seem to you like I'm being \ndisingenuous and that I really don't want the answer, but nothing could be \nfurther from the truth.  I'd like to hear what the straight answer is from \nsomeone who's willing to state it publicly.  Since there's no shortage of \npeople who will hound RealNetworks publicly about not yet supporting \nMPEG-4, I'm sure there's someone who can give a good answer to this.  :)\n\n>I will simply point out these two very simple and incontrovertible facts:\n>1. the number of MP3 processors (encoders, decoders etc.) can be counted \n>by the tens of millions (at least 60 million Napster users :-)\n\nYes, but over the years, as MP3 has gotten more popular, Thomson has \nchanged the terms on MP3 to be more restrictive (from what I \nunderstand).  This is very reminiscent of what happened with GIF...which \nwould lead one to think that maybe a PNG effort is in order.  For example, \nthe Vorbis project has a good start on an audio codec:\n\nhttp://www.wired.com/news/culture/0,1284,37538,00.html\n\n...but alas, there's a lot more to doing full-blown multimedia than \naudio.  That's not a slam on the Vorbis people; they recognize it too and \nhave a very nascent video format and other elements of a complete \nsystem.  But I guess I'm tired of hearing that MPEG-4 is the undisputed \nstandard here, and I'm frustrated that I encounter so many people who \naren't even aware that there are licensing issues at all with MPEG-4.\n\n>2. the number of MPEG-2 processors is well above 100 million (50 million\n>digital television set top boxes, 30 million hardware-based DVDs, 10 \n>million Playstation 2, an unknown number of software DVD decoders, an \n>unknown number of DviX converters :-).\n\nAs they say in the stock market:  \"Past results are no indication of future \nperformance\"   :)\n\nMPEG-4 is a very different technology than MPEG-2, and \"licensable\" is very \ndifferent than openly available.\n\nI'd also note that DivX files are not .mp4, but are .avi, right?  I think \nthat speaks to the heart of the issue.\n\n>I hear reports that implementation of these two standards requires the use\n>of patented technologies (I have been told about 100 patents for MPEG-2).\n>It may suit some parties to run down MPEG-4, but the power of standard\n>technologies demonstrated by the two cases above stays unchallenged. \n>Patent issues may be complex, but so are business decisions for which \n>patents are just one element. That is why I am sure that, as for the past, \n>wise people will make wise decisions.\n\nI'm not arguing against standards (that'd be pretty stupid in general, and \n*really* stupid given this audience).  I'm saying that there doesn't \nexist  multimedia standard with the stated goal of being royalty-free.\n\nI guess it would be nice to redirect the efforts of the IETF toward truly \nopen formats, since most of the effort thus far has been toward things like \ndocumenting the .wav file format (as VPIM has been doing), or defining the \npacketization formats for MPEG-4 (as AVT is doing).\n\nRob\n\n-----Original Message-----\n>From: Rob Lanphier [mailto:robla@real.com]\n>Sent: 2001 marzo venerd? 22:26\n>To: olivier.avaro@francetelecom.com; 'Hari Kalva'; rem-conf@es.net\n>Cc: gen-sys@advent. ee. columbia. edu (E-mail); discuss@apps.ietf.org\n>Subject: RE: MP4 Player Available for Download\n>\n>\n>I've hesitated from joining this conversation because it was pointed out\n>that it's \"off-topic\".  Since everyone has been dying to get the last word\n>in on this thread, and since I do think this is an important discussion to\n>have, I'm requesting that we move it to the Apps area discussion list\n>rather than end the thread altogether (hence the addition of\n>\"discuss@apps.ietf.org\" to the cc line...please send followups to this\n>alias instead of rem-conf).\n>\n>For those in the apps area, a brief introduction.  Someone posted a note to\n>rem-conf (the IETF AVT working group mail alias) on the topic of two\n>players that support the \".mp4\" file extension which don't\n>interoperate.  The discussion turned toward the issue of whether or not\n>genuine interoperability is possible, due to patent licensing restrictions,\n>to which several people made statements to the effect of \"oh, that's just a\n>red herring\".\n>\n>Well, I disagree.  MPEG-4 licensing is still very murky.  Here's the\n>statement in the M4IF FAQ (see http://www.m4if.org):\n>\n>      Based on the information that M4IF has received, the situation\n>      is as follows:\n>\n>      MPEG-4 Systems: A call for essential patents was issued at the\n>      beginning of September. Licensing is expected to start in\n>      Spring 2001, and should encompass all of MPEG-4 version 1 and\n>      version 2 technology\n>\n>      MPEG-4 Visual: portfolios are under development for the Simple\n>      and Core Visual Profiles. Patents are currently being evaluated,\n>      and a meeting will be called in October. It is expected that\n>      licensing will begin in the beginning of 2001.\n>\n>      MPEG-4 Audio: A Call for essential patents is expected by the\n>      end of October. Licensing should start in 2001.  Details are\n>      still being worked out.\n>\n>In other words, there's still a bunch of people talking in smoke filled\n>rooms about what the licensing terms are.  Fine....just don't push this as\n>a standard that's ready for prime time.\n>\n>Having seen the hue and cry in IETF plenary meetings when *one* company\n>holds an essential patent, I shudder to think how a discussion of MPEG-4\n>licensing would play out if done in the IETF, where my understanding is\n>that there are dozens of rights holders involved in the essential\n>technology.  Perhaps that's why it's never been brought up.....   :)\n>\n>So, I'm at a loss.  The MPEG4 group hasn't been very vigilant in ensuring\n>that the technology that they are standardizing is practical to implement,\n>from a technology perspective or from a business perspective. On the\n>technology front, the specification is a sprawling set of documents from\n>which only a small portion is useful for the nuts-and-bolts of\n>interoperability, and even then it's not complete and is still a\n>work-in-progress. On the business side, there are dozens of companies\n>claiming to own intellectual property associated with essential technology\n>in the specification, and the group responsible for working out a licensing\n>pool (the MPEG-4 Industry Forum, M4IF) is long overdue in its attempts to\n>work out the first of many pieces necessary for a complete end-to-end\n>system.\n>\n>Would it be useful for the IETF to engage in standardization of audio/video\n>file formats?  If not the IETF, then who?\n>\n>Rob\n>\n>At 09:12 AM 3/27/01 +0200, Olivier Avaro wrote:\n> >Hi all,\n> >\n> >For clarification on some questions raised by the original mail from\nHari.\n> >\n> >1- mp4 is the file format of MPEG-4. If you comply to the mp4 spec., you\n>can\n> >parse any mp4 stream. The ability to play the stream is another dimension\n> >covered by the signaling of the audio, video, graphics and scene\n>description\n> >profiles contained in the file.\n> >\n> >2- Because it would be nice when opening an mp4 file to know what bundles\n>of\n> >codecs you need, the mp4 file format contains specific tags to signal\nthis.\n> >As decided in the last MPEG meeting, these tags will be in part managed\nby\n>a\n> >registration authority outside MPEG. Industry fora, like ISMA, 3GPP, ...\n>can\n> >therefore defined the specific flavor of the MP4 file and signal it in a\n> >clean way.\n> >\n> >3- It's great to see the MPEG-4 wave happening now, with new MPEG-4\n>products\n> >released regularly (and not only audio and video !).Still, I am also\n> >concerned about the confusion created when people do not announce to what\n> >part of MPEG-4 they comply. It would be interesting to have this\n>information\n> >from the technology provider, otherwise the products are pretty useless,\n>and\n> >even more, they do not serve neither themselves nor the standard.\n> >\n> >4- I join Philippe regarding patents issues. I am also surprised by the\n>kind\n> >of naive questions raised and therefore am inclined to doubt their true\n> >naivity. Quoting Leonardo : \"Of course getting things for free is nice,\nbut\n> >wise buyers know that a \"free\" price tag on something that is known to be\n> >valuable means that the cost of that particular \"free\" item is just\nfolded\n> >into another cost item. The particular cost item that remunerates those\nwho\n> >have developed Intellectual Property applies to the MPEG standard\nsolution\n> >as much as to a proprietary solution. The fact that there is no explicit\n> >price tag for the Intellectual Property of proprietary solutions does not\n> >mean there there is no cost associated with it, it just means that it is\n> >hidden. And this is not necessarily a good feature for a wise buyer.\". I\n> >would add to this that before considering developing another solution,\n> >possibly free of IP, maybe wise buyers should consider the cost of doing\n>so,\n> >including the extra cost of navigating between the existing patents.\n> >\n> >Kind regards,\n> >\n> >Olivier\n> >\n> > > > >> Flavor Software is proud to release the first commercial\n> > > > MPEG-4 player\n> > > > >> and authoring software. The Mild Flavor(tm) player and\n> > > > sample MP4 files\n> > > > >> featuring New York City indi bands \"The Pasties\", \"Brave\n> > > > New Girl\", and\n> > > > >> \"The Rosenbergs\" are available for download from the\n> > > > Flavor Software web\n> > > > >> site.\n> > > > >>\n> > > > >> Go to http://www.flavorsoftware.com and click on downloads.\n> > > > >>\n> > > > >> Spread the joy... tell your friends to go to the Flavor\n> > > > web site and get\n> > > > >> into MP4! Even better... create your own MP4 files and\n> > > > send them to your\n> > > > >> friends!  -- The Flavor Team\n\n\n\n", "id": "lists-007-15762756"}, {"subject": "Re: MP4 Player Available for Downloa", "content": "As far as I'm concerned, if MPEG-4 requires ANY IPR licensing then\nit is a non-starter.  Those four letters don't mean jack - what matters\nis whether people can use the technology without strings.  And if the \nMPEG developer community isn't committed to producing a standard\nthat is free of IPR - then the sooner the rest of the world abandons\nthem, the better.\n\nKeith\n\n\n\n", "id": "lists-007-15787973"}, {"subject": "RE: MP4 Player Available for Downloa", "content": ">then it is a non-starter\n\nMay be. We'll see.\n\n>then the sooner the rest of the world abandons\n>them, the better\n\nFor whom? For owners of proprietary technologies who do not have the least\nintention of making _their_ IPR available?\n\nLeonardo Chiariglione\n\n-----Original Message-----\nFrom: Keith Moore [mailto:moore@cs.utk.edu]\nSent: 2001 marzo sabato 19:41\nTo: Chiariglione Leonardo\nCc: 'Rob Lanphier'; discuss@apps.ietf.org\nSubject: Re: MP4 Player Available for Download\n\n\nAs far as I'm concerned, if MPEG-4 requires ANY IPR licensing then\nit is a non-starter.  Those four letters don't mean jack - what matters\nis whether people can use the technology without strings.  And if the \nMPEG developer community isn't committed to producing a standard\nthat is free of IPR - then the sooner the rest of the world abandons\nthem, the better.\n\nKeith\n\n\n\n", "id": "lists-007-15795769"}, {"subject": "RE: Replacing the Label header with a DAV:labeled-version repor", "content": "So far, everyone has either agreed or remained silent on this topic,\nso as a motivator for anyone objecting to speak up (:-), I will mark this\nissue\nas resolved in the errata, with the resolution being that the Label\nheader will be deprecated, and the DAV:labeled-version REPORT inserted\nin its place.  In particular, I propose the following definition for\nthe DAV:labeled-version REPORT:\n\n-------------------\n\n8.3DAV:labeled-version Report\nThe DAV:labeled-version report describes the requested properties\nof the version with that label in a specified version history.\nIf the DAV:labeled-version report is applied to a version-controlled\nresource, it is applied to the DAV:version-history of that\nversion-controlled resource.\n\nMarshalling:\n\nThe request body MUST be a DAV:labeled-version XML element.\n\n<!ELEMENT labeled-version ANY>\n\nANY value: a sequence of zero or more elements, with\nat most one DAV:prop element and with exactly one\nDAV:label-name element.\n\nprop: see RFC 2518, Section 12.11\n\nThe response body for a successful request MUST be a DAV:multistatus\nXML element.\n\nmultistatus: see RFC 2518, Section 12.9\n\nThe response body for a successful DAV:labeled-version REPORT\nrequest MUST contain a DAV:response element for each resource\nthat satisfies the Depth header of the request.\n\n8.3.1Example - DAV:labeled-version Report\n\n>>REQUEST\n\n  REPORT /folder/ HTTP/1.1\n  Host: www.webdav.org\n  Content-Type: text/xml; charset=\"utf-8\"\n  Content-Length: xxxx \n  Depth: 1\n\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:labeled-version xmlns:D=\"DAV:\">\n    <D:label-name>tested</D:label-name>\n    <D:prop>\n      <D:version-name/>\n      <D:version/>\n    </D:prop>\n  </D:labeled-version>\n\n>>RESPONSE\n\n  HTTP/1.1 207 Multi-Status\n  Content-Type: text/xml; charset=\"utf-8\"\n  Content-Length: xxxx\n\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:multistatus xmlns:D=\"DAV:\">\n    <D:response>\n      <D:href>http://www.webdav.org/folder/</D:href>\n      <D:propstat>\n        <D:prop>\n          <D:version-name>V5</D:version-name>\n          <D:creator-displayname>Fred</D:creator-displayname>\n          <D:version>\n            <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n          </D:version>\n        </D:prop>\n        <D:status>HTTP/1.1 200 OK</D:status>\n      </D:propstat>\n    </D:response>\n    <D:response>\n      <D:href>http://www.webdav.org/folder/foo.html</D:href>\n      <D:propstat>\n        <D:prop>\n          <D:version-name>V8</D:version-name>\n          <D:version>\n            <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n          </D:version>\n        </D:prop>\n        <D:status>HTTP/1.1 200 OK</D:status>\n      </D:propstat>\n    </D:response>\n  </D:multistatus>\n\n-----------------------------------------\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@Rational.Com]\nSent: Sunday, April 28, 2002 9:53 AM\nTo: 'Deltav WG'\nSubject: Replacing the Label header with a DAV:labeled-version report\n\n\nSince this is a fairly significant change, I'd like to\nhear from a few more folks before adding this to the 3253 Errata.\n\nThanks,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Saturday, April 27, 2002 5:09 AM\nTo: Clemm, Geoff; 'Deltav WG'\nSubject: RE: Label header vs PROPFIND depth 1\n\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, April 26, 2002 6:06 PM\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    - I'd like to see the label *header* deprecated\n>    - I'm happy with the LABEL method and the label-name-set property\n>    - I think that PROPFIND/label should be replaced by a specific REPORT\n>\n> Is the proposed DAV:labeled-version report OK with you?\n\nYes. But I think it's Tim's turn to say whether this would work for him or\nnot...\n\n>    - I'm unsure about other methods that are currently affected by the\n>    header -- what were the requirements...?\n>\n> The other methods are LABEL, CHECKOUT, GET, and COPY.\n> For Depth:0 variants of these operations, the Label header\n> just provided an optimization to save one roundtrip\n> (i.e. first getting the version URL via the DAV:labeled-version report).\n> I believe we can easily do without that Depth:0 optimization.\n\nAs stated before, I think that's not the single problem. Having GET return a\n(representation of a) version rather than (a representation of) the VCR\nmakes the version *by definition* a variant (representation) of the VCR --\nand it seems that most of us want to avoid that interpretation.\n\n> For Depth:infinity (only relevant for LABEL and COPY), the savings\n> would be more significant, but unfortunately the semantics is broken\n> (since if the namespace is being versioned, you'll get the wrong\n> resources if you simply do a Depth operation on the current namespace).\n>\n> The Depth:infinity Label header operations are really just a way of\n> trying to have the client fake workspaces and baselines, instead of\n> having the server support them directly.  Since it is much more\n> efficient and reliable to have the server layer these constructs\n> above a labeling infrastructure, rather than having the client do\n> so, I believe the cost of maintaining these Depth:infinity Label\n> header operations in the protocol is not warranted.\n>\n> Note though that (depth:0) labeling and baselining go very well\n> together.  Instead of doing a Depth:infinity LABEL, you can create a\n> baseline (which under the hood the server may well implement with\n> reserved labels, but maybe not), and then LABEL that baseline.  Then\n> when you want to do a Depth:infinity COPY, you retrieve the\n> DAV:baseline-collection of the labeled baseline (using the\n> DAV:labeled-version report), and copy that to wherever you want.\n>\n> Alternatively, if you want a \"modifiable\" selection, you can create a\n> workspace (which under the hood the server may well implement with\n> reserved labels, but maybe not).  When you want to adjust the versions\n> being selected, you just use UPDATE.  Then when you want to do a\n> Depth:infinity COPY, you just copy from that workspace to wherever you\n> want.\n>\n>    - Servers that decide to implement LABEL and DAV:label-name-set,\n>    but no not support the label header should *not* report the LABEL\n>    feature in OPTIONS.\n>\n> That's probably right.  A client can find out if the LABEL operation\n> is supported by querying the DAV:supported-method-set property values\n> of a VCR.\n\n...and also use DAV:supported-live-property-set to discover the\nDAV:label-name-set property.\n\n\n\n", "id": "lists-007-1579819"}, {"subject": "Re: MP4 Player Available for Downloa", "content": "> >then the sooner the rest of the world abandons\n> >them, the better\n> \n> For whom? For owners of proprietary technologies who do not have the least\n> intention of making _their_ IPR available?\n\nno.  for everyone else.  the \"owners\" of the proprietary technology can go\nbankrupt, for all I care, and the rest of the world will be better off if \nthey do so.  of course, we'd be even better off if they got a clue.\n\nthe term \"intellectual property\" is a misnomer.  the use of the word\n\"property\" to describe ideas and expression of ideas has led to a widespread \nconfusion that ideas are like tangible property.  they're not.  for one thing, \nthe laws of supply and demand that apply to tangible property do not apply to \n\"intellectual property\".  quite often \"intellectual property\" is worth more \nif you give it away than if you try to control it.  holders of IPR \nmidunderstand this at their peril.\n\nmeanwhile, the net will treat IPR as damage and route around it. \n\nKeith\n\n\n\n", "id": "lists-007-15805185"}, {"subject": "RE: MP4 Player Available for Downloa", "content": "Hi Leonardo,\n\nMore answers inline:\n\nOn Sat, 31 Mar 2001, Chiariglione Leonardo wrote:\n> [Rob Lanphier wrote:]\n> >MPEG-4 is a very different technology than MPEG-2, and \"licensable\" is very\n> >different than openly available.\n>\n> Is RealNetworks technology licensable or openly available?\n\nAbsolutely.  You've opened up a huge door for me to give a long sales\npitch, but out of courtesy to the people on this list, I'll try to keep it\nbrief.  We give away versions of RealPlayer, RealServer and RealProducer,\nand license our technology to many companies.  It's also an open,\nextensible architecture which anyone can write new datatypes\n(standards-based or otherwise):\n\nAbout our ubiquity (and hence availability):\nhttp://www.realnetworks.com/company/pressroom/pr/2001/metrics.html\nAbout our extensibility:\nhttp://www.realnetworks.com/company/pressroom/pr/2001/autoupdate.html\n\nAs to the standards we support, there's RTP, RTSP, SDP, SMIL, H.261,\nG.711, PNG, and countless others I'm forgetting, all of which have\nspecifications available for interoperability with our system -- and all\nof which are available for royalty-free implementation to the best of my\nknowledge.  Additionally, we support many of the MPEG family of standards\n(MP3 audio natively, and MPEG-1/MPEG-2 video via third party support\nthrough our plugin architecture).  We even have partners working on MPEG-4\nsupport.\n\n> >I'm saying that there doesn't\n> >exist  multimedia standard with the stated goal of being royalty-free.\n>\n> Stated by whom?\n\nStated by the people working on it.  When the chair of the working group\nworking on a standard says that he doesn't know the IPR situation with the\nspec he's working on, that should raise big red flags in the minds of\nthose who are actually concerned with licensability.\n\nRob\n\n> -----Original Message-----\n> From: Rob Lanphier [mailto:robla@real.com]\n> Sent: 2001 marzo sabato 04:03\n> To: Chiariglione Leonardo\n> Cc: discuss@apps.ietf.org\n> Subject: RE: MP4 Player Available for Download\n>\n>\n> Leonardo,\n>\n> Thank you for your reply.  I would like to respond to some of your points:\n>\n> At 11:37 PM 3/30/01 +0200, Chiariglione Leonardo wrote:\n> >I do not know for the IETF email address that appears in Cc:, but as far\n> >as MPEG is concerned discussions about patents are not allowed by the\n> >ISO/IEC directives. [...]\n> >In any case, please do not make further discussions about patents on MPEG\n> >reflectors.\n>\n> My apologies.  I didn't realize that there was any reflector other than the\n> two IETF lists (rem-conf@es.net and discuss@apps.ietf.org)  I'm assuming\n> gen-sys@advent.ee.columbia.edu is the ISO reflector?  It's no longer listed\n> as a recipient in my reply.\n>\n> >I can understand that it may suit some parties to state that \"MPEG-4\n> >licensing is still very murky\" and I will make no efforts to convince such\n> >parties that its is not, for the very simple reason that I do not know\n> >whether this is true or not and I do not want to know.\n>\n> Hey, if you can find someone who's willing to make a non-murky public\n> statement on this issue, I'm all ears.  It may seem to you like I'm being\n> disingenuous and that I really don't want the answer, but nothing could be\n> further from the truth.  I'd like to hear what the straight answer is from\n> someone who's willing to state it publicly.  Since there's no shortage of\n> people who will hound RealNetworks publicly about not yet supporting\n> MPEG-4, I'm sure there's someone who can give a good answer to this.  :)\n>\n> >I will simply point out these two very simple and incontrovertible facts:\n> >1. the number of MP3 processors (encoders, decoders etc.) can be counted\n> >by the tens of millions (at least 60 million Napster users :-)\n>\n> Yes, but over the years, as MP3 has gotten more popular, Thomson has\n> changed the terms on MP3 to be more restrictive (from what I\n> understand).  This is very reminiscent of what happened with GIF...which\n> would lead one to think that maybe a PNG effort is in order.  For example,\n> the Vorbis project has a good start on an audio codec:\n>\n> http://www.wired.com/news/culture/0,1284,37538,00.html\n>\n> ...but alas, there's a lot more to doing full-blown multimedia than\n> audio.  That's not a slam on the Vorbis people; they recognize it too and\n> have a very nascent video format and other elements of a complete\n> system.  But I guess I'm tired of hearing that MPEG-4 is the undisputed\n> standard here, and I'm frustrated that I encounter so many people who\n> aren't even aware that there are licensing issues at all with MPEG-4.\n>\n> >2. the number of MPEG-2 processors is well above 100 million (50 million\n> >digital television set top boxes, 30 million hardware-based DVDs, 10\n> >million Playstation 2, an unknown number of software DVD decoders, an\n> >unknown number of DviX converters :-).\n>\n> As they say in the stock market:  \"Past results are no indication of future\n> performance\"   :)\n>\n> MPEG-4 is a very different technology than MPEG-2, and \"licensable\" is very\n> different than openly available.\n>\n> I'd also note that DivX files are not .mp4, but are .avi, right?  I think\n> that speaks to the heart of the issue.\n>\n> >I hear reports that implementation of these two standards requires the use\n> >of patented technologies (I have been told about 100 patents for MPEG-2).\n> >It may suit some parties to run down MPEG-4, but the power of standard\n> >technologies demonstrated by the two cases above stays unchallenged.\n> >Patent issues may be complex, but so are business decisions for which\n> >patents are just one element. That is why I am sure that, as for the past,\n> >wise people will make wise decisions.\n>\n> I'm not arguing against standards (that'd be pretty stupid in general, and\n> *really* stupid given this audience).  I'm saying that there doesn't\n> exist  multimedia standard with the stated goal of being royalty-free.\n>\n> I guess it would be nice to redirect the efforts of the IETF toward truly\n> open formats, since most of the effort thus far has been toward things like\n> documenting the .wav file format (as VPIM has been doing), or defining the\n> packetization formats for MPEG-4 (as AVT is doing).\n>\n> Rob\n>\n> -----Original Message-----\n> >From: Rob Lanphier [mailto:robla@real.com]\n> >Sent: 2001 marzo venerd? 22:26\n> >To: olivier.avaro@francetelecom.com; 'Hari Kalva'; rem-conf@es.net\n> >Cc: gen-sys@advent. ee. columbia. edu (E-mail); discuss@apps.ietf.org\n> >Subject: RE: MP4 Player Available for Download\n> >\n> >\n> >I've hesitated from joining this conversation because it was pointed out\n> >that it's \"off-topic\".  Since everyone has been dying to get the last word\n> >in on this thread, and since I do think this is an important discussion to\n> >have, I'm requesting that we move it to the Apps area discussion list\n> >rather than end the thread altogether (hence the addition of\n> >\"discuss@apps.ietf.org\" to the cc line...please send followups to this\n> >alias instead of rem-conf).\n> >\n> >For those in the apps area, a brief introduction.  Someone posted a note to\n> >rem-conf (the IETF AVT working group mail alias) on the topic of two\n> >players that support the \".mp4\" file extension which don't\n> >interoperate.  The discussion turned toward the issue of whether or not\n> >genuine interoperability is possible, due to patent licensing restrictions,\n> >to which several people made statements to the effect of \"oh, that's just a\n> >red herring\".\n> >\n> >Well, I disagree.  MPEG-4 licensing is still very murky.  Here's the\n> >statement in the M4IF FAQ (see http://www.m4if.org):\n> >\n> >      Based on the information that M4IF has received, the situation\n> >      is as follows:\n> >\n> >      MPEG-4 Systems: A call for essential patents was issued at the\n> >      beginning of September. Licensing is expected to start in\n> >      Spring 2001, and should encompass all of MPEG-4 version 1 and\n> >      version 2 technology\n> >\n> >      MPEG-4 Visual: portfolios are under development for the Simple\n> >      and Core Visual Profiles. Patents are currently being evaluated,\n> >      and a meeting will be called in October. It is expected that\n> >      licensing will begin in the beginning of 2001.\n> >\n> >      MPEG-4 Audio: A Call for essential patents is expected by the\n> >      end of October. Licensing should start in 2001.  Details are\n> >      still being worked out.\n> >\n> >In other words, there's still a bunch of people talking in smoke filled\n> >rooms about what the licensing terms are.  Fine....just don't push this as\n> >a standard that's ready for prime time.\n> >\n> >Having seen the hue and cry in IETF plenary meetings when *one* company\n> >holds an essential patent, I shudder to think how a discussion of MPEG-4\n> >licensing would play out if done in the IETF, where my understanding is\n> >that there are dozens of rights holders involved in the essential\n> >technology.  Perhaps that's why it's never been brought up.....   :)\n> >\n> >So, I'm at a loss.  The MPEG4 group hasn't been very vigilant in ensuring\n> >that the technology that they are standardizing is practical to implement,\n> >from a technology perspective or from a business perspective. On the\n> >technology front, the specification is a sprawling set of documents from\n> >which only a small portion is useful for the nuts-and-bolts of\n> >interoperability, and even then it's not complete and is still a\n> >work-in-progress. On the business side, there are dozens of companies\n> >claiming to own intellectual property associated with essential technology\n> >in the specification, and the group responsible for working out a licensing\n> >pool (the MPEG-4 Industry Forum, M4IF) is long overdue in its attempts to\n> >work out the first of many pieces necessary for a complete end-to-end\n> >system.\n> >\n> >Would it be useful for the IETF to engage in standardization of audio/video\n> >file formats?  If not the IETF, then who?\n> >\n> >Rob\n> >\n> >At 09:12 AM 3/27/01 +0200, Olivier Avaro wrote:\n> > >Hi all,\n> > >\n> > >For clarification on some questions raised by the original mail from\n> Hari.\n> > >\n> > >1- mp4 is the file format of MPEG-4. If you comply to the mp4 spec., you\n> >can\n> > >parse any mp4 stream. The ability to play the stream is another dimension\n> > >covered by the signaling of the audio, video, graphics and scene\n> >description\n> > >profiles contained in the file.\n> > >\n> > >2- Because it would be nice when opening an mp4 file to know what bundles\n> >of\n> > >codecs you need, the mp4 file format contains specific tags to signal\n> this.\n> > >As decided in the last MPEG meeting, these tags will be in part managed\n> by\n> >a\n> > >registration authority outside MPEG. Industry fora, like ISMA, 3GPP, ...\n> >can\n> > >therefore defined the specific flavor of the MP4 file and signal it in a\n> > >clean way.\n> > >\n> > >3- It's great to see the MPEG-4 wave happening now, with new MPEG-4\n> >products\n> > >released regularly (and not only audio and video !).Still, I am also\n> > >concerned about the confusion created when people do not announce to what\n> > >part of MPEG-4 they comply. It would be interesting to have this\n> >information\n> > >from the technology provider, otherwise the products are pretty useless,\n> >and\n> > >even more, they do not serve neither themselves nor the standard.\n> > >\n> > >4- I join Philippe regarding patents issues. I am also surprised by the\n> >kind\n> > >of naive questions raised and therefore am inclined to doubt their true\n> > >naivity. Quoting Leonardo : \"Of course getting things for free is nice,\n> but\n> > >wise buyers know that a \"free\" price tag on something that is known to be\n> > >valuable means that the cost of that particular \"free\" item is just\n> folded\n> > >into another cost item. The particular cost item that remunerates those\n> who\n> > >have developed Intellectual Property applies to the MPEG standard\n> solution\n> > >as much as to a proprietary solution. The fact that there is no explicit\n> > >price tag for the Intellectual Property of proprietary solutions does not\n> > >mean there there is no cost associated with it, it just means that it is\n> > >hidden. And this is not necessarily a good feature for a wise buyer.\". I\n> > >would add to this that before considering developing another solution,\n> > >possibly free of IP, maybe wise buyers should consider the cost of doing\n> >so,\n> > >including the extra cost of navigating between the existing patents.\n> > >\n> > >Kind regards,\n> > >\n> > >Olivier\n> > >\n> > > > > >> Flavor Software is proud to release the first commercial\n> > > > > MPEG-4 player\n> > > > > >> and authoring software. The Mild Flavor(tm) player and\n> > > > > sample MP4 files\n> > > > > >> featuring New York City indi bands \"The Pasties\", \"Brave\n> > > > > New Girl\", and\n> > > > > >> \"The Rosenbergs\" are available for download from the\n> > > > > Flavor Software web\n> > > > > >> site.\n> > > > > >>\n> > > > > >> Go to http://www.flavorsoftware.com and click on downloads.\n> > > > > >>\n> > > > > >> Spread the joy... tell your friends to go to the Flavor\n> > > > > web site and get\n> > > > > >> into MP4! Even better... create your own MP4 files and\n> > > > > send them to your\n> > > > > >> friends!  -- The Flavor Team\n>\n\n\n\n", "id": "lists-007-15813649"}, {"subject": "RE: MP4 Player Available for Downloa", "content": "Hi Dave,\n\nReplies inline....\n\nAt 06:28 PM 3/30/01 -0800, Dave Singer wrote:\n>you may be right about the licensing of MPEG-4 in general;  but I believe \n>I have told this group already the best of my knowledge on the licensing \n>of the file format, so I am a little disappointed that you should end up \n>on that particular subject.\n\nMy parting shot wasn't intended for strictly the file format as you \nprobably think of it, but in terms of a general interoperable blob of a/v \ndata that includes audio, video, and the structure of the file format.  If \n.foo is an interoperable multimedia file format, and there are two .foo \nplayers, they should have all of the necessary components to interoperate.\n\nFor those of you not familiar with the distinction, in the multimedia world \nthere's a pretty distinct separation between the codec used (such as H.261 \nvideo, or G.711 audio), and the container its put in (such as Quicktime's \n.mov format, Microsoft's .asf, .avi, and .wav formats, RealNetworks .rm \nformat, or the .mp4 format in the MPEG-4 v2 spec).  A minor additional \ncomplexity is that the codecs have to be inserted into the container file \nusing the same conventions (same codec identifier, interoperable codec \nparameters, etc).  What Dave is referring to is the container itself.\n\nNow Dave, since you are practically begging me to respond to your earlier \nmail....  :)\n\nFor the benefit of those not on the full thread, I've included the full \nemail from Dave at the bottom of this message.  Here's the snippit I want \nto respond to, though:\n\nAt 10:00 AM 3/14/01 -0800, Dave Singer wrote:\n>I hate to carry on an off-topic thread, but the MPEG-4 file format is not \n>heavily encumbered.  To my knowledge, we (Apple) are the only IPR owners \n>in the file format per se, and the license needed would be the same as for \n>the QT file format (i.e. it's the same IPR), for which we have plenty of \n>examples of licensees (including Real Networks).\n\nAre you really willing to stand up and disclose the terms of the \nApple/RealNetworks agreement?  I think it's entirely inappropriate to cite \nthe Apple/RealNetworks agreement as an example of an MPEG-4 file format \nlicensing success story, and entirely inappropriate to discuss the terms of \nany deal that go beyond the joint press release:\n\nhttp://www.realnetworks.com/company/pressroom/pr/2000/apple.html\n\nBesides that, I don't think it's at all reasonable that if RealNetworks and \nsome other company/project want to interoperate, that that other \ncompany/project should have to go to Apple to get permission.  Do you?\n\nRob\n\n\n>X-Sender: singer@mail.apple.com (Unverified)\n>Date: Wed, 14 Mar 2001 10:00:03 -0800\n>To: Rob Lanphier <robla@real.com>\n>From: Dave Singer <singer@apple.com>\n>Subject: Re: File formats (RE: MP4 Player Available for Download)\n>Cc: \"'rem-conf@es.net'\" <rem-conf@es.net>\n>\n>At 9:35 AM -0800 3/14/01, Rob Lanphier wrote:\n>>At 11:54 AM 3/13/01 -0800, Bill Nowicki wrote:\n>>>We just tried the obvious experiment.\n>>>\n>>>The \".mp4\" files on the \"Flavor\" site do not play with the\n>>>Philips player, and the Philips \".mp4\" files do not play with\n>>>the Flavor player. Sounds like a litle inter-operability\n>>>testing might have been in order before calling them the same\n>>>name!\n>>>\n>>>(and of course file format standards are outside the charter\n>>>of IETF, but are still useful)\n>>\n>>Not that I'm disagreeing with you here, but an honest question for \n>>you:  whose charter includes specifying file formats?  Clearly, ISO/MPEG \n>>have taken it on, but they've also created a situation where I think \n>>genuine interoperability is out of the question for anyone who either \n>>doesn't have a patent licensing agreement from 30 different companies, or \n>>who chooses to ignore the issue.\n>>\n>>Is there a standards group out there who does file formats who would \n>>actually work toward an unencumbered format?\n>>\n>>Rob\n>\n>I hate to carry on an off-topic thread, but the MPEG-4 file format is not \n>heavily encumbered.  To my knowledge, we (Apple) are the only IPR owners \n>in the file format per se, and the license needed would be the same as for \n>the QT file format (i.e. it's the same IPR), for which we have plenty of \n>examples of licensees (including Real Networks).\n>\n>ISMA will be testing interop very carefully, as Philippe says.  And there \n>have been interop tests done under the conformance group at MPEG-4.\n>\n>Now, the encumbrance of MPEG-4 in general is a different matter, as anyone \n>who follows m4if will attest....\n>--\n>David Singer\n>Apple Computer/QuickTime\n\n\n\n", "id": "lists-007-15838987"}, {"subject": "User/Admin selection of authentication mechanisms by   &quot;strength&quot; leve", "content": "Your comments on the following I-D are solicited.\n\nTitle: Authentication Mechanisms Levels\nFilename: draft-zeilenga-auth-lvl-01.txt\n\n  Numerous authentication mechanisms are in use today on the Internet.\n  It is desirable to give administrators the choice of which mechanisms\n  to support in their deployments and to give users the choice which\n  mechanisms to use.  This document offers terminology designed to be\n  easily understandable by users and administrators of Internet\n  services, while being meaningful to designers and developers of these\n  services and associated Internet protocols.\n\nThanks, Kurt\n\n\n\n", "id": "lists-007-15880655"}, {"subject": "Intelligence in standards-based softwar", "content": "IETF has a set of \"golden rules\". The two most well-known\nrules are:\n\n(1) Be conservative in what you send, liberal in what\n     you accept.\n\n(2) Do not munge (= modify information objects you\n     are just transferring)\n\nI am beginning to understand that there is a need for\na new golden rule:\n\n(n) Do not specify standards which require any kind\n     of intelligence of the software using it.\n\nOne example which shows the importance of this new golden rule is the\nproblem with multipart/alternative and different body parts\ncontaining the same text in different languages. Such use of\nmultipart/alternative is correct according to the MIME standard (RFC\n1522, RFC 2046) only says that this are different alternative\nrenderings of the same information, but does not say what the\ndifference is. The receiving mailers must then analyze what is\ndifferent between the body parts, in order to find out which piece is\nbest according to the needs of a particular user. And to make this\ndecision requires more intelligence than is reasonable to expect of a\nmail software. Much less intelligence is needed if the \"difference\"\nattribute to multipart/alternative is used (that attribute is\nspecified in RFC 1766\n\nAs I have poisnted out in previous messages to this mailing list,\nsuch use of multipart/alternative causes disastrous problems with\nmany popular existing mailers. The original MIME standard did not\nhave the \"difference\" attribute\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-15887731"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "> I am beginning to understand that there is a need for\n> a new golden rule:\n> \n> (n) Do not specify standards which require any kind\n>      of intelligence of the software using it.\n\nIf that were a rule, very few of our protocols would pass muster.\n\nI think you are grossly overexaggerating the problems with multipart/\nalternative.   As far as I can tell, the biggest problem with \nmultipart/alternative is that the set of attributes on which a \nchoice between alternatives might be based is extensible - it includes\nnot only content-type and its parameters, but also content-language,\nand perhaps other attributes not yet invented.   It's difficult to \nimagine how to write a user agent that can effectively make choices \nbetween alternatives based on attributes whose syntax and semantics \nare not yet defined.\n\nKeith\n\n\n\n", "id": "lists-007-15897134"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application /BatchBee", "content": "At 12.55 -0700 01-04-24, Dave Crocker wrote:\n>Alas, it uses far more than that...\n>\n>>     <from>\n>>       <user-friendly-name>\n>           <friendly-name-char>F</friendly-name-char>\n>           <friendly-name-char>a</friendly-name-char>\n>           <friendly-name-char>t</friendly-name-char>\n>           <friendly-name-char>h</friendly-name-char>\n>           <friendly-name-char>e</friendly-name-char>\n>           <friendly-name-char>r</friendly-name-char>\n>           <friendly-name-char> </friendly-name-char>\n>           <friendly-name-char>C</friendly-name-char>\n>           <friendly-name-char>h</friendly-name-char>\n>           <friendly-name-char>r</friendly-name-char>\n>           <friendly-name-char>i</friendly-name-char>\n>           <friendly-name-char>s</friendly-name-char>\n>           <friendly-name-char>t</friendly-name-char>\n>           <friendly-name-char>m</friendly-name-char>\n>           <friendly-name-char>a</friendly-name-char>\n>           <friendly-name-char>s</friendly-name-char>\n>         </user-friendly-name>\n\nThere is no reason to do this. The different characters\nare not separate logical entities, which need to be separated\nin processing. In an e-mail name like:\n\n    John Smith <johns@foo.bar.net>\n\n\"John Smith\", \"johns\", \"foo\", \"bar\" and \"net\" are distinct\nlogical entitites which need to be separated in order to\nuse the information to transport for example a personal\nreply to the sender of the replied-to message.\n\nThe characters \"<\", \"@\", \".\" and \">\" are syntactic separators,\nput there in order to allow software to do this separation.\n<user-friendly-name>, <localpart>, <domain>, etc. are an\nXML way of specifying the same separation.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-15905361"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application /BatchBee", "content": "At 20.29 +0200 01-04-24, Jacob Palme wrote:\n>The main principle of efficient coding of protocols is to only send \n>the information which varies over time. Information which is static, \n>like\n>the names of the fields, is either suppressed or compacted very strongly.\n>It is this compacting of this information which is a main reason why\n>the ASN.1 encoding got so compact.\n\nAt 15.17 -0400 01-04-24, Keith Moore wrote:\n>This isn't a feature of ASN.1.  It's a feature of encoding the\n>field names implicitly via their position in the data stream vs.\n>encoding them explicitly with tags.  ASN.1 can do this either\n>way.  For instance, SNMP uses ASN.1 but tags each datum with an OID.\n\nOK. I see your point now. One might also say that the RFC822\nand XML formats offer an extension possibility, by adding new\nheader-names, which a recipient code which does not recognize\nthem can disregard.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-15915813"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application /BatchBee", "content": "> In an e-mail name like:\n> \n>     John Smith <johns@foo.bar.net>\n> \n> \"John Smith\", \"johns\", \"foo\", \"bar\" and \"net\" are distinct\n> logical entitites which need to be separated in order to\n> use the information to transport for example a personal\n> reply to the sender of the replied-to message.\n\nfor most purposes these entities do not need to be separated any more\nthan the individual letters.  and it's arguably better if certain\nfields of an address aren't identified separately to every thing that \nhandles an email message - for instance, only the primary mail exchanger\nfor the domain of an address should be treating the local-part of that\naddress separately.\n\n> The characters \"<\", \"@\", \".\" and \">\" are syntactic separators,\n> put there in order to allow software to do this separation.\n\nas well as to be friendly to humans.  \nputting XML inside an email address would be a disaster.\n\nKeith\n\n\n\n", "id": "lists-007-15924578"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and Application   /BatchBee", "content": "At 11:02 PM 5/2/2001, Jacob Palme wrote:\n>There is no reason to do this.\n...\n>The characters \"<\", \"@\", \".\" and \">\" are syntactic separators,\n\nJacob,\n\nThanks for the lesson in parsing.\n\nI never said that the extended example was an excellent design choice.  It \nwas provided to demonstrate that there is considerable choice available to \nthe person doing the specification.\n\nIn fact, you ignored the end of my note, citing a real-world specification \nthat is substantially different from the XML example that you \nchose.  Although it takes more characters than a pure RFC822 address, it is \nnot as onerous as yours.\n\nd/\n\n\n----------\nDave Crocker   <mailto:dcrocker@brandenburg.com>\nBrandenburg InternetWorking   <http://www.brandenburg.com>\ntel: +1.408.246.8253;   fax: +1.408.273.6464\n\n\n\n", "id": "lists-007-15933766"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "At 17.16 -0400 01-05-02, Keith Moore wrote:\n>  > I am beginning to understand that there is a need for\n>>  a new golden rule:\n>>\n>>  (n) Do not specify standards which require any kind\n>>       of intelligence of the software using it.\n>\n>If that were a rule, very few of our protocols would pass muster.\n>\n>I think you are grossly overexaggerating the problems with multipart/\n>alternative.   As far as I can tell, the biggest problem with\n>multipart/alternative is that the set of attributes on which a\n>choice between alternatives might be based is extensible - it includes\n>not only content-type and its parameters, but also content-language,\n>and perhaps other attributes not yet invented.\n\nThe problem is that if I send a message in the format\n\"multipart/alternative\" with different languages in the\ndifferent body parts, then most major mailers will\nonly show the recipient one of the body parts, not\nselected based on the language preferences of the\nrecipient, and will not even tell the recipient that\nthere are other body parts.\n\nIn practice this means that no sensible person will\never send different language versions using\nmultipart/alternative. What is the meaning of sending\na message in more than one language, if the recepient\nmay get the message in a language which the recipient\ncannot read.\n\nI regularly get e-mail in French, which I cannot read, and\nI use http://www.systransoft.com/ to get them translated\nto English. That is rather cumbersome for me. That is\nwhy I want to develop software such that I will automatically\nget the message in the languages I can read. And such software\ncannot use multipart/alternative, the way it works today\nin major mailers.\n\nAt 17.16 -0400 01-05-02, Keith Moore wrote:\n>It's difficult to\n>imagine how to write a user agent that can effectively make choices\n>between alternatives based on attributes whose syntax and semantics\n>are not yet defined.\n\nExactly. That is why it was a mistake, that the MIME standard\nallowed use of multipart/alternative with other differences\nbetween the alternatives than Content-Type, and without aiding\nthe receiver (in the original MIME text) to select the right\npart to display to the user. That is exactly the kind of\nintelligence which standards should not require software to\nhave.\n\nIt might have worked, if the MIME standard from the beginning\nhad included the \"difference\" attribute to multipart/alternative,\nand had very strongly said that a mailer which cannot handle\nthe value of the \"difference\" attribute, should treat the\nmultipart/alternative as multipart/mixed.\n\nThe \"difference\" attribute should either have been mandatory, or the\nstandard should say that its absence defaults to \"Content-Type\".\n\nAddition of a mandatory \"difference\" parameter will reduce\nthe intelligence required of the receiving process to\na much more reasonable level.\n\nNow, however, I believe it is too late. It will not be possible\nto get mailers to change their implementation to support\na feature (different content-types in different languages)\nwhich no one ever uses (for reasons described above).\n\nSome possible choices today are:\n\n(a) A new kind of Content-Type: multipart/choices.\n     (Which in practice is almost the same as using\n     multipart/mixed).\n\n(b) Send multi-language messages as multipart/mixed.\n\n(c) Send multi-language messages in HTML format as\n     multipart/related. The first page the user sees\n     would then show a list of languages, the user\n     clicks on the preferred language.\n\n(d) As (c) but all languages in the same HTML document,\n     with a language-choice bar at the top which links\n     locally within the HTML document.\n\nWhen we start implementing this, I will have to test\nhow major existing mailers can handle these alternatives.\n\nWe will *not* implement something which is theoretically\nright according to the standards, but which will work\ndiastrously poor for the users receiving messages in\nmore than one language.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-15942519"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "Jacob Palme wrote:\n\n\n> The problem is that if I send a message in the format\n> \"multipart/alternative\" with different languages in the\n> different body parts, then most major mailers will\n> only show the recipient one of the body parts, not\n> selected based on the language preferences of the\n> recipient, and will not even tell the recipient that\n> there are other body parts.\n\nThe \"will not even tell the recipient\" seems to me to be the real \nproblem.\n\nI've recently come to the opinion that transparency in electronic \ndocument formats and viewers is critically important to wider \nacceptance of them in (non-geek) society.  One of the very real \ndifferences between a paper document and an electronic one is that \nwith the paper document you can, when using the normal viewing mode \n(looking at it with sufficient ambient light :-), see everything \nthat is in the document; with an electronic document you normally \nsee some rendering onto a display - even the author may not be aware \nof everything that is actually contained in the document.  All \ndocument viewing applications should provide a choice of viewing \nmodes, one of which should always be to display the lowest level \npossible encoding (view source in an html browser being a good \nexample).\n\nTo your original point - why shouldn't the MUA provide an indication \nthat alternatives are available, a display of the Content-* values \nfor each alternative, and allow manual override of the selection? \nYour problem disappears, and so does the problem of dealing with \ndifference attributes that were not anticipated when the program was \nwrittten.\n\n-- \nScott Lawrence      Architect            slawrence@virata.com\nVirata       Embedded Web Technology    http://www.emweb.com/\n\n\n\n", "id": "lists-007-15954398"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "> At 17.16 -0400 01-05-02, Keith Moore wrote:\n> >  > I am beginning to understand that there is a need for\n> >>  a new golden rule:\n> >>\n> >>  (n) Do not specify standards which require any kind\n> >>       of intelligence of the software using it.\n> >\n> >If that were a rule, very few of our protocols would pass muster.\n> >\n> >I think you are grossly overexaggerating the problems with multipart/\n> >alternative.   As far as I can tell, the biggest problem with\n> >multipart/alternative is that the set of attributes on which a\n> >choice between alternatives might be based is extensible - it includes\n> >not only content-type and its parameters, but also content-language,\n> >and perhaps other attributes not yet invented.\n> \n> The problem is that if I send a message in the format\n> \"multipart/alternative\" with different languages in the\n> different body parts, then most major mailers will\n> only show the recipient one of the body parts, not\n> selected based on the language preferences of the\n> recipient, and will not even tell the recipient that\n> there are other body parts.\n\nright.  but this is a problem inherent in any new feature - you can\nhardly expect existing user agents to do something reasonable with\na construct that has never been tried before.\n\ndefining a new content-type doesn't help this problem much, if at\nall - either the recipient's mailer *still* refuses to show the\ntext, or the mailer treats as multipart/mixed and displays all of the\nparts (which can be quite annoying).  neither is satisfactory.\n\n> I regularly get e-mail in French, which I cannot read, and\n> I use http://www.systransoft.com/ to get them translated\n> to English. That is rather cumbersome for me. That is\n> why I want to develop software such that I will automatically\n> get the message in the languages I can read. And such software\n> cannot use multipart/alternative, the way it works today\n> in major mailers.\n\nthere's nothing stopping new software from using multipart/alternative\nto distinguish between text in different languages and display the\ntext in the user's preferred language.  your complaint appears to be \nthat old software will not do this.\n\nnor is there anything stopping you from writing a filter that will\nrecognize French mail and translate it to English.  you don't need\nmultipart/choices to do this.\n\nEven if you wanted this filter to act at message presentation time\nrather than at say delivery time, having multipart/choices wouldn't\nhelp you create a hook for converting French mail to English.\n\nKeith\n\n\n\n", "id": "lists-007-15963785"}, {"subject": "RE: Replacing the Label header with a DAV:labeled-version repor", "content": "Geoff,\n\none concern, almost the same as with the old approach (PROPFIND with label\nheader):\n\nWhich hrefs should be reported? I think the href property should be the URI\nof the version, not the one of the VCR or the VHR.\n\nAlso: what is the DAV:version property that appears in the example?\n\nJulian\n\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, June 28, 2002 9:18 PM\n> To: 'Deltav WG'\n> Subject: RE: Replacing the Label header with a DAV:labeled-version\n> report\n>\n>\n>\n> So far, everyone has either agreed or remained silent on this topic,\n> so as a motivator for anyone objecting to speak up (:-), I will mark this\n> issue\n> as resolved in the errata, with the resolution being that the Label\n> header will be deprecated, and the DAV:labeled-version REPORT inserted\n> in its place.  In particular, I propose the following definition for\n> the DAV:labeled-version REPORT:\n>\n> -------------------\n>\n> 8.3DAV:labeled-version Report\n> The DAV:labeled-version report describes the requested properties\n> of the version with that label in a specified version history.\n> If the DAV:labeled-version report is applied to a version-controlled\n> resource, it is applied to the DAV:version-history of that\n> version-controlled resource.\n>\n> Marshalling:\n>\n> The request body MUST be a DAV:labeled-version XML element.\n>\n> <!ELEMENT labeled-version ANY>\n>\n> ANY value: a sequence of zero or more elements, with\n> at most one DAV:prop element and with exactly one\n> DAV:label-name element.\n>\n> prop: see RFC 2518, Section 12.11\n>\n> The response body for a successful request MUST be a DAV:multistatus\n> XML element.\n>\n> multistatus: see RFC 2518, Section 12.9\n>\n> The response body for a successful DAV:labeled-version REPORT\n> request MUST contain a DAV:response element for each resource\n> that satisfies the Depth header of the request.\n>\n> 8.3.1Example - DAV:labeled-version Report\n>\n> >>REQUEST\n>\n>   REPORT /folder/ HTTP/1.1\n>   Host: www.webdav.org\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>   Depth: 1\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:labeled-version xmlns:D=\"DAV:\">\n>     <D:label-name>tested</D:label-name>\n>     <D:prop>\n>       <D:version-name/>\n>       <D:version/>\n>     </D:prop>\n>   </D:labeled-version>\n>\n> >>RESPONSE\n>\n>   HTTP/1.1 207 Multi-Status\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:multistatus xmlns:D=\"DAV:\">\n>     <D:response>\n>       <D:href>http://www.webdav.org/folder/</D:href>\n>       <D:propstat>\n>         <D:prop>\n>           <D:version-name>V5</D:version-name>\n>           <D:creator-displayname>Fred</D:creator-displayname>\n>           <D:version>\n>             <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n>           </D:version>\n>         </D:prop>\n>         <D:status>HTTP/1.1 200 OK</D:status>\n>       </D:propstat>\n>     </D:response>\n>     <D:response>\n>       <D:href>http://www.webdav.org/folder/foo.html</D:href>\n>       <D:propstat>\n>         <D:prop>\n>           <D:version-name>V8</D:version-name>\n>           <D:version>\n>             <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n>           </D:version>\n>         </D:prop>\n>         <D:status>HTTP/1.1 200 OK</D:status>\n>       </D:propstat>\n>     </D:response>\n>   </D:multistatus>\n>\n> -----------------------------------------\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Clemm, Geoff [mailto:gclemm@Rational.Com]\n> Sent: Sunday, April 28, 2002 9:53 AM\n> To: 'Deltav WG'\n> Subject: Replacing the Label header with a DAV:labeled-version report\n>\n>\n> Since this is a fairly significant change, I'd like to\n> hear from a few more folks before adding this to the 3253 Errata.\n>\n> Thanks,\n> Geoff\n>\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Saturday, April 27, 2002 5:09 AM\n> To: Clemm, Geoff; 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Friday, April 26, 2002 6:06 PM\n> > To: 'Deltav WG'\n> > Subject: RE: Label header vs PROPFIND depth 1\n> >\n> >\n> >    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> >\n> >    - I'd like to see the label *header* deprecated\n> >    - I'm happy with the LABEL method and the label-name-set property\n> >    - I think that PROPFIND/label should be replaced by a specific REPORT\n> >\n> > Is the proposed DAV:labeled-version report OK with you?\n>\n> Yes. But I think it's Tim's turn to say whether this would work for him or\n> not...\n>\n> >    - I'm unsure about other methods that are currently affected by the\n> >    header -- what were the requirements...?\n> >\n> > The other methods are LABEL, CHECKOUT, GET, and COPY.\n> > For Depth:0 variants of these operations, the Label header\n> > just provided an optimization to save one roundtrip\n> > (i.e. first getting the version URL via the DAV:labeled-version report).\n> > I believe we can easily do without that Depth:0 optimization.\n>\n> As stated before, I think that's not the single problem. Having\n> GET return a\n> (representation of a) version rather than (a representation of) the VCR\n> makes the version *by definition* a variant (representation) of the VCR --\n> and it seems that most of us want to avoid that interpretation.\n>\n> > For Depth:infinity (only relevant for LABEL and COPY), the savings\n> > would be more significant, but unfortunately the semantics is broken\n> > (since if the namespace is being versioned, you'll get the wrong\n> > resources if you simply do a Depth operation on the current namespace).\n> >\n> > The Depth:infinity Label header operations are really just a way of\n> > trying to have the client fake workspaces and baselines, instead of\n> > having the server support them directly.  Since it is much more\n> > efficient and reliable to have the server layer these constructs\n> > above a labeling infrastructure, rather than having the client do\n> > so, I believe the cost of maintaining these Depth:infinity Label\n> > header operations in the protocol is not warranted.\n> >\n> > Note though that (depth:0) labeling and baselining go very well\n> > together.  Instead of doing a Depth:infinity LABEL, you can create a\n> > baseline (which under the hood the server may well implement with\n> > reserved labels, but maybe not), and then LABEL that baseline.  Then\n> > when you want to do a Depth:infinity COPY, you retrieve the\n> > DAV:baseline-collection of the labeled baseline (using the\n> > DAV:labeled-version report), and copy that to wherever you want.\n> >\n> > Alternatively, if you want a \"modifiable\" selection, you can create a\n> > workspace (which under the hood the server may well implement with\n> > reserved labels, but maybe not).  When you want to adjust the versions\n> > being selected, you just use UPDATE.  Then when you want to do a\n> > Depth:infinity COPY, you just copy from that workspace to wherever you\n> > want.\n> >\n> >    - Servers that decide to implement LABEL and DAV:label-name-set,\n> >    but no not support the label header should *not* report the LABEL\n> >    feature in OPTIONS.\n> >\n> > That's probably right.  A client can find out if the LABEL operation\n> > is supported by querying the DAV:supported-method-set property values\n> > of a VCR.\n>\n> ...and also use DAV:supported-live-property-set to discover the\n> DAV:label-name-set property.\n>\n>\n\n\n\n", "id": "lists-007-1596584"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "> > The problem is that if I send a message in the format\n> > \"multipart/alternative\" with different languages in the\n> > different body parts, then most major mailers will\n> > only show the recipient one of the body parts, not\n> > selected based on the language preferences of the\n> > recipient, and will not even tell the recipient that\n> > there are other body parts.\n\n> right.  but this is a problem inherent in any new feature - you can\n> hardly expect existing user agents to do something reasonable with\n> a construct that has never been tried before.\n\n> defining a new content-type doesn't help this problem much, if at\n> all - either the recipient's mailer *still* refuses to show the\n> text, or the mailer treats as multipart/mixed and displays all of the\n> parts (which can be quite annoying).  neither is satisfactory.\n\nExactly. We defined something in a standard that hasn't been implemented by\nuser agents to your satisfaction, and now you hope to solve this problem by\ndefining something that's essentially the same but labelled differently. I'm\nsorry, but I fail to see any reason why multipart/choices will work out any\nbetter in this regard. Standards can only do so much.\n\nNed\n\n\n\n", "id": "lists-007-15973686"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "I disagree with all three of the proposed rules.\n\n\"be liberal in what you accept\" leads to non-interoperability when \ninterpreted too broadly.\n\nMunging can be a good idea when changing data in a way that improves the \nreceiver's ability to render it.  Munging ill-formed data can improve \ninteroperability if done appropriately.\n\nNecessary intelligence is important in software.  NTP has to be rather \nintelligent to work correctly.  And it works quite well.\n\nThe multipart/alternative spec probably just failed to provide enough UI \nadvice.  But Mulberry implemented it correctly.\n\n- Chris\n\n\n\n", "id": "lists-007-15982738"}, {"subject": "New draft: Application/Multiplexe", "content": "I have submitted a new IETF draft on the Application/Multiplexed\nContent-Type. Its URL is\nhttp://search.ietf.org/internet-drafts/draft-herriot-application-multiplexed\n-00.txt\n\nThis draft is simpler than the two previous drafts for Application/BatchBeep\nand Multipart/Interleaved and results from feedback about the two previous\ndrafts.\n\nAn Application/Multiplexed entity consists of one or more chunks. Each chunk\nstarts with a chunk header line whose syntax is:\n\n\"CHK\" SP messageNumber SP length SP isMore CR LF\n\nFor example, message 3 split into two chunks might have the headers \n\"CHK 3 512 Y CR LF\" and \"CHK 3 358 N CR LF\". \n\nThe last chunk is an empty chunk with just the header line \"CHK 0 0 N CR\nLF\".\n\nI intend for the proposed solution to solve a useful class of printing\nproblems that Multipart/Related does not solve.  I also recognize that a\nprotocol would solve and even wider class of problems, but there are cases\nin the printing world where a single stream of bytes is a better solution\nthan a protocol, e.g. when the submitter of the print job doesn't hang\naround until the printing occurs.\n\nI would appreciate comments.\n\nBob Herriot\n\n\n\n", "id": "lists-007-15990563"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "On 5/3/01 at 4:16 PM -0700, <ned.freed@mrochek.com> wrote:\n\n>  > > The problem is that if I send a message in the format\n>>  > \"multipart/alternative\" with different languages in the\n>>  > different body parts, then most major mailers will\n>  > > only show the recipient one of the body parts\n>\n>  > right.  but this is a problem inherent in any new feature - you can\n>  > hardly expect existing user agents to do something reasonable with\n>  > a construct that has never been tried before.\n\nNonsense. This is not a problem with a \"new feature\". The spec said \nsomething very specific about implementation (which I'll get to \nbelow) and unfortunately that ended up pushing clients toward a poor \nimplementation choice for this particular use.\n\n>  > defining a new content-type doesn't help this problem much, if at\n>  > all - either the recipient's mailer *still* refuses to show the\n>  > text, or the mailer treats as multipart/mixed and displays all of the\n>  > parts (which can be quite annoying).  neither is satisfactory.\n\nOr the new content-type definition gives specific text about what it \nis to be used for and implementors will have better guidance to \naddress the problem at hand.\n\n>Exactly. We defined something in a standard that hasn't been implemented by\n>user agents to your satisfaction\n\nNo, what was written in 2046 actually encouraged implementors to \"do \nthe wrong thing\" (section 5.1.4):\n\n    As with \"multipart/mixed\", the order of body parts is\n    significant.  In this case, the alternatives appear in an order of\n    increasing faithfulness to the original content.  In general, the\n    best choice is the LAST part of a type supported by the recipient\n    system's local environment.\n\nand:\n\n    Receiving user agents should pick and display the last format\n    they are capable of displaying.\n\nThe semantics of multipart/alternative are defined in such a way that \nthey assume there is generally one \"best choice\" for it's \n\"faithfulness to the original content.\" The definition given in 2046 \ndoes not adequately address the case where the alternatives are \ncompletely equal in value from the perspective of the sender and \nrecipient user agents, that the order of the parts is not significant \nat all, and that the alternatives only differ in their relative value \nto the *human recipient*. Had such an example been discussed \nexplicitly, and explicit direction been given to implementors that \nuser agents would do well to allow humans to choose to display any of \nthe parts that they wished, less user agents would have gone for the \n\"display the last alternative that you can display and throw away the \nrest\" implementation.\n\nPerhaps before going to full standard, such text could be explicitly \nput into the text.\n\npr\n-- \nPete Resnick <mailto:presnick@qualcomm.com>\nQUALCOMM Incorporated - Direct phone: (858)651-4478, Fax: (858)651-1102\n\n\n\n", "id": "lists-007-15999093"}, {"subject": "Re: New draft: Application/Multiplexe", "content": "if this is really intended just to solve some printing problems, how\nabout calling it something like application/multiplexed-printer-data\nor some such?  I hate to see something which is intended as a stopgap\nmeasure given a name that makes it look like a general-purpose facility.\n\n\n\n", "id": "lists-007-16010367"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "> > Exactly. We defined something in a standard that hasn't been implemented by\n> > user agents to your satisfaction\n\n> No, what was written in 2046 actually encouraged implementors to \"do\n> the wrong thing\" (section 5.1.4):\n\n>     As with \"multipart/mixed\", the order of body parts is\n>     significant.  In this case, the alternatives appear in an order of\n>     increasing faithfulness to the original content.  In general, the\n>     best choice is the LAST part of a type supported by the recipient\n>     system's local environment.\n\n> and:\n\n>     Receiving user agents should pick and display the last format\n>     they are capable of displaying.\n\n> The semantics of multipart/alternative are defined in such a way that\n> they assume there is generally one \"best choice\" for it's\n> \"faithfulness to the original content.\" The definition given in 2046\n> does not adequately address the case where the alternatives are\n> completely equal in value from the perspective of the sender and\n> recipient user agents, that the order of the parts is not significant\n> at all, and that the alternatives only differ in their relative value\n> to the *human recipient*. Had such an example been discussed\n> explicitly, and explicit direction been given to implementors that\n> user agents would do well to allow humans to choose to display any of\n> the parts that they wished, less user agents would have gone for the\n> \"display the last alternative that you can display and throw away the\n> rest\" implementation.\n\nThis argument might wash if it was the only thing written about the semantics\nof multipart/alternative. But it isn't. In fact we're not talking about what\nRFC 2046 says here at all, we're talking about RFC 1766, where the\nfunctionality of multipart/alternative was significantly extended past what's\ncovered in RFC 2046. (I think the addition of a new parameter that entirely\nchanges how you're supposed to interpret multipart/alternative qualifies as a\nsignificant extension.)\n\nIn fact the effect of section 4 of RFC 1766 on the semantics of\nmultipart/alternative is to extend it in exactly the way you describe: You can\nnow have a situation where there's no \"best\" part per se and the differences\nparameter tells you how to choose the right one for a given user.\n\nNow, maybe you would like to argue that the text in RFC 1766 isn't sufficiently\nclear to understand what needs to be done to handle generalized alternatives\ncorrectly. And I might even agree with that assessment. But I don't think you\ncan claim that you received no indication whatsoever that the simplistic\n\"last one you can display\" approach described in RFC 2046 had been\nextended.\n\nIncidentially, it would have been nice to include the RFC 1766 text in RFC\n2046, however, RFC 2046 is a revision of a draft standard (RFC 1521) and at the\ntime RFC 1766 was only proposed. So I couldn't add it without forcing a recycle\nat proposed. Heck, it could not even be referenced, since such a reference\nwould obviously be normative.\n\n> Perhaps before going to full standard, such text could be explicitly\n> put into the text.\n\nGiven that the text in RFC 1766 about this approach has been dropped in RFC\n3066 due to lack of interest on the part of implementors, I see no chance\nof adding it to MIME itself during a move from draft to full standard.\n\nNed\n\n\n\n", "id": "lists-007-16017839"}, {"subject": "Re: Two new drafts: Multipart/Interleaved and  Application /BatchBee", "content": "At 09.11 -0400 01-05-03, Keith Moore wrote:\n>  > In an e-mail name like:\n>>\n>>      John Smith <johns@foo.bar.net>\n>>\n>>  \"John Smith\", \"johns\", \"foo\", \"bar\" and \"net\" are distinct\n>>  logical entitites which need to be separated in order to\n>>  use the information to transport for example a personal\n>>  reply to the sender of the replied-to message.\n>\n>for most purposes these entities do not need to be separated any more\n>than the individual letters.  and it's arguably better if certain\n>fields of an address aren't identified separately to every thing that\n>handles an email message - for instance, only the primary mail exchanger\n>for the domain of an address should be treating the local-part of that\n>address separately.\n>\n>>  The characters \"<\", \"@\", \".\" and \">\" are syntactic separators,\n>>  put there in order to allow software to do this separation.\n>\n>as well as to be friendly to humans.\n>putting XML inside an email address would be a disaster.\n\nI agree. My example was not intended to say that XML would\nbe better in this case. It was just meant as a basis for\nthe comparison of XML and RFC822.\n\nAt 09.08 -0700 01-05-03, Dave Crocker wrote:\n>In fact, you ignored the end of my note, citing a real-world \n>specification that is substantially different from the XML example \n>that you chose.  Although it takes more characters than a pure \n>RFC822 address, it is not as onerous as yours.\n\nI am not saying that the examples in the end of your message are\nwrong. Combining different encoding methods within data sent\nis common and sometimes useful, even if it is not neat.\n\nSince XML does not have any format for transmitting binary\ndate, it forces users of XML to use some other encoding format\nthan XML if they need to transmit binary data. That is one\nof the main drawbacks of XML, compared to ASN.1-BER.\n\nOne main advantage with RFC822 e-mail addresses is that they\nare short (compared to, for example, X.400 addresses). That\nis probably one of several reasons which Internet mail has\nsucceeded and X.400 has not. The shortness is of value to\nhumans, who want to copy it from, for example, a business\ncard. From a user point of view, the choice of \"@\" as a\nseparator was maybe a mistake, a common beginners complaint\nis \"where do I find '@' on my keyboard\".\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16030052"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "At 14.50 -0400 01-05-03, Scott Lawrence wrote:\n>To your original point - why shouldn't the MUA provide an indication \n>that alternatives are available, a display of the Content-* values \n>for each alternative, and allow manual override of the selection? \n>Your problem disappears, and so does the problem of dealing with \n>difference attributes that were not anticipated when the program was \n>writtten.\n\nNo problem with me. That is good way for a MUA to handle this.\nHowever, none of the mailers I tested works like this. And I\nthink it will be very difficult to get MUA implementors to\nchange their implementations in order to better receive\nmessages in a format which no one sends any message in.\n\nAt 16.17 -0400 01-05-03, Keith Moore wrote:\n>right.  but this is a problem inherent in any new feature - you can\n>hardly expect existing user agents to do something reasonable with\n>a construct that has never been tried before.\n\nThe normal IETF practice is to specify new features so that they\ndowngrade gracefully to older mailers.\n\n>defining a new content-type doesn't help this problem much, if at\n>all - either the recipient's mailer *still* refuses to show the\n>text, or the mailer treats as multipart/mixed and displays all of the\n>parts (which can be quite annoying).  neither is satisfactory.\n\nTreating it as multipart/mixed and showing all the body parts\nis *much* better than showing only one body part in the wrong\nlanguage, and not telling the user that there are other body\nparts in other languages.\n\nAt 16.17 -0400 01-05-03, Keith Moore wrote:\n>there's nothing stopping new software from using multipart/alternative\n>to distinguish between text in different languages and display the\n>text in the user's preferred language.  your complaint appears to be\n>that old software will not do this.\n\nThat will only work when sender and recipient both use the\nsame, enhanced software. But when sender and recipient both\nuse the same software, no standards are needed. Standards are\nfor cases where the sender and recipient uses different\nsoftware.\n\nAt 16.17 -0400 01-05-03, Keith Moore wrote:\n>nor is there anything stopping you from writing a filter that will\n>recognize French mail and translate it to English.  you don't need\n>multipart/choices to do this.\n\nThat is a solution which will work for recipients who get messages\nin languages they cannot read. It would help for me in the case\nI describe above. But it will not help when I send answers,\nunless I make my own MUA so intelligent that it send, to each\nrecipient of the answer, its translation to the language of\nthat user. And that is not a good choice either, many recipients\ncan understand more than one language, and may for example\nprefer to see a message in its original English, rather than\nin bad machine-translated French.\n\n>Even if you wanted this filter to act at message presentation time\n>rather than at say delivery time, having multipart/choices wouldn't\n>help you create a hook for converting French mail to English.\n\nMultipart/choices (or Multipart/mixed) is much better than\nMultipart/alternative when sending a message in more than\none language, or when an agent between the sender and the\nrecipient translates the message to multiple languages.\n\n--- --- ---\n\nThis discussion seems to have changed tack to the issue\nof where translation should best be done. Should it be done\nby the sender (using multipart with different languages\nin different parts, or some other standards construct),\nby an agent close to the sender (similar to by the sender),\nor by the recipient or an agent close to the recipient.\n\nIf translation is to be done by the recipient or by an\nagent close to a recipient, multipart/alternative might\nbe used since the recipient will in this case have some\nenhanced MUA which can handle multipart(/alternative.\n\nI want, however, to be able to correspond with people\nin France and Spain without having to force the to switch\nto a different mailer than they currently use. It is\nonly in very special circumstances you can force someone\nto swith to a new MUA just to be able to communicate\nwith you. In my case, this is definitely out of the\nquestion.\n\nAt 16.16 -0700 01-05-03, <ned.freed@mrochek.com> wrote:\n>  > defining a new content-type doesn't help this problem much, if at\n>>  all - either the recipient's mailer *still* refuses to show the\n>>  text, or the mailer treats as multipart/mixed and displays all of the\n>>  parts (which can be quite annoying).  neither is satisfactory.\n>\n>Exactly. We defined something in a standard that hasn't been implemented by\n>user agents to your satisfaction, and now you hope to solve this problem by\n>defining something that's essentially the same but labelled differently. I'm\n>sorry, but I fail to see any reason why multipart/choices will work out any\n>better in this regard. Standards can only do so much.\n\n\"Multipart/choices\" will work like \"Multipart/mixed\" in\nexisting mailers. And giving the recipient all the language\nversions is *much* much better than giving the recipient only\none language version, which is the wrong language for this\nrecipient, and not even telling the recipient that there are\nother language versions available.\n\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16040592"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "On 5/3/01 at 11:06 PM -0700, <ned.freed@mrochek.com> wrote:\n\n>This argument might wash if it was the only thing written about the semantics\n>of multipart/alternative. But it isn't. In fact we're not talking about what\n>RFC 2046 says here at all, we're talking about RFC 1766, where the\n>functionality of multipart/alternative was significantly extended past what's\n>covered in RFC 2046.\n\nI'm perfectly willing to see the history the way you describe:\n\n- RFC 1521 defined multipart/alternative in such a way that it \nassumed there is generally one \"best choice\" for it's \"faithfulness \nto the original content\" and did not adequately address the case \nwhere the alternatives are completely equal in value except in their \nvalue to the *human recipient*. This encouraged implementors to write \ncode of the \"display the last alternative that you can display and \nthrow away the rest\" variety.\n\n- RFC 1766 tried to remedy that situation by significantly extending \n1521 for the specific case of language. The remedy did not catch on \nwith implementors. (I take it this was the usual Catch 22, since no \none would implement sending until their were receivers, and receivers \nwouldn't change their code because there were no senders.)\n\n>But I don't think you\n>can claim that you received no indication whatsoever that the simplistic\n>\"last one you can display\" approach described in RFC 2046 had been\n>extended.\n\nThe old and crusty of us didn't do it because of the Catch 22 \ninvolved; I wouldn't argue that was from lack of notice. However, my \nguess is that newer implementations didn't do it because there was no \nindication to do so in 2046.\n\n>Incidentially, it would have been nice to include the RFC 1766 text in RFC\n>2046, however, RFC 2046 is a revision of a draft standard (RFC 1521) \n>and at the\n>time RFC 1766 was only proposed. So I couldn't add it without \n>forcing a recycle\n>at proposed. Heck, it could not even be referenced, since such a reference\n>would obviously be normative.\n\nI disagree that the reference would have necessarily been normative. \nI assume that 1766 had at least *one* implementation when it came \nout. When we have new implementation experience, certainly it \nwouldn't cause a recycle at proposed to include a \"Note:\" of warning \nindicating that the \"best-is-last\" approach doesn't work with some \nuses and that implementors would do well to account for this by \nproviding user interaction.\n\n>Given that the text in RFC 1766 about this approach has been dropped in RFC\n>3066 due to lack of interest on the part of implementors, I see no chance\n>of adding it to MIME itself during a move from draft to full standard.\n\nThis, on the other hand, might be true; I don't know if it's legit to \nmake the change going to full standard. Hey, wait a minute....aren't \nyou the one who decides this stuff? :-)\n\npr\n-- \nPete Resnick <mailto:presnick@qualcomm.com>\nQUALCOMM Incorporated - Direct phone: (858)651-4478, Fax: (858)651-1102\n\n\n\n", "id": "lists-007-16053517"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "> >Incidentially, it would have been nice to include the RFC 1766 text in RFC\n> >2046, however, RFC 2046 is a revision of a draft standard (RFC 1521)\n> >and at the\n> >time RFC 1766 was only proposed. So I couldn't add it without\n> >forcing a recycle\n> >at proposed. Heck, it could not even be referenced, since such a reference\n> >would obviously be normative.\n\n> I disagree that the reference would have necessarily been normative.\n\nYou can disagree all you want and I might even agree with your position\nsomewhat. However, this sort of thing is up to the IESG as a whole, and at the\ntime when I did the revision there was substantial pushback on even including\nthings that were widely, but not universally, implemented in the document. I\nactually don't recall whether or not I proposed including an appropriately\nworded reference to RFC 1766 at the time, but had I done so I don't think there\nwas any chance it would have made it. And to be frank, given the scope of the\nrevisions done in RFC 2045-2049 I had a lot other stuff to worry about at this\npoint.\n\n> I assume that 1766 had at least *one* implementation when it came out.\n\nActually, I doubt that it did. If memory serves, it was something of a last\nminute addition to RFC 1766.\n\n> When we have new implementation experience, certainly it\n> wouldn't cause a recycle at proposed to include a \"Note:\" of warning\n> indicating that the \"best-is-last\" approach doesn't work with some\n> uses and that implementors would do well to account for this by\n> providing user interaction.\n\n> > Given that the text in RFC 1766 about this approach has been dropped in RFC\n> > 3066 due to lack of interest on the part of implementors, I see no chance\n> > of adding it to MIME itself during a move from draft to full standard.\n\n> This, on the other hand, might be true; I don't know if it's legit to\n> make the change going to full standard. Hey, wait a minute....aren't\n> you the one who decides this stuff? :-)\n\nI understand you intend this to be humorous, but I think this actually deserves\na serious response. When I present one of my own documents to the IESG for\napproval I am automatically disqualified from acting as a reviewer.\nAdditionally, anything I or any other IESG member presents tends to be reviwed\nmuch more carefully than stuff coming in from other sources. RIghtly or\nwrongly, the IESG is quite sensitive to charges of favoritism, and if anything\ntends to err in the other direction.\n\nI only wish I didn't speak from experience on this particular point.\n\nNed\n\n\n\n", "id": "lists-007-16065137"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "> I understand you intend this to be humorous, but I think this actually\n> deserves a serious response. When I present one of my own documents \n> to the IESG for approval I am automatically disqualified from acting as \n> a reviewer.  Additionally, anything I or any other IESG member presents \n> tends to be reviwed much more carefully than stuff coming in from other \n> sources. RIghtly or wrongly, the IESG is quite sensitive to charges of \n> favoritism, and if anything tends to err in the other direction.\n> \n> I only wish I didn't speak from experience on this particular point.\n\nI can confirm this from my own experience.  I would even say that one or \ntwo IESG members are actively hostile to such submissions.  \n\nKeith\n\n\n\n", "id": "lists-007-16076105"}, {"subject": "Re: Intelligence in standards-based softwar", "content": "--On Thursday, May 3, 2001 23:06 -0700 ned.freed@mrochek.com wrote:\n> Given that the text in RFC 1766 about this approach has been dropped in\n> RFC 3066 due to lack of interest on the part of implementors, I see no\n> chance of adding it to MIME itself during a move from draft to full\n> standard.\n\nI concur.  However, I think the text in RFC 2046 could be clarified to \nreflect field experience with multipart/alternative better.  It's certainly \nhelpful in practice for a multipart/alternative viewer to give the user the \noption to view the different alternatives.  Indeed, I frequently prefer the \nplain text 1st part to ransom-letter HTML in the 2nd part.\n\nThe bottom line is that a user's preference doesn't necessarily align with \nthe order selected by the originating software.\n\n- Chris\n\n\n\n", "id": "lists-007-16083729"}, {"subject": "Discussion of an app-layer API for IPse", "content": "Greetings. The IPsec WG mailing list now has a discussion about the \nusefulness and feasibility of an application-layer API to IPsec. This \nwould allow an application to see if it is running over IPsec and, if \nso, what kind of authentication was used (possibly to allow \nauthorization in the application). The discussion just started; \napplications folks might want to join in.\n\nYou can see the archive at \n<http://www.vpnc.org/ietf-ipsec/mail-archive/>. Information on \nsubscribing to the mailing list can be found at \n<http://www.vpnc.org/ietf-ipsec/>.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-16092432"}, {"subject": "Re: Discussion of an app-layer API for IPse", "content": "--On 01-05-04 11.39 -0700 \"Paul Hoffman / IMC\" <phoffman@imc.org> wrote:\n\n> The discussion just started; \n> applications folks might want to join in.\n\n...and part from having you joining that discussion, I am as AD interested\nto know if you are interested in something like that?\n\n   paf\n\n\n\n", "id": "lists-007-16100357"}, {"subject": "multipart/alternative extension (Re: Intelligence in   standards-based software", "content": "given the vehemence of this debate, would there be interest in pursuing an \nidea of making a more complete multipart/alternative specification \n(including the RFC 1766 stuff, discussion of various scenarios including \nour by-now long experience with Outlook's use of the feature) and pushing \nit onto the standards track as an update to MIME?\n\n            Harald\n\nAt 23:06 03.05.2001 -0700, ned.freed@mrochek.com wrote:\n>This argument might wash if it was the only thing written about the semantics\n>of multipart/alternative. But it isn't. In fact we're not talking about what\n>RFC 2046 says here at all, we're talking about RFC 1766, where the\n>functionality of multipart/alternative was significantly extended past what's\n>covered in RFC 2046. (I think the addition of a new parameter that entirely\n>changes how you're supposed to interpret multipart/alternative qualifies as a\n>significant extension.)\n>\n>In fact the effect of section 4 of RFC 1766 on the semantics of\n>multipart/alternative is to extend it in exactly the way you describe: You can\n>now have a situation where there's no \"best\" part per se and the differences\n>parameter tells you how to choose the right one for a given user.\n>\n>Now, maybe you would like to argue that the text in RFC 1766 isn't \n>sufficiently\n>clear to understand what needs to be done to handle generalized alternatives\n>correctly. And I might even agree with that assessment. But I don't think you\n>can claim that you received no indication whatsoever that the simplistic\n>\"last one you can display\" approach described in RFC 2046 had been\n>extended.\n>\n>Incidentially, it would have been nice to include the RFC 1766 text in RFC\n>2046, however, RFC 2046 is a revision of a draft standard (RFC 1521) and \n>at the\n>time RFC 1766 was only proposed. So I couldn't add it without forcing a \n>recycle\n>at proposed. Heck, it could not even be referenced, since such a reference\n>would obviously be normative.\n>\n>>Perhaps before going to full standard, such text could be explicitly\n>>put into the text.\n>\n>Given that the text in RFC 1766 about this approach has been dropped in RFC\n>3066 due to lack of interest on the part of implementors, I see no chance\n>of adding it to MIME itself during a move from draft to full standard.\n\n\n\n", "id": "lists-007-16108508"}, {"subject": "Re: Discussion of an app-layer API for IPse", "content": ">allow an application to see if it is running over\n\nI was tempted to delete the last word. ptrace(2) comes to mind.\n\nSeriously, I love API work, but we do very little of it (v6, ldap, and what \nelse?).\nThe proposal is ipsec-specific, the problem is more general, and we've not had\na go at the more general problem in a decade (host requirements), having left\nthat in the POSIX, XPG and Redmond sets of hands.\n\nWhat would interoperate? What two independent implementations would do\nwhat when independently discovering that each is \"running over <foo>\", on\nthe same, or distinct, and possibly dissimilar and not necessarily \ninterconnected\nhosts?\n\nEric\n(author, XPG/1, XPG/4.2, and sundry other inconsequential bits of nonsense)\n\nAt 5/4/01 09:40 PM, Patrik F?ltstr?m wrote:\n>--On 01-05-04 11.39 -0700 \"Paul Hoffman / IMC\" <phoffman@imc.org> wrote:\n>\n> > The discussion just started;\n> > applications folks might want to join in.\n>\n>...and part from having you joining that discussion, I am as AD interested\n>to know if you are interested in something like that?\n>\n>    paf\n\n\n\n", "id": "lists-007-16120534"}, {"subject": "Re: multipart/alternative extensio", "content": "At 13.59 +0200 01-05-04, Harald Tveit Alvestrand wrote:\n>given the vehemence of this debate, would there be interest in \n>pursuing an idea of making a more complete multipart/alternative \n>specification (including the RFC 1766 stuff, discussion of various \n>scenarios including our by-now long experience with Outlook's use of \n>the feature) and pushing it onto the standards track as an update to \n>MIME?\n\nSounds like a good idea. However, I think the type should be given\na new name, for example multipart/choices, because so many existing\nmailers treat multipart/alternative so badly that no one will ever\ndare using it except in accordance with its original spec in\nthe first MIME version.\n\nIn general, if an existing feature is implemented badly, IETF\nprefers to use a new name for the new feature, in order to\navoid clashes with old implementations. Examples of this is\nErrors-To:,\nReturn-Receipt-To:,\nRead-Receipt-To:,\nX-Confirm-reading-to:,\nReturn-Receipt-Requested,\nRegister-Mail-Reply-Requested-By:\n\nor Encoding: specified in RFC 1154 and RFC 1505, which was\nreplaced by Content-Transfer-Encoding in MIME.\n\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16129674"}, {"subject": "Re: multipart/alternative extensio", "content": "> At 13.59 +0200 01-05-04, Harald Tveit Alvestrand wrote:\n> >given the vehemence of this debate, would there be interest in\n> >pursuing an idea of making a more complete multipart/alternative\n> >specification (including the RFC 1766 stuff, discussion of various\n> >scenarios including our by-now long experience with Outlook's use of\n> >the feature) and pushing it onto the standards track as an update to\n> >MIME?\n\n> Sounds like a good idea. However, I think the type should be given\n> a new name, for example multipart/choices, because so many existing\n> mailers treat multipart/alternative so badly that no one will ever\n> dare using it except in accordance with its original spec in\n> the first MIME version.\n\nWhile I somewhat agree with your conclusion the reasoning leading up to it is\nbogus. This discussion has shwn that by some measures the implementations of\nmultipart/alternative you're complaining about are correct. They are not\n\"implemented badly\".\n\nWhat happened was implementors followed the original MIME specification and\nthen for whatever reason didn't implement on the subsequent extension to\nalternative implied by RFC 1766. You cannot blame folks for implementing what\nthe MIME specification told them to implement; you can only blame them for not\npicking up on the additional stuff they needed to do.\n\nWhether or not a new subtype makes sense is dependent why the extension in RFC\n1766 wasn't widely implemented. If the reason is that multipart/alternative got\nimplemented in a particular way before RFC 1766 came out and people didn't want\nto revise that, then a new type is the right way to go. But if the reason is\nthat people simply didn't understand what needed to be done and are willing to\ndo the right thing once they understand it, then building off of the\nestablished base of support for alternative will get you a lot further a lot\nfaster.\n\nIt may also be the case that the reasons for the lack of uptake of\nmultipart/alternative vary from vendor to vendor, which makes assessing whether\nor not a new subtype is a good idea practically impossible to assess.\n\nAll in all I'm inclined to go with multipart/choices, but first I'd like to at\nleast hear from the client implementors on this list about how they think we\nshould proceed. IMO their opinion is the best direction we're going to get.\n\n> In general, if an existing feature is implemented badly, IETF\n> prefers to use a new name for the new feature, in order to\n> avoid clashes with old implementations.\n\nAgain, your premise here has been shown to be false. Reread Pete Resnick's\nmessages if you don't believe this.\n\n Examples of this is\n\n> Errors-To:,\n> Return-Receipt-To:,\n> Read-Receipt-To:,\n> X-Confirm-reading-to:,\n> Return-Receipt-Requested,\n> Register-Mail-Reply-Requested-By:\n\nSigh. There are plenty of examples of features that were badly implemented in\nvarious protocols, but you haven't hit on any of them here. The problem with\nall of these header fields is that the design behind them is fatally flawed.\nThat makes it impossible to implement any of them \"well\". And the reason we\nstandardized on different fields for DSNs and MDNs is that we needed a\nfundamentally different underlying design.\n\nAnd getting back to multipart/alternative, it isn't clear that the underlying\ndesign in RFC 1766 is fundamentally different.\n\n> or Encoding: specified in RFC 1154 and RFC 1505, which was\n> replaced by Content-Transfer-Encoding in MIME.\n\nHere you've finally hit on one where things were indeed badly implemented. (For\nthose of you who don't know, some implementations of Encoding: assume units of\nbytes and others assume units of lines. The specification clearly says lines,\nso there is a problems with how this was implemented.) However, bad\nimplementations weren't the reason a different field was chosen in MIME.  That\nhappened after the MIME specification was complete. There were several reasons\nwhy we abandoned Encoding: in MIME, bu the big one was that experience with\nthis mechanism showed that such counts just weren't reliable.\n\nAnyway, if you want valid examples of features that were abandoned because of\npoor handling by various implementations, I suggest you look at RFC 2822. The\nobsolete syntax contains many examples of such features.\n\nNed\n\n\n\n", "id": "lists-007-16139184"}, {"subject": "Re: multipart/alternative extensio", "content": "At 09.28 -0700 01-05-06, <ned.freed@mrochek.com> wrote:\n>>Sounds like a good idea. However, I think the type should be given\n>>a new name, for example multipart/choices, because so many existing\n>>mailers treat multipart/alternative so badly that no one will ever\n>>dare using it except in accordance with its original spec in\n>>the first MIME version.\n>\n>While I somewhat agree with your conclusion the reasoning leading up to it is\n>bogus. This discussion has shwn that by some measures the implementations of\n>multipart/alternative you're complaining about are correct. They are not\n>\"implemented badly\".\n>\n>What happened was implementors followed the original MIME specification and\n>then for whatever reason didn't implement on the subsequent extension to\n>alternative implied by RFC 1766. You cannot blame folks for implementing what\n>the MIME specification told them to implement; you can only blame them for not\n>picking up on the additional stuff they needed to do.\n\nI did not mean \"badly\" from the implementors view. However, if\na message is sent in English, German and French, and shown\nto a person who cannot read French only in the French version,\nthen that implementation is obviously bad from the user's\nviewpoint.\n\nAt 09.28 -0700 01-05-06, <ned.freed@mrochek.com> wrote:\n>  Whether or not a new subtype makes sense is dependent why the\n>  extension in RFC 1766 wasn't widely implemented. If the reason is\n>  that multipart/alternative got implemented in a particular way before\n>  RFC 1766 came out and people didn't want to revise that, then a new\n>  type is the right way to go. But if the reason is that people simply\n>  didn't understand what needed to be done and are willing to do the\n>  right thing once they understand it, then building off of the\n>  established base of support for alternative will get you a lot\n>  further a lot faster.\n\nIts is not reasonable to expect that a new definition of this\nwill be rapidly implemented. It is reasonable to expect that\nmany mailers will for a long time follow the original MIME\nspecification of multipart/alternative. Note that there are\nstill many implementations which treat multipart/alternative\nas multipart/mixed (which actually happens to be better\nthan the most common present implementation of\nmultipart/alternative in the case of multiple languages).\n\nIs there an established base of support for alternative,\nwhich is better than multipart/mixed for multi-language\nmessages? None of the systems I tested did better than\nmultipart/mixed. And none of the systems seemed to\nrecognize the \"differences\" attribute to\nmultipart/alternative.\n\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16150895"}, {"subject": "RE: Replacing the Label header with a DAV:labeled-version repor", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   one concern, almost the same as with the old approach (PROPFIND\n   with label header):\n\n   Which hrefs should be reported? I think the href property should be\n   the URI of the version, not the one of the VCR or the VHR.\n\nAs indicated in the DAV:labeled-version example, the URI is the\none of the VCR (just like a Depth PROPFIND).  But see the answer\nto your next question.\n\n   Also: what is the DAV:version property that appears in the example?\n\nI should have mentioned that I resurrected the old DAV:version\nproperty to make the DAV:labeled-version report work cleanly.\nThe DAV:version property only appears on version resources,\nand contains the server-defined URL for that version.\n\nSo the DAV:labeled-version report always reports the VCR URL,\nbut can also report the version URL (and/or the version history URL)\nif requested to do so by the client (i.e. specifies\nDAV:version and/or DAV:version-history in the DAV:prop request\nelement.\n\nDoes this address your concern?\n\nCheers,\nGeoff\n\n   > -----Original Message-----\n   > From: ietf-dav-versioning-request@w3.org\n   > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n   > Sent: Friday, June 28, 2002 9:18 PM\n   > To: 'Deltav WG'\n   > Subject: RE: Replacing the Label header with a DAV:labeled-version\n   > report\n   >\n   >\n   >\n   > So far, everyone has either agreed or remained silent on this topic,\n   > so as a motivator for anyone objecting to speak up (:-), I will mark\nthis\n   > issue\n   > as resolved in the errata, with the resolution being that the Label\n   > header will be deprecated, and the DAV:labeled-version REPORT inserted\n   > in its place.  In particular, I propose the following definition for\n   > the DAV:labeled-version REPORT:\n   >\n   > -------------------\n   >\n   > 8.3DAV:labeled-version Report\n   > The DAV:labeled-version report describes the requested properties\n   > of the version with that label in a specified version history.\n   > If the DAV:labeled-version report is applied to a version-controlled\n   > resource, it is applied to the DAV:version-history of that\n   > version-controlled resource.\n   >\n   > Marshalling:\n   >\n   > The request body MUST be a DAV:labeled-version XML element.\n   >\n   > <!ELEMENT labeled-version ANY>\n   >\n   > ANY value: a sequence of zero or more elements, with\n   > at most one DAV:prop element and with exactly one\n   > DAV:label-name element.\n   >\n   > prop: see RFC 2518, Section 12.11\n   >\n   > The response body for a successful request MUST be a DAV:multistatus\n   > XML element.\n   >\n   > multistatus: see RFC 2518, Section 12.9\n   >\n   > The response body for a successful DAV:labeled-version REPORT\n   > request MUST contain a DAV:response element for each resource\n   > that satisfies the Depth header of the request.\n   >\n   > 8.3.1Example - DAV:labeled-version Report\n   >\n   > >>REQUEST\n   >\n   >   REPORT /folder/ HTTP/1.1\n   >   Host: www.webdav.org\n   >   Content-Type: text/xml; charset=\"utf-8\"\n   >   Content-Length: xxxx\n   >   Depth: 1\n   >\n   >   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n   >   <D:labeled-version xmlns:D=\"DAV:\">\n   >     <D:label-name>tested</D:label-name>\n   >     <D:prop>\n   >       <D:version-name/>\n   >       <D:version/>\n   >     </D:prop>\n   >   </D:labeled-version>\n   >\n   > >>RESPONSE\n   >\n   >   HTTP/1.1 207 Multi-Status\n   >   Content-Type: text/xml; charset=\"utf-8\"\n   >   Content-Length: xxxx\n   >\n   >   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n   >   <D:multistatus xmlns:D=\"DAV:\">\n   >     <D:response>\n   >       <D:href>http://www.webdav.org/folder/</D:href>\n   >       <D:propstat>\n   >         <D:prop>\n   >           <D:version-name>V5</D:version-name>\n   >           <D:creator-displayname>Fred</D:creator-displayname>\n   >           <D:version>\n   >             <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n   >           </D:version>\n   >         </D:prop>\n   >         <D:status>HTTP/1.1 200 OK</D:status>\n   >       </D:propstat>\n   >     </D:response>\n   >     <D:response>\n   >       <D:href>http://www.webdav.org/folder/foo.html</D:href>\n   >       <D:propstat>\n   >         <D:prop>\n   >           <D:version-name>V8</D:version-name>\n   >           <D:version>\n   >             <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n   >           </D:version>\n   >         </D:prop>\n   >         <D:status>HTTP/1.1 200 OK</D:status>\n   >       </D:propstat>\n   >     </D:response>\n   >   </D:multistatus>\n   >\n   > -----------------------------------------\n   >\n   > Cheers,\n   > Geoff\n   >\n   > -----Original Message-----\n   > From: Clemm, Geoff [mailto:gclemm@Rational.Com]\n   > Sent: Sunday, April 28, 2002 9:53 AM\n   > To: 'Deltav WG'\n   > Subject: Replacing the Label header with a DAV:labeled-version report\n   >\n   >\n   > Since this is a fairly significant change, I'd like to\n   > hear from a few more folks before adding this to the 3253 Errata.\n   >\n   > Thanks,\n   > Geoff\n   >\n   > -----Original Message-----\n   > From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n   > Sent: Saturday, April 27, 2002 5:09 AM\n   > To: Clemm, Geoff; 'Deltav WG'\n   > Subject: RE: Label header vs PROPFIND depth 1\n   >\n   >\n   > > From: ietf-dav-versioning-request@w3.org\n   > > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n   > > Sent: Friday, April 26, 2002 6:06 PM\n   > > To: 'Deltav WG'\n   > > Subject: RE: Label header vs PROPFIND depth 1\n   > >\n   > >\n   > >    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n   > >\n   > >    - I'd like to see the label *header* deprecated\n   > >    - I'm happy with the LABEL method and the label-name-set property\n   > >    - I think that PROPFIND/label should be replaced by a specific\nREPORT\n   > >\n   > > Is the proposed DAV:labeled-version report OK with you?\n   >\n   > Yes. But I think it's Tim's turn to say whether this would work for him\nor\n   > not...\n   >\n   > >    - I'm unsure about other methods that are currently affected by\nthe\n   > >    header -- what were the requirements...?\n   > >\n   > > The other methods are LABEL, CHECKOUT, GET, and COPY.\n   > > For Depth:0 variants of these operations, the Label header\n   > > just provided an optimization to save one roundtrip\n   > > (i.e. first getting the version URL via the DAV:labeled-version\nreport).\n   > > I believe we can easily do without that Depth:0 optimization.\n   >\n   > As stated before, I think that's not the single problem. Having\n   > GET return a\n   > (representation of a) version rather than (a representation of) the VCR\n   > makes the version *by definition* a variant (representation) of the VCR\n--\n   > and it seems that most of us want to avoid that interpretation.\n   >\n   > > For Depth:infinity (only relevant for LABEL and COPY), the savings\n   > > would be more significant, but unfortunately the semantics is broken\n   > > (since if the namespace is being versioned, you'll get the wrong\n   > > resources if you simply do a Depth operation on the current\nnamespace).\n   > >\n   > > The Depth:infinity Label header operations are really just a way of\n   > > trying to have the client fake workspaces and baselines, instead of\n   > > having the server support them directly.  Since it is much more\n   > > efficient and reliable to have the server layer these constructs\n   > > above a labeling infrastructure, rather than having the client do\n   > > so, I believe the cost of maintaining these Depth:infinity Label\n   > > header operations in the protocol is not warranted.\n   > >\n   > > Note though that (depth:0) labeling and baselining go very well\n   > > together.  Instead of doing a Depth:infinity LABEL, you can create a\n   > > baseline (which under the hood the server may well implement with\n   > > reserved labels, but maybe not), and then LABEL that baseline.  Then\n   > > when you want to do a Depth:infinity COPY, you retrieve the\n   > > DAV:baseline-collection of the labeled baseline (using the\n   > > DAV:labeled-version report), and copy that to wherever you want.\n   > >\n   > > Alternatively, if you want a \"modifiable\" selection, you can create a\n   > > workspace (which under the hood the server may well implement with\n   > > reserved labels, but maybe not).  When you want to adjust the\nversions\n   > > being selected, you just use UPDATE.  Then when you want to do a\n   > > Depth:infinity COPY, you just copy from that workspace to wherever\nyou\n   > > want.\n   > >\n   > >    - Servers that decide to implement LABEL and DAV:label-name-set,\n   > >    but no not support the label header should *not* report the LABEL\n   > >    feature in OPTIONS.\n   > >\n   > > That's probably right.  A client can find out if the LABEL operation\n   > > is supported by querying the DAV:supported-method-set property values\n   > > of a VCR.\n   >\n   > ...and also use DAV:supported-live-property-set to discover the\n   > DAV:label-name-set property.\n   >\n   >\n\n\n\n", "id": "lists-007-1615780"}, {"subject": "Re: Discussion of an app-layer API for IPse", "content": "I basically think that IPsec is nearly useless without an application-layer\nAPI, but the API needs to not only make applications aware of whether\na security association has been established (along with the credentials\nso that the application can evaluate them for itself) but also allow\nthe application to control the credentials that are used when establishing\nSAs.\n\nKeith\n\n\n\n", "id": "lists-007-16161527"}, {"subject": "Re: multipart/alternative extensio", "content": "> In general, if an existing feature is implemented badly, IETF\n> prefers to use a new name for the new feature, in order to\n> avoid clashes with old implementations. Examples of this is\n> Errors-To:,\n> Return-Receipt-To:,\n> Read-Receipt-To:,\n> X-Confirm-reading-to:,\n> Return-Receipt-Requested,\n> Register-Mail-Reply-Requested-By:\n\nthese aren't persuasive examples.  many of them shouldn't have been\nin the message header in the first place - and those that were \nappropriate in the message header were never well defined.\n\nin other words, the problem was not that the spec for these features\nwas poorly written or badly implemented - the problem was that the\nspec was never written and/or never received any kind of public review\nin the first place.\n\nmultipart/alternative is light-years ahead of any of these.\n\nKeith\n\n\n\n", "id": "lists-007-16169730"}, {"subject": "Re: multipart/alternative extensio", "content": "Jacob,\n\nplease explain to me how an existing UA will fare any better when\npresented with multipart/choices than it fares when presented\nwith multipart/alternative.\n\nin either case the UA has to be upgraded before displaying the content\nideally for the recipient.\n\nwe know that there are at least a few UAs that currently allow\nthe recipient to choose which of a multipart/alternative to \ndisplay.  they will not do this with multipart/choices.\n\nKeith\n\n\n\n", "id": "lists-007-16177570"}, {"subject": "RE: New draft: Application/Multiplexe", "content": "> -----Original Message-----\n> From: Keith Moore [mailto:moore@cs.utk.edu]\n> Sent: Thursday, May 03, 2001 10:47 PM\n\n> if this is really intended just to solve some printing problems, how\n> about calling it something like application/multiplexed-printer-data\n> or some such?  I hate to see something which is intended as a stopgap\n> measure given a name that makes it look like a \n> general-purpose facility.\n\nAlthough problems in the printing world provide the motivation for\nApplication/Multiplexed, there may be other applications that would be able\nto use it. So, I don't want to pick a name that suggests that this solution\nis limited to printing applications. \n\n\n\n", "id": "lists-007-16185210"}, {"subject": "Re: multipart/alternative extensio", "content": "> >  Whether or not a new subtype makes sense is dependent why the\n> >  extension in RFC 1766 wasn't widely implemented. If the reason is\n> >  that multipart/alternative got implemented in a particular way before\n> >  RFC 1766 came out and people didn't want to revise that, then a new\n> >  type is the right way to go. But if the reason is that people simply\n> >  didn't understand what needed to be done and are willing to do the\n> >  right thing once they understand it, then building off of the\n> >  established base of support for alternative will get you a lot\n> >  further a lot faster.\n\n> Its is not reasonable to expect that a new definition of this\n> will be rapidly implemented. It is reasonable to expect that\n> many mailers will for a long time follow the original MIME\n> specification of multipart/alternative.\n\nThis may or may not be so. For one thing, implementation and deployment have a\nlot more to do with timing than anything else. I've seen plenty of instances of\nnew features being implemented quite rapidly. A good example is NOTARY support.\nNOTARY happened to arrive a time when various mailers were being extensively\nmodified for other reasons so support for it started appearing quite rapidly --\nfar more rapidly than most of us involved in the effort would have predicted\ngiven the complexity of the necessary code.\n\nDeployment is a trickier proposition than implementation. But in the present\ncase we can chear: When you're talking about recipient functionality all you\nreally need is implementation availability. Users will decide whether or not\nthey need to upgrade on an individual basis. (This differs markedly from things\nlike NOTARY, which requires that all intermediaries support it to be effective,\nand hence despite rapid implementation is still short of being universally\ndeployed.)\n\n> Note that there are\n> still many implementations which treat multipart/alternative\n> as multipart/mixed (which actually happens to be better\n> than the most common present implementation of\n> multipart/alternative in the case of multiple languages).\n\n> Is there an established base of support for alternative,\n> which is better than multipart/mixed for multi-language\n> messages?\n\nChris Newman already answered this question in the affirmative: Mulberry\ngets this right.\n\n> None of the systems I tested did better than\n> multipart/mixed. And none of the systems seemed to\n> recognize the \"differences\" attribute to\n> multipart/alternative.\n\nThe problem with building something completely new is that there's a very real\nchance that essentially nobody will implement it. So suppose this turns into a\nchoice between rapid uptake of an enhancement to alternative in several key\nclients versus new facility that remains unimplemented for the forseeable\nfuture. What then?\n\nNed\n\n\n\n", "id": "lists-007-16193815"}, {"subject": "Re: multipart/alternative extensio", "content": "Here is an example how a mailer which does not support multipart/choices\nmight show a multi-language message in the multipart/choices format,\nhandling it as multipart/mixed:\n\n--- --- ---\n\nDate: Mon, 7 May 2001 11:49:02 +0200\nFrom: Jacob Palme <jpalme@dsv.su.se>\nTo: jptest@dsv.su.se\nSubject: Message in multiple languages\nParts/Attachments:\n    1 Shown      0 lines  Text\n    2   OK      48 bytes  Text\n    3   OK      48 bytes  Text\n    4   OK      48 bytes  Text\n    5 Shown      2 lines  Text\n----------------------------------------\n\nThis message is available in multiple languages.\n\nPart 2: English\nPart 3: Fran?ais\nPart 4: Deutsch\n\n     [ Part 2, Text/plain  48bytes. ]\n     [ Not Shown. Use the \"V\" command to view or save this part. ]\n\n\n     [ Part 3, Text/plain  48bytes. ]\n     [ Not Shown. Use the \"V\" command to view or save this part. ]\n\n\n     [ Part 4, Text/plain  48bytes. ]\n     [ Not Shown. Use the \"V\" command to view or save this part. ]\n\n\n     [ Part 5: \"Attached Text\" ]\n\n--\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16204088"}, {"subject": "Re: multipart/alternative extensio", "content": "At 18.08 -0400 01-05-06, Keith Moore wrote:\n>please explain to me how an existing UA will fare any better when\n>presented with multipart/choices than it fares when presented\n>with multipart/alternative.\n\nSuppose a message contains three body parts, containing the\nsame text in German, English and French. Suppose the English\ntext is the original, the other are not-very good machine\ntranslations.\n\nMultipart/choices will work like multipart/mixed for MUAs\nwhich do not support multipart/choices. This means that\nall three parts are delivered to the user, and the user\ncan choose which part to read. If the parts are given\nsuitable file names using Content-Disposition, for example\n\"German-machine-translation\", \"English-original\", \"French-\nmachine-translation\" most MUAs will show these file\nnames and thus help the users choose which attachment to\nread.\n\nSome MUAs show the first body part of multipart/mixed,\nand treat the others as attachments. It might be better\nin such a case to add an almost empty body part first\nwhich just says that the other parts contain the same\ninfo in multiple languages.\n\nThis, as well as how to provide translation of the\nSubject, are issues which might be discussed if IETF\nstarts work on this issue.\n\n(If IETF wants to start work on this, I have already\nstarted a mailing list which can be used,\nLANGTRANS@psychmax.psychology.su.se, use Listserv\nconventions to subscribe. Archives at\nhttp://salut.nu/forum/uno/6/1/.)\n\nMultipart/alternative will mean that users of many existing\nMUAs will be shown only one of the body parts, usually\neither the first or the third. A user who prefers to read\nthe message in the language used in any of the other body\nparts will not even be told that there are other language\nversions.\n\nIt is obviously better to give a recipient a choice of\ntranslations to different languages, than to give the\nuser only one single translation, which is not adapted\nto the language preferences of the user.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16213418"}, {"subject": "Re: multipart/alternative extensio", "content": "At 15.12 -0700 01-05-06, <ned.freed@mrochek.com> wrote:\n>>None of the systems I tested did better than\n>>multipart/mixed. And none of the systems seemed to\n>>recognize the \"differences\" attribute to\n>>multipart/alternative.\n>\n>The problem with building something completely new is that there's a very real\n>chance that essentially nobody will implement it. So suppose this turns into a\n>choice between rapid uptake of an enhancement to alternative in several key\n>clients versus new facility that remains unimplemented for the forseeable\n>future. What then?\n\nSuppose someone sets up a server which will take an incoming\ne-mail and resend it in multiple machine-translated versions.\nWe hope to be able to get money to develop such a server.\nI am just now working on an application for funding of this.\n\nIf IETF says that multipart/alternative should be used, such\na server will still not use it, since using multipart/alternative\nwill cause many recipients to only get one of the translations,\nnot adapted to their language capabilities. So in this case,\nwe will implement this as either multipart/mixed or\nunstandardized multipart/choices, since MUAs treat\nmultipart/unknown as multipart/mixed. Other implementors\nof such an email translation service will also for the\nsame reason not choose multipart/alternative.\n\nIf the translation servers do not send multiple translations\nin the multipart/alternative format, MUA implementors will\nhave no incentive to implement handling of this format\nin the multiple-language case.\n\nIf, on the other hand, IETF says that multipart/choices\nshould be used, we will of course use it. If our and other\nsimilar services become popular, many people will get\nmessages in multiple languages which their mailers will\ntreat as multipart/mixed. If many people get such sets\nof translations, this may stimulate MUA implementors to\nsupport it better. If not, the users will still at least\nbe given all the different translations and be able to\nselect which of them to read.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16223130"}, {"subject": "Re: multipart/alternative extensio", "content": "which\n\n\n\n", "id": "lists-007-16232640"}, {"subject": "Re: multipart/alternative extensio", "content": "unsubscribe *\n\n\n\n", "id": "lists-007-16239675"}, {"subject": "Re: multipart/alternative extensio", "content": "> Some MUAs show the first body part of multipart/mixed,\n> and treat the others as attachments. \n\nthose MUAs are broken, and I believe they are in the minority.\nshall we adopt a strategy for deployment of new content types \nthat depends on broken behavior of a few MUAs?\n\nKeith\n\n\n\n", "id": "lists-007-16246510"}, {"subject": "Re: multipart/alternative extensio", "content": "unsubscribe\n\n\n\n\nJacob Palme <jpalme@dsv.su.se> on 05/07/2001 02:52:16 AM\n\nTo:   IETF Applications Area general discussion list <discuss@apps.ietf.org>\ncc:    (bcc: Peter Kyone/AUCO/US)\n\nSubject:  Re: multipart/alternative extension\n\n\n\nAt 15.12 -0700 01-05-06, <ned.freed@mrochek.com> wrote:\n>>None of the systems I tested did better than\n>>multipart/mixed. And none of the systems seemed to\n>>recognize the \"differences\" attribute to\n>>multipart/alternative.\n>\n>The problem with building something completely new is that there's a very real\n>chance that essentially nobody will implement it. So suppose this turns into a\n>choice between rapid uptake of an enhancement to alternative in several key\n>clients versus new facility that remains unimplemented for the forseeable\n>future. What then?\n\nSuppose someone sets up a server which will take an incoming\ne-mail and resend it in multiple machine-translated versions.\nWe hope to be able to get money to develop such a server.\nI am just now working on an application for funding of this.\n\nIf IETF says that multipart/alternative should be used, such\na server will still not use it, since using multipart/alternative\nwill cause many recipients to only get one of the translations,\nnot adapted to their language capabilities. So in this case,\nwe will implement this as either multipart/mixed or\nunstandardized multipart/choices, since MUAs treat\nmultipart/unknown as multipart/mixed. Other implementors\nof such an email translation service will also for the\nsame reason not choose multipart/alternative.\n\nIf the translation servers do not send multiple translations\nin the multipart/alternative format, MUA implementors will\nhave no incentive to implement handling of this format\nin the multiple-language case.\n\nIf, on the other hand, IETF says that multipart/choices\nshould be used, we will of course use it. If our and other\nsimilar services become popular, many people will get\nmessages in multiple languages which their mailers will\ntreat as multipart/mixed. If many people get such sets\nof translations, this may stimulate MUA implementors to\nsupport it better. If not, the users will still at least\nbe given all the different translations and be able to\nselect which of them to read.\n--\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16253816"}, {"subject": "Re: multipart/alternative extensio", "content": "> If IETF says that multipart/alternative should be used, such\n> a server will still not use it, since using multipart/alternative\n> will cause many recipients to only get one of the translations,\n> not adapted to their language capabilities. \n\nThe same is true if you use either multipart/mixed or multipart/choices.\n\nKeith\n\n\n\n", "id": "lists-007-16264541"}, {"subject": "Re: multipart/alternative extensio", "content": "On 5/7/01 at 2:42 PM -0400, Keith Moore wrote:\n\n>  > If IETF says that multipart/alternative should be used, such\n>>  a server will still not use it, since using multipart/alternative\n>>  will cause many recipients to only get one of the translations,\n>>  not adapted to their language capabilities.\n>\n>The same is true if you use either multipart/mixed or multipart/choices.\n\nNo. Please re-read Jacob's message. It is acceptable to use either \n/mixed or /choices because you won't *lose* information in any \nclients. With /alternative, there is information loss in some \nclients, which the servers in question are unwilling to risk.\n\nYou're not following the argument, Keith.\n\npr\n-- \nPete Resnick <mailto:presnick@qualcomm.com>\nQUALCOMM Incorporated - Direct phone: (858)651-4478, Fax: (858)651-1102\n\n\n\n", "id": "lists-007-16272385"}, {"subject": "Re: multipart/alternative extensio", "content": "> >  > If IETF says that multipart/alternative should be used, such\n> >>  a server will still not use it, since using multipart/alternative\n> >>  will cause many recipients to only get one of the translations,\n> >>  not adapted to their language capabilities.\n> >\n> >The same is true if you use either multipart/mixed or multipart/choices.\n> \n> No. Please re-read Jacob's message. It is acceptable to use either\n> /mixed or /choices because you won't *lose* information in any\n> clients. With /alternative, there is information loss in some\n> clients, which the servers in question are unwilling to risk.\n\nWith multipart/choices there is still potential for information loss, \nbecause some clients fail to follow the specs regarding treatment\nof multipart/unknown.\n\nEven with multipart/mixed, if the desired content is presented as an \nattachment, this can effectively cause information loss if the recipient\ndoesn't understand that the version he/she understands is in that \nattachment, and/or he/she doesn't know how to read that attachment.\n\nKeith\n\n\n\n", "id": "lists-007-16281270"}, {"subject": "Re: multipart/alternative extensio", "content": "On 5/7/01 at 2:53 PM -0400, Keith Moore wrote:\n\n>With multipart/choices there is still potential for information loss,\n>because some clients fail to follow the specs regarding treatment\n>of multipart/unknown.\n\nI've never known any implementation that actually throws away pieces \nof a multipart/unknown. But even if there were such a beast, one or \ntwo occurrences of actively broken software would not prevent any \nserver from trying to send multipart/unknown when the vast majority \nof clients out there deal perfectly reasonably with it as \nmultipart/mixed.\n\n>Even with multipart/mixed, if the desired content is presented as an\n>attachment, this can effectively cause information loss if the recipient\n>doesn't understand that the version he/she understands is in that\n>attachment, and/or he/she doesn't know how to read that attachment.\n\nThat certainly leads to information *obscuration*, but it doesn't \nlead to information *loss*. I'm not sure if you exactly understand \nthe extent of the problem. Eudora, for instance, if it receives a \nmultipart/alternative with text/plain and text/html, will \n*irretrievably throw away* the text/plain on the assumption (as the \nspec implies) that the HTML is higher fidelity and therefore no \ninformation was actually in fact lost (a rather bold assumption, \neh?). This makes multipart/alternative way too scary for someone to \nsend if they know that the recipient might need to see the other \nparts. With a multipart/mixed or multipart/foobar, you at least have \npretty good odds that the user will see something reasonable.\n\npr\n-- \nPete Resnick <mailto:presnick@qualcomm.com>\nQUALCOMM Incorporated - Direct phone: (858)651-4478, Fax: (858)651-1102\n\n\n\n", "id": "lists-007-16290546"}, {"subject": "Re: multipart/alternative extensio", "content": "> Eudora, for instance, if it receives a\n> multipart/alternative with text/plain and text/html, will\n> *irretrievably throw away* the text/plain on the assumption (as the\n> spec implies) that the HTML is higher fidelity and therefore no\n> information was actually in fact lost (a rather bold assumption,\n> eh?). \n\nyes.  that's *really* unfortunate.  \n\nKeith\n\n\n\n", "id": "lists-007-16300722"}, {"subject": "Re: multipart/alternative extensio", "content": "> >With multipart/choices there is still potential for information loss,\n> >because some clients fail to follow the specs regarding treatment\n> >of multipart/unknown.\n> \n> I've never known any implementation that actually throws away pieces\n> of a multipart/unknown. But even if there were such a beast, one or\n> two occurrences of actively broken software would not prevent any\n> server from trying to send multipart/unknown when the vast majority\n> of clients out there deal perfectly reasonably with it as\n> multipart/mixed.\n\nperhaps.  but it seems that we're starting to argue about which kind \nof brokenness is more widespread - brokenness on handling multipart/\nalternative vs. broken on handling multipart/foo.  historically\nthese kinds of arguments have been difficult for IETF to evaluate.\n\nKeith\n\n\n\n", "id": "lists-007-16308887"}, {"subject": "Re: multipart/alternative extensio", "content": "> On 5/7/01 at 2:53 PM -0400, Keith Moore wrote:\n\n> >With multipart/choices there is still potential for information loss,\n> >because some clients fail to follow the specs regarding treatment\n> >of multipart/unknown.\n\n> I've never known any implementation that actually throws away pieces\n> of a multipart/unknown. But even if there were such a beast, one or\n> two occurrences of actively broken software would not prevent any\n> server from trying to send multipart/unknown when the vast majority\n> of clients out there deal perfectly reasonably with it as\n> multipart/mixed.\n\nI've seen such implementations, but not any time recently. A couple of\nthem appeared right after MIME first came out. For some reason people\njust couldn't get their head around the generic nature of multipart and\nthe notion of falling back to multipart/mixed.\n\nThe implementions I remember that did this were mostly gateway sorts of things,\nand given how the landscape has changed I suspect they are extinct. But\nit is always impossible to be sure about stuff like this.\n\nNed\n\n\n\n", "id": "lists-007-16317540"}, {"subject": "Re: Discussion of an app-layer API for IPse", "content": "At 6:01 PM -0400 5/6/01, Keith Moore wrote:\n>I basically think that IPsec is nearly useless without an application-layer\n>API,\n\nCreating secure WANs is a pretty large market...\n\n>  but the API needs to not only make applications aware of whether\n>a security association has been established (along with the credentials\n>so that the application can evaluate them for itself)\n\nRight\n\n>  but also allow\n>the application to control the credentials that are used when establishing\n>SAs.\n\nThat's assuming that the API allows SA creation. I think that is a \nseparate API from \"am I already covered\", and one tha will be much \nharder to design.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-16326652"}, {"subject": "Re: Discussion of an app-layer API for IPse", "content": "> >I basically think that IPsec is nearly useless without an application-layer\n> >API,\n> \n> Creating secure WANs is a pretty large market...\n\ngranted.  perhaps I should have said \"nearly useless to applications\".\n(of course, just because something has a large market doesn't necessarily\nmean it's useful)\n\n> >  but the API needs to not only make applications aware of whether\n> >a security association has been established (along with the credentials\n> >so that the application can evaluate them for itself)\n> \n> Right\n> \n> >  but also allow\n> >the application to control the credentials that are used when establishing\n> >SAs.\n> \n> That's assuming that the API allows SA creation. I think that is a\n> separate API from \"am I already covered\", and one tha will be much\n> harder to design.\n\ngranted that it will be much harder to design, but the idea that the\nend hosts can decide how to set up an SA suitable to authenticate to\napplications, without the applications being involved, strikes me as\nextremely dubious.  which is why I've never felt like IPsec was very\nvaluable without an application-layer API.\n\nKeith\n\n\n\n", "id": "lists-007-16334567"}, {"subject": "Re: multipart/alternative extensio", "content": "At 14.53 -0400 01-05-07, Keith Moore wrote:\n>Even with multipart/mixed, if the desired content is presented as an\n>attachment, this can effectively cause information loss if the recipient\n>doesn't understand that the version he/she understands is in that\n>attachment, and/or he/she doesn't know how to read that attachment.\n\nYes, right, that is a problem. One solution might be that the first\nbody part (since mailers usually display at least the first body\npart inline) should contain a list of the other body parts. Something\nlike this:\n\n     After this text or as attachments comes the message in\n     different languages:\n     - English\n     - French\n     - German\n\nAnother alternative might be that if you have an original\nin English, and translations to French and Germany, then\nuse multipart/choice with four body parts. The first body part\nwould include all three language versions, plus some text\nin the beginning, explaining that the message contains the\nsame text in more than one language. The other three parts\nwould contain each language version.\n\nAn MUA supporting the new contstruct would then ignore the\nfirst body part. Since most mailers display the first\nbody part inline, this would give adequate result with\nexisting mailers.\n\nAt 15.49 -0400 01-05-07, Keith Moore wrote:\n>perhaps.  but it seems that we're starting to argue about which kind\n>of brokenness is more widespread - brokenness on handling multipart/\n>alternative vs. broken on handling multipart/foo.  historically\n>these kinds of arguments have been difficult for IETF to evaluate.\n\nMy original proposal was based on tests of some of the most common\nmailers. Before I made these tests, I was all for multipart/alternative.\nIt was the test results which caused me to understand that multipart/\nalternative could not be used.\n\nThe full test report can be found as an attachment at the end of\nftp://ftp.dsv.su.se/users/jpalme/draft-palme-email-translation-02.txt\n\nI tested the following mailers:\nEudora 5 Macintosh\nPine 4.21 Unix\nNetscape 4.7 Macintosh\nOutlook Express 5 Macintosh\nFirst Class 5.611 Macintosh\nKOM 2000 web-based\nHotmail web-based\n\n\n\n\n\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16342960"}, {"subject": "Re: multipart/alternative extensio", "content": "> >Even with multipart/mixed, if the desired content is presented as an\n> >attachment, this can effectively cause information loss if the recipient\n> >doesn't understand that the version he/she understands is in that\n> >attachment, and/or he/she doesn't know how to read that attachment.\n> \n> Yes, right, that is a problem. One solution might be that the first\n> body part (since mailers usually display at least the first body\n> part inline) should contain a list of the other body parts. Something\n> like this:\n> \n>      After this text or as attachments comes the message in\n>      different languages:\n>      - English\n>      - French\n>      - German\n> \n\nyou could even use MHTML and multipart/related.  put the above text\nin HTML with clickable links to the other body parts.\n\nKeith\n\n\n\n", "id": "lists-007-16352644"}, {"subject": "Re: multipart/alternative extensio", "content": "At 16.32 -0400 01-05-08, Keith Moore wrote:\n>you could even use MHTML and multipart/related.  put the above text\n>in HTML with clickable links to the other body parts.\n\nYes, I have been thinking of that. However, I am not sure how\nmany MHTML-compliant mailers support clickable links between\nor even within body parts.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16360872"}, {"subject": "RE: Replacing the Label header with a DAV:labeled-version repor", "content": "Julian didn't like the marshalling of this report,\nbecause it makes it look like the properties are those of\nthe VCR, when they actually are properties of the version\n(Basically, I was just being lazy and re-using the D:response\nelement in a bogus fashion).\n\nSo how about the following instead:\n\n-----------------------------------------------\n\n8.3DAV:labeled-version Report\n\nThe DAV:labeled-version report describes the requested\nproperties of the version with that label in a specified\nversion history.  If the DAV:labeled-version report is \napplied to a version-controlled resource, it is applied \nto the DAV:version-history of that version-controlled resource.\n\nMarshalling:\n\nThe request body MUST be a DAV:labeled-version XML element.\n<!ELEMENT labeled-version ANY>\nANY value: a sequence of zero or more elements, with at most \none DAV:prop element and with exactly one DAV:label-name element.\nprop: see RFC 2518, Section 12.11\n\nThe response body for a successful Depth:0 request MUST be \na DAV:labeled-version-report XML element.\n\n<!ELEMENT labeled-version-report (href, prop)>\nprop: see RFC 2518, Section 12.11\n\nThe DAV:href identifies the selected version, and the DAV:prop \ncontains the requested properties of that version.\n\n8.3.1Example - DAV:labeled-version Report\n>>REQUEST\n\n  REPORT /folder/ HTTP/1.1\n  Host: www.webdav.org\n  Content-Type: text/xml; charset=\"utf-8\"\n  Content-Length: xxxx \n  Depth: 1\n\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:labeled-version xmlns:D=\"DAV:\">\n    <D:label-name>tested</D:label-name>\n    <D:prop>\n      <D:version-name/>\n    </D:prop>\n  </D:labeled-version>\n\n>>RESPONSE\n\n  HTTP/1.1 207 Multi-Status\n  Content-Type: text/xml; charset=\"utf-8\"\n  Content-Length: xxxx\n\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:multistatus xmlns:D=\"DAV:\">\n    <D:response>\n      <D:href>http://www.webdav.org/folder/</D:href>\n      <D:propstat>\n        <D:prop> <D:labeled-version-report>\n          <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n          <D:prop>\n            <D:version-name>V5</D:version-name>\n          </D:prop>\n          </D:labeled-version-report> </D:prop>\n        <D:status>HTTP/1.1 200 OK</D:status>\n      </D:propstat>\n    </D:response>\n    <D:response>\n      <D:href>http://www.webdav.org/folder/foo.html</D:href>\n      <D:propstat>\n        <D:prop> <D:labeled-version-report>\n          <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n          <D:prop>\n            <D:version-name>V8</D:version-name>\n          </D:prop>\n        </D:labeled-version-report> </D:prop>\n        <D:status>HTTP/1.1 200 OK</D:status>\n      </D:propstat>\n    </D:response>\n  </D:multistatus>\n\n\n-----------------------------------------\n\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@Rational.Com]\nSent: Friday, June 28, 2002 3:18 PM\nTo: 'Deltav WG'\nSubject: RE: Replacing the Label header with a DAV:labeled-version\nreport\n\n\n\nSo far, everyone has either agreed or remained silent on this topic,\nso as a motivator for anyone objecting to speak up (:-), I will mark this\nissue\nas resolved in the errata, with the resolution being that the Label\nheader will be deprecated, and the DAV:labeled-version REPORT inserted\nin its place.  In particular, I propose the following definition for\nthe DAV:labeled-version REPORT:\n\n-------------------\n\n8.3DAV:labeled-version Report\nThe DAV:labeled-version report describes the requested properties\nof the version with that label in a specified version history.\nIf the DAV:labeled-version report is applied to a version-controlled\nresource, it is applied to the DAV:version-history of that\nversion-controlled resource.\n\nMarshalling:\n\nThe request body MUST be a DAV:labeled-version XML element.\n\n<!ELEMENT labeled-version ANY>\n\nANY value: a sequence of zero or more elements, with\nat most one DAV:prop element and with exactly one\nDAV:label-name element.\n\nprop: see RFC 2518, Section 12.11\n\nThe response body for a successful request MUST be a DAV:multistatus\nXML element.\n\nmultistatus: see RFC 2518, Section 12.9\n\nThe response body for a successful DAV:labeled-version REPORT\nrequest MUST contain a DAV:response element for each resource\nthat satisfies the Depth header of the request.\n\n8.3.1Example - DAV:labeled-version Report\n\n>>REQUEST\n\n  REPORT /folder/ HTTP/1.1\n  Host: www.webdav.org\n  Content-Type: text/xml; charset=\"utf-8\"\n  Content-Length: xxxx \n  Depth: 1\n\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:labeled-version xmlns:D=\"DAV:\">\n    <D:label-name>tested</D:label-name>\n    <D:prop>\n      <D:version-name/>\n      <D:version/>\n    </D:prop>\n  </D:labeled-version>\n\n>>RESPONSE\n\n  HTTP/1.1 207 Multi-Status\n  Content-Type: text/xml; charset=\"utf-8\"\n  Content-Length: xxxx\n\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:multistatus xmlns:D=\"DAV:\">\n    <D:response>\n      <D:href>http://www.webdav.org/folder/</D:href>\n      <D:propstat>\n        <D:prop>\n          <D:version-name>V5</D:version-name>\n           <D:version>\n            <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n          </D:version>\n        </D:prop>\n        <D:status>HTTP/1.1 200 OK</D:status>\n      </D:propstat>\n    </D:response>\n    <D:response>\n      <D:href>http://www.webdav.org/folder/foo.html</D:href>\n      <D:propstat>\n        <D:prop>\n          <D:version-name>V8</D:version-name>\n          <D:version>\n            <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n          </D:version>\n        </D:prop>\n        <D:status>HTTP/1.1 200 OK</D:status>\n      </D:propstat>\n    </D:response>\n  </D:multistatus>\n\n-----------------------------------------\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@Rational.Com]\nSent: Sunday, April 28, 2002 9:53 AM\nTo: 'Deltav WG'\nSubject: Replacing the Label header with a DAV:labeled-version report\n\n\nSince this is a fairly significant change, I'd like to\nhear from a few more folks before adding this to the 3253 Errata.\n\nThanks,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Saturday, April 27, 2002 5:09 AM\nTo: Clemm, Geoff; 'Deltav WG'\nSubject: RE: Label header vs PROPFIND depth 1\n\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, April 26, 2002 6:06 PM\n> To: 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    - I'd like to see the label *header* deprecated\n>    - I'm happy with the LABEL method and the label-name-set property\n>    - I think that PROPFIND/label should be replaced by a specific REPORT\n>\n> Is the proposed DAV:labeled-version report OK with you?\n\nYes. But I think it's Tim's turn to say whether this would work for him or\nnot...\n\n>    - I'm unsure about other methods that are currently affected by the\n>    header -- what were the requirements...?\n>\n> The other methods are LABEL, CHECKOUT, GET, and COPY.\n> For Depth:0 variants of these operations, the Label header\n> just provided an optimization to save one roundtrip\n> (i.e. first getting the version URL via the DAV:labeled-version report).\n> I believe we can easily do without that Depth:0 optimization.\n\nAs stated before, I think that's not the single problem. Having GET return a\n(representation of a) version rather than (a representation of) the VCR\nmakes the version *by definition* a variant (representation) of the VCR --\nand it seems that most of us want to avoid that interpretation.\n\n> For Depth:infinity (only relevant for LABEL and COPY), the savings\n> would be more significant, but unfortunately the semantics is broken\n> (since if the namespace is being versioned, you'll get the wrong\n> resources if you simply do a Depth operation on the current namespace).\n>\n> The Depth:infinity Label header operations are really just a way of\n> trying to have the client fake workspaces and baselines, instead of\n> having the server support them directly.  Since it is much more\n> efficient and reliable to have the server layer these constructs\n> above a labeling infrastructure, rather than having the client do\n> so, I believe the cost of maintaining these Depth:infinity Label\n> header operations in the protocol is not warranted.\n>\n> Note though that (depth:0) labeling and baselining go very well\n> together.  Instead of doing a Depth:infinity LABEL, you can create a\n> baseline (which under the hood the server may well implement with\n> reserved labels, but maybe not), and then LABEL that baseline.  Then\n> when you want to do a Depth:infinity COPY, you retrieve the\n> DAV:baseline-collection of the labeled baseline (using the\n> DAV:labeled-version report), and copy that to wherever you want.\n>\n> Alternatively, if you want a \"modifiable\" selection, you can create a\n> workspace (which under the hood the server may well implement with\n> reserved labels, but maybe not).  When you want to adjust the versions\n> being selected, you just use UPDATE.  Then when you want to do a\n> Depth:infinity COPY, you just copy from that workspace to wherever you\n> want.\n>\n>    - Servers that decide to implement LABEL and DAV:label-name-set,\n>    but no not support the label header should *not* report the LABEL\n>    feature in OPTIONS.\n>\n> That's probably right.  A client can find out if the LABEL operation\n> is supported by querying the DAV:supported-method-set property values\n> of a VCR.\n\n...and also use DAV:supported-live-property-set to discover the\nDAV:label-name-set property.\n\n\n\n", "id": "lists-007-1636127"}, {"subject": "Business/Employment Opportunit", "content": "Dear Friend:\n\n\"Making over half million dollars every 4 to 5 months from your\nhome for an investment of only $25 U.S. Dollars expense one\ntime\"\n\nTHANKS TO THE COMPUTER AGE AND THE INTERNET!\n===============================================\n\nBE A MILLIONAIRE LIKE OTHERS WITHIN A YEAR !!\n\nBefore you say \"Bull\" , please read the following. This is the\nletter you have been hearing about on the news lately. Due to the\npopularity of this letter on the internet, a national weekly news\nprogram recently devoted an entire show to the investigation of\nthis program described below , to see if it really can make people\nmoney.\n\nThe show also investigated whether or not the program was legal.\nTheir findings proved once and for all that there are \"absolutely\nno laws prohibiting the participation in the program and if people\ncan follow the simple instructions, they are bound to make\nsome mega bucks with only $25 out of pocket cost\".\n\nDUE TO THE RECENT INCREASE OF POPULARITY & RESPECT\nTHIS PROGRAM HAS ATTAINED, IT IS CURRENTLY WORKING\nBETTER THAN EVER.\n\nThis is what one had to say:\n\n\"Thanks to this profitable opportunity. I was approached\nmany times before but each time I passed on it. I am so glad\nI finally joined just to see what one could expect in return\nfor the minimal effort and money required. To my astonishment, I\nreceived total $ 610,470.00 in 21 weeks, with money still\ncoming in\".\nPam Hedland, Fort Lee, New Jersey.\n\n-------------------------------------------------------------------------\n\nHere is another testimonial:\n\n\"This program has been around for a long time but I never\nbelieved in it. But one day when I received this again in\nthe mail I decided to gamble my $25 on it. I followed thesimple instructions and walaa ..... 3 weeks later the money\nstarted to come in. First month I only made $240.00 but\nthe next 2 months after that I made a total of $290,000.00.\nSo far, in the past 8 months by re-entering the program,I\nhave made over $710,000.00 and I am playing it again.\nThe key to success in this program is to follow the simple\nsteps and NOT change anything .\"\n\nMore testimonials later but first,\n\n****** PRINT THIS NOW FOR YOUR FUTURE REFERENCE *******\n\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\nIf you would like to make at least $500,000 every 4 to 5 months\neasily and comfortably, please read the following...THEN READ\nIT AGAIN and AGAIN !!!\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n\nFOLLOW THE SIMPLE INSTRUCTION BELOW AND YOUR\nFINANCIAL DREAMS WILL COME TRUE, GUARANTEED!\n\nINSTRUCTIONS:\n\n**** Order all 5 reports shown on the list below.\n\n**** For each report, send $5 CASH, THE NAME & NUMBER OF THE\nREPORT YOU ARE ORDERING and YOUR E-MAIL ADDRESS\nto the person whose name appears ON THAT LIST next to the report.\nMAKE SURE YOUR RETURN ADDRESS IS ON YOUR ENVELOPE\nTOP LEFT CORNER in case of any mail problems.\n\n**** When you place your order, make sure you order each of the 5\nreports. You will need all 5 reports so that you can save them on your \ncomputer and resell them. YOUR TOTAL COST $5 X 5 = $25.00.\n\n**** Within a few days you will receive, via e-mail, each of the 5\nreports from these 5 different individuals. Save them on your computer\nso they will be accessible for you to send to the 1,000's of people\nwho will order them from you. Also make a floppy of these\nreports and keep it on your desk in case something happen to your\ncomputer.\n\n****.IMPORTANT - DO NOT alter the names of the people who are\nlisted next to each report, or their sequence on the list, in\nany way other than what is instructed below in steps 1 through6 or you will loose out on majority of your profits. Once you\nunderstand the way this works, you will also see how it does not work if you \nchange it.\n\nRemember, this method has been tested, and if you alter, it\nwill NOT work!!! People have tried to put their friends/relatives names\non all five thinking they could get all the money. But it does not work this \nway. Believe us, we all have tried to be greedy and then nothing happened. \nSo Do Not try to change anything other than what is instructed. Because if \nyou do, it will not work for you. Remember, honesty reaps the reward!!!\n\n1.. After you have ordered all 5 reports, take this advertisement\nand REMOVE the name & address of the person in REPORT # 5. This\nperson has made it through the cycle and is no doubt counting\ntheir fortune.\n\n2.... Move the name & address in REPORT # 4 down TO REPORT # 5.\n\n3.... Move the name & address in REPORT # 3 down TO REPORT # 4.\n\n4.... Move the name & address in REPORT # 2 down TO REPORT # 3.\n\n5.... Move the name & address in REPORT # 1 down TO REPORT # 2\n\n6.... Insert YOUR name & address in the REPORT # 1 Position.\n\nPLEASE MAKE SURE you copy every name & address ACCURATELY !\n=========================================================\n\nTake this entire letter, with the modified list of names, and save\nit on your computer. DO NOT MAKE ANY OTHER CHANGES.\nSave this on a disk as well just in case if you loose any data.\n\nTo assist you with marketing your business on the internet, the\n5 reports you purchase will provide you with invaluable\nmarketing information which includes how to send bulk e-mails legally,\nwhere to find thousands of free classified ads and much more.\n\nThere are 2 Primary methods to get this venture going:\n\nMETHOD # 1 : BY SENDING BULK E-MAIL LEGALLY\n============================================\nlet's say that you decide to start small, just to see how it\ngoes, and we will assume You and those involved send out only\n5,000 e-mails each. Let's also assume that the mailing receive only a0.2% response (the response could be much better but lets just\nsay it is only 0.2% . Also many people will send out hundreds of\nthousands e-mails instead of only 5,000 each).\n\nContinuing with this example, you send out only 5,000 e-mails.\nWith a 0.2% response, that is only 10 orders for report # 1.\nThose 10 people responded by sending out 5,000 e-mail\neach for a total of 50,000. Out of those 50,000 e-mails only\n0.2% responded with orders. That's = 100 people responded\nand ordered Report # 2. Those 100 people mail out 5,000\ne-mails each for a total of 500,000 e-mails. The 0.2% response\nto that is 1000 orders for Report # 3. Those 1000 people send\nout 5,000 e-mails each for a total of 5 million e-mails sent out.\nThe 0.2% response to that is 10,000 orders for Report # 4.\nThose 10,000 people send out 5,000 e-mails each for a total of\n50,000,000 (50 million) e-mails. The 0.2% response to that is\n100,000 orders for Report # 5.\n\nTHAT'S 100,000 ORDERS TIMES $5 EACH = $500,000.00 (half million).\n\nYour total income in this example is:\n1..... $50 +\n2..... $500 +\n3..... $5,000 +\n4..... $50,000 +\n5..... $500,000 ......... Grand Total = $555,550.00\n\nNUMBERS DO NOT LIE. GET A PENCIL & PAPER AND FIGURE\nOUT THE WORST POSSIBLE RESPONSES AND NO MATTER\nHOW YOU CALCULATE IT, YOU WILL STILL MAKE A LOT OF\nMONEY !\n\n------------------------------------------------------------------------------\n\nREMEMBER FRIEND, THIS IS ASSUMING ONLY 10 PEOPLE\nORDERING OUT OF 5,000 YOU MAILED TO. Dare to think for\na moment what would happen if everyone, or half or even one 4th\nof those people mailed 100,000 e-mails each or more? There are\nover 250 million people on the internet worldwide and counting.\nBelieve me, many people will do just that, and more!\n\nMETHOD # 2 : BY PLACING FREE ADS ON THE INTERNET\n===================================================\nAdvertising on the net is very very inexpensive and there are\nhundreds of FREE places to advertise. Placing a lot of free adson the internet will easily get a larger response. We strongly\nsuggest you start with Method # 1 and add METHOD # 2 as you go\nalong.\n\nFor every $5 you receive, all you must do is e-mail them the Report\nthey ordered. That's it . Always provide same day service on all\norders. This will guarantee that the e-mail they send out, with your\nname and address on it, will be prompt because they can not advertise until \nthey receive the report.\n\n_____________________ AVAILABLE REPORTS_____________________\n\nORDER EACH REPORT BY ITS NUMBER & NAME ONLY.\n\nNotes: Always send $5 cash (U.S. CURRENCY) for each Report.\nChecks NOT accepted. Make sure the cash is concealed by wrapping\nit in at least 2 sheets of paper. On one of those sheets of paper,\nWrite the NUMBER & the NAME of the Report you are ordering, YOUR\nE-MAIL ADDRESS and your name and postal address.\n\nPLACE YOUR ORDER FOR THESE REPORTS NOW :\n==============================================\nREPORT #1, \"The Insider's Guide to Sending\nBulk E-mail on the Internet\"\n\nORDER REPORT #1 FROM:\n\nG. Donaldson\nP.O. Box 25884\nHonolulu, Hawaii 96825-0884\n\n\ndon't forget to provide a permanent e-mail address in clear writing (better \ntyped) to receive the reports. We had problems in delivery e-mails before!!!\n\n==============================================\nREPORT #2 \"The Insider's Guide to Advertising for Free on the\nInternet\"\nORDER REPORT #2 FROM:\n\nVijay Paul\nC-291, Second Floor\nDefence Colony\nNew Delhi - 110024\nINDIA\n\n==============================================\nREPORT #3 \"The Secrets to Multilevel Marketing on the Internet\"\nORDER REPORT #3 FROM:\n\nJD\nP.O.Box 1114\nDes Plaines, IL 60017\nUSA\n\n==============================================\nREPORT #4 \"How to become a Millionaire utilizing the Power of\nMultilevel Marketing and the Internet\"\nORDER REPORT #4 FROM:\n\nJ Santi\n833 Walter Ave\nDes Plaines, IL 60016\nUSA\n\n==============================================\nREPORT #5 \"How to SEND 1,000,000 e-mails for FREE\"\nORDER REPORT #5 FROM:\n\nElaine Rix\n138 Dundas Street, West, #243\nToronto, Ontario\nCanada M5G 1C3\n\n==============================================\nThere are currently more than 250,000,000 people online\nworldwide!\n\n$$$$$$$$$ YOUR SUCCESS GUIDELINES $$$$$$$$$$$\n\nFollow these guidelines to guarantee your success:\n\nIf you do not receive at least 10 orders for Report #1 within 2\nweeks, continue sending e-mails until you do.\n\nAfter you have received 10 orders, 2 to 3 weeks after that\nyou should receive 100 orders or more for REPORT # 2.\nIf you did not, continue advertising or sending e-mails until\nyou do.\nOnce you have received 100 or more orders for Report # 2,\nYOU CAN RELAX, because the system is already working for\nyou , and the cash will continue to roll in !\n\nTHIS IS IMPORTANT TO REMEMBER : Every time your name is\nmoved down on the list, you are placed in front of a different report.\nYou can KEEP TRACK of your PROGRESS by watching which\nreport people are ordering from you. IF YOU WANT TO GENERATE\nMORE INCOME SEND ANOTHER BATCH OF E-MAILS AND\nSTART THE WHOLE PROCESS AGAIN. There is NO LIMIT to\nthe income you can generate from this business !!!\n____________________________________________________\n\nFOLLOWING IS A NOTE FROM THE ORIGINATOR OF THIS\nPROGRAM:\n\nYou have just received information that can give you financial\nfreedom for the rest of your life, with NO RISK and JUST A\nLITTLE BIT OF EFFORT. You can make more money in the\nnext few weeks and months than you have ever imagined.\n\nFollow the program EXACTLY AS INSTRUCTED. Do Not change\nit in any way. It works exceedingly well as it is now.\nRemember to e-mail a copy of this exciting report after you\nhave put your name and address in Report #1 and moved others to\n#2...........# 5 as instructed above. One of the people you send this to may \nsend out 100,000 or more e-mails and your name will be on everyone of them. \nRemember though, the more you send out the more potential customers you will \nreach.\n\nSo my friend, I have given you the ideas, information,\nmaterials and opportunity to become financially independent. IT IS UP TO YOU \nNOW !\n\n************** MORE TESTIMONIALS ****************\n\n\"My name is Mitchell. My wife , Jody and I live in Chicago.\nI am an accountant with a major U.S. Corporation and I\nmake pretty good money. When I received this program I grumbled\nto Jody about receiving ''junk mail''. I made fun of the\nwhole thing, spouting my knowledge of the population and\npercentages involved. I ''knew'' it wouldn't work. Jody\ntotally ignored my supposed intelligence and few days later she jumped in \nwith both feet. I made merciless fun of her, and was ready to\nlay the old ''I told you so'' on her when the thing didn'twork. Well, the laugh was on me! Within 3 weeks she had received\n50 responses. Within the next 45 days she had received a\ntotal of $ 147,200.00 all cash! I was shocked. I have\njoined Jody in her ''hobby''.\"\nMitchell Wolf,\nChicago, Illinois\n\n------------------------------------------------------------\n\n\"Not being the gambling type, it took me several weeks to\nmake up my mind to participate in this plan. But conservative that\nI am, I decided that the initial investment was so little\nthat there was just no way that I wouldn't get enough orders to at\nleast get my money back.\n\nI was surprised when I found my medium size post office box\ncrammed with orders. I made $319,210.00 in the first 12\nweeks. The nice thing about this deal is that it does not matter\nwhere people live. There simply isn't a better investment\nwith a faster return and so big.\"\nDan Sondstrom, Alberta,\nCanada\n\n-----------------------------------------------------------\n\n\"I had received this program before. I deleted it, but\nlater I wondered if I should have given it a try. Of course, I had\nno idea who to contact to get another copy, so I had to wait\nuntil I was e-mailed again by someone else.........11 months\npassed then it luckily came again...... I did not delete this\none! I made more than $490,000 on my first try and all the\nmoney came within 22 weeks\".\nSusan De Suza,\nNew York, N.Y.\n\n----------------------------------------------------\n\n\"It really is a great opportunity to make relatively easy\nmoney with little cost to you. I followed the simple\ninstructions carefully and within 10 days the money\nstarted to come in. My first month I made $ 20,560.00\nand by the end of third month my total cash count was\n$ 362,840.00. Life is beautiful, Thanx to internet\".\nFred Dellaca, Westport,\nNew Zealand\n------------------------------------------------------------\n\n\nORDER YOUR REPORTS TODAY AND GET STARTED ON\nYOUR ROAD TO FINANCIAL FREEDOM !\n\n=======================================================\n\nIf you have any questions of the legality of this program, contact the\nOffice of Associate Director for Marketing Practices, Federal Trade\nCommission, Bureau of Consumer Protection, Washington, D.C.\n\n\nUnder Bill s.1618 TITLE III passed by the 105th US Congress this\nletter cannot be considered spam as long as the sender includes\ncontact information and a method of removal.\nThis is one time e-mail transmission. No request for removal is\nnecessary.\n\n------------------------------------------------------------\nThis message is sent in compliance of the new email\nBill HR 1910. Under Bill HR 1910 passed by the 106th\nUS Congress on May 24, 1999, this message cannot be\nconsidered Spam as long as we include the way to be\nremoved. Per Section HR 1910, Please type \"REMOVE\" in\nthe subject line and reply to this email. All removal\nrequests are handled personally an immediately once\nreceived.\n\n\n\n", "id": "lists-007-16368391"}, {"subject": "Re: multipart/alternative extensio", "content": "At 16.32 -0400 01-05-08, Keith Moore wrote:\n>you could even use MHTML and multipart/related.  put the above text\n>in HTML with clickable links to the other body parts.\n\nAn example how this could look to a user of a web-based MUA\nis shown at http://cmc.dsv.su.se/kom/specs/simple-translation-step.html.\nThat example, however, puts all the different translations in\na single body part.\n\nI have not yet tested how well existing mailers can handle something\nlike this.\n-- \nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-16389766"}, {"subject": "Re: Discussion of an app-layer API for IPse", "content": "Keith Moore wrote:\n\n> I basically think that IPsec is nearly useless without an application-layer\n> API, but the API needs to not only make applications aware of whether\n> a security association has been established (along with the credentials\n> so that the application can evaluate them for itself) but also allow\n> the application to control the credentials that are used when establishing\n> SAs.\n\nAnd one possible use of this is API is for EXTERNAL SASL mechanism, implemented\non top of IPSec.\n\nAlexey\n\n\n\n", "id": "lists-007-16397541"}, {"subject": "Re: Discussion of an app-layer API for IPse", "content": "At 2:30 AM -0600 5/14/01, Alexey Melnikov wrote:\n>Keith Moore wrote:\n>\n>>  I basically think that IPsec is nearly useless without an application-layer\n>>  API, but the API needs to not only make applications aware of whether\n>>  a security association has been established (along with the credentials\n>>  so that the application can evaluate them for itself) but also allow\n>>  the application to control the credentials that are used when establishing\n>>  SAs.\n>\n>And one possible use of this is API is for EXTERNAL SASL mechanism, \n>implemented\n>on top of IPSec.\n\nThis makes a lot of sense. Is anyone here in the Apps Area \ninteresting in really persuing it? If not, I don't expect it to move \nforwards. There are only two or three people in the IPsec area who \nexpressed any interest in doing the real work (Bill Sommerfeld and \nSteve Bellovin).\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-16405878"}, {"subject": "Re: Discussion of an app-layer API for IPse", "content": "> At 2:30 AM -0600 5/14/01, Alexey Melnikov wrote:\n> >Keith Moore wrote:\n> >\n> >>  I basically think that IPsec is nearly useless without an application-layer\n> >>  API, but the API needs to not only make applications aware of whether\n> >>  a security association has been established (along with the credentials\n> >>  so that the application can evaluate them for itself) but also allow\n> >>  the application to control the credentials that are used when establishing\n> >>  SAs.\n> >\n> >And one possible use of this is API is for EXTERNAL SASL mechanism,\n> >implemented\n> >on top of IPSec.\n\n> This makes a lot of sense. Is anyone here in the Apps Area\n> interesting in really persuing it? If not, I don't expect it to move\n> forwards. There are only two or three people in the IPsec area who\n> expressed any interest in doing the real work (Bill Sommerfeld and\n> Steve Bellovin).\n\nThe main problem with application use of IPSec is that it crosses the\napplication/OS boundary. Crossing such boundaries is tricky -- it places\nadditional constraints on vendors, release schedules, and so on.\n\nRemember, applications already have TLS/SSL. And while TLS/SSL has many\ndisadvantages in terms of performance, applicability to UDP, and so on, it has\none truly overwhelming advantage: It is entirely within the application's\ncontrol. Application developers spend a lot of their time working around OS\ndifferences, bugs, and other issues, and are underwhelmed by the prospect of\nadditional issues in this area.\n\nUnless IPSec has a really good story to tell appliccations about the advantages\nthat will accrue from its use as well as some indication that it will actually\ndeploy in a fashion that's usable by applications, I despair of getting\napplications people fired up about it.\n\nNed\n\n\n\n", "id": "lists-007-16414472"}, {"subject": "Re: Discussion of an app-layer API for IPse", "content": "> Unless IPSec has a really good story to tell appliccations about the advantages\n> that will accrue from its use as well as some indication that it will actually\n> deploy in a fashion that's usable by applications, I despair of getting\n> applications people fired up about it.\n\nIf the good story exists, I suspect it is in the ability to use the same authentication \ncredentials be verifiable by the endpoints as well as the network.  i.e. the same IPsec \ncredentials could be used at multiple points in the path from end to end. ideally,\none set of credentials would suffice for the entire path, even though it crossed\nmultiple administrative realms.\n\nmy admittedly weak understanding of this indicates that it would require making\ncross-realm authentication (and cross-realm trust) scalable.  which sounds more \nlike a research problem to me than an engineering exercise.  but I'd love to hear \notherwise.\n\nKeith\n\n\n\n", "id": "lists-007-16424515"}, {"subject": "Applications performance measuremen", "content": "Network Computing has an article in the current issue about \nApplications Performance Measurement, with lots of talk about the \nIETF work on it. <http://www.networkcomputing.com/1210/1210f4.html> \nThe article is written by the author of the following draft, which is \nbeing discussed in the RMONMIB WG:\n\n   \"Application Performance Measurement MIB\", Steven Waldbusser, 03/07/2001,\n   <draft-ietf-rmonmib-apm-mib-03.txt>\n\n     This memo defines a portion of the Management Information Base\n     (MIB) for use with network management protocols in TCP/IP-\n     based internets.  In particular, it defines objects for\n     measuring the application performance as experienced by end-\n     users.\n\nApplications folks may want to follow this.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-16433486"}, {"subject": "Health Coverage Quote", "content": "------ Are you tired of rising health insurance rates?\n\nHave you noticed things not covered that used to be? \n\n\n---------------    What is happening?    -----------------  \n\n\nDo you want control of your\n insurance and medical costs once again?\n\nAre you paying your own health insurance costs, and are you under 65?  \n\nIf you are on a Cobra plan, self-employed, a spouse without \nbenefits or an early retiree email us for free information.  \n\nFamilies typically save from $1050-$3250 per year and get better coverage.\n\nIf you would like information on how to upgrade your coverage and save money at the same time, please email us.  \n\nmailto:Harry70_@excite.com \n\n\n\n\n\n\n\nto be removed from our list mailto:Insurancequotes100@yahoo.com\n------ Are you tired of rising health insurance rates?\n\nHave you noticed things not covered that used to be? \n\n\n---------------    What is happening?    -----------------  \n\n\nDo you want control of your\n insurance and medical costs once again?\n\nAre you paying your own health insurance costs, and are you under 65?  \n\nIf you are on a Cobra plan, self-employed, a spouse without \nbenefits or an early retiree email us for free information.  \n\nFamilies typically save from $1050-$3250 per year and get better coverage.\n\nIf you would like information on how to upgrade your coverage and save money at the same time, please email us.  \n\nmailto:Harry70_@excite.com \n\n\n\n\n\n\n\nto be removed from our list mailto:Insurancequotes100@yahoo.com\n\n\n\n", "id": "lists-007-16440600"}, {"subject": "Re: Discussion of an app-layer API for IPse", "content": "I'm new to the IPSEC world, but 'm looking for a generic IPSEC API. \nIs there such a thing? If not, is this a good topic for ietf working group?\n\nThanks!\n\n\n\n", "id": "lists-007-16448866"}, {"subject": "Re: X3.4-196", "content": "> From: \"Eric A. Hall\" <ehall@ehsco.com>\n> To: <discuss@apps.ietf.org>\n> Sent: Wednesday, October 24, 2001 10:06 AM\n> Subject: X3.4-1968\n\nI found one a week ago. Ignore the delayed post.\n\n:)\n\n\n\n", "id": "lists-007-16509535"}, {"subject": "canonical MIME header", "content": "I've been looking through the various MIME specifications looking for a\nspecific reference to a canonical form for MIME headers.  The canonical\nencoding model in 2049 is not quite what I'm looking for.  Hoping I'm\nsimply overlooking it here's what I am looking for.\n\nSuppose an external application wanted to digitally sign a MIME body\npart, which would include its headers and content.  What it needs is a\nunique and unambiguous representation of the headers.\n\nThe line terminator issue is covered by the canonical encoding model but\nthere's no discussion of issues like downcasing case insensitive values,\nunfolding lines, collapsing repeating whitespace, ordering parameters,\netc.\n\nIs this discussed anywhere?\n\nThanks,\n\nJim\n\n\n\n", "id": "lists-007-16515996"}, {"subject": "Re: canonical MIME header", "content": "> I've been looking through the various MIME specifications looking for a\n> specific reference to a canonical form for MIME headers. \n\nthere's not one.\n\nfurthermore, the set of transformations which are applied by widely-deployed\nMTAs is such that it's probably impossible to define a canonical form such \nthat canonical_form(source message) == canonical_form(delivered message)\nwith any reliability.\n\nthis is why all of the protocols for signing mail encapsulate the signed\nmessage inside an attachment, and expect MTAs to treat the attachment as\nan opaque object rather than (say) munging its header or translating its\ncontent.\n\nunder those conditions there is no need for a unique and unambiguous \nrepresentation of the headers.\n\nKeith\n\n\n\n", "id": "lists-007-16524005"}, {"subject": "Re: canonical MIME header", "content": "> > I've been looking through the various MIME specifications looking for a\n> > specific reference to a canonical form for MIME headers.\n\n> there's not one.\n\n> furthermore, the set of transformations which are applied by widely-deployed\n> MTAs is such that it's probably impossible to define a canonical form such\n> that canonical_form(source message) == canonical_form(delivered message)\n> with any reliability.\n\nI agree.\n\n> this is why all of the protocols for signing mail encapsulate the signed\n> message inside an attachment, and expect MTAs to treat the attachment as\n> an opaque object rather than (say) munging its header or translating its\n> content.\n\n> under those conditions there is no need for a unique and unambiguous\n> representation of the headers.\n\nIt would be handy, however, if we were to define a hash with the\nproperties that:\n\n(1) Body data encodings were removed prior to hash computation, and\n(2) Each body was hashed separately and then the sequence of hashes and\n    headers hashed again.\n(3) Content-transfer-encoding indicators would not be included in the\n    hash.\n\nThe advantage here would be that the result would be invariant under encoding\nchanges (albeit with the remaining requirement that header ordering and\nboundaries would have to be preserved) and would allow reuse of previously\ncomputed hashes of body data. But all this could be done with a\nspecialized micalg; there is no need to define a full canonical form.\n\nI've been meaning to write this up for years but I've never gotten around\nto it.\n\nNed\n\n\n\n", "id": "lists-007-16531664"}, {"subject": "Re: canonical MIME header", "content": "Seems like it would also be fairly easy to abstract out multipart\nseparators so as to be immune from them being re-written.\n\nDonald\n\nFrom:  <ned.freed@mrochek.com>\nDate:  Wed, 07 Nov 2001 21:59:12 -0800 (PST)\nIn-reply-to:  \"Your message dated Wed, 07 Nov 2001 20:47:02 -0500\"\n      <200111080147.fA81l2T21356@astro.cs.utk.edu>\nTo:  Keith Moore <moore@cs.utk.edu>\nCc:  James M Galvin <galvin@elistx.com>, discuss@apps.ietf.org\nMessage-id:  <01KAFS6BRZDI0013KR@mauve.mrochek.com>\nReferences:  <Pine.BSF.4.21.0111071458070.2976-100000@two.elistx.com>\n\n>> > I've been looking through the various MIME specifications looking for a\n>> > specific reference to a canonical form for MIME headers.\n>\n>> there's not one.\n>\n>> furthermore, the set of transformations which are applied by widely-deployed\n>> MTAs is such that it's probably impossible to define a canonical form such\n>> that canonical_form(source message) == canonical_form(delivered message)\n>> with any reliability.\n>\n>I agree.\n>\n>> this is why all of the protocols for signing mail encapsulate the signed\n>> message inside an attachment, and expect MTAs to treat the attachment as\n>> an opaque object rather than (say) munging its header or translating its\n>> content.\n>\n>> under those conditions there is no need for a unique and unambiguous\n>> representation of the headers.\n>\n>It would be handy, however, if we were to define a hash with the\n>properties that:\n>\n>(1) Body data encodings were removed prior to hash computation, and\n>(2) Each body was hashed separately and then the sequence of hashes and\n>    headers hashed again.\n>(3) Content-transfer-encoding indicators would not be included in the\n>    hash.\n>\n>The advantage here would be that the result would be invariant under encoding\n>changes (albeit with the remaining requirement that header ordering and\n>boundaries would have to be preserved) and would allow reuse of previously\n>computed hashes of body data. But all this could be done with a\n>specialized micalg; there is no need to define a full canonical form.\n>\n>I've been meaning to write this up for years but I've never gotten around\n>to it.\n>\n>Ned\n>\n\n\n\n", "id": "lists-007-16540873"}, {"subject": "Re: canonical MIME header", "content": "> Seems like it would also be fairly easy to abstract out multipart\n> separators so as to be immune from them being re-written.\n\nThe problem is that the separator is buried in the preceeding header.\nHandling that correctly ups the complexity considerability. IMO the\nadded complexity isn't worth it.\n\nNed\n\n\n\n", "id": "lists-007-16552697"}, {"subject": "Re: canonical MIME header", "content": "I just know I'm going to feel dumb when you point out the obvious but\nfrankly I don't get your point at all.\n\nI've just finished processing the \"preceding\" header so I've got the\nboundary marker and now I'm moving through the content.  I simply\nsubstitute some standard string for digest purposes for every boundary\nmarker as I come across it.\n\nWhat am I missing?\n\nJim\n\n\n\n\nOn Thu, 8 Nov 2001 ned.freed@mrochek.com wrote:\n\n    Date: Thu, 08 Nov 2001 19:50:15 -0800 (PST)\n    From: ned.freed@mrochek.com\n    To: Donald E. Eastlake 3rd <dee3@torque.pothole.com>\n    Cc: ned.freed@mrochek.com, Keith Moore <moore@cs.utk.edu>,\n         James M Galvin <galvin@eListX.com>, discuss@apps.ietf.org\n    Subject: Re: canonical MIME headers\n    \n    > Seems like it would also be fairly easy to abstract out multipart\n    > separators so as to be immune from them being re-written.\n    \n    The problem is that the separator is buried in the preceeding header.\n    Handling that correctly ups the complexity considerability. IMO the\n    added complexity isn't worth it.\n    \n    Ned\n    \n\n\n\n", "id": "lists-007-16561001"}, {"subject": "RE: Replacing the Label header with a DAV:labeled-version repor", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Saturday, June 29, 2002 12:23 AM\n> To: 'Deltav WG'\n> Subject: RE: Replacing the Label header with a DAV:labeled-version\n> report\n>\n>\n>\n> Julian didn't like the marshalling of this report,\n> because it makes it look like the properties are those of\n> the VCR, when they actually are properties of the version\n> (Basically, I was just being lazy and re-using the D:response\n> element in a bogus fashion).\n\nYes, that's the problem, and I fear the new format doesn't address this.\n\nIf the multistatus/response format is re-used for a REPORT (basically a good\nthing), it must not break the existing semantics, in particular:\n\n- the properties reported must actually be the properties of the resource\nidentified by the reported URI (DAV:href) and\n- the properties reported actually must be properties (!).\n\nIf this is not the case, the response seems to indicate that there's a\nDAV:labeled-version-report property, which isn't the case.\n\nSo how about properly extending the response element, for instance:\n\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:multistatus xmlns:D=\"DAV:\">\n\n    <D:response>\n      <D:href>http://www.webdav.org/folder/</D:href>\n      <D:labeled-version-report>\n        <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n        <D:propstat>\n          <D:prop>\n            <D:version-name>V5</D:version-name>\n          </D:prop>\n          <D:status>HTTP/1.1 200 OK</D:status>\n        </Dpropstat>\n      </D:labeled-version-report>\n      <D:status>HTTP/1.1 200 OK</D:status>\n    </D:response>\n\n   <D:response>\n      <D:href>http://www.webdav.org/folder/foo.html</D:href>\n      <D:labeled-version-report>\n        <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n          <D:propstat>\n            <D:prop>\n              <D:version-name>V8</D:version-name>\n          </D:prop>\n          <D:status>HTTP/1.1 200 OK</D:status>\n        </D:propstat>\n      </D:labeled-version-report>\n      <D:status>HTTP/1.1 200 OK</D:status>\n    </D:response>\n\n  </D:multistatus>\n\n\n\n", "id": "lists-007-1656666"}, {"subject": "Re: canonical MIME header", "content": "> I just know I'm going to feel dumb when you point out the obvious but\n> frankly I don't get your point at all.\n> \n> I've just finished processing the \"preceding\" header so I've got the\n> boundary marker and now I'm moving through the content.  I simply\n> substitute some standard string for digest purposes for every boundary\n> marker as I come across it.\n\nyes, I think this is doable.\n\nKeith\n\n\n\n", "id": "lists-007-16571244"}, {"subject": "Re: canonical MIME header", "content": "> I've just finished processing the \"preceding\" header so I've got the\n> boundary marker and now I'm moving through the content.  I simply\n> substitute some standard string for digest purposes for every boundary\n> marker as I come across it.\n\n> What am I missing?\n\nAside from the not-inconsiderable complexity of writing the right sort of\nparser for this, I don't know of any problems actually computing the digest.\nThe problems arise when software attempts to take advantage of this new-found\nability to actually substitute boundary strings since it knows the substitution\nwon't change the resulting MIC. If your new boundary is longer than the\noriginal you have to worry about line length issues. And even if your new\nboundary is shorter or the same size as the original, line wrap in the middle\nof a boundary may force you to use a marker containing a space so as to avoid\nline length issues that might arise if you remove the fold as part of your\nprocessing.\n\nSounds pretty complicated to me. And more to the point: What does it gain? My\nunderstanding is that the underlying goal here is to eliminate the requirement\nthat signed messages be 7bit. That requirement exists because of the need to\ndowngrade 8bit messages to 7bit in some cases, which currently would break the\nsignature. We therefore need a signature mechanism that is invariant when\nencodings are downgraded. But such downgrading never needs to change the\nboundary marker -- base64 never conflicts with an existing marker and\nquoted-printable can be done in such a way that boundary marker collisons\ncannot happen.\n\nNed\n\nP.S. I should also mention that extremely long content-type fields are not a\npurely academic concern. Applications exist that routinely generate\ncontent-type fields thousands of characters long.\n\n\n\n", "id": "lists-007-16578849"}, {"subject": "Fwd: Last Call: Date and Time on the Internet: Timestamps to   Proposed Standar", "content": "Greetings again. The following draft (covering date and time formats) \nprobably affects all IETF applications protocols, and makes for \ninteresting reading. It is in IETF last call, so this is a good time \nto do serious nit-picking on it.\n\n>To: IETF-Announce: ;\n>Cc: impp@iastate.edu\n>From: The IESG <iesg-secretary@ietf.org>\n>SUBJECT: Last Call: Date and Time on the Internet: Timestamps to\n>Proposed Standard\n>Reply-to: iesg@ietf.org\n>Date: Fri, 09 Nov 2001 11:57:32 -0500\n>Sender: scoya@cnri.reston.va.us\n>\n>\n>The IESG has received a request from the Instant Messaging and Presence\n>Protocol Working Group to consider Date and Time on the Internet:\n>Timestamps <draft-ietf-impp-datetime-05.txt> as a Proposed Standard.\n>\n>The IESG plans to make a decision in the next few weeks, and solicits\n>final comments on this action.  Please send any comments to the\n>iesg@ietf.org or ietf@ietf.org mailing lists by November 23, 2001.\n>\n>Files can be obtained via\n>http://www.ietf.org/internet-drafts/draft-ietf-impp-datetime-05.txt\n\n\n\n", "id": "lists-007-16587766"}, {"subject": "Re: canonical MIME header", "content": "> > Seems like it would also be fairly easy to abstract out multipart\n> > separators so as to be immune from them being re-written.\n> \n> I'm missing something ... why do we want to do this?\n\nsome translators change multipart boundary markers.\n\nwhile Ned is correct that there's no need to do this when downgrading\nfrom 8bit/binary/q-p to base64 because multipart boundaries inherently\ncannot be confused with base64, there are re-encoders that can \"upgrade\"\nas well as \"downgrade\", and which use the same code path to convert from \none encoding to another regardless of whether the destination is base64.  \nfor those re-encoders it's easier to always rewrite boundary markers.\n\nKeith\n\n\n\n", "id": "lists-007-16597392"}, {"subject": "Re: canonical MIME header", "content": "> > > Seems like it would also be fairly easy to abstract out multipart\n> > > separators so as to be immune from them being re-written.\n> >\n> > I'm missing something ... why do we want to do this?\n\n> some translators change multipart boundary markers.\n\n> while Ned is correct that there's no need to do this when downgrading\n> from 8bit/binary/q-p to base64 because multipart boundaries inherently\n> cannot be confused with base64,\n\nor with q-p.\n\n> there are re-encoders that can \"upgrade\"\n> as well as \"downgrade\", and which use the same code path to convert from\n> one encoding to another regardless of whether the destination is base64.\n> for those re-encoders it's easier to always rewrite boundary markers.\n\nSuch reencoders aren't going to exercise the care needed to get the right\nof this right, so the installed base of reencoders aren't relevant to\nthe task at hand. As for the prospect of a new reencoder that does handle\nthis correctly, I guess that could be useful, but IMO its usefulness doesn't\nmeasure up to the implementation complexity needed.\n\nNed\n\n\n\n", "id": "lists-007-16606434"}, {"subject": "Re: canonical MIME header", "content": "> > while Ned is correct that there's no need to do this when downgrading\n> > from 8bit/binary/q-p to base64 because multipart boundaries inherently\n> > cannot be confused with base64, there are re-encoders that can \"upgrade\"\n> > as well as \"downgrade\", and which use the same code path to convert from\n> > one encoding to another regardless of whether the destination is base64.\n> > for those re-encoders it's easier to always rewrite boundary markers.\n> \n> OK, I understand that.   But, if we have per-part MIC's calculated, why do\n> we care whether boundary markers are rewritten or not?\n\nclearly we can write a canonicalization algorithm that is independent of\nboth the choice of boundary marker and content-transfer-encoding.\n(though it's not quite as simple as having per-part MICs)\n\nthe relevant questions would seem to be:\n\n- besides re-encoding, what other kinds of munging would we need to \n  accomodate, and what are the effects on the message?\n\n- given that it would be possible to transmit information in\n  boundary markers and content-transfer-encoding headers and\n  received headers, (as well as whatever else we find)...\n  how much leakage potential is acceptable?    \n\n  (I mean, you can also transmit information using alternative\n   means of encoding certain constructs in BER. But I gather that it's\n   somehow considered acceptable to recast the entire structure into\n   DER before evaluating and to ignore this source of leakage?\n   Is there some logic that dictates when it's acceptable and when not?)\n\nKeith\n\n\n\n", "id": "lists-007-16615595"}, {"subject": "Re: canonical MIME header", "content": "On Thu, 08 Nov 2001 22:07:39 -0500 \"Donald E. Eastlake 3rd\" \n<dee3@torque.pothole.com> wrote:\n\n> \n> Seems like it would also be fairly easy to abstract out multipart\n> separators so as to be immune from them being re-written.\n\nI'm missing something ... why do we want to do this?\n\nCheers.\n---\nSteve Hole\nChief Technology Officer -  Electronic Billing and Payment Systems\nACI Worldwide - MessagingDirect\n<mailto:Steve.Hole@MessagingDirect.com>\nPhone: 780-424-4922\n\n\n\n", "id": "lists-007-16625422"}, {"subject": "Re: canonical MIME header", "content": "On Fri, 09 Nov 2001 14:20:26 -0500 Keith Moore <moore@cs.utk.edu> wrote:\n\n> while Ned is correct that there's no need to do this when downgrading\n> from 8bit/binary/q-p to base64 because multipart boundaries inherently\n> cannot be confused with base64, there are re-encoders that can \"upgrade\"\n> as well as \"downgrade\", and which use the same code path to convert from \n> one encoding to another regardless of whether the destination is base64.  \n> for those re-encoders it's easier to always rewrite boundary markers.\n\nOK, I understand that.   But, if we have per-part MIC's calculated, why do\nwe care whether boundary markers are rewritten or not?\n\nCheers.\n\n---\nSteve Hole\nChief Technology Officer -  - Billing and Payment Systems\nACI Worldwide - MessagingDirect\n<mailto:Steve.Hole@MessagingDirect.com>\nPhone: 780-424-4922\n\n\n\n", "id": "lists-007-16634476"}, {"subject": "Re: canonical MIME header", "content": "On Wed, 07 Nov 2001 21:59:12 -0800 (PST) ned.freed@mrochek.com wrote:\n\n> It would be handy, however, if we were to define a hash with the\n> properties that:\n> \n> (1) Body data encodings were removed prior to hash computation, and\n> (2) Each body was hashed separately and then the sequence of hashes and\n>     headers hashed again.\n> (3) Content-transfer-encoding indicators would not be included in the\n>     hash.\n\nYes, it certainly would.  This would make the message insensitive to \nencoding modification in transit.   This is a highly desirable feature, \nparticularly for large volume contents that would ideally be transferred \nend-to-end with BINARY encodings (audio, video, images).   Very useful.\n \n> The advantage here would be that the result would be invariant under encoding\n> changes (albeit with the remaining requirement that header ordering and\n> boundaries would have to be preserved)\n\nYes ... I should have read on before typing above ... but I agree.\n\n> and would allow reuse of previously\n> computed hashes of body data. \n\nWhich is highly beneficial in high volume composition and delivery \nsituations like document (bills, statements, forms etc.) production \nengines.\n\n> But all this could be done with a\n> specialized micalg; there is no need to define a full canonical form.\n> \n> I've been meaning to write this up for years but I've never gotten around\n> to it.\n\nWhat's holding you up?   A beer?   I'm sure I could rummage one up for you\n:-)\n\nCheers.\n\n---\nSteve Hole\nChief Technology Officer -  Electronic Billing and Payment Systems\nACI Worldwide - MessagingDirect\n<mailto:Steve.Hole@MessagingDirect.com>\nPhone: 780-424-4922\n\n\n\n", "id": "lists-007-16643878"}, {"subject": "Re: canonical MIME header", "content": "You obviously have to stop somewhere.  I would think it would be to\nmake the hash invarient over basic insignificant changes in 822\nheaders and body encoding from MIME... Presumably the result would be\nquite like RFC 2803 but for MIME messages instead of XML.\n\nDonald\n\nFrom:  Keith Moore <moore@cs.utk.edu>\nMessage-Id:  <200111092035.fA9KZ0T15973@astro.cs.utk.edu>\nX-URI:  http://www.cs.utk.edu/~moore/\nTo:  Steve Hole <steve.hole@messagingdirect.com>\ncc:  Keith Moore <moore@cs.utk.edu>,\n            \"Donald E. Eastlake 3rd\" <dee3@torque.pothole.com>,\n            ned.freed@mrochek.com, James M Galvin <galvin@elistx.com>,\n            discuss@apps.ietf.org\nIn-reply-to:  Your message of \"Fri, 09 Nov 2001 13:12:17 MST.\"\n                  <EXECMAIL.20011109131217.N692@kepler.esys.ca> \nDate:  Fri, 09 Nov 2001 15:35:00 -0500\n\n>> > while Ned is correct that there's no need to do this when downgrading\n>> > from 8bit/binary/q-p to base64 because multipart boundaries inherently\n>> > cannot be confused with base64, there are re-encoders that can \"upgrade\"\n>> > as well as \"downgrade\", and which use the same code path to convert from\n>> > one encoding to another regardless of whether the destination is base64.\n>> > for those re-encoders it's easier to always rewrite boundary markers.\n>> \n>> OK, I understand that.   But, if we have per-part MIC's calculated, why do\n>> we care whether boundary markers are rewritten or not?\n>\n>clearly we can write a canonicalization algorithm that is independent of\n>both the choice of boundary marker and content-transfer-encoding.\n>(though it's not quite as simple as having per-part MICs)\n>\n>the relevant questions would seem to be:\n>\n>- besides re-encoding, what other kinds of munging would we need to \n>  accomodate, and what are the effects on the message?\n>\n>- given that it would be possible to transmit information in\n>  boundary markers and content-transfer-encoding headers and\n>  received headers, (as well as whatever else we find)...\n>  how much leakage potential is acceptable?    \n>\n>  (I mean, you can also transmit information using alternative\n>   means of encoding certain constructs in BER. But I gather that it's\n>   somehow considered acceptable to recast the entire structure into\n>   DER before evaluating and to ignore this source of leakage?\n>   Is there some logic that dictates when it's acceptable and when not?)\n>\n>Keith\n\n\n\n", "id": "lists-007-16653665"}, {"subject": "Help The Wido", "content": "FROM,Isah Mohammed\n.  \nContact info;\nPHONE#:(874)-762864166,\nFAX#:  {874}-762864168,\nJOHANNESBURG-SOUTH AFRICA\n\n\nDear Sir,\n\nFUND MANAGEMENT \n\nI humbly wish to seek your assistance in matter that\nis very important and needs utmost trust and\nconfidence. I am Mr.Isah Mohammed\n.a close confidant\nof\none of South-African most powerful family. The wife of\nformer top Government official, a Gold magnet\n{Original Owner of GRUGGER GOLD CO.}, i.e. late CHIEF\nBAMUNGA SANGO MBEKI, former Junior Minister of Mines\nand Power Federal republic of South-Africa.\nUnfortunately, he died soon after handing over because\nthe new Government wanted to probe his activities\nwhile in office for financial misappropriations.\nPresently, all their foreign and local account was\nfrozen and their assets confiscated.\n\nThe wife wishes to move out of South-Africa the sum of\nUS$42 million along with some large quantity of gold\nand diamond, she wishes to invest the aforementioned\nsum in viable investment overseas.\n\nFor obvious reasons, my client does not want to place\nthis fund with established financial institution with\nthe family name for security reasons. It is her desire\nthat the deal be handled as quietly as possible\nwithout possibility of any leakage to the public or\nGovernment. She has therefore empowered me to find and\nnegotiate for a reliable and trustworthy foreigner who\ncan assist us by using his/her name in moving the\nmoney to a foreign safe account and who can assist to\ninvest the fund properly for the family.\n\nIf you agree to act as a fund manager for my client\nand the family, I shall release the sum of US$42\nmillion to you if you meet my requirements. The money\nis available safe with a private security company\ncoded and lodged in with a fictitious name. Upon a\nfavorable response from you, I shall let you know the\nsteps involve.\n\nYour commission shall be down payment of 15% of the\ntotal sum, that is US$6.3 million and annual 10% of\nthe after tax returns on investment for the first 5\nyears. Thereafter,The terms shall be re-negotiated.\n\nIf you are capable and willing to participate in this\ntransaction contact me through my email address OR by\nphone for a heart to heart discussion.\n\nNOTE, IF FOR ANY REASON YOU ARE NOT DISPOSED AT MOMENT\nTO UNDERTAKE THIS DEAL, LET ME KNOW ON TIME AS TO MAKE\nALTERNATIVE ARRANGEMENT.\n\nI look forward to your earliest reply through my email\nIn any case, please keep it tight secret.\n\nBest regards\nIsah Mohammed\n\n\n\n\n\n__________________________________________________\nDo You Yahoo!?\nFind a job, post your resume.\nhttp://careers.yahoo.com\n\n\n\n", "id": "lists-007-16666554"}, {"subject": "draft-allocchio-gstn-00.txt - request for comments", "content": "Hallo,\n\nI would like to explicitly point your attention to the following draft \nwhich was just published:\n\n>A New Internet-Draft is available from the on-line Internet-Drafts \n>directories.\n>\n>Title: Text string notation for Dial Sequences and GSTN / \n>                         E.164 addresses\n>Filename: draft-allocchio-gstn-00.txt\n>\n>This memo describes the full set of notations needed to represent\n>in a text string a Dial Sequence. A Dial Sequence is normally\n>composed by Dual Tone Multi Frequency (DTMF) elements [1] plus \n>separators and the additional 'actions' (such as 'wait for\n>dialtone', 'pause for N secs', etc.) which could be needed to \n>successfully establish the connection with the target service:\n>this includes the cases where subaddresses or DTMF menu navigation \n>apply. Global Switched Telephone Numbers (GSTN) / E.164 addresses \n>(commonly called 'telephone numbers') [2] are a subset of a Dial \n>Sequence, and thus use the same set of notations.\n>\n>A URL for this Internet-Draft is:\n>http://www.ietf.org/internet-drafts/draft-allocchio-gstn-00.txt\n\nAs already stated in the abstract, the intention for this document is to \nprovide a unique syntax for Dial Sequences, including expecially phone \nnumbers as a subset. The definitions contained in the draft actually come \nfrom existing Draft Standard and Proposed Standard specifications, but \nwere collected here to provide a quick, easy and unique reference \ndocument for anybody needing this particualr encoding. The original idea \ncomes from the Application Area Directors, and I made the collection and \nedited the I-D.\n\nAs some of you already did (thank you indeed !), spotting some needed \ncorrections, I kindly invite you to provide me your comments and \nsuggestions. They will also be useful to the revision of the Draft and \nProposed standards the definitions come from.\n\nThank you all, and regards!\n\nClaudio Allocchio\nietf fax wg co-chair\n\n\n\n", "id": "lists-007-16675380"}, {"subject": "Request for comment", "content": "Hello all.\n\nThis message is a request for comments on draft\nhttp://www.ietf.org/internet-drafts/draft-singh-eaddr-00.txt. This memo\nsimply extends the ENUM idea in RFC 2916 to get various contact URIs\nusing an email address, instead of a telephone address, as the starting\npoint. The question to this group is if this is a useful idea to pursue.\n\nAbstract:\n\n\"ENUM uses NAPTR DNS Resource Records (RRs) to map an E.164 telephone\n number to Uniform Resource Identifiers (URIs) of other ways of\n contacting (for example, by email) a specific resource. This memo\n proposes an ENUM-like service called EADDR where an email address,\n instead of a telephone number, is used as the key to fetch other\n contact URIs. At human level, EADDR seems more useful than ENUM\n because it is easier to remember an email address than a telephone\n number as the key. At machine level, both services are equally\n useful.\"\n\nJasdip\n\n\n\n", "id": "lists-007-16685351"}, {"subject": "draft-allocchio-gstn-00.txt - changes as per your suggestions", "content": "Hallo,\n\nthanks to all who already sent in their commments, I already included in \nthe \"01\" version in preparation the following changes:\n\nSection 3.2\n\n      local-phone =  [ exit-code ] dial-number\n\n      local-phone =/ exit-code [ dial-number ]\n\n(...)\n\n   Notes:\n      the \"+\" character is reserved for use in global-phone and MUST NOT\n      be used in a local-phone string;\n\n      please note that a local-phone string MUST NOT be a null string,\n      i.e. at least an exit-code, or a dial-number or both MUST be\n      present.\n                                              \n*** in fact the local-phone string cannot be a null string!\n\nSection 6\n\n   A Dial Sequence using exit-code \"0\", a wait for dial tone,\n   local-phone for an International \"800\" toll-free number dialled\n   from Beglium (international prefix \"00\"), and a post-dial sequence\n   to access a voice mailbox with userID \"334422\" and Personal\n   Identification Number (PIN) code \"1234\":\n\n      0w00800-39380023pp334422p1234\n\n*** the previous example was WRONG !\n\nSection 7\n\n   This proposal creates a full standard text encoding for Dial\n   Sequences, including GSTN / E.164 addresses, and thus provides a\n   unique common representation method both for standard protocols\n   and applications.\n\n   Some definitions, like these corresponding to an alias of the generic\n   phone-string element, are somewhat a theoretical distinction; however\n   they are useful to provide a more subtle distinction, allowing other\n   specifications to be more exact in a consistent way, too.\n\n   The proposal is consistent with existing standard specifications.\n\n*** it seems that expliciting the reason why exit-code, phone-dial, \npost-dial etc... exists is a good idea.\n\nSection 9\n\n      global-phone = \"+\" 1*( DIGIT / written-sep )\n\n      local-phone =  [ exit-code ] dial-number\n\n      local-phone =/ exit-code [ dial-number ]\n       \n\n*** consequently also the local-phone definition here has been updated, \nand an ABNF syntax error was corrected, too\n\nOk, all these changes will be included in version \"01\", and anything else \nneeded after your comments, too.\n\nRegards,\n\n------------------------------------------------------------------------------\nClaudio Allocchio             G   A   R   R          Claudio.Allocchio@garr.it\n                        Project Technical Officer\ntel: +39 040 3758523      Italian Academic and       G=Claudio; S=Allocchio;\nfax: +39 040 3758565        Research Network         P=garr; A=garr; C=it;\n\n     PGP Key: http://security.fi.infn.it/cgi-bin/spgpk.pl?KeyId=0C5C2A09\n\n\n\n", "id": "lists-007-16692868"}, {"subject": "Re: Request for comment", "content": "sounds much like what the RESCAP WG is working on.  perhaps you should \nbring your proposal there.\n\nthe question is not whether this will work, but whether it's better to\nput stuff in DNS or to vector it to a separate lookup service.\n \n> This message is a request for comments on draft\n> http://www.ietf.org/internet-drafts/draft-singh-eaddr-00.txt. This memo\n> simply extends the ENUM idea in RFC 2916 to get various contact URIs\n> using an email address, instead of a telephone address, as the starting\n> point. The question to this group is if this is a useful idea to pursue.\n> \n> Abstract:\n> \n> \"ENUM uses NAPTR DNS Resource Records (RRs) to map an E.164 telephone\n>  number to Uniform Resource Identifiers (URIs) of other ways of\n>  contacting (for example, by email) a specific resource. This memo\n>  proposes an ENUM-like service called EADDR where an email address,\n>  instead of a telephone number, is used as the key to fetch other\n>  contact URIs. At human level, EADDR seems more useful than ENUM\n>  because it is easier to remember an email address than a telephone\n>  number as the key. At machine level, both services are equally\n>  useful.\"\n> \n\n\n\n", "id": "lists-007-16703415"}, {"subject": "Re: Request for comment", "content": "Keith Moore wrote:\n\n> sounds much like what the RESCAP WG is working on.\n\nNot sure whether to agree or disagree. :)\n\n>  perhaps you should bring your proposal there.\n>\n> the question is not whether this will work, but whether it's better to\n> put stuff in DNS or to vector it to a separate lookup service.\n\nExactly. The choice will have various trade-offs for this and similar\nproblems.\n\n- Loosely-coupled query framework - Result based on queries to DNS, Metadata\nserver, and Data server, or a tighter coupling in terms of role of a\nparticular protocol server (for example, ENUM (and EADDR) using DNS for\nfunctionality beyond SRV and A queries).\n\n- Access control in terms of who can ask and/or update what.\n\n- (Ab)using an existing, deployed protocol or defining one anew? What criteria\ndefine an abuse and are they reasonable in contrast with other factors in\nfavor of using something extant? What criteria justify creating a new\nprotocol? The dreadful question IMHO seems to be where do you stop touching\nDNS? Also, where to start and stop using directory services like LDAP?\n\nI don't know.\n\n> > This message is a request for comments on draft\n> > http://www.ietf.org/internet-drafts/draft-singh-eaddr-00.txt. This memo\n> > simply extends the ENUM idea in RFC 2916 to get various contact URIs\n> > using an email address, instead of a telephone address, as the starting\n> > point. The question to this group is if this is a useful idea to pursue.\n> >\n> > Abstract:\n> >\n> > \"ENUM uses NAPTR DNS Resource Records (RRs) to map an E.164 telephone\n> >  number to Uniform Resource Identifiers (URIs) of other ways of\n> >  contacting (for example, by email) a specific resource. This memo\n> >  proposes an ENUM-like service called EADDR where an email address,\n> >  instead of a telephone number, is used as the key to fetch other\n> >  contact URIs. At human level, EADDR seems more useful than ENUM\n> >  because it is easier to remember an email address than a telephone\n> >  number as the key. At machine level, both services are equally\n> >  useful.\"\n> >\n\n\n\n", "id": "lists-007-16711968"}, {"subject": "Re: Request for comment", "content": "On Thu, Nov 15, 2001 at 12:13:16PM -0500, Keith Moore wrote:\n> sounds much like what the RESCAP WG is working on.  perhaps you should \n> bring your proposal there.\n\nIs the working group page for RESCAP just really out-of-date or\nare there actually no ID's and RFC's yet for it.\n\n-andy\n\n-- \nAndrew Newton\nVeriSign Applied Research\nanewton@research.netsol.com\n\n\n\n", "id": "lists-007-16721358"}, {"subject": "Re: Request for comment", "content": "> Is the working group page for RESCAP just really out-of-date or\n> are there actually no ID's and RFC's yet for it.\n\nthe page is out-of-date.  there have been several proposals submitted\nas internet-drafts, and discussed by the group, but they've all been \n*individual* internet drafts.  such drafts don't appear on the group's\nweb page until the chair asks the secretariat that they be put there.\n\nKeith\n\n\n\n", "id": "lists-007-16729204"}, {"subject": "Re: Request for comment", "content": "> > the question is not whether this will work, but whether it's better to\n> > put stuff in DNS or to vector it to a separate lookup service.\n\n... this is a very old discussion, and in general the opinion was DNS \nworks well, but it is also the fundamental glue between addresses and \nservices, names etc, thus overloading it with new stuff IS WRONG.\n\nMore over I believe that DNS is OK for machine driven quick lookups, i.e.\ndomain name to server address or server name. \n\n> protocol? The dreadful question IMHO seems to be where do you stop touching\n> DNS? Also, where to start and stop using directory services like LDAP?\n\nOne of the main resons for using DNS is often said to be \"it works, it is \neverywhere\". But:\n\n - this is no nore exectly true: it \"seems to be everywhere\", but virtual\n   hosting often makes the DNS server not under control of the domain name\n   users\n\n - it works, but it is defintly not suited for an \"information lookup \n   service\". IMHO the major disaster that DNS has ever made was the attempt\n   to identify it with a trademark and distighushed names database. :-)\n\n - currently, and finally, due to a number of application seriously needing\n   real directory services in order to work (GRID computing, mobile users\n   authorisations - AAA, on-line phone books, X.509 Government issued\n   certificates to citizens,...) the LDAP / Directory infrastructure is\n   being deployed (often non hyerarchically, but the directory bridge concept\n   seems to overcome the problem). This infrastructure is not at all in the\n   same places and same hands than DNS servers, but it seems much more\n   suitable to the needs expressed in your document.\n\nIt is just a personal view, of course, but I woul prefer efforts being \naimed to coordinate LDAP servers and define the relevant OIDs.\n\n:-)\n\nClaudio\n\n\n\n", "id": "lists-007-16736507"}, {"subject": "Re: Request for comment", "content": "Claudio Allocchio wrote:\n\n> > > the question is not whether this will work, but whether it's better to\n> > > put stuff in DNS or to vector it to a separate lookup service.\n>\n> ... this is a very old discussion, and in general the opinion was DNS\n> works well, but it is also the fundamental glue between addresses and\n> services, names etc, thus overloading it with new stuff IS WRONG.\n\nThe phrases \"putting stuff in DNS\" and \"overloading DNS\" deserve another look. It\nseems that the \"U\" flag in NAPTR RR is being questioned in contrast with the \"S\"\nand \"A\" flags. If yes, then does ENUM as proposed in RFC 2916 need\nstandardization? The use of the \"U\" flag in NAPTR RR for ENUM seems reasonable as\nit starts with a derived domain name and transforms it to another network\nresource identifier and not the data within it. However, this solution is limited\nby lack of access control if an application needs so.\n\nWe probably need a clearer definition of a lookup framework specifying the roles\nof various protocols like DNS, LDAP, CNRP, RESCAP, etc(?) in the various layers\nof the framework for resolution discovery and resolution. And, when and if\nviolation of these layers is ok. IMHO, this will greatly help alleviate the\nconfusion.\n\nJasdip\n\n\n\n", "id": "lists-007-16746204"}, {"subject": "Re: Request for comment", "content": "On Thu, Nov 15, 2001 at 06:50:00PM -0500, Jasdip Singh wrote:\n> protocol? The dreadful question IMHO seems to be where do you stop touching\n> DNS? Also, where to start and stop using directory services like LDAP?\n\nAs in the method layed in this draft:\n\n  draft-hall-ldap-whois-00.txt\n  http://search.ietf.org/internet-drafts/draft-hall-ldap-whois-00.txt\n\n-andy\n\n-- \nAndrew Newton\nVeriSign Applied Research\nanewton@research.netsol.com\n\n\n\n", "id": "lists-007-16754603"}, {"subject": "New URI scheme: tft", "content": "The draft draft-schulzrinne-tftp-url-01 has been submitted to the I-D\neditor and should appear in the archives shortly. Until that time, you\ncan find the draft at\n\nhttp://www.cs.columbia.edu/~hgs/sip/drafts/draft-schulzrinne-tftp-url-01.txt\n\nComments are solicited. Please cc me on any comments.\n\nThank you.\n\n(I wouldn't anticipate that tftp URLs will or should appear on web\npages, but tftp is very widely used for configuration of embedded\nsystems where higher-complexity protocols are inappropriate. The tftp\nURL is already in informal use, see for example by random search\nhttp://www.cisco.com/univercd/cc/td/doc/product/software/ios121/121cgcr/fun_r/frprt2/frd2002.htm\n)\n-- \nHenning Schulzrinne   http://www.cs.columbia.edu/~hgs\n\n\n\n", "id": "lists-007-16762090"}, {"subject": "Re: TFTP UR", "content": "Hi.\n\nPatrik suggested that I post these notes back to this list.\n\nQuick summary:  TFTP, while useful for some purposes, is not, by\na wide margin, our best example of operationally- or\nsecurity-conscious protocol design.  It should not be used\nexcept under carefully-constrained and controlled circumstances\n(the RFCs on it say that).  Consequently, unless there is a very\nstrong argument showing why we need a URL type for it, one of\nthose (or anything else that encourages \"just click here\" or\n\"just execute that line\" use should be avoided.  Obviously, we\nknow how to do a URL for it, but the fact that we can doesn't\nindicate that we should.\n\nJust my opinion, but I'm happy to show scars and tell war\nstories if needed.\n\n   john\n\nHenning,\n\nWhile it is necessary (not important enough to try to deploy a\nreplacement) to other things we do, TFTP is a _bad_ protocol and\nseveral efforts have been made to restrict its use or even to\ndeprecate it.  The analogy to anonymous FTP in your security\nsection is not adequate; the other problem is that, in practice,\nthe TFTP client/receiver has even less assurance that it is\ngetting the right file, with valid content, than is the case with\nanonymous FTP's somewhat more extensive handshaking.  I.e., the\nproblem is less the public-ness of the file, but confidence about\nits contents.   There is also potential for DOS attacks, etc.\n\nWe have learned to live with TFTP in, e.g., the DHCP case because\nwe hope that process of having to configure it into another\nprotocol will lead to consideration of issues and risks and/or\nisolation of client and server into protected LANs.  Providing an\neasy, \"one-click\", URL interface would seem to have negative\nvalue relative to thos considerations.\n\nSo, speaking personally, I'd like to see this go away.  If there\nis actual need for it, I'd like to see that need documented along\nwith a security considerations section that really explores the\nrisks, problems, and alternatives (e.g., in what cases would a\nTFTP URL be useful for which an FTP or HTTP URL would not\nsuffice?).\n\nThe fact that we know how to define/specify something doesn't\nimply that we should.  The requirement that the IETF approve\nthese things was intended at least as much to let them apply a\nstandard of good taste as it was that the documents be reviewed\ntechnically.\n\n    john\n\n\n--On Monday, 19 November, 2001 07:23 +0100 Patrik F?ltstr?m\n<paf@cisco.com> wrote:\n\n> --On 2001-11-18 21.02 -0500 \"Henning G. Schulzrinne\"\n> <hgs@cs.columbia.edu> wrote:\n> \n>> More than seven months ago, I had sent the following message,\n>> but as far as I can tell, received no reply. Should I just\n>> send you this as an individual submission? The draft has been\n>> at\n>> http://www.ietf.org/internet-drafts//draft-schulzrinne-tftp-ur\n>> l-00.txt since that time.\n>> \n>> Since RFC 2717 requires a standards-track document for most\n>> new URL schemes, just submitting this to the RFC editor for\n>> publication as informational is not likely to work.\n>> \n>> Your help and advice is appreciated.\n> \n> Send an announcement to the following lists, where URI's are\n> discussed, and request comments:\n> \n>    uri@w3c.org\n>    discuss@apps.ietf.org\n\n--On Monday, 19 November, 2001 10:10 -0500 \"Henning G.\nSchulzrinne\" <hgs@cs.columbia.edu> wrote:\n\n>> While it is necessary (not important enough to try to deploy a\n>> replacement) to other things we do, TFTP is a _bad_ protocol\n>> and several efforts have been made to restrict its use or even\n>> to deprecate it.  The analogy to anonymous FTP in your security\n> \n> However, it remains in extremely wide-spread use for updating\n> boot ROMs and configuration files, among other uses.\n\nNo question about it.  But your document provides no explanation\nas to why those applications require a URL type.  Several have\nworked very successfully without one for years.   And I'd argue\nthat most configuration file uses are ones that IETF should\ndiscourage --and point toward DHCP or something like ACAP--\nrather than encouraging more use of TFTP by making it easier to\nuse.\n\n>> section is not adequate; the other problem is that, in\n>> practice, the TFTP client/receiver has even less assurance\n>> that it is getting the right file, with valid content, than is\n>> the case with anonymous FTP's somewhat more extensive\n>> handshaking.  I.e., the\n> \n> Could you elaborate on that? That would be a difference worth\n> describing in more technical detail. \n\nYes, but not at this moment.  I'm trying to get the \"DNS search\"\nmaterials out, and they are a lot more important.\n\n>> We have learned to live with TFTP in, e.g., the DHCP case\n>> because\n> \n> I'm not sure I understand the relationship to DHCP (except as an\n> \"instigator\" that triggers tftp), but from all I can tell, tftp\n> is used in millions of embedded devices, with and without DHCP.\n> Many of these devices won't necessarily even implement TCP.\n\nI need to go back and look at the spec, but I don't recall TFTP\nbeing defined except in TCP terms.\n\n>> we hope that process of having to configure it into another\n>> protocol will lead to consideration of issues and risks and/or\n>> isolation of client and server into protected LANs.  Providing\n>> an easy, \"one-click\", URL interface would seem to have negative\n>> value relative to thos considerations.\n> \n> The idea is not to provide a one-click URL on a web page; the\n> motivation is to have an easy means to encode this information\n> where multiple update protocols can be used, typically in\n> configuration files and other similar locations. For example,\n> it is rather natural to have\n> \n> http://www.someserver.org/config\n> or\n> ftp://www.someserver.org/config\n> or\n> tftp://www.someserver.org/config\n\nFor the first twenty or so years of the ARPANET and Internet, it\nwas considered equally natural, or more so, to have \"open a TFTP\nconnection to foo.someserver.org and obtain the file called\n\"config\".\n\n>> So, speaking personally, I'd like to see this go away.  If\n>> there is actual need for it, I'd like to see that need\n>> documented along with a security considerations section that\n>> really explores the risks, problems, and alternatives (e.g.,\n>> in what cases would a TFTP URL be useful for which an FTP or\n>> HTTP URL would not suffice?).\n> \n> One reason is above - many of the devices don't support the\n> protocols mentioned.\n\nThat explains TFTP, not URLs.\n\n>> The fact that we know how to define/specify something doesn't\n>> imply that we should.  The requirement that the IETF approve\n>> these things was intended at least as much to let them apply a\n>> standard of good taste as it was that the documents be reviewed\n>> technically.\n> \n> If tftp is so bad, shouldn't it be deprecated as historic\n> rather than being STD 33?\n\nIt has not been felt, so far, to be bad enough that we have\nstandardized an alternative.  And other standards depend on it,\nas noted above and elsewhere.  But things are standardized within\nan applicability context, and I'm reluctant to see the\napplicability of TFTP broadened and more reluctant to see it\nappear in contexts that seem to encourage general use.\n\n    john\n\n\n\n", "id": "lists-007-16769298"}, {"subject": "BASELINE-CONTROL &amp; Workspac", "content": "HI,\n\nhappy new year to everyone!\n\nAnd now my question: Is a DeltaV server allowed to automatically put a\nworkspace under baseline control at creation time (MKWORKSPACE)? This would\nbe similar to automatically put a resource under version control at creation\ntime via PUT.\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-1779461"}, {"subject": "autoversion on VC", "content": "Hi,\n\nis there a simalar thing like the auto-version property of a VCR (or is it a\nproperty of a version of the VCR? anyway) for a VCC/Baseline?\n\nWell the other way around: Is there a mechanism to automatically perform a\ncheckin on a checked out VCC while a VCR (member of the very VCC) is checked\nin?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-1786741"}, {"subject": "Checkout se", "content": "Hi,\n\na version does have a checkout set property containing all the uri's of the\nVCR's the very version is the value of the checked-out version property.\nDoes this set also contain the WR's this version was checked out with?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-1794114"}, {"subject": "RE: autoversion on VC", "content": "A VCCl is a VCR, so it also has a DAV:auto-version property,\nwhich does what you expect.  In particular, look at the\nDAV:modify-configuration postconditions of 12.12, 12.13, and 12.14.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Friday, January 04, 2002 7:14 AM\nTo: 'ietf-dav-versioning@w3.org'\nSubject: autoversion on VCC\n\n\nHi,\n\nis there a simalar thing like the auto-version property of a VCR (or is it a\nproperty of a version of the VCR? anyway) for a VCC/Baseline?\n\nWell the other way around: Is there a mechanism to automatically perform a\ncheckin on a checked out VCC while a VCR (member of the very VCC) is checked\nin?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-1801316"}, {"subject": "RE: BASELINE-CONTROL &amp; Workspac", "content": "Definitely yes.\n\nI expect it to be common for servers to constrain where baselined\ncollections can occur (e.g. the entire workspace, or the immediate\nmembers of the workspace).  That was one of the motivations for the\nDAV:baselined-collection-set property for a workspace, so that a\nclient can discover where the baselined collections are in a workspace.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Friday, January 04, 2002 7:10 AM\nTo: 'ietf-dav-versioning@w3.org'\nSubject: BASELINE-CONTROL & Workspace\n\n\nHI,\n\nhappy new year to everyone!\n\nAnd now my question: Is a DeltaV server allowed to automatically put a\nworkspace under baseline control at creation time (MKWORKSPACE)? This would\nbe similar to automatically put a resource under version control at creation\ntime via PUT.\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-1809264"}, {"subject": "RE: Checkout se", "content": "Yes, the DAV:checkout-set is defined to be the \"checked-out resources\"\nwhich includes both checked-out VCR's and working resources.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Friday, January 04, 2002 7:17 AM\nTo: 'ietf-dav-versioning@w3.org'\nSubject: Checkout set\n\n\nHi,\n\na version does have a checkout set property containing all the uri's of the\nVCR's the very version is the value of the checked-out version property.\nDoes this set also contain the WR's this version was checked out with?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-1817567"}, {"subject": "Localisation header on creating a new versio", "content": "Hi,\nif I read the spec correctly on creation of a new (initial) version by VERSION-CONTROL\nthe version URL must be accessed by DAV:checked-in of the new VCR.\nUsing CHECKIN to create an additional version returns the version URL in a Location\nheader. BTW, I guess that a CHECKIN on a baseline also returns the baseline URL.\nSo why don't we return a Location header with VERSION-CONTROL and BASELINE-CONTROL\nif a new version/baseline was created ?\n\nCheers, Edgar\n\n\n\n-- \nedgar@edgarschwarz.de                    http://www.edgarschwarz.de\n*          DOSenfreie Zone.        Running Active Oberon.         *\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-1825373"}, {"subject": "Re: Localisation header on creating a new versio", "content": "The version URL must be accessed by DAV:checked-in because you may need to \nget it sometime later, after the version was created. It certainly could \nbe returned in the location header of the VERSION-CONTROL method too in \norder to prevent the extra round trip.\n\n\n\n\n\nEdgar@EdgarSchwarz.de\nSent by: ietf-dav-versioning-request@w3.org\n01/07/2002 05:01 PM\n\n \n        To:     ietf-dav-versioning@w3.org\n        cc:     Edgar@EdgarSchwarz.de\n        Subject:        Localisation header on creating a new version\n\n \n\nHi,\nif I read the spec correctly on creation of a new (initial) version by \nVERSION-CONTROL\nthe version URL must be accessed by DAV:checked-in of the new VCR.\nUsing CHECKIN to create an additional version returns the version URL in a \nLocation\nheader. BTW, I guess that a CHECKIN on a baseline also returns the \nbaseline URL.\nSo why don't we return a Location header with VERSION-CONTROL and \nBASELINE-CONTROL\nif a new version/baseline was created ?\n\nCheers, Edgar\n\n\n\n-- \nedgar@edgarschwarz.de                    http://www.edgarschwarz.de\n*          DOSenfreie Zone.        Running Active Oberon.         *\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-1833344"}, {"subject": "RE: Localisation header on creating a new versio", "content": "The rationale for having CHECKIN return a Location header was that\nthe \"primary purpose\" of the CHECKIN request is to create a new \nresource (i.e. a new version resource), while the \"primary purpose\" of\na VERSION-CONTROL request is to put an existing resource under\nversion control (and the creation of a version and a\nversion history was merely a side effect).\n\nBut this rationale is not nearly as compelling as something like\nCHECKOUT returning the location of a new working resource in the\nLocation header, in which case unlike CHECKIN, you don't have\nany other good way to find the URL of the resource you just created.\n\nSo the use of the Location header in CHECKIN is probably best thought\nof as a historical quirk.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Edgar@EdgarSchwarz.de [mailto:Edgar@EdgarSchwarz.de]\nSent: Monday, January 07, 2002 5:01 PM\nTo: ietf-dav-versioning@w3.org\nCc: Edgar@EdgarSchwarz.de\nSubject: Localisation header on creating a new version\n\n\nHi,\nif I read the spec correctly on creation of a new (initial) version by\nVERSION-CONTROL\nthe version URL must be accessed by DAV:checked-in of the new VCR.\nUsing CHECKIN to create an additional version returns the version URL in a\nLocation\nheader. BTW, I guess that a CHECKIN on a baseline also returns the baseline\nURL.\nSo why don't we return a Location header with VERSION-CONTROL and\nBASELINE-CONTROL\nif a new version/baseline was created ?\n\n\n\n", "id": "lists-007-1843052"}, {"subject": "LOCK/UNLOCK or CHECKIN/CHECKOU", "content": "Hi,\n\nI'd like to know whether I well understood : the mechanism of checkout-put-checkin cretes a new version of a resource, while the lock-unlock mechanism allows to modify a resource without creating a new version, is that right ?\nCan someone explain me the exact difference between this two mechanisms ?\n\nThanx\n\n\n\n", "id": "lists-007-1852954"}, {"subject": "Activitie", "content": "Hi,\n\na question dealing with activities:\n\nSuppose two  workspaces A and B. Both of them are under baseline control on\nits own. Now suppose an activity C. Is there a server side mechanism defined\nin DeltaV that could prevent a client from checking out resources of WS A\nand B and including them by the way into activity C. Instead a client should\nbe forced to checkout a resource of WS B into a different activity if\nactivity C allready contains a checked out resource of workspace A.\n\nFrom reading the DeltaV I got no idea how to do this, propably it's not even\nthere ...\n\nThanks,\nDaniel\n\n\n\n", "id": "lists-007-1860250"}, {"subject": "Re: LOCK/UNLOCK or CHECKIN/CHECKOU", "content": "Elodie,\n\n> I'd like to know whether I well understood : the  mechanism of \ncheckout-put-checkin\n> cretes a new version of a resource,\n\ncorrect -- indeed the version is a resource, so checking-in creates a new \nversion resource.\n\n> while the  lock-unlock mechanism allows to modify a resource without \ncreating a new\n> version, is that right ?\n\nthis is also correct.  Locking a resource just causes a state change in \nthe locked resource; it does not create any other resources.\n\n> Can someone explain me the exact difference between  this two mechanisms \n?\n \nLocking is typically used in a multi-user environment.  Obtaining a lock \npermits you to modify a resource and prevents others from modifying the \nresource.  This allows you to ensure others' contents are not overwritten, \nand you can set consistent content and dead properties for example.\nChecking out and in are used to capture a meaningful state of a resource \nas a version.  It is meaningful to do this in single or multi-user \nenvironments.  The captured states can be 'viewed' or restored at some \nlater time.\n\nLocking and versioning are separate concepts.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-1868600"}, {"subject": "RE: LOCK/UNLOCK or CHECKIN/CHECKOU", "content": "To avoid ambiguities: if you modify a locked, version-controlled\nresource, you will create a new version (if the server supports\nauto versioning that is).\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Thursday, January 10, 2002 3:34 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: Re: LOCK/UNLOCK or CHECKIN/CHECKOUT\n>\n>\n> Elodie,\n>\n> > I'd like to know whether I well understood : the  mechanism of\n> checkout-put-checkin\n> > cretes a new version of a resource,\n>\n> correct -- indeed the version is a resource, so checking-in creates a new\n> version resource.\n>\n> > while the  lock-unlock mechanism allows to modify a resource without\n> creating a new\n> > version, is that right ?\n>\n> this is also correct.  Locking a resource just causes a state change in\n> the locked resource; it does not create any other resources.\n>\n> > Can someone explain me the exact difference between  this two\n> mechanisms\n> ?\n>\n> Locking is typically used in a multi-user environment.  Obtaining a lock\n> permits you to modify a resource and prevents others from modifying the\n> resource.  This allows you to ensure others' contents are not\n> overwritten,\n> and you can set consistent content and dead properties for example.\n> Checking out and in are used to capture a meaningful state of a resource\n> as a version.  It is meaningful to do this in single or multi-user\n> environments.  The captured states can be 'viewed' or restored at some\n> later time.\n>\n> Locking and versioning are separate concepts.\n>\n> Regards,\n> Tim\n>\n>\n>\n\n\n\n", "id": "lists-007-1877045"}, {"subject": "Re: Activitie", "content": "Daniel,\n\nYou are right that there is no way to restrict an activity resource only \nto select versions of a single workspace.  Given that all checked-out \nresources (i.e. working-resources as well as checked-out \nversion-controlled resources) have an unprotected DAV:activity-set, this \nwould be potentially very expensive to enforce -- it would have to be done \non the proppatch.  DeltaV does not preclude servers from enforcing such a \nrule if you choose to do so. but it is not required by the protocol \ndefinition.\n\nRegards,\nTim\n\n\n\n\n\"Kirmse, Daniel\" <daniel.kirmse@sap.com>\nSent by: ietf-dav-versioning-request@w3.org\n2002-01-10 11:32 AM\n\n \n        To:     \"Ietf-Dav-Versioning (E-mail)\" <ietf-dav-versioning@w3.org>\n        cc: \n        Subject:        Activities\n\n \n\n\nHi,\n\na question dealing with activities:\n\nSuppose two  workspaces A and B. Both of them are under baseline control \non\nits own. Now suppose an activity C. Is there a server side mechanism \ndefined\nin DeltaV that could prevent a client from checking out resources of WS A\nand B and including them by the way into activity C. Instead a client \nshould\nbe forced to checkout a resource of WS B into a different activity if\nactivity C allready contains a checked out resource of workspace A.\n\nFrom reading the DeltaV I got no idea how to do this, propably it's not \neven\nthere ...\n\nThanks,\nDaniel\n\n\n\n", "id": "lists-007-1886741"}, {"subject": "LOCATE-BY-HISTORY repor", "content": "If server doesn't support workspaces (or server supports workspaces but\nclient is not using this feature), is there any chance to get\nversion controlled resource for the given version or version history?\nSuppose the following scenario:\n\nMKDIR MyProject\nPUT MyProject/foo.txt\nVERSION-CONTROL MyProject\n\nSo now version controlled resource, version history and initial version\nare created for all resources in MyProject.\n\nNow I set the label to the project:\n\nLABEL MyProject\nDepth: Infinite\n<DAV:label xmlns:DAV=\"DAV:\">\n  <DAV:set>\n     <DAV:label-name>\n       ALPHA-RELEASE\n     </DAV:label-name>\n  </DAV:set>\n</DAV:label>\n\nLater I want to extract this state of the project. Certainly I know\nthat BASELINE is write way for doing it, but\n1. What if server doesn't support baselines (labels belong to the\nbasic versioning stuff, while baselines belong to advanced)?\n2. Once labels are defined by specification, it should be clear how to\nuse them, right?\n\nSo I do:\n\nPROPFIND MyProject\ndepth: Infinite\n<DAV:propfind xmlns:DAV=\"DAV:\">\n  <DAV:prop>\n     <DAV:displayname/>\n     <DAV:creationdate/>\n     <DAV:contenttype/>\n     ...\n  </DAV:prop>\n</DAV:propfind>\n\nSo I will be given information about all versions in MyProject labeled\nby \"ALHPA-RELEASE\". Is is ok, but now I want to extract this files to\nthe client's local disk. In here is a trouble - I don't know path of\nthe resources. In report I will be given:\n\n<DAV:response>\n  <DAV:href>\n     /.repo/vh1/ver1.1\n  </DAV:href>\n  <DAV:displayname>\n     MyProject\n  </DAV:displayname>\n  ...\n</DAV:response>\n<DAV:response>\n  <DAV:href>\n     /.repo/vh2/ver1.1\n  </DAV:href>\n  <DAV:displayname>\n     foo.txt\n  </DAV:displayname>\n  ...\n</DAV:response>\n...\n\nHow the client will understand that foo.txt should be saved in the\nfile \\MyProject\\foo.txt at local disk?\nThe only way is to find out version controlled resource for the givven\nversion (or version history).\nReport locate-by-history requires workspace as request target. But\nclient knows nothing about workspaces and my be that are not even\nsupported by server.\nSo what should I do?\n\nIf version history will be specified as target of LOCATE-BY-HISTORY report\nand workspace can be optionally specified in request body, then\nthis report can be used to get versioned resource even if server\ndoesn't support workspaces or it support workspaces and when workspace\nis not explicitly specified by client, then resource is implicitly\nplaced in some default workspace.\nBut even in this case getting resource name require two additional\nrequests: PROPFIND to get version history by version and\nlocate-by-history REPORT to give versioned resource reference.\n\nAnother way is to add property <DAV:defaultdisplacepath/> with the\nfollowing semantic:\n- for version controlled resource, it returns its URL\n- for version and version history - URL of version controlled resource\n  in default workspace if such exists\n\n\n\n", "id": "lists-007-1895733"}, {"subject": "RE: LOCK/UNLOCK or CHECKIN/CHECKOU", "content": "To further illustrate Tim's point that locking and\ncheckout/checkin are largely orthogonal, a client accessing\na shared workspace would normally lock a checked-out\nversion-controlled resource while it is editing it,\njust as it would a non-version-controlled resource\n(and for the same reasons).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\nSent: Thursday, January 10, 2002 9:34 AM\nTo: ietf-dav-versioning@w3.org\nSubject: Re: LOCK/UNLOCK or CHECKIN/CHECKOUT\n\n\nElodie,\n\n> I'd like to know whether I well understood : the  mechanism of \ncheckout-put-checkin\n> cretes a new version of a resource,\n\ncorrect -- indeed the version is a resource, so checking-in creates a new \nversion resource.\n\n> while the  lock-unlock mechanism allows to modify a resource without \ncreating a new\n> version, is that right ?\n\nthis is also correct.  Locking a resource just causes a state change in \nthe locked resource; it does not create any other resources.\n\n> Can someone explain me the exact difference between  this two mechanisms \n?\n \nLocking is typically used in a multi-user environment.  Obtaining a lock \npermits you to modify a resource and prevents others from modifying the \nresource.  This allows you to ensure others' contents are not overwritten, \nand you can set consistent content and dead properties for example.\nChecking out and in are used to capture a meaningful state of a resource \nas a version.  It is meaningful to do this in single or multi-user \nenvironments.  The captured states can be 'viewed' or restored at some \nlater time.\n\nLocking and versioning are separate concepts.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-1905895"}, {"subject": "RE: LOCATE-BY-HISTORY repor", "content": "   From: Konstantin Knizhnik [mailto:KKnizhnik@togetherlab.com]\n\n   If server doesn't support workspaces (or server supports workspaces\n   but client is not using this feature), is there any chance to get\n   version controlled resource for the given version or version\n   history?\n\nThe DAV:locate-by-history report is part of the version-history\nfeature, not part of the workspace feature, so any server that\nsupports version histories should support this report.\n\n   Suppose the following scenario:\n\n   MKDIR MyProject\n   PUT MyProject/foo.txt\n   VERSION-CONTROL MyProject\n\n   So now version controlled resource, version history and initial version\n   are created for all resources in MyProject.\n\nNote that this VERSION-CONTROL request will only place the collection\n\"MyProject\" under version control.  It does *not* place any of the \nmembers of MyProject under version control (VERSION-CONTROL is not\na depth operation).\n\nYou would have to explicitly apply VERSION-CONTROL to each member of\nMyProject that you wanted to be under version control (unless of course\nyour server puts every resource under version control, in which case\nno VERSION-CONTROL request is required for MyProject or any other\nresource).\n\n   Now I set the label to the project:\n\n   LABEL MyProject\n   Depth: Infinite\n   <DAV:label xmlns:DAV=\"DAV:\">\n     <DAV:set>\n<DAV:label-name>\n  ALPHA-RELEASE\n</DAV:label-name>\n     </DAV:set>\n   </DAV:label>\n\n   Later I want to extract this state of the project. Certainly I know\n   that BASELINE is write way for doing it,\n\nYes.\n\n   but\n   1. What if server doesn't support baselines (labels belong to the\n   basic versioning stuff, while baselines belong to advanced)?\n\nJust to avoid any misunderstanding, the label feature is only\npart of the basic-client-workspace package, not part of all basic\nversioning packages, so in general a client cannot count on the presence of\nthe label feature from a basic versioning server.\n\n(A server can of course decide to support both the basic-server-workspace\npackage and the label feature, but a client should not expect this).\n\n   2. Once labels are defined by specification, it should be clear how to\n   use them, right?\n\nYes, but you shouldn't expect to be able to do with labels what\nyou can with baselines (i.e. if you need baseline functionality,\nyou should get it from the server, not try to fake it with labels).\n\n   So I do:\n\n   PROPFIND MyProject\n   depth: Infinite\n   <DAV:propfind xmlns:DAV=\"DAV:\">\n     <DAV:prop>\n<DAV:displayname/>\n<DAV:creationdate/>\n<DAV:contenttype/>\n...\n     </DAV:prop>\n   </DAV:propfind>\n\nI assume you meant to have a \"Label ALPHA-RELEASE\" header in the\nrequest?\n\n   So I will be given information about all versions in MyProject labeled\n   by \"ALHPA-RELEASE\". Is is ok, but now I want to extract this files to\n   the client's local disk. In here is a trouble - I don't know path of\n   the resources. In report I will be given:\n\n   <DAV:response>\n     <DAV:href>\n/.repo/vh1/ver1.1\n     </DAV:href>\n     <DAV:displayname>\nMyProject\n     </DAV:displayname>\n     ...\n   </DAV:response>\n   <DAV:response>\n     <DAV:href>\n/.repo/vh2/ver1.1\n     </DAV:href>\n     <DAV:displayname>\nfoo.txt\n     </DAV:displayname>\n     ...\n   </DAV:response>\n   ...\n\nYes, that is correct.\n\n   How the client will understand that foo.txt should be saved in the\n   file \\MyProject\\foo.txt at local disk?\n\nYou should also have asked for the DAV:version-history property, and\nthen you can use a single DAV:locate-by-history report to find the pathname\nto the VCRs for those histories in the MyProject collection.\n\nThis is of course trivial when a server supports baselines.  The Label\nmechanism is mostly useful for doing things one resource at a time.\n\n   The only way is to find out version controlled resource for the\n   givven version (or version history).  Report locate-by-history\n   requires workspace as request target. But client knows nothing\n   about workspaces and my be that are not even supported by server.\n   So what should I do?\n\nThe simple answer is to only provide this functionality for servers\nthat support baselines.  It's good to interoperate with any server,\nbut trying to \"fake\" missing server functionality (e.g. faking\nbaselines with labels) will result in a complex (and often inefficient)\nclient.  But you can use the DAV:locate-by-history report if you\nreally want to do this.\n\n   If version history will be specified as target of LOCATE-BY-HISTORY\nreport\n   and workspace can be optionally specified in request body, then\n   this report can be used to get versioned resource even if server\n   doesn't support workspaces or it support workspaces and when workspace\n   is not explicitly specified by client, then resource is implicitly\n   placed in some default workspace.\n\nThe request-URL for the DAV:locate-by-history identifies any collection\n(i.e. it doesn't have to be a workspace).  The version-historys are\nspecified in the request body to allow you to ask for several in\none request.\n\n   But even in this case getting resource name require two additional\n   requests: PROPFIND to get version history by version and\n   locate-by-history REPORT to give versioned resource reference.\n\n   Another way is to add property <DAV:defaultdisplacepath/> with the\n   following semantic:\n   - for version controlled resource, it returns its URL\n   - for version and version history - URL of version controlled resource\n     in default workspace if such exists\n\nThere is no concept of a \"default workspace\", so there is no\nparticular path that could be displayed here.  It is unlikely that we\nwould add a new concept like \"default workspace\" just to allow one\nfeature (i.e. labels) to better simulate another existing feature\n(i.e. baselines).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1914694"}, {"subject": "Workspaces, Baseline-Control und auto-version, MKCO", "content": "Hi,\n\njust for clarification and reassurance:\n\nSuppose a workspace WS with uri /ws that is under baseline-control and the\nauto-version property of the version controlled collection representing the\nbaseline controlled workspace WS is set to checkout-checkin.\n\nNow suppose a MKCOL request on uri /ws/folder. With that \"directory\" folder\nis created within the workspace WS. Does the creation of this folder cause a\nnew baseline to be created within the baseline-history of the vcc\nrepresenting WS?\n\nI assume it would do, if so is it a MUST or a SHOULD? From my reading I\nassume MUST.\n\n\nThanks,\nDaniel\n\n\n\n", "id": "lists-007-1927546"}, {"subject": "Re: Workspaces, Baseline-Control und auto-version, MKCO", "content": "\"Kirmse, Daniel\" <daniel.kirmse@sap.com>\n\n> Suppose a workspace WS with uri /ws that is under baseline-\n> control and the auto-version property of the version controlled\n> collection representing the baseline controlled workspace WS\n> is set to checkout-checkin.\n\nWhen you say \"the version controlled collection representing the baseline \ncontrolled workspace\" do you mean the _version-controlled configuration_ \nof the workspace or the workspace itself?  I'll assume you mean the \nconfiguration.\n\n> Now suppose a MKCOL request on uri /ws/folder. With that\n> \"directory\" folder is created within the workspace WS. Does the\n> creation of this folder cause a new baseline to be created\n> within the baseline-history of the vcc representing WS?\n\nNo.  Modifications to the resources making up the configuration are not \nconsidered modifications to the version-controlled configuration resource \nitself.  If they were, you would be able to lock an entire configuration \netc. by locking this one resource.\n\n> I assume it would do, if so is it a MUST or a SHOULD? From my\n> reading I assume MUST.\n\nI assume it would not.  Which part of the spec. are you referring to?\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-1936909"}, {"subject": "RE: Workspaces, Baseline-Control und auto-version, MKCO", "content": ">-----Original Message-----\n>From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n>Sent: Freitag, 11. Januar 2002 11:48\n>To: ietf-dav-versioning@w3.org\n>Subject: Re: Workspaces, Baseline-Control und auto-version, MKCOL\n>\n>\n>\"Kirmse, Daniel\" <daniel.kirmse@sap.com>\n>\n>> Suppose a workspace WS with uri /ws that is under baseline-\n>> control and the auto-version property of the version controlled\n>> collection representing the baseline controlled workspace WS\n>> is set to checkout-checkin.\n>\n>When you say \"the version controlled collection representing \n>the baseline \n>controlled workspace\" do you mean the _version-controlled \n>configuration_ \n>of the workspace or the workspace itself?  I'll assume you mean the \n>configuration.\n>\n\nRight assumption\n\n>> Now suppose a MKCOL request on uri /ws/folder. With that\n>> \"directory\" folder is created within the workspace WS. Does the\n>> creation of this folder cause a new baseline to be created\n>> within the baseline-history of the vcc representing WS?\n>\n>No.  Modifications to the resources making up the \n>configuration are not \n>considered modifications to the version-controlled \n>configuration resource \n>itself.  If they were, you would be able to lock an entire \n>configuration \n>etc. by locking this one resource.\n>\n\nRight here is my mistake! So with that I also assume it would not.\nI mixed up (again) workspace and the vcc.\n\n>> I assume it would do, if so is it a MUST or a SHOULD? From my\n>> reading I assume MUST.\n>\n>I assume it would not.  Which part of the spec. are you referring to?\n\n>\n>Regards,\n>Tim\n>\n\n\n\n", "id": "lists-007-1945938"}, {"subject": "RE: Workspaces, Baseline-Control und auto-version, MKCO", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   Suppose a workspace WS with uri /ws that is under baseline-control\n   and the auto-version property of the version controlled collection\n   representing the baseline controlled workspace WS is set to\n   checkout-checkin.\n\nI think you mean the \"version-controlled configuration\" here, not\nthe \"version-controlled collection\".\n\n   Now suppose a MKCOL request on uri /ws/folder. With that \"directory\"\nfolder\n   is created within the workspace WS. Does the creation of this folder\ncause a\n   new baseline to be created within the baseline-history of the vcc\n   representing WS?\n\n   I assume it would do, if so is it a MUST or a SHOULD? From my reading I\n   assume MUST.\n\nThe creation of a folder does not trigger the creation of a\nnew baseline (baselines track the state of version-controlled resources).\nSo you would have to change the version-controlled state of the\nworkspace to see the creation of a new baseline (e.g. CHECKIN, \nVERSION-CONTROL, UPDATE, or MERGE to the workspace)\n\nBut if your server automatically puts resources under version control\nwhen they are created (including collections), and if DAV:auto-version\nis appropriately set on /ws, then the MKCOL would result in the creation\nof a new version of /ws, and the placing of /ws/folder under version\ncontrol, which would result in a new baseline (containing the new\nversion-controlled collection, /ws/folder).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1956184"}, {"subject": "RE: Workspaces, Baseline-Control und auto-version, MKCO", "content": "   From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n\n   \"Kirmse, Daniel\" <daniel.kirmse@sap.com>\n\n   > Suppose a workspace WS with uri /ws that is under baseline-\n   > control and the auto-version property of the version controlled\n   > configuration representing the baseline controlled workspace WS\n   > is set to checkout-checkin.\n   > Now suppose a MKCOL request on uri /ws/folder. With that\n   > \"directory\" folder is created within the workspace WS. Does the\n   > creation of this folder cause a new baseline to be created\n   > within the baseline-history of the vcc representing WS?\n\n   No.  Modifications to the resources making up the configuration are\n   not considered modifications to the version-controlled\n   configuration resource itself.  If they were, you would be able to\n   lock an entire configuration etc. by locking this one resource.\n\nWell, depends what you mean by \"modification\".  If it is a change that\nresults in a change to the DAV:checked-in property of any member of\nthe baseline controlled collection (e.g. CHECKIN, UPDATE, MERGE),\nthen it is considered a change to the\nversion-controlled configuration, and such a change MUST be\nrejected unless the VCCn is checked out, or if auto-versioning is\nappropriately set for the VCCn.\n\nBut if it is not a change to a version-controlled resource (such as\na MKCOL that creates a non-version-controlled collection), then\nI agree that it is not a modification to the VCCn.\n\n   > I assume it would do, if so is it a MUST or a SHOULD? From my\n   > reading I assume MUST.\n\n   I assume it would not.  Which part of the spec. are you referring to?\n\nNote that the DAV:modify-configuration postconditions in sections 12.12,\n12.13, and 12.14 define the semantics related to this question.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1965391"}, {"subject": "depth heade", "content": "In WebDAV methods where there can be a Depth header, the rule is :\n\"0\" : the method applies only to the resource\n\"1\" : to the resource and its immediate children\n\"infinity\" : to the resource and all its progeny\n\nOk, but what does it mean for a collection, that contains usually many resources : does the  1 or infinity give informations about the resources/files in the collection/directory ?\nIt's not clear for me...\n\n\n\n", "id": "lists-007-1974988"}, {"subject": "RE: Workspaces, Baseline-Control und auto-version, MKCO", "content": "\"Clemm, Geoff\" <gclemm@rational.com> wrote:\n\n>    From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n> \n>    \"Kirmse, Daniel\" <daniel.kirmse@sap.com>\n> \n>    > Suppose a workspace WS with uri /ws that is under baseline-\n>    > control and the auto-version property of the version controlled\n>    > configuration representing the baseline controlled workspace WS\n>    > is set to checkout-checkin.\n>    > Now suppose a MKCOL request on uri /ws/folder. With that\n>    > \"directory\" folder is created within the workspace WS. Does the\n>    > creation of this folder cause a new baseline to be created\n>    > within the baseline-history of the vcc representing WS?\n> \n>    No.  Modifications to the resources making up the configuration are\n>    not considered modifications to the version-controlled\n>    configuration resource itself.  If they were, you would be able to\n>    lock an entire configuration etc. by locking this one resource.\n> \n> Well, depends what you mean by \"modification\".  If it is a change that\n> results in a change to the DAV:checked-in property of any member of\n> the baseline controlled collection (e.g. CHECKIN, UPDATE, MERGE),\n> then it is considered a change to the\n> version-controlled configuration, and such a change MUST be\n> rejected unless the VCCn is checked out, or if auto-versioning is\n> appropriately set for the VCCn.\n> \n> But if it is not a change to a version-controlled resource (such as\n> a MKCOL that creates a non-version-controlled collection), then\n> I agree that it is not a modification to the VCCn.\n> \n>    > I assume it would do, if so is it a MUST or a SHOULD? From my\n>    > reading I assume MUST.\n> \n>    I assume it would not.  Which part of the spec. are you referring to?\n> \n> Note that the DAV:modify-configuration postconditions in sections 12.12,\n> 12.13, and 12.14 define the semantics related to this question.\n\nOk, that is clear.  Apologies to Daniel for my misleading response. That \nis not how I remembered it.\n\nI'm left wondering why this is so.  On the face of it, these \npostconditions mean that where a baseline-controlled collection has a \nchecked-in version-controlled configuration there is a guarantee that the \nmembership of the configuration (rooted at the baseline-controlled \ncollection) is the same as that represented by the checked-in \nversion-controlled configuration -- however, that only covers the \nchecked-in version-controlled members of the configuration ... there can \nbe variance by non-version-controlled members and/or checked-out \nversion-controlled members.  So what is the value of this postcondition?\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-1982286"}, {"subject": "RE: Workspaces, Baseline-Control und auto-version, MKCO", "content": "   From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n\n   \"Clemm, Geoff\" <gclemm@rational.com> wrote:\n\n   > If it is a change that results in a change to the DAV:checked-in\n   > property of any member of the baseline controlled collection\n   > (e.g. CHECKIN, UPDATE, MERGE), then it is considered a change to\n   > the version-controlled configuration, and such a change MUST be\n   > rejected unless the VCCn is checked out, or if auto-versioning is\n   > appropriately set for the VCCn.\n\n   I'm left wondering why this is so.  On the face of it, these\n   postconditions mean that where a baseline-controlled collection has\n   a checked-in version-controlled configuration there is a guarantee\n   that the membership of the configuration (rooted at the\n   baseline-controlled collection) is the same as that represented by\n   the checked-in version-controlled configuration -- however, that\n   only covers the checked-in version-controlled members of the\n   configuration ... there can be variance by non-version-controlled\n   members and/or checked-out version-controlled members.  So what is\n   the value of this postcondition?\n\nThe purpose of these postconditions is so that you can get some\ndefault baselining behavior for a baselining-unaware client,\njust as DAV:auto-version on a VCR gives you default versioning\nbehavior for a versioning-unaware client.  In particular,\nthe reasonable time to automatically create a new baseline would\nbe when it would capture a different value than the current baseline,\n(i.e. when the DAV:checked-in version of one of the version-controlled\nmembers has changed).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-1993386"}, {"subject": "RE: depth heade", "content": "I'm not quite sure what you are asking here.\nPerhaps if you made the question more concrete, it would be more\nunderstandable,\ne.g. \"if I do a Depth:xxx PROPFIND on a collection like yyy, would the\nresult\nbe aaa or bbb\".\n\nCheers,\nGeoff \n\n-----Original Message-----\nFrom: Elodie Tasia [mailto:e.tasia@ever-team.com]\nSent: Friday, January 11, 2002 11:00 AM\nTo: IETF DAV\nSubject: depth header\n\n\nIn WebDAV methods where there can be a Depth header, the rule is :\n\"0\" : the method applies only to the resource\n\"1\" : to the resource and its immediate children\n\"infinity\" : to the resource and all its progeny\n\nOk, but what does it mean for a collection, that contains usually many\nresources : does the  1 or infinity give informations about the\nresources/files in the collection/directory ?\nIt's not clear for me...\n \n\n\n\n", "id": "lists-007-2002804"}, {"subject": "FW: Activitie", "content": "Would it be acceptable to have server with the following behavior:\n\nA client performs a checkout to a VCR located within a certain workspace WS\nto some activity not containing any versions yet. Regarding to this the\nDAV:current-workspace-set property must be empty. \nAfter the checkout the DAV:current-workspace-set property contains a href of\nWS. \nNow the server is implemented that way that DAV:current-workspace-set does\ncontain one workspace at most.\nGiven that a checkout to a VCR located within a different workspace WS' to\nthe very same activity must fail.\nWith that an activity is only able to contain versions of resources of one\nworkspace only.\n\nRegards,\nDaniel\n\n>-----Original Message-----\n>From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n>Sent: Donnerstag, 10. Januar 2002 18:30\n>To: ietf-dav-versioning@w3.org\n>Subject: Re: Activities\n>\n>\n>Daniel,\n>\n>You are right that there is no way to restrict an activity \n>resource only \n>to select versions of a single workspace.  Given that all checked-out \n>resources (i.e. working-resources as well as checked-out \n>version-controlled resources) have an unprotected \n>DAV:activity-set, this \n>would be potentially very expensive to enforce -- it would \n>have to be done \n>on the proppatch.  DeltaV does not preclude servers from \n>enforcing such a \n>rule if you choose to do so. but it is not required by the protocol \n>definition.\n>\n>Regards,\n>Tim\n>\n>\n>\n>\n>\"Kirmse, Daniel\" <daniel.kirmse@sap.com>\n>Sent by: ietf-dav-versioning-request@w3.org\n>2002-01-10 11:32 AM\n>\n> \n>        To:     \"Ietf-Dav-Versioning (E-mail)\" \n><ietf-dav-versioning@w3.org>\n>        cc: \n>        Subject:        Activities\n>\n> \n>\n>\n>Hi,\n>\n>a question dealing with activities:\n>\n>Suppose two  workspaces A and B. Both of them are under \n>baseline control \n>on\n>its own. Now suppose an activity C. Is there a server side mechanism \n>defined\n>in DeltaV that could prevent a client from checking out \n>resources of WS A\n>and B and including them by the way into activity C. Instead a client \n>should\n>be forced to checkout a resource of WS B into a different activity if\n>activity C allready contains a checked out resource of workspace A.\n>\n>From reading the DeltaV I got no idea how to do this, propably \n>it's not \n>even\n>there ...\n>\n>Thanks,\n>Daniel\n>\n>\n>\n\n\n\n", "id": "lists-007-2010671"}, {"subject": "RE: Workspaces, Baseline-Control und auto-version, MKCO", "content": "\"Clemm, Geoff\" <gclemm@rational.com> wrote:\n\n>    From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n> \n>    \"Clemm, Geoff\" <gclemm@rational.com> wrote:\n> \n>    > If it is a change that results in a change to the DAV:checked-in\n>    > property of any member of the baseline controlled collection\n>    > (e.g. CHECKIN, UPDATE, MERGE), then it is considered a change to\n>    > the version-controlled configuration, and such a change MUST be\n>    > rejected unless the VCCn is checked out, or if auto-versioning is\n>    > appropriately set for the VCCn.\n> \n>    I'm left wondering why this is so.  On the face of it, these\n>    postconditions mean that where a baseline-controlled collection has\n>    a checked-in version-controlled configuration there is a guarantee\n>    that the membership of the configuration (rooted at the\n>    baseline-controlled collection) is the same as that represented by\n>    the checked-in version-controlled configuration -- however, that\n>    only covers the checked-in version-controlled members of the\n>    configuration ... there can be variance by non-version-controlled\n>    members and/or checked-out version-controlled members.  So what is\n>    the value of this postcondition?\n> \n> The purpose of these postconditions is so that you can get\n> some default baselining behavior for a baselining-unaware\n> client, just as DAV:auto-version on a VCR gives you default\n> versioning behavior for a versioning-unaware client.  In\n> particular, the reasonable time to automatically create a\n> new baseline would be when it would capture a different value\n> than the current baseline, (i.e. when the DAV:checked-in\n> version of one of the version-controlled members has changed).\n\nWhile I agree that this gives some 'default baselining behavior' I don't \nthink that such behaviour is desirable.\n\nFirstly, the group decided that the DAV:auto-version property had to have \na choice of four values to avoid versioning unaware clients causing \nproblems.  These baselining postconditions have no such provision, so a \nbaselining unaware client can inadvertantly cause a large number of \nbaselines to be created (which may be a very time/space expensive \noperation).  What is worse, it is not a property of the resource or \nimmediate resource parent that indicates the auto-behavior, but may be a \nproperty of an arbitrary parent.  I think it is quite possible that a \nclient will issue multiple UPDATEs to a version-controlled resource; \npotentially unaware that they are creating multiple baselines along the \nway.\n\nSecondly, as I pointed out above, creating a baseline only captures the \nchecked-in version-controlled resources, yet there are likely to be \nnon-version-controlled and checked-out resources in the configuration.  A \nbaselining unaware client is clearly not in a position to ensure that all \nresources are maintained in their checked-in state so that they are \ncaptured in the auto-baseline (they _can_ do it, they just don't know _to_ \ndo it), which means that the auto-baselines are likely to be `logically \ninconsistent`.\n\nI don't think the case for auto-baselining is nearly as strong as that for \nauto-versioning for a number of reasons; and it will behove baseliners to \nlabel 'good' baselines so they can find them in the noise of the \nauto-baselines.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-2021399"}, {"subject": "RE: Activitie", "content": "\"Kirmse, Daniel\" <daniel.kirmse@sap.com> wrote:\n\n> Would it be acceptable to have server with the following\n> behavior:\n> \n> A client performs a checkout to a VCR located within a\n> certain workspace WS to some activity not containing any\n> versions yet. Regarding to this the DAV:current-workspace-set\n> property must be empty.  After the checkout the\n> DAV:current-workspace-set property contains a href of WS.\n> Now the server is implemented that way that\n> DAV:current-workspace-set does contain one workspace at most.\n> Given that a checkout to a VCR located within a different\n> workspace WS' to the very same activity must fail.\n> With that an activity is only able to contain versions of\n> resources of one workspace only.\n\nI think it would be simpler to create a new activity, let's say \n/foo/unique, then do all the subsequent check-outs with a request body \nincluding an activity set, but not including unreserved, i.e., \n<DAV:checkout> <DAV:activity-set> \n<DAV:href>http://bar/foo/unique</DAV:href> </DAV:activity-set> \n</DAV:checkout>. The DAV:one-checkout-per-activity-per-history \nprecondition (Sec.13.10) should do it.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-2033068"}, {"subject": "Re: depth heade", "content": "\"Elodie Tasia\" <e.tasia@ever-team.com> wrote:\n\n> In WebDAV methods where there can be a Depth  header, the rule is :\n> \"0\" : the method applies only to the  resource\n> \"1\" : to the resource and its immediate  children\n> \"infinity\" : to the resource and all its  progeny\n>  \n> Ok, but what does it mean for a collection, that  contains usually many\n> resources : does the  1 or infinity give informations  about the\n> resources/files in the collection/directory ?\n> It's not clear for me...\n\nThe depth header is described in RFC2518 at\nhttp://www1.ics.uci.edu/pub/ietf/webdav/protocol/rfc2518.html#HEADER_Depth\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-2041436"}, {"subject": "RE: Activitie", "content": "Tim,\n\nright the DAV:one-checkout-per-activity-per-history precondition (Sec.13.10)\ndoes it for two VCR's pointing to the very same version-history. My problem\nwas more general. I want to prevent any two VCR's of two workspaces (VCR1\nmember of WS1 and VCR2 member of WS2) to be in the same activity. So\nchanging VCR's of both of the workspaces I do need two activities. One for\neach Workspace.\n\nBackground: I want to prevent a client mixing up changes made to a\ndevelopment codeline and changes made to a correction or consolidation\ncodeline into one activity.\n\nAs you said for VCR's sharing the same version-history this is ensured with\nthe precondition you mentioned. It is for the other ones I need a solution\nfor. Thats why I came up with the idea of restricting the\nDAV:current-workspace-set property to contain at most one workspace\nreference.\n\nRegards,\nDaniel\n\n>-----Original Message-----\n>From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n>Sent: Montag, 14. Januar 2002 16:27\n>To: ietf-dav-versioning@w3.org\n>Subject: RE: Activities\n>\n>\n>\"Kirmse, Daniel\" <daniel.kirmse@sap.com> wrote:\n>\n>> Would it be acceptable to have server with the following\n>> behavior:\n>> \n>> A client performs a checkout to a VCR located within a\n>> certain workspace WS to some activity not containing any\n>> versions yet. Regarding to this the DAV:current-workspace-set\n>> property must be empty.  After the checkout the\n>> DAV:current-workspace-set property contains a href of WS.\n>> Now the server is implemented that way that\n>> DAV:current-workspace-set does contain one workspace at most.\n>> Given that a checkout to a VCR located within a different\n>> workspace WS' to the very same activity must fail.\n>> With that an activity is only able to contain versions of\n>> resources of one workspace only.\n>\n>I think it would be simpler to create a new activity, let's say \n>/foo/unique, then do all the subsequent check-outs with a request body \n>including an activity set, but not including unreserved, i.e., \n><DAV:checkout> <DAV:activity-set> \n><DAV:href>http://bar/foo/unique</DAV:href> </DAV:activity-set> \n></DAV:checkout>. The DAV:one-checkout-per-activity-per-history \n>precondition (Sec.13.10) should do it.\n>\n>Regards,\n>Tim\n>\n\n\n\n", "id": "lists-007-2049012"}, {"subject": "RE: Activitie", "content": "> Thats why I came up with the idea of restricting the\n> DAV:current-workspace-set property to contain at most\n> one workspace reference.\n\nYup, you can do that.  The DAV:current-workspace-set is a computed \nproperty; i.e., it's value is defined as a function of another property. \nIn this case the other property is a workspace's DAV:current-activity-set, \nthe definition of which states 'The DAV:current-activity-set MAY be \nrestricted to identify at most one activity.' (13.4.1)\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-2059071"}, {"subject": "RE: Activitie", "content": "Yes, that is acceptable behavior.  It probably will in fact be very\ncommon for the DAV:current-workspace-set property to be limited to\nat most one workspace.\n\nNote though that this only limits *concurrent* additions to the same\nactivity to be from the same workspace.  If a user in one workspace is\ndone with the activity, and removes it from the DAV:current-activity-set\nof that workspace, the activity can now be worked on in another workspace.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Monday, January 14, 2002 5:44 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: FW: Activities\n\n\nWould it be acceptable to have server with the following behavior:\n\nA client performs a checkout to a VCR located within a certain workspace WS\nto some activity not containing any versions yet. Regarding to this the\nDAV:current-workspace-set property must be empty. \nAfter the checkout the DAV:current-workspace-set property contains a href of\nWS. \nNow the server is implemented that way that DAV:current-workspace-set does\ncontain one workspace at most.\nGiven that a checkout to a VCR located within a different workspace WS' to\nthe very same activity must fail.\nWith that an activity is only able to contain versions of resources of one\nworkspace only.\n\nRegards,\nDaniel\n\n>-----Original Message-----\n>From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n>Sent: Donnerstag, 10. Januar 2002 18:30\n>To: ietf-dav-versioning@w3.org\n>Subject: Re: Activities\n>\n>\n>Daniel,\n>\n>You are right that there is no way to restrict an activity \n>resource only \n>to select versions of a single workspace.  Given that all checked-out \n>resources (i.e. working-resources as well as checked-out \n>version-controlled resources) have an unprotected \n>DAV:activity-set, this \n>would be potentially very expensive to enforce -- it would \n>have to be done \n>on the proppatch.  DeltaV does not preclude servers from \n>enforcing such a \n>rule if you choose to do so. but it is not required by the protocol \n>definition.\n>\n>Regards,\n>Tim\n>\n>\n>\n>\n>\"Kirmse, Daniel\" <daniel.kirmse@sap.com>\n>Sent by: ietf-dav-versioning-request@w3.org\n>2002-01-10 11:32 AM\n>\n> \n>        To:     \"Ietf-Dav-Versioning (E-mail)\" \n><ietf-dav-versioning@w3.org>\n>        cc: \n>        Subject:        Activities\n>\n> \n>\n>\n>Hi,\n>\n>a question dealing with activities:\n>\n>Suppose two  workspaces A and B. Both of them are under \n>baseline control \n>on\n>its own. Now suppose an activity C. Is there a server side mechanism \n>defined\n>in DeltaV that could prevent a client from checking out \n>resources of WS A\n>and B and including them by the way into activity C. Instead a client \n>should\n>be forced to checkout a resource of WS B into a different activity if\n>activity C allready contains a checked out resource of workspace A.\n>\n>From reading the DeltaV I got no idea how to do this, propably \n>it's not \n>even\n>there ...\n>\n>Thanks,\n>Daniel\n>\n>\n>\n\n\n\n", "id": "lists-007-2066316"}, {"subject": "RE: Workspaces, Baseline-Control und auto-version, MKCO", "content": "   From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n   >    \"Clemm, Geoff\" <gclemm@rational.com> wrote:\n   >    > If it is a change that results in a change to the DAV:checked-in\n   >    > property of any member of the baseline controlled collection\n   >    > (e.g. CHECKIN, UPDATE, MERGE), then it is considered a change to\n   >    > the version-controlled configuration, and such a change MUST be\n   >    > rejected unless the VCCn is checked out, or if auto-versioning is\n   >    > appropriately set for the VCCn.\n   > \n\n   While I agree that this gives some 'default baselining behavior' I don't \n   think that such behaviour is desirable.\n\nThat's fine.  A server is free to support whatever subset of the\nauto-versioning behavior that it wants.  So if you want just\n\"auto-checkout\" behavior (i.e. no automatic creation of baselines) for\nyour server, that is fine.\n\n   Firstly, the group decided that the DAV:auto-version property had\n   to have a choice of four values to avoid versioning unaware clients\n   causing problems.  These baselining postconditions have no such\n   provision, so a baselining unaware client can inadvertantly cause a\n   large number of baselines to be created (which may be a very\n   time/space expensive operation).\n\nI don't understand your point here.  A VCCn is just a special kind of\nVCR, and therefore its DAV:auto-version property has the same (4)\nvalues that any other VCR would have.  The meanings of these values\nremain unchanged ... the only thing that changes is what is considered\na \"change of state\" to the resource.  For a VCR, it is its content and\ndead properties.  For a VCCl, it is the name and version history of\nits internal members.  For a VCCn, it is the DAV:checked-in value of\nany of the members of its DAV:baselined-collection.\n\n   What is worse, it is not a property of the resource or immediate\n   resource parent that indicates the auto-behavior, but may be a\n   property of an arbitrary parent.\n\nActually, it is a property of the DAV:version-controlled-configuration\nof the resource, not a property of any of its parents.  This is easily\nfound with a single DAV:expand-property request (or two PROPFIND\nrequests).\n\n   I think it is quite possible that a client will issue multiple\n   UPDATEs to a version-controlled resource; potentially unaware that\n   they are creating multiple baselines along the way.\n\nA server that is concerned about this will support the appropriate\nflavor of DAV:auto-version (such as DAV:checkout, which never\nautomatically creates a baseline).\n\n   Secondly, as I pointed out above, creating a baseline only captures the \n   checked-in version-controlled resources, yet there are likely to be \n   non-version-controlled and checked-out resources in the configuration.  A\n\n   baselining unaware client is clearly not in a position to ensure that all\n\n   resources are maintained in their checked-in state so that they are \n   captured in the auto-baseline (they _can_ do it, they just don't know\n_to_ \n   do it), which means that the auto-baselines are likely to be `logically \n   inconsistent`.\n\nIt is true that inconsistent states of version-controlled resources\ncan exist on the server, and that a baselining unaware client has no\nway of baselining only the consistent states.  But a server with the\nappropriately efficient baselining mechanisms might just want to\ncapture all of those states.  And a server that doesn't want to will\njust use DAV:checkout as the value of DAV:auto-version.\n\n   I don't think the case for auto-baselining is nearly as strong as\n   that for auto-versioning for a number of reasons; and it will\n   behove baseliners to label 'good' baselines so they can find them\n   in the noise of the auto-baselines.\n\nSimilarly, the case for auto-versioning collections is probably even\nstronger than the case for auto-versioning resources with content, and\na server is free to support the appropriate kind of auto-versioning\nwith each kind of resource.  I personally believe that\nDAV:checkout-unlocked-checkin or DAV:locked-checkout will be most\ncommon for resources with content, DAV:checkout-checkin will be most\ncommon for version-controlled collections, and DAV:checkout will be\nmost common for version-controlled configurations.\n\nBut that doesn't argue against the use of auto-versioning for\nVCCn's, it just says that the \"common\" DAV:auto-version value\nfor a VCCn will be different from a VCR or a VCCl.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2077682"}, {"subject": "RE: Workspaces, Baseline-Control und auto-version, MKCO", "content": "I agree with everything written below.  So I'm happy again.\nThanks Geoff.\n\n(In particular, nodding vigously at likely default values for the \nDAV:auto-version property on different resource types.)\n\nRegards,\nTim\n\n\n\n\n\"Clemm, Geoff\" <gclemm@rational.com>\nSent by: ietf-dav-versioning-request@w3.org\n2002-01-14 10:08 PM\n\n \n        To:     ietf-dav-versioning@w3.org\n        cc: \n        Subject:        RE: Workspaces, Baseline-Control und auto-version, MKCOL\n\n \n\n\n   From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n   >    \"Clemm, Geoff\" <gclemm@rational.com> wrote:\n   >    > If it is a change that results in a change to the DAV:checked-in\n   >    > property of any member of the baseline controlled collection\n   >    > (e.g. CHECKIN, UPDATE, MERGE), then it is considered a change to\n   >    > the version-controlled configuration, and such a change MUST be\n   >    > rejected unless the VCCn is checked out, or if auto-versioning \nis\n   >    > appropriately set for the VCCn.\n   >\n\n   While I agree that this gives some 'default baselining behavior' I \ndon't\n   think that such behaviour is desirable.\n\nThat's fine.  A server is free to support whatever subset of the\nauto-versioning behavior that it wants.  So if you want just\n\"auto-checkout\" behavior (i.e. no automatic creation of baselines) for\nyour server, that is fine.\n\n   Firstly, the group decided that the DAV:auto-version property had\n   to have a choice of four values to avoid versioning unaware clients\n   causing problems.  These baselining postconditions have no such\n   provision, so a baselining unaware client can inadvertantly cause a\n   large number of baselines to be created (which may be a very\n   time/space expensive operation).\n\nI don't understand your point here.  A VCCn is just a special kind of\nVCR, and therefore its DAV:auto-version property has the same (4)\nvalues that any other VCR would have.  The meanings of these values\nremain unchanged ... the only thing that changes is what is considered\na \"change of state\" to the resource.  For a VCR, it is its content and\ndead properties.  For a VCCl, it is the name and version history of\nits internal members.  For a VCCn, it is the DAV:checked-in value of\nany of the members of its DAV:baselined-collection.\n\n   What is worse, it is not a property of the resource or immediate\n   resource parent that indicates the auto-behavior, but may be a\n   property of an arbitrary parent.\n\nActually, it is a property of the DAV:version-controlled-configuration\nof the resource, not a property of any of its parents.  This is easily\nfound with a single DAV:expand-property request (or two PROPFIND\nrequests).\n\n   I think it is quite possible that a client will issue multiple\n   UPDATEs to a version-controlled resource; potentially unaware that\n   they are creating multiple baselines along the way.\n\nA server that is concerned about this will support the appropriate\nflavor of DAV:auto-version (such as DAV:checkout, which never\nautomatically creates a baseline).\n\n   Secondly, as I pointed out above, creating a baseline only captures the\n   checked-in version-controlled resources, yet there are likely to be\n   non-version-controlled and checked-out resources in the configuration. \nA\n\n   baselining unaware client is clearly not in a position to ensure that \nall\n\n   resources are maintained in their checked-in state so that they are\n   captured in the auto-baseline (they _can_ do it, they just don't know\n_to_\n   do it), which means that the auto-baselines are likely to be `logically\n   inconsistent`.\n\nIt is true that inconsistent states of version-controlled resources\ncan exist on the server, and that a baselining unaware client has no\nway of baselining only the consistent states.  But a server with the\nappropriately efficient baselining mechanisms might just want to\ncapture all of those states.  And a server that doesn't want to will\njust use DAV:checkout as the value of DAV:auto-version.\n\n   I don't think the case for auto-baselining is nearly as strong as\n   that for auto-versioning for a number of reasons; and it will\n   behove baseliners to label 'good' baselines so they can find them\n   in the noise of the auto-baselines.\n\nSimilarly, the case for auto-versioning collections is probably even\nstronger than the case for auto-versioning resources with content, and\na server is free to support the appropriate kind of auto-versioning\nwith each kind of resource.  I personally believe that\nDAV:checkout-unlocked-checkin or DAV:locked-checkout will be most\ncommon for resources with content, DAV:checkout-checkin will be most\ncommon for version-controlled collections, and DAV:checkout will be\nmost common for version-controlled configurations.\n\nBut that doesn't argue against the use of auto-versioning for\nVCCn's, it just says that the \"common\" DAV:auto-version value\nfor a VCCn will be different from a VCR or a VCCl.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2089965"}, {"subject": "Adding a new file to an activit", "content": "Hi,\n\nsuppose I have a repository landscape with a workspace under\nbaseline-control. The workspace contains my VCR's. Checkout is done with\nDAV:apply-to-version and DAV:activity-set (href or new). So Work in process\nis represented by working-resources collected in activities.\n\nWell what if a client wants to add a file to the repository using a given\nactivity (or a newly created one). The file should be placed under version\ncontrol automatically. Do it have to directly add the file/resource to the\nworkspace where all the VCR's are stored? Or is there a way to have a\nworking resource connected to the activity and creating the VCR of that file\nat checkin?\n\nMay I perform a checkout to a not existing VCR (like locking a not existing\nresource in WebDAV to reserve the name) with apply-to-version and\nactivoity-set to get an working-resource in my activity? What happens when I\ncheckin this (creation of VCR, version-history etc.)? What happens when I\nwant to revert this (uncheckout? is this defined for working-resources to -\nI suppose it is)\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2103606"}, {"subject": "Activities and Checkin/Merg", "content": "Hi,\n\nsuppose I have a repository landscape with a workspace under\nbaseline-control. The workspace contains my VCR's. Checkout is done with\nDAV:apply-to-version and DAV:activity-set (href or new). So Work in process\nis represented by working-resources collected in activities.\n\n\nWhat is the difference of performing a checkin on the activity or do a merge\nof that activity to the workspace the VCR's are located in with\nDAV:checkin-activity?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2112448"}, {"subject": "RE: Activitie", "content": ">-----Original Message-----\n>From: Clemm, Geoff [mailto:gclemm@rational.com]\n>Sent: Montag, 14. Januar 2002 18:38\n>To: Ietf-Dav-Versioning (E-mail)\n>Subject: RE: Activities\n>\n>\n>Yes, that is acceptable behavior.  It probably will in fact be very\n>common for the DAV:current-workspace-set property to be limited to\n>at most one workspace.\n>\n>Note though that this only limits *concurrent* additions to the same\n>activity to be from the same workspace.  If a user in one workspace is\n>done with the activity, and removes it from the \n>DAV:current-activity-set\n>of that workspace, the activity can now be worked on in \n>another workspace.\n\nthats reasonable behavior.\n\nBut it raises another question: When does an activity end its existence?\nWell as far as my understanding from reading DeltaV goes it seems to me an\nexplicit DELETE has to be performed, right?\n\n>\n>Cheers,\n>Geoff\n>\n>-----Original Message-----\n>From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n>Sent: Monday, January 14, 2002 5:44 AM\n>To: Ietf-Dav-Versioning (E-mail)\n>Subject: FW: Activities\n>\n>\n>Would it be acceptable to have server with the following behavior:\n>\n>A client performs a checkout to a VCR located within a certain \n>workspace WS\n>to some activity not containing any versions yet. Regarding to this the\n>DAV:current-workspace-set property must be empty. \n>After the checkout the DAV:current-workspace-set property \n>contains a href of\n>WS. \n>Now the server is implemented that way that \n>DAV:current-workspace-set does\n>contain one workspace at most.\n>Given that a checkout to a VCR located within a different \n>workspace WS' to\n>the very same activity must fail.\n>With that an activity is only able to contain versions of \n>resources of one\n>workspace only.\n>\n>Regards,\n>Daniel\n>\n>>-----Original Message-----\n>>From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n>>Sent: Donnerstag, 10. Januar 2002 18:30\n>>To: ietf-dav-versioning@w3.org\n>>Subject: Re: Activities\n>>\n>>\n>>Daniel,\n>>\n>>You are right that there is no way to restrict an activity \n>>resource only \n>>to select versions of a single workspace.  Given that all checked-out \n>>resources (i.e. working-resources as well as checked-out \n>>version-controlled resources) have an unprotected \n>>DAV:activity-set, this \n>>would be potentially very expensive to enforce -- it would \n>>have to be done \n>>on the proppatch.  DeltaV does not preclude servers from \n>>enforcing such a \n>>rule if you choose to do so. but it is not required by the protocol \n>>definition.\n>>\n>>Regards,\n>>Tim\n>>\n>>\n>>\n>>\n>>\"Kirmse, Daniel\" <daniel.kirmse@sap.com>\n>>Sent by: ietf-dav-versioning-request@w3.org\n>>2002-01-10 11:32 AM\n>>\n>> \n>>        To:     \"Ietf-Dav-Versioning (E-mail)\" \n>><ietf-dav-versioning@w3.org>\n>>        cc: \n>>        Subject:        Activities\n>>\n>> \n>>\n>>\n>>Hi,\n>>\n>>a question dealing with activities:\n>>\n>>Suppose two  workspaces A and B. Both of them are under \n>>baseline control \n>>on\n>>its own. Now suppose an activity C. Is there a server side mechanism \n>>defined\n>>in DeltaV that could prevent a client from checking out \n>>resources of WS A\n>>and B and including them by the way into activity C. Instead a client \n>>should\n>>be forced to checkout a resource of WS B into a different activity if\n>>activity C allready contains a checked out resource of workspace A.\n>>\n>>From reading the DeltaV I got no idea how to do this, propably \n>>it's not \n>>even\n>>there ...\n>>\n>>Thanks,\n>>Daniel\n>>\n>>\n>>\n>\n\n\n\n", "id": "lists-007-2119912"}, {"subject": "RE: Activities and Checkin/Merg", "content": "If the working resources were created by checking out VCR's\nwith DAV:apply-to-versoin, then there is no difference between\nchecking in the activity and MERGEing the activity with\nDAV:checkin-activity set.\n\nThe only reason DAV:checkin-activity is provided as a parameter\nto MERGE is to support clients that create working resources by\nchecking out versions (in which case checking in the activity just\ncreates new versions, while MERGE both creates the versions and\nmerges them to the specified collection.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Tuesday, January 15, 2002 6:43 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Activities and Checkin/Merge\n\n\nHi,\n\nsuppose I have a repository landscape with a workspace under\nbaseline-control. The workspace contains my VCR's. Checkout is done with\nDAV:apply-to-version and DAV:activity-set (href or new). So Work in process\nis represented by working-resources collected in activities.\n\n\nWhat is the difference of performing a checkin on the activity or do a merge\nof that activity to the workspace the VCR's are located in with\nDAV:checkin-activity?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2132644"}, {"subject": "RE: Adding a new file to an activit", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   suppose I have a repository landscape with a workspace under\n   baseline-control. The workspace contains my VCR's. Checkout is done\n   with DAV:apply-to-version and DAV:activity-set (href or new). So\n   Work in process is represented by working-resources collected in\n   activities.\n\n   Well what if a client wants to add a file to the repository using a\n   given activity (or a newly created one). The file should be placed\n   under version control automatically. Do it have to directly add the\n   file/resource to the workspace where all the VCR's are stored?\n\nYes.\n\n   Or is there a way to have a working resource connected to the\n   activity and creating the VCR of that file at checkin?\n\nTo keep that resource \"hidden\", your server would need to support\neither multiple workspaces or version-controlled collections.\nWith multiple workspaces, you could create the new resource in\na second workspace, and it would be hidden until you MERGE'd\ninto the first workspace.  With version-controlled collections,\nyou could checkout the collection that is to contain the new\nresource, add the resource to the working collection, and the\nnew resource will only be visible when you check in that working\ncollection. \n\n   May I perform a checkout to a not existing VCR (like locking a not\n   existing resource in WebDAV to reserve the name) with\n   apply-to-version and activoity-set to get an working-resource in my\n   activity?\n\nThis is not currently supported (CHECKOUT can only be applied\nto an existing checked-in resource).  There was no push to \nprovide this kind of behavior because you can get the same effect\nthrough working collections.  Also, the problems encountered with\nthe whole \"lock null resource\" concept would probably cause us\nto shy away from something like this (this is kind of like a\n\"versioning-null resource), unless there were no alternative.\n\n   What happens when I checkin this (creation of VCR,\n   version-history etc.)?\n\nIf it were legal, creating the VCR and version history at checkin\ntime is probably what would happen.\n\n   What happens when I want to revert this\n   (uncheckout? is this defined for working-resources to - I suppose\n   it is)\n\nIn general, if you want to cancel a checkout that resulted in a\nworking resource, just delete the working resource. \n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2140799"}, {"subject": "RE: Activitie", "content": "Correct.  An activity lives on until explicitly deleted.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\nBut it raises another question: When does an activity end its existence?\nWell as far as my understanding from reading DeltaV goes it seems to me an\nexplicit DELETE has to be performed, right?\n\n\n\n", "id": "lists-007-2150523"}, {"subject": "RE: Adding a new file to an activit", "content": "Landscape:\n>   suppose I have a repository landscape with a workspace under\n>   baseline-control. The workspace contains my VCR's and version-controlled\ncollections. Checkout is done\n>   with DAV:apply-to-version and DAV:activity-set (href or new). So\n>   Work in process is represented by working-resources collected in\n>   activities. Baselining is done with auto-version = checkout-checkin.\n\nO.k. after some more reading and thinkinh I'll take version-controlled\ncollections. But there are some questions left:\n\n0. Does a checkout to a version-controlled collection always create a\nworking-collection? So there is no checkout-in-place available for\nversion-controlled collections.\n\n1. Do I understand it the right way if I assume in order to have a \"hidden\"\nPUT (adding a new file w/o makinging it visible within the workspace\n(codeline) containing all the VCR's) I have to perform an explicit checkout\nto the version-controlled collection that's to contain this file. After that\nI perform the PUT on the working collection. And not before checkin there is\nthe newly added file visible in the workspace. By the way a new baseline of\nthe baseline-controlled workspace is created (because of the change of the\nDAV:checked-in property of the version-controlled collection)?\n\n2. Every namespace operation (DELETE, MOVE, COPY) and only they (except for\nMKCOL see 5.) would cause an auto-checkout if auto-version is set to\nDAV:checkout behavior?\n\n3. In case 2. is true: Is there a way to give an activity the created\nworking-collection will be bound to? Maybe I just give the DAV:activity-set\ntag in the body?\n\n4. A non-version-controlled resource MUST be created within the\nversion-controlled collection itself instead of creating it within the\nworking collection?\n\n5. As I come to think of it: MKCOL will not cause an working-collection to\nbe created when performed on a version-controlled collection, will it?\nBecause at MKCOL it is not clear wether the created collection will be under\nversion-control (if no auto-version-control behavior is implemented). Or\nmore precise: MKCOL creates non-version-controlled collections (if no\nauto-version-control behavior is implemented)?\n\n6. What about Request that deal with two version-controlled collections as\nfor example MOVE. With an auto-version = DAV:checkout both collections have\nto be checked out, two working collections are created. The source\ncollection working-collection will get rid of the binding of the moved out\nresource. The destination collection working-collection will add a new\nbinding for the moved in resource. But now I'm free to check in the source\ncollection working-collection, so the binding there is gone with the wind.\nAnd I delete the destination collection working-collection, so the new\nbinding is not added. The result is inconsistent, its a half way done MOVE!\nIs there anything to prevent this?\n\nSo that's all for now, maybe there are some more questions to come later on.\n\nRegards,\nDaniel\n\n\n\n>-----Original Message-----\n>From: Clemm, Geoff [mailto:gclemm@rational.com]\n>Sent: Dienstag, 15. Januar 2002 14:46\n>To: Ietf-Dav-Versioning (E-mail)\n>Subject: RE: Adding a new file to an activity\n>\n>\n>   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n>\n>   suppose I have a repository landscape with a workspace under\n>   baseline-control. The workspace contains my VCR's. Checkout is done\n>   with DAV:apply-to-version and DAV:activity-set (href or new). So\n>   Work in process is represented by working-resources collected in\n>   activities.\n>\n>   Well what if a client wants to add a file to the repository using a\n>   given activity (or a newly created one). The file should be placed\n>   under version control automatically. Do it have to directly add the\n>   file/resource to the workspace where all the VCR's are stored?\n>\n>Yes.\n>\n>   Or is there a way to have a working resource connected to the\n>   activity and creating the VCR of that file at checkin?\n>\n>To keep that resource \"hidden\", your server would need to support\n>either multiple workspaces or version-controlled collections.\n>With multiple workspaces, you could create the new resource in\n>a second workspace, and it would be hidden until you MERGE'd\n>into the first workspace.  With version-controlled collections,\n>you could checkout the collection that is to contain the new\n>resource, add the resource to the working collection, and the\n>new resource will only be visible when you check in that working\n>collection. \n>\n>>>>> snipp\n>\n\n\n\n", "id": "lists-007-2157658"}, {"subject": "Version-controlled collection CHECKOU", "content": "Hi,\n\ndoes the checkout behavior of a version-controlled collection be the same as\nthe checkout behavior of a version-controlled resource with\nDAV:apply-to-version flag? (Because of working-collection sounds similar to\nworking-resource) \nIs there the same behavior for parallel development (parallel checkouts,\ncheckin behavior) as for working-resources?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2170086"}, {"subject": "RE: Adding a new file to an activit", "content": "\"Kirmse, Daniel\" <daniel.kirmse@sap.com> wrote:\n\n> Landscape:\n> >   suppose I have a repository landscape with a workspace under\n> >   baseline-control. The workspace contains my VCR's and \nversion-controlled\n> collections. Checkout is done\n> >   with DAV:apply-to-version and DAV:activity-set (href or new). So\n> >   Work in process is represented by working-resources collected in\n> >   activities. Baselining is done with auto-version = checkout-checkin.\n> \n> O.k. after some more reading and thinkinh I'll take version-controlled\n> collections. But there are some questions left:\n> \n> 0. Does a checkout to a version-controlled collection always create a\n> working-collection? So there is no checkout-in-place available for\n> version-controlled collections.\n\nNo, you can have a checked-out version-controlled collection (i.e., \ncheckout in place).\n\n> 1. Do I understand it the right way if I assume in order to have a \n\"hidden\"\n> PUT (adding a new file w/o makinging it visible within the workspace\n> (codeline) containing all the VCR's) I have to perform an explicit \ncheckout\n> to the version-controlled collection that's to contain this file. After \nthat\n> I perform the PUT on the working collection. And not before checkin \nthere is\n> the newly added file visible in the workspace.\n\nYes, to keep the new resource hidden from other users of the same \nworkspace, you would have to create a working collection (possibly with \nthe auto-update feature so that it is reflected back in the workspace when \nthe working collection is checked in).\n\n> By the way a new baseline of\n> the baseline-controlled workspace is created (because of the change of \nthe\n> DAV:checked-in property of the version-controlled collection)?\n\nThe new auto baseline would be created when the working collection is \nchecked-in (assuming auto-update).  As you point out, it occurs when the \nDAV:checked-in property of any version-controlled resource changes.\n\n> 2. Every namespace operation (DELETE, MOVE, COPY) and only they (except \nfor\n> MKCOL see 5.) would cause an auto-checkout if auto-version is set to\n> DAV:checkout behavior?\n\nYes,  I was thinking about MERGE too, but that does it's 'own' check-outs \nso does not rely on auto-versioning behavior.\n\n> 3. In case 2. is true: Is there a way to give an activity the created\n> working-collection will be bound to? Maybe I just give the \nDAV:activity-set\n> tag in the body?\n\nNo, it is not defined for those namespace modifying operations to take an \nDAV:activity-set tag in the body, so you would have to rely upon the \nDAV:current-activity-set of the workspace to capture them.\n \n> 4. A non-version-controlled resource MUST be created within the\n> version-controlled collection itself instead of creating it within the\n> working collection?\n\nIf you want the resource to remain non-version-controlled, then yes.  It \nis defined that checking in a working collection applys VERSION-CONTROL to \nall the versionable resources in the working collection.\n\n> 5. As I come to think of it: MKCOL will not cause an working-collection to\n> be created when performed on a version-controlled collection, will it?\n> Because at MKCOL it is not clear wether the created collection will be \nunder\n> version-control (if no auto-version-control behavior is implemented). Or\n> more precise: MKCOL creates non-version-controlled collections (if no\n> auto-version-control behavior is implemented)?\n\nalthough the new collection will not be version-controlled, the parent of \nthe new collection will have been modified to add the new internal member \nname, so it much be checked-out (automatically or otherwise).  Inthis \nrespect, there is no difference between a MKCOL and a PUT, DELETE, etc.\n \n> 6. What about Request that deal with two version-controlled collections as\n> for example MOVE. With an auto-version = DAV:checkout both collections \nhave\n> to be checked out, two working collections are created.\n\nSince you are applying MOVE to members of two version-controlled \ncollections, then the auto-versioning will checkout the version-controlled \ncollections in-place.  This would not create any working collections.\n\n> The source\n> collection working-collection will get rid of the binding of the moved \nout\n> resource. The destination collection working-collection will add a new\n> binding for the moved in resource. But now I'm free to check in the \nsource\n> collection working-collection, so the binding there is gone with the \nwind.\n> And I delete the destination collection working-collection, so the new\n> binding is not added. The result is inconsistent, its a half way done \nMOVE!\n> Is there anything to prevent this?\n\nNo, if you apply the MOVE to working collections so that they are 'work in \nprogress' there is nothing to prevent clients from checking in one working \nresource and DELETEing the other.  Although the MOVE was good, the \nchecked-in results would be inconsistent (either the binding disappears \nalltogether, or there are now two bindings to the same history depending \nupon which you checked in and which you deleted).\n\n> So that's all for now, maybe there are some more questions to come later \non.\n\nI'll add my usual plug for the DeltaV FAQ.  It would be good if you could \nadd any \"aha!'s\" to the FAQ at http://www.webdav.org/deltav/faq\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-2177947"}, {"subject": "RE: Adding a new file to an activit", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   O.k. after some more reading and thinkinh I'll take version-controlled\n   collections. But there are some questions left:\n\n   0. Does a checkout to a version-controlled collection always create a\n   working-collection? So there is no checkout-in-place available for\n   version-controlled collections.\n\nA version-controlled collection is just a VCR with some additional\nrules, so it inherits all the VCR rules.  In particular, this means\nthat when you apply CHECKOUT to a VCR, it is an in place checkout\nunless you specify the DAV:apply-to-version parameter.\n\n   1. Do I understand it the right way if I assume in order to have a\n\"hidden\"\n   PUT (adding a new file w/o makinging it visible within the workspace\n   (codeline) containing all the VCR's) I have to perform an explicit\ncheckout\n   to the version-controlled collection that's to contain this file.\n\nYes.\n\n   After that\n   I perform the PUT on the working collection.\n\nYes.\n\n   And not before checkin there is\n   the newly added file visible in the workspace.\n\nYes.\n\n   By the way a new baseline of\n   the baseline-controlled workspace is created (because of the change of\nthe\n   DAV:checked-in property of the version-controlled collection)?\n\nYes, if you have DAV:auto-version appropriately set on the\nDAV:version-controlled-configuration of the workspace\n(e.g. DAV:checkout-checkin).\n\n   2. Every namespace operation (DELETE, MOVE, COPY) and only they (except\nfor\n   MKCOL see 5.) would cause an auto-checkout if auto-version is set to\n   DAV:checkout behavior?\n\nAuto-checkout only occurs for in-place checkouts (there is\nno way to specify a DAV:apply-to-version flag for an auto-checkout).\nAuto-checkout is primarily for versioning unaware clients,\nand this means that the result of auto-checkout must be something\nthat makes sense to a versioning unaware client (and leaving the\nresource unchanged while returning a working collection containing\nthe change is *definitely* not something that would make sense\nto a versioning unaware client).\n\n   3. In case 2. is true: Is there a way to give an activity the\n   created working-collection will be bound to? Maybe I just give the\n   DAV:activity-set tag in the body?\n\nThis only applies to \"in-place\" checkouts, but currently the\nonly interoperable way of setting the activity for auto-checkout\nis through the DAV:current-activity-set of the workspace.\nIf your client wants greater control on the activity, it either\nneeds to do explicit CHECKOUT's, or needs to adjust the DAV:activity\nvalue once the auto-checkout has occurred.\n\n   4. A non-version-controlled resource MUST be created within the\n   version-controlled collection itself instead of creating it within\n   the working collection?\n\nYes.  All non-version-controlled members of a working collection\nare put under version control when that working collection is\nchecked in.\n\n   5. As I come to think of it: MKCOL will not cause an\n   working-collection to be created when performed on a\n   version-controlled collection, will it?  Because at MKCOL it is not\n   clear wether the created collection will be under version-control\n   (if no auto-version-control behavior is implemented). Or more\n   precise: MKCOL creates non-version-controlled collections (if no\n   auto-version-control behavior is implemented)?\n\nCorrect.\n\n   6. What about Request that deal with two version-controlled\n   collections as for example MOVE. With an auto-version =\n   DAV:checkout both collections have to be checked out, two working\n   collections are created. The source collection working-collection\n   will get rid of the binding of the moved out resource. The\n   destination collection working-collection will add a new binding\n   for the moved in resource. But now I'm free to check in the source\n   collection working-collection, so the binding there is gone with\n   the wind.  And I delete the destination collection\n   working-collection, so the new binding is not added. The result is\n   inconsistent, its a half way done MOVE!  Is there anything to\n   prevent this?\n\nNote that auto-versioning does not occur with working resources.\nBut your question is still valid, when applied to explicitly\ncreated working collections (all working collections must be\nexplicitly created by CHECKOUT).\n\nA \"partial-MOVE\" is the same as a DELETE.  If that what a client tells\nthe server to do, the server must do it.  Similarly, there is no way\nfor a server to tell when a client issues a DELETE when it meant to\nissue a MOVE.  If a client has a bug and sends the wrong requests\nto the server, there's not much a server can do about it.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2190946"}, {"subject": "RE: Version-controlled collection CHECKOU", "content": "Yes.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Wednesday, January 16, 2002 8:36 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Version-controlled collection CHECKOUT\n\n\nHi,\n\ndoes the checkout behavior of a version-controlled collection be the same as\nthe checkout behavior of a version-controlled resource with\nDAV:apply-to-version flag? (Because of working-collection sounds similar to\nworking-resource) \nIs there the same behavior for parallel development (parallel checkouts,\ncheckin behavior) as for working-resources?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2203026"}, {"subject": "Problems with Delete of a version-controlled collectio", "content": "Hi,\n\nsuppose this:\n\n/foo\n        |\n        +- /bar\n             |\n             +- foobar.c\n\nall the resources are under version-control. Now suppose this sequence of\nrequests:\n\nCHECKOUT /foo/bar\n  DAV:apply-to-version\n\n(working-collection: /wc/wc1  auto-update: /foo/bar)\n\nCHECKOUT /foo\n  DAV:apply-to-version\n\n(working-collection: /wc/wc2, auto-update: /foo)\n\ndelete folder /foo/bar:\nDELETE /wc/wc2/bar   \nor is it done via the real VCR? I hope not! The DELETE should be hidden\nuntil checkin!\n\nCHECKIN /wc/wc2\n(applied to /foo -> the folder /bar and all its content is gone)\n\nCHECKIN /wc/wc1\n(must fail because the VCR the auto-update should go to is gone)\n\n\nQuestions:\n1. Is this right?\n2. If yes: Shouldn't the deletion be prevented or fail because a subfolder\nis checked out and therefore some kind of \"locked\"?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2211098"}, {"subject": "RE: Problems with Delete of a version-controlled collectio", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   suppose this:\n\n   /foo\n   |\n   +- /bar\n|\n+- foobar.c\n\n   all the resources are under version-control. Now suppose this\n   sequence of requests:\n\n   CHECKOUT /foo/bar\n     DAV:apply-to-version\n\n   (working-collection: /wc/wc1  auto-update: /foo/bar)\n\n   CHECKOUT /foo\n     DAV:apply-to-version\n\n   (working-collection: /wc/wc2, auto-update: /foo)\n\n   delete folder /foo/bar:\n   DELETE /wc/wc2/bar   \n   or is it done via the real VCR? I hope not! The DELETE should be hidden\n   until checkin!\n\nYou are correct.  The DELETE should be done to the working collection,\nas you show here.\n\n   CHECKIN /wc/wc2\n   (applied to /foo -> the folder /bar and all its content is gone)\n\n   CHECKIN /wc/wc1\n   (must fail because the VCR the auto-update should go to is gone)\n\nThat depends on the server.  A server could just delete the\nauto-update property when the VCR referenced by that property\nis deleted, and allow the CHECKIN of /wc/wc1 to succeed.\nYou haven't really \"lost\" anything, because this version is\nnow available in the version history that is associated with\n/wc/wc1.\n\n   Questions:\n   1. Is this right?\n   2. If yes: Shouldn't the deletion be prevented or fail because a\nsubfolder\n   is checked out and therefore some kind of \"locked\"?\n\nA server certainly could fail the CHECKIN of /wc/wc2 for this reason,\nbut that would have to be a server-defined precondition (i.e. this\nCHECKIN is not forbidden by any of the standard preconditions).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2220104"}, {"subject": "Slide Client AP", "content": "Hi !\n\nHas anyone ever used the Slide Client API ?\nDo you know if there is some implementation examples anywhere on the Web ?\n\nThanx\n\n\n\n", "id": "lists-007-2229362"}, {"subject": "FW: Problems with Delete of a version-controlled collectio", "content": "-----Original Message-----\nFrom: Kirmse, Daniel \nSent: Donnerstag, 17. Januar 2002 17:19\nTo: 'Clemm, Geoff'\nSubject: RE: Problems with Delete of a version-controlled collection\n\n\n\n\n>-----Original Message-----\n>From: Clemm, Geoff [mailto:gclemm@rational.com]\n>Sent: Mittwoch, 16. Januar 2002 17:50\n>To: Ietf-Dav-Versioning (E-mail)\n>Subject: RE: Problems with Delete of a version-controlled collection\n>\n>\n>\n>   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n>\n>   suppose this:\n>\n>   /foo\n>   |\n>   +- /bar\n>|\n>+- foobar.c\n>\n>   all the resources are under version-control. Now suppose this\n>   sequence of requests:\n>\n>   CHECKOUT /foo/bar\n>     DAV:apply-to-version\n>\n>   (working-collection: /wc/wc1  auto-update: /foo/bar)\n>\n>   CHECKOUT /foo\n>     DAV:apply-to-version\n>\n>   (working-collection: /wc/wc2, auto-update: /foo)\n>\n>   delete folder /foo/bar:\n>   DELETE /wc/wc2/bar   \n>   or is it done via the real VCR? I hope not! The DELETE \n>should be hidden\n>   until checkin!\n>\n>You are correct.  The DELETE should be done to the working collection,\n>as you show here.\n>\n>   CHECKIN /wc/wc2\n>   (applied to /foo -> the folder /bar and all its content is gone)\n>\n>   CHECKIN /wc/wc1\n>   (must fail because the VCR the auto-update should go to is gone)\n>\n>That depends on the server.  A server could just delete the\n>auto-update property when the VCR referenced by that property\n>is deleted, and allow the CHECKIN of /wc/wc1 to succeed.\n>You haven't really \"lost\" anything, because this version is\n>now available in the version history that is associated with\n>/wc/wc1.\n\n---->\nSo the VCR of /foo/bar is still gone (even so the VCR of /foo/bar/foobar.c)\nbut the version-hsitory of it would contain a new version created by the\nlast checkin.\nHmmm. What if the deleted VCR was the last one pointing to this\nversion-history? Is there a way of creating a new VCR pointing to a existing\nVH? Rolling back the delete would be an option too, I think.\n--->\n\n>\n>   Questions:\n>   1. Is this right?\n>   2. If yes: Shouldn't the deletion be prevented or fail because a\n>subfolder\n>   is checked out and therefore some kind of \"locked\"?\n>\n>A server certainly could fail the CHECKIN of /wc/wc2 for this reason,\n>but that would have to be a server-defined precondition (i.e. this\n>CHECKIN is not forbidden by any of the standard preconditions).\n>\n>Cheers,\n>Geoff\n>\n\n\n\n", "id": "lists-007-2236673"}, {"subject": "Re: FW: Problems with Delete of a version-controlled collectio", "content": ">  <<snip>>\n> ---->\n> So the VCR of /foo/bar is still gone (even so the VCR of\n> /foo/bar/foobar.c) but the version-hsitory of it would\n> contain a new version created by the last checkin.\n> Hmmm. What if the deleted VCR was the last one pointing\n> to this version-history? Is there a way of creating a new\n> VCR pointing to a existing VH? Rolling back the delete\n> would be an option too, I think.\n> --->\n\nUse VERSION-CONTROL with a DAV:version body(*) to create a new\nversion-controlled resource on an existing version.  Don't know how you\nwould `roll-back` a DELETE though ;-)\n\n(*) I'm pretty sure that is what it is called, but I don't have the spec in\nfront of me at the moment.\n> <<snip>>\n\n\n\n", "id": "lists-007-2247706"}, {"subject": "RE: Problems with Delete of a version-controlled collectio", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   >From: Clemm, Geoff [mailto:gclemm@rational.com]\n   >   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n   >\n   >   suppose this:\n   >\n   >   /foo\n   >   |\n   >   +- /bar\n   >|\n   >+- foobar.c\n   >\n   >   all the resources are under version-control. Now suppose this\n   >   sequence of requests:\n   >\n   >   CHECKOUT /foo/bar\n   >     DAV:apply-to-version\n   >\n   >   (working-collection: /wc/wc1  auto-update: /foo/bar)\n   >\n   >   CHECKOUT /foo\n   >     DAV:apply-to-version\n   >\n   >   (working-collection: /wc/wc2, auto-update: /foo)\n   >\n   >   delete folder /foo/bar:\n   >   DELETE /wc/wc2/bar   \n   >\n   >   CHECKIN /wc/wc2\n   >   (applied to /foo -> the folder /bar and all its content is gone)\n   >\n   >   CHECKIN /wc/wc1\n\n   >You haven't\n   >really \"lost\" anything, because this version is now available in\n   >the version history that is associated with /wc/wc1.\n\n   So the VCR of /foo/bar is still gone (even so the VCR of\n   /foo/bar/foobar.c) but the version-history of it would contain a\n   new version created by the last checkin.\n\nYes.\n\n   Hmmm. What if the deleted VCR was the last one pointing to this\n   version-history?\n\nThe earlier version of the folder /foo (the one visible before the\nCHECKIN of /wc/wc2) will still contain a reference to that version\nhistory (in its DAV:version-controlled-binding-set property).\n\n   Is there a way of creating a new VCR pointing to a existing\n   VH? Rolling back the delete would be an option too, I think.\n\nYes, you would just UPDATE /foo to the earlier version (before the\nCHECKIN of /wc/wc2), which would recreate a VCR named /foo/bar, and\nyou can then UPDATE /foo/bar to select the version that was created\nby the CHECKIN of /wc/wc1.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2256074"}, {"subject": "RE: Problems with Delete of a version-controlled collectio", "content": ">-----Original Message-----\n>From: Clemm, Geoff [mailto:gclemm@rational.com]\n>Sent: Freitag, 18. Januar 2002 04:49\n>To: Ietf-Dav-Versioning (E-mail)\n>Subject: RE: Problems with Delete of a version-controlled collection\n>\n>\n>   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n>\n>   >From: Clemm, Geoff [mailto:gclemm@rational.com]\n>   >   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n>   >\n>   >   suppose this:\n>   >\n>   >   /foo\n>   >   |\n>   >   +- /bar\n>   >|\n>   >+- foobar.c\n>   >\n>   >   all the resources are under version-control. Now suppose this\n>   >   sequence of requests:\n>   >\n>   >   CHECKOUT /foo/bar\n>   >     DAV:apply-to-version\n>   >\n>   >   (working-collection: /wc/wc1  auto-update: /foo/bar)\n>   >\n>   >   CHECKOUT /foo\n>   >     DAV:apply-to-version\n>   >\n>   >   (working-collection: /wc/wc2, auto-update: /foo)\n>   >\n>   >   delete folder /foo/bar:\n>   >   DELETE /wc/wc2/bar   \n>   >\n>   >   CHECKIN /wc/wc2\n>   >   (applied to /foo -> the folder /bar and all its content is gone)\n>   >\n>   >   CHECKIN /wc/wc1\n>\n>   >You haven't\n>   >really \"lost\" anything, because this version is now available in\n>   >the version history that is associated with /wc/wc1.\n>\n>   So the VCR of /foo/bar is still gone (even so the VCR of\n>   /foo/bar/foobar.c) but the version-history of it would contain a\n>   new version created by the last checkin.\n>\n>Yes.\n>\n>   Hmmm. What if the deleted VCR was the last one pointing to this\n>   version-history?\n>\n>The earlier version of the folder /foo (the one visible before the\n>CHECKIN of /wc/wc2) will still contain a reference to that version\n>history (in its DAV:version-controlled-binding-set property).\n>\n>   Is there a way of creating a new VCR pointing to a existing\n>   VH? Rolling back the delete would be an option too, I think.\n>\n>Yes, you would just UPDATE /foo to the earlier version (before the\n>CHECKIN of /wc/wc2), which would recreate a VCR named /foo/bar, and\n>you can then UPDATE /foo/bar to select the version that was created\n>by the CHECKIN of /wc/wc1.\n>\n>Cheers,\n>Geoff\n>\n\nSo there is a reasonable use case for UPDATE finally. ;o)\n\nThanks,\nDaniel\n\nP.S.:\nBy the way: My experience with the DeltaV Spec is that many people have\nproblems to actually understand what can be done using DeltaV. In my\noppinion it is mainly a misunderstanding. Most people I talked to to \"sell\"\nDeltaV expect the spec to describe how the can use DeltaV to have some\nversioning done. They wish to have more examples, even the not so simple\nones, provided with the spec. (I for myself did to!) Sure it is not the task\nof a spec to explain use cases. It would puff up the whole thing. But what\nabout the Szenarios document that is on the DeltaV Homepage? This would be\nthe right place for such use cases or best practices. Why isn't this pursued\nanymore?\n\n\nP.P.S:\nAn answer to Tim: I will eventually put all my \"a ha\"'s on the FAQ (so I\nhave an archive for my questions ;o) ). But it will take some time (I have\nto find a time slot to do this reasonably).\n\n\n\n", "id": "lists-007-2266363"}, {"subject": "RE: Problems with Delete of a version-controlled collectio", "content": "Yes, a scenarios document is badly needed.  Anyone who is willing to start\nsuch a document will be doing a valuable service.\n\nCurrently, most of the time available to the designers of the DeltaV\nprotocol for standards-related work is focused on getting the Java\nbinding to DeltaV defined (WVCM: JSR-147),\nbut when we get that done, I hope to have some subset of us focused on\nthe scenarios document.  It would be great if we could do both,\nbut realistically, we all have \"real jobs\" that we need to spend at\nleast some of our time doing (:-).\n\nUntil then, please keep those scenario questions coming to the mailing\nlist, since that makes the email archive a significant source of\ninformation,\nand is likely to find its way into both the FAQ and the scenarios document.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Friday, January 18, 2002 3:36 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Problems with Delete of a version-controlled collection\n\n\n\nBy the way: My experience with the DeltaV Spec is that many people have\nproblems to actually understand what can be done using DeltaV. In my\noppinion it is mainly a misunderstanding. Most people I talked to to \"sell\"\nDeltaV expect the spec to describe how the can use DeltaV to have some\nversioning done. They wish to have more examples, even the not so simple\nones, provided with the spec. (I for myself did to!) Sure it is not the task\nof a spec to explain use cases. It would puff up the whole thing. But what\nabout the Szenarios document that is on the DeltaV Homepage? This would be\nthe right place for such use cases or best practices. Why isn't this pursued\nanymore?\n\n\nP.P.S:\nAn answer to Tim: I will eventually put all my \"a ha\"'s on the FAQ (so I\nhave an archive for my questions ;o) ). But it will take some time (I have\nto find a time slot to do this reasonably).\n\n\n\n", "id": "lists-007-2278611"}, {"subject": "RE: Adding a new file to an activit", "content": "I agree with all of Tim's responses in this message except for\nthe following;\n\n   From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n\n   \"Kirmse, Daniel\" <daniel.kirmse@sap.com> wrote:\n\n   > As I come to think of it: MKCOL will not cause an\n   > working-collection to be created when performed on a\n   > version-controlled collection, will it?  Because at MKCOL it is\n   > not clear wether the created collection will be under\n   > version-control (if no auto-version-control behavior is\n   > implemented). Or more precise: MKCOL creates\n   > non-version-controlled collections (if no auto-version-control\n   > behavior is implemented)?\n\n   although the new collection will not be version-controlled, the\n   parent of the new collection will have been modified to add the new\n   internal member name, so it much be checked-out (automatically or\n   otherwise).  Inthis respect, there is no difference between a MKCOL\n   and a PUT, DELETE, etc.\n\nNo, only the addition/removal of a version-controlled internal\nmember requires the version-controlled collection to be checked out.\nIn particular, quoting from section 14:\n\n \"Non-version-controlled bindings are not under version control, and\n therefore can be added or deleted without checking out the\n version-controlled collection.\"\n\nSo you do not need to checkout a version-controlled collection in\norder to use PUT and MKCOL to create new non-version-controlled\nresources in that collection, or use DELETE to delete\nnon-version-controlled resources from that collection.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2287961"}, {"subject": "DAV:workspace of a VCC", "content": "For a workspace's DAV:baseline-controlled-collection-set,\nfor their DAV:version-controlled-configurations, \nis their DAV:workspace property value required to be \nthe same as the workspace?\n\nI am thinking it is not required, because 6.2.1 says\n\n  The DAV:workspace property of a workspace resource MUST identify\n  itself.  The DAV:workspace property of any other type of resource\n  MUST be the same as the DAV:workspace of its parent collection.\n\nand I can't find a requirement that a VCCn must be a member \nof its associated workspace.\n\nIs my understanding correct?\n\nThanks,\nRoy\n\n\n\n", "id": "lists-007-2296780"}, {"subject": "RE: workspace of a VCC", "content": "   From: Roy Seto [mailto:Roy.Seto@oracle.com]\n\n   For a workspace's DAV:baseline-controlled-collection-set,\n   for their DAV:version-controlled-configurations, \n   is their DAV:workspace property value required to be \n   the same as the workspace?\n\n   I am thinking it is not required, because 6.2.1 says\n\n     The DAV:workspace property of a workspace resource MUST identify\n     itself.  The DAV:workspace property of any other type of resource\n     MUST be the same as the DAV:workspace of its parent collection.\n\n   and I can't find a requirement that a VCCn must be a member \n   of its associated workspace.\n\n   Is my understanding correct?\n\nYes, that is correct.  Commonly, a VCCn will not be a member of\nits associated workspace.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2304192"}, {"subject": "DAV:version-tree REPORT on non-version-controlled resourc", "content": "Hi,\n\nwhat would be the expected response code for a DAV:version-tree report on a resource which is not version controlled? Bad Request?\n\nJulian\n\n\n\n", "id": "lists-007-2311571"}, {"subject": "RE: version-tree REPORT on non-version-controlled resourc", "content": "No, not \"400:Conflict.\n\nEither \"409: Conflict\" if the resource could be put under version control,\nor \"403: Forbidden\" if the resource cannot be put under version control.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Wednesday, January 23, 2002 11:30 AM\nTo: ietf-dav-versioning@w3.org\nSubject: DAV:version-tree REPORT on non-version-controlled resource\n\n\nHi,\n\nwhat would be the expected response code for a DAV:version-tree report on a\nresource which is not version controlled? Bad Request?\n\nJulian\n\n\n\n", "id": "lists-007-2318771"}, {"subject": "RE: version-tree REPORT on non-version-controlled resourc", "content": "OK,\n\nthis make sense.\n\nThe spec could be a bit clearer, though :-)\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Wednesday, January 23, 2002 6:43 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: version-tree REPORT on non-version-controlled resource\n> \n> \n> No, not \"400:Conflict.\n> \n> Either \"409: Conflict\" if the resource could be put under version control,\n> or \"403: Forbidden\" if the resource cannot be put under version control.\n> \n> Cheers,\n> Geoff\n> \n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Wednesday, January 23, 2002 11:30 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: DAV:version-tree REPORT on non-version-controlled resource\n> \n> \n> Hi,\n> \n> what would be the expected response code for a DAV:version-tree \n> report on a\n> resource which is not version controlled? Bad Request?\n> \n> Julian\n> \n> \n> \n\n\n\n", "id": "lists-007-2327648"}, {"subject": "RE: version-tree REPORT on non-version-controlled resourc", "content": "The meaning of these error codes is defined by 2616,\nand the DeltaV spec makes a point of not repeating information from\nthe base spec (so that we automatically inherit any\nlater revision of 2616, rather than conflict with it).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Wednesday, January 23, 2002 12:47 PM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: version-tree REPORT on non-version-controlled resource\n\n\nOK,\n\nthis make sense.\n\nThe spec could be a bit clearer, though :-)\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Wednesday, January 23, 2002 6:43 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: version-tree REPORT on non-version-controlled resource\n> \n> \n> No, not \"400:Conflict.\n> \n> Either \"409: Conflict\" if the resource could be put under version control,\n> or \"403: Forbidden\" if the resource cannot be put under version control.\n> \n> Cheers,\n> Geoff\n> \n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Wednesday, January 23, 2002 11:30 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: DAV:version-tree REPORT on non-version-controlled resource\n> \n> \n> Hi,\n> \n> what would be the expected response code for a DAV:version-tree \n> report on a\n> resource which is not version controlled? Bad Request?\n> \n> Julian\n> \n> \n> \n\n\n\n", "id": "lists-007-2338127"}, {"subject": "RE: version-tree REPORT on non-version-controlled resourc", "content": "Geoff,\n\nno offense intended.\n\nI think it would be clearer if the status (being a VCR or a version) would explicitly be listed as precondition.\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Wednesday, January 23, 2002 6:55 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: version-tree REPORT on non-version-controlled resource\n> \n> \n> The meaning of these error codes is defined by 2616,\n> and the DeltaV spec makes a point of not repeating information from\n> the base spec (so that we automatically inherit any\n> later revision of 2616, rather than conflict with it).\n> \n> Cheers,\n> Geoff\n> \n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Wednesday, January 23, 2002 12:47 PM\n> To: Clemm, Geoff; ietf-dav-versioning@w3.org\n> Subject: RE: version-tree REPORT on non-version-controlled resource\n> \n> \n> OK,\n> \n> this make sense.\n> \n> The spec could be a bit clearer, though :-)\n> \n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Wednesday, January 23, 2002 6:43 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: RE: version-tree REPORT on non-version-controlled resource\n> > \n> > \n> > No, not \"400:Conflict.\n> > \n> > Either \"409: Conflict\" if the resource could be put under \n> version control,\n> > or \"403: Forbidden\" if the resource cannot be put under version control.\n> > \n> > Cheers,\n> > Geoff\n> > \n> > -----Original Message-----\n> > From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> > Sent: Wednesday, January 23, 2002 11:30 AM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: DAV:version-tree REPORT on non-version-controlled resource\n> > \n> > \n> > Hi,\n> > \n> > what would be the expected response code for a DAV:version-tree \n> > report on a\n> > resource which is not version controlled? Bad Request?\n> > \n> > Julian\n> > \n> > \n> > \n> \n> \n\n\n\n", "id": "lists-007-2349446"}, {"subject": "RE: version-tree REPORT on non-version-controlled resourc", "content": "No offense taken!\n(Sorry if I sounded offended ... I didn't feel offended :-).\n\nBut I'm glad that you followed up, because that saves me from\nhaving to follow up my own post (which I hate to do :-).\n\nIn particular, I was going to add that in addition to the 403/409,\nyou should have \n  <DAV:error> <DAV:supported-report/> </DAV:error>\nin the response body or DAV:responsedescription.  (See section 3.6).\n\nWe didn't want to have \"must be version or VCR\" in the precondition\nfor the DAV:version-tree report, to allow future extensions to allow\nthis report on other kinds of resources.\n\nCheers,\nGeoff \n\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Wednesday, January 23, 2002 1:31 PM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: version-tree REPORT on non-version-controlled resource\n\n\nGeoff,\n\nno offense intended.\n\nI think it would be clearer if the status (being a VCR or a version) would\nexplicitly be listed as precondition.\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Wednesday, January 23, 2002 6:55 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: version-tree REPORT on non-version-controlled resource\n> \n> \n> The meaning of these error codes is defined by 2616,\n> and the DeltaV spec makes a point of not repeating information from\n> the base spec (so that we automatically inherit any\n> later revision of 2616, rather than conflict with it).\n> \n> Cheers,\n> Geoff\n> \n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Wednesday, January 23, 2002 12:47 PM\n> To: Clemm, Geoff; ietf-dav-versioning@w3.org\n> Subject: RE: version-tree REPORT on non-version-controlled resource\n> \n> \n> OK,\n> \n> this make sense.\n> \n> The spec could be a bit clearer, though :-)\n> \n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Wednesday, January 23, 2002 6:43 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: RE: version-tree REPORT on non-version-controlled resource\n> > \n> > \n> > No, not \"400:Conflict.\n> > \n> > Either \"409: Conflict\" if the resource could be put under \n> version control,\n> > or \"403: Forbidden\" if the resource cannot be put under version control.\n> > \n> > Cheers,\n> > Geoff\n> > \n> > -----Original Message-----\n> > From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> > Sent: Wednesday, January 23, 2002 11:30 AM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: DAV:version-tree REPORT on non-version-controlled resource\n> > \n> > \n> > Hi,\n> > \n> > what would be the expected response code for a DAV:version-tree \n> > report on a\n> > resource which is not version controlled? Bad Request?\n> > \n> > Julian\n> > \n> > \n> > \n> \n> \n\n\n\n", "id": "lists-007-2362684"}, {"subject": "Editorial question for Section 11.", "content": "The marshalling for the DAV:merge-preview report in 11.3 says the response body must be a DAV:merge-preview-response XML element. But the example in 11.3.1 has a DAV:merge-preview-report XML element instead. Which is correct?\n\nThanks,\nRoy\n\n\n\n", "id": "lists-007-2376468"}, {"subject": "Typo in Section 5.4.1", "content": "The example request body for the DAV:locate-by-history report in 5.4.1 contains an empty DAV:version-history element inside the DAV:prop element. This empty element is \n\n  </D:version-history>\n\nin the text. Should it be <D:version-history/> instead?\n\nRoy\n\n\n\n", "id": "lists-007-2383643"}, {"subject": "RE: Editorial question for Section 11.", "content": "The example is right, it should be DAV:merge-preview-report.\nI'll fix that in the final editing pass.\n\nThanks for noticing and reporting this!\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Roy Seto [mailto:Roy.Seto@oracle.com]\nSent: Wednesday, January 23, 2002 4:41 PM\nTo: ietf-dav-versioning@w3.org\nSubject: Editorial question for Section 11.3\n\n\nThe marshalling for the DAV:merge-preview report in 11.3 says the response\nbody must be a DAV:merge-preview-response XML element. But the example in\n11.3.1 has a DAV:merge-preview-report XML element instead. Which is correct?\n\nThanks,\nRoy\n\n\n\n", "id": "lists-007-2390697"}, {"subject": "RE: Typo in Section 5.4.1", "content": "It sure should!  Will fix.\nThanks again!\nGeoff\n\n-----Original Message-----\nFrom: Roy Seto [mailto:Roy.Seto@oracle.com]\nSent: Wednesday, January 23, 2002 4:46 PM\nTo: ietf-dav-versioning@w3.org\nSubject: Typo in Section 5.4.1?\n\n\nThe example request body for the DAV:locate-by-history report in 5.4.1\ncontains an empty DAV:version-history element inside the DAV:prop element.\nThis empty element is \n\n  </D:version-history>\n\nin the text. Should it be <D:version-history/> instead?\n\nRoy\n\n\n\n", "id": "lists-007-2398578"}, {"subject": "Response marshalling for activity checki", "content": "How should the response for an activity checkin (as defined by 13.11) be marshalled? \n\nShould the response code be 201 or 207? Should there be a Location header containing the URL for each new version resource created? Should the response body be a DAV:multistatus element with a DAV:href for each new version resource created?\n\nThanks,\nRoy\n\n\n\n", "id": "lists-007-2406516"}, {"subject": "Activity and logical chang", "content": "Hi !\n\nI read that in the DeltaV specifications : \n\"A common problem that motivates the use of activities is that it is often desirable to perform several different logical changes in a single workspace, and then selectively merge a subset of those logical changes to other workspaces. \"\n\n\n\nMaybe because I'm french, but I don't understand what \"logical change\" means : it has no sens to translate literally this expression.\n\nCan someone explain me it ?\n\nThanx\n\n\n\n", "id": "lists-007-2413975"}, {"subject": "Re: Activity and logical chang", "content": "\"Elodie Tasia\" <e.tasia@ever-team.com> wrote:\n> Hi !\n> \n> I read that in the DeltaV specifications : \n> \"A common problem that motivates the use of activities is that it is often\n> desirable to perform several different logical changes in a single \nworkspace,\n> and then selectively merge a subset of those logical changes to other\n> workspaces. \"\n>  \n> Maybe because I'm french, but I don't understand what \"logical change\" \nmeans\n> : it has no sens to translate literally this expression.\n> Can someone explain me it ?\n> Thanx\n\nHere 'logical' means that the change is associated with some work item -- \nfor example, fixing a bug or supporting a particular feature.  Activities \nallow the client to associate each changed resource with this 'work item' \nor 'task' so that they can be separately identified if required.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-2422015"}, {"subject": "Missing &lt;status&gt; elements from examples in the DeltaV specificati o", "content": "Hi,\n\nSection 12.9.1 of RFC2518 gives a DTD for the response element of\nmultistatus:\n\n<!ELEMENT response (href, ((href*, status)|(propstat+)),\nresponsedescription?) >\n\nBut in the examples in section 7.1.1 and 11.2.1 in the deltav specification\nwe have multistatus responses with <href> elements but no <status> or\n<propstat>\nelements.  These are invalid given the above DTD.\n\nSo, are the examples missing <status> elements or is the DTD wrong and\nshould we\nallow responses without status and assume 200 OK?\n\nRegards,\n--\nPeter Raymond - MERANT\nPrincipal Architect (PVCS)\nTel: +44 (0)1727 813362\nFax: +44 (0)1727 869804\nmailto:Peter.Raymond@merant.com\nWWW: http://www.merant.com\n\n\n\n", "id": "lists-007-2430688"}, {"subject": "RE: Activity and logical chang", "content": "And now for the French version of my response.....\n\nBonjour,\n\nJ'essayerai d'expliquer ceci ? vous\n\nUn \"changement logique \" signifie que plusieurs fichiers sont modifi?s pour\nmettre en place un \"fixe\" simple ou une demande de ?volution. Ainsi\nimaginons que un developeur a ?t? invit? ? changer l'arrangement de couleur\nd'un page Web. Il doit changer le HTML et modifier les couleurs mais\n?galement doit modifier quelques images de GIF employ?es ? la page pour\nchanger leurs couleurs. Donc, Il modifie beaucoup de fichiers mais fait\nc'est un \" changement logique \".\n\nDans la m?me ?space de travail de DeltaV un autre developeur a ?t? invit? ?\nchanger un prix d'un ?l?ment qui est annonc? pour la vente sur le website. l\ndoit changer plusieurs morceaux de HTML dans diff?rentes trames pour mettre\n? jour le prix. Ceci aet un autre \" changement logique \".\n\nUn chef de projet peut d?cider de commencer une nouvelle ?space de travail\npour quelques autres mises ? jour au site Web, par example, Il voudrait\ninclure la mise ? jour des prix mais de pas inclure le changement de\ncouleur. Si des activit?s sont employ?es pour d?pister les deux changements\nci-dessus il peut employer l'activit? pour fusionner seulement le changement\nd?sir? dans sa nouvelle ?space de travail.\n\nJ'esp?re que ceci vous aide ? comprendre.\n\nCordialement,\n\nPeter Raymond\n\n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com <mailto:Peter.Raymond@merant.com>  \nWWW: http://www.merant.com <http://www.merant.com/>  \n\n-----Original Message-----\nFrom: Elodie Tasia [mailto:e.tasia@ever-team.com]\nSent: 24 January 2002 07:54\nTo: WebDAV Group; IETF DAV\nSubject: Activity and logical change\n\n\nHi !\n \nI read that in the DeltaV specifications : \n\n\"A common problem that motivates the use of activities is that it is often\ndesirable to perform several different logical changes in a single\nworkspace, and then selectively merge a subset of those logical changes to\nother workspaces. \"\n\n \n\nMaybe because I'm french, but I don't understand what \"logical change\" means\n: it has no sens to translate literally this expression.\n\nCan someone explain me it ?\n\nThanx\n\n\n\n", "id": "lists-007-2439783"}, {"subject": "RE: Activity and logical chang", "content": "Hi,\n\nI will try to give a explanation.....\n\nA \"logical change\" is one where several files are modified to implement a\nsingle fix or \nenhancement request.\n\nSo let's imagine a developer has been asked to change the color scheme of a\nweb page.  \nHe has to change the HTML and modify the colors but also has to modify some\nGIF images \nused on the page to change their colors.  He is modifying many files but is\nmaking one \n\"logical change\".\n\nIn the same DeltaV workspace another developer has been asked to change a\nprice for an \nitem that is being advertised for sale on the website.  He needs to change\nseveral pieces \nof HTML in different frames to update the price.  This is another \"logical\nchange\".\n\nA project manager may decide to start a new workspace for some further\nupdates to the web \nsite, he wants to include the price update but does not want to include the\ncolor change.  \nIf activities are used to track the above two changes he can use the\nactivity to merge \nonly the desired change into his new workspace.\n\nHope this helps.\n\nRegards,\n--\nPeter Raymond - MERANT\nPrincipal Architect (PVCS)\nTel: +44 (0)1727 813362\nFax: +44 (0)1727 869804\nmailto:Peter.Raymond@merant.com\nWWW: http://www.merant.com\n\n\n\n", "id": "lists-007-2450819"}, {"subject": "Re: Response marshalling for activity checki", "content": "\"Roy Seto\" <Roy.Seto@oracle.com> wrote:\n\n> How should the response for an activity checkin (as defined by\n> 13.11) be marshalled? \n> \n> Should the response code be 201 or 207? Should there be a Location\n> header containing the URL for each new version resource created?\n> Should the response body be a DAV:multistatus element with a\n> DAV:href for each new version resource created?\n> \n> Thanks,\n> Roy\n\nWell it isn't defined, so I guess it can be whatever you like<g>.\nThe only requirement is that:\n\"If a response body is included, it MUST be a DAV:checkin-response\nXML element.\n    <!ELEMENT checkin-response ANY>\"\n\nThe method is being applied to a single resource (the activity) with no \ndepth implications, so a 207 does not 'feel' right.  I realize that there \nare multiple resources affected, but would expect problems with them to be \nmarshalled in the error response element.\n\nSo if all is well, return '201 Created'.\nI wouldn't return multiple Location: headers.  How would you know which \nchecked-out resource led to which location?\n\nIf there are checkin failures, you could return something like\n409 Conflict\n\n<DAV:checkin-response>\n  <DAV:checkin-activity/>\n  <DAV:multi-status>\n    <DAV:...\n  </DAV:multi-status>\n</DAV:checkin-response>\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-2459797"}, {"subject": "Re: Missing &lt;status&gt; elements from examples in the DeltaV specificati o", "content": "The examples should be updated.\nThere is no good reason to depart from that DTD.\n\nRegards,\n\nTim Ellison\nJava Technology Centre, MP146\nIBM UK Laboratory, Hursley Park, Winchester, UK. SO21 2JN\ntel: +44 (0)1962 819872  internal: 249872  MOBx: 270452\n\n\n\n\nPeter Raymond <Peter.Raymond@merant.com>\nSent by: ietf-dav-versioning-request@w3.org\n2002-01-24 09:59\n\n \n        To:     ietf-dav-versioning@w3.org\n        cc:     w3c-dist-auth@w3c.org\n        Subject:        Missing <status> elements from examples in the DeltaV specificati       on\n\n \n\nHi, \nSection 12.9.1 of RFC2518 gives a DTD for the response element of \nmultistatus: \n<!ELEMENT response (href, ((href*, status)|(propstat+)), \nresponsedescription?) > \nBut in the examples in section 7.1.1 and 11.2.1 in the deltav \nspecification \nwe have multistatus responses with <href> elements but no <status> or \n<propstat> \nelements.  These are invalid given the above DTD. \nSo, are the examples missing <status> elements or is the DTD wrong and \nshould we \nallow responses without status and assume 200 OK? \nRegards, \n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n\n\n\n", "id": "lists-007-2468790"}, {"subject": "RE: Activity and logical chang", "content": "Hi,\n\nI will try to give a explanation.....\n\nA \"logical change\" is one where several files are modified to implement a\nsingle fix or \nenhancement request.\n\nSo let's imagine a developer has been asked to change the color scheme of a\nweb page.  \nHe has to change the HTML and modify the colors but also has to modify some\nGIF images \nused on the page to change their colors.  He is modifying many files but is\nmaking one \n\"logical change\".\n\nIn the same DeltaV workspace another developer has been asked to change a\nprice for an \nitem that is being advertised for sale on the website.  He needs to change\nseveral pieces \nof HTML in different frames to update the price.  This is another \"logical\nchange\".\n\nA project manager may decide to start a new workspace for some further\nupdates to the web \nsite, he wants to include the price update but does not want to include the\ncolor change.  \nIf activities are used to track the above two changes he can use the\nactivity to merge \nonly the desired change into his new workspace.\n\nHope this helps.\n\nRegards,\n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n-----Original Message-----\nFrom: Elodie Tasia [mailto:e.tasia@ever-team.com]\nSent: 24 January 2002 07:54\nTo: WebDAV Group; IETF DAV\nSubject: Activity and logical change\n\n\nHi !\n\nI read that in the DeltaV specifications : \n\"A common problem that motivates the use of activities is that it is often\ndesirable to perform several different logical changes in a single\nworkspace, and then selectively merge a subset of those logical changes to\nother workspaces. \"\n\nMaybe because I'm french, but I don't understand what \"logical change\" means\n: it has no sens to translate literally this expression.\nCan someone explain me it ?\nThanx\n\n\n\n", "id": "lists-007-2480450"}, {"subject": "COPY, MOVE and VCR'", "content": "Hi,\n\nI wonder what happens when I copy or move a VCR? \nFor COPY I'd expect to got a new VCR at the destination with an exact copy\nof properties. This implies that the new created VCR must share the\nversion-history with the source VCR. Is this correct? Is this desireable?\nDefining this behavior as not expected by the user, I'd say COPY means\ncreation of a new version-history and copy of the checked-in version to that\nnew VH. With that the checked-in property of the copied VCR must change.\nSame for MOVE except for the deletion of the source. \n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2490503"}, {"subject": "RE: COPY, MOVE and VCR'", "content": "Hi,\n\n[Daniel said:]\n>For COPY I'd expect to got a new VCR at the destination with an exact copy\n>of properties. This implies that the new created VCR must share the\n>version-history with the source VCR. Is this correct? Is this desirable?\n\nI think this is desirable and correct but with one caveat...\n\nBoth in section 1.3 (where the workspace term is defined) and in section 6\nthe DeltaV specification says that you can only have one VCR for a given\nversion history in a workspace.  If copy created a new VCR but pointed to\nthe original VHR then this rule could be violated if the destination is in\nthe same workspace as the source of the copy.\nIf the copy does not break this rule then it would be fine to have two VCRs\npointing to the same version history.\n\nI certainly wouldn't have thought that moving a VCR would create a new\nhistory resource.\n \nRegards,\n--\nPeter Raymond - MERANT\nPrincipal Architect (PVCS)\nTel: +44 (0)1727 813362\nFax: +44 (0)1727 869804\nmailto:Peter.Raymond@merant.com\nWWW: http://www.merant.com\n\n\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: 24 January 2002 13:56\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: COPY, MOVE and VCR's\n\n\nHi,\n\nI wonder what happens when I copy or move a VCR? \nDefining this behavior as not expected by the user, I'd say COPY means\ncreation of a new version-history and copy of the checked-in version to that\nnew VH. With that the checked-in property of the copied VCR must change.\nSame for MOVE except for the deletion of the source. \n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2499045"}, {"subject": "RE: COPY, MOVE and VCR'", "content": "So my first assumption was right - except for workspaces\nThanks for clarification\nDaniel\n\n-----Original Message-----\nFrom: Peter Raymond [mailto:Peter.Raymond@merant.com]\nSent: Donnerstag, 24. Januar 2002 15:12\nTo: Kirmse, Daniel; Ietf-Dav-Versioning (E-mail)\nSubject: RE: COPY, MOVE and VCR's\n\n\n\nHi, \n\n[Daniel said:] \n>For COPY I'd expect to got a new VCR at the destination with an exact copy \n>of properties. This implies that the new created VCR must share the \n>version-history with the source VCR. Is this correct? Is this desirable? \n\nI think this is desirable and correct but with one caveat... \n\nBoth in section 1.3 (where the workspace term is defined) and in section 6 \nthe DeltaV specification says that you can only have one VCR for a given \nversion history in a workspace.  If copy created a new VCR but pointed to \nthe original VHR then this rule could be violated if the destination is in \nthe same workspace as the source of the copy. \nIf the copy does not break this rule then it would be fine to have two VCRs \npointing to the same version history. \n\nI certainly wouldn't have thought that moving a VCR would create a new \nhistory resource. \n  \nRegards, \n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com <mailto:Peter.Raymond@merant.com>  \nWWW: http://www.merant.com <http://www.merant.com>  \n\n\n\n-----Original Message----- \nFrom: Kirmse, Daniel [ mailto:daniel.kirmse@sap.com\n<mailto:daniel.kirmse@sap.com> ] \nSent: 24 January 2002 13:56 \nTo: Ietf-Dav-Versioning (E-mail) \nSubject: COPY, MOVE and VCR's \n\n\nHi, \n\nI wonder what happens when I copy or move a VCR? \nDefining this behavior as not expected by the user, I'd say COPY means \ncreation of a new version-history and copy of the checked-in version to that\n\nnew VH. With that the checked-in property of the copied VCR must change. \nSame for MOVE except for the deletion of the source. \n\nRegards, \nDaniel \n\n\n\n", "id": "lists-007-2508535"}, {"subject": "RE: COPY, MOVE and VCR'", "content": "Hi,\n\nIn my opinion yes, it makes sense to create a new VCR pointing to the\nexisting history if possible.\n\nSome server implementers may not want to copy version-controlled resources,\neg the result of\nthe copy would be a new non-version-controlled resource.  I think this is\nwhy the specification is\nvague about the results of copying a VCR.  Also note that in WebDAV (RFC2518\nsection 8.8.2) \nthe copying of the resources live properties is optional (eg some servers\nmay not copy the live \nproperties).\n\nRegards,\n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: 24 January 2002 14:20\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: COPY, MOVE and VCR's\n\n\nSo my first assumption was right - except for workspaces\nThanks for clarification\nDaniel\n-----Original Message-----\nFrom: Peter Raymond [mailto:Peter.Raymond@merant.com]\nSent: Donnerstag, 24. Januar 2002 15:12\nTo: Kirmse, Daniel; Ietf-Dav-Versioning (E-mail)\nSubject: RE: COPY, MOVE and VCR's\n\n\nHi, \n[Daniel said:] \n>For COPY I'd expect to got a new VCR at the destination with an exact copy \n>of properties. This implies that the new created VCR must share the \n>version-history with the source VCR. Is this correct? Is this desirable? \nI think this is desirable and correct but with one caveat... \nBoth in section 1.3 (where the workspace term is defined) and in section 6 \nthe DeltaV specification says that you can only have one VCR for a given \nversion history in a workspace.  If copy created a new VCR but pointed to \nthe original VHR then this rule could be violated if the destination is in \nthe same workspace as the source of the copy. \nIf the copy does not break this rule then it would be fine to have two VCRs \npointing to the same version history. \nI certainly wouldn't have thought that moving a VCR would create a new \nhistory resource. \n  \nRegards, \n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n\n\n\n-----Original Message----- \nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com] \nSent: 24 January 2002 13:56 \nTo: Ietf-Dav-Versioning (E-mail) \nSubject: COPY, MOVE and VCR's \n\n\nHi, \nI wonder what happens when I copy or move a VCR? \nDefining this behavior as not expected by the user, I'd say COPY means \ncreation of a new version-history and copy of the checked-in version to that\n\nnew VH. With that the checked-in property of the copied VCR must change. \nSame for MOVE except for the deletion of the source. \nRegards, \nDaniel \n\n\n\n", "id": "lists-007-2518989"}, {"subject": "Preventing a resource from being writte", "content": "Hi,\n\nSuppose that I want to prevent a resource from being modified, just read. And I use only what Webdav or ACL offers, not DeltaV.\nWhat can I do ?\nI can't set a infinite lock on that resource : it's \"dangerous\" and not nice ;o)\nI could use the access control protocol, maybe, but I don't know how to proceed : must I create juste one principal, that represent anyone, and has a \"read-only\" right ?\nWhat would be a good solution ?\n\nthanx\n\n\n\n", "id": "lists-007-2530558"}, {"subject": "RE: Preventing a resource from being writte", "content": "Hi,\n\nThe ACL specification defines a \"pseudo-principal\" called DAV:all this\nrepresents\nall users.  So you could set an ACL on all resources denying write to\nDAV:all.\nSomething that contains an ACE like....\n\n  <D:ace> \n    <D:principal> \n      <D:all/> \n    </D:principal> \n    <D:deny> \n    <D:privilege> <D:write/> </D:privilege>  \n    </D:deny> \n  </D:ace> \n\nRegards,\n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n-----Original Message-----\nFrom: Elodie Tasia [mailto:e.tasia@ever-team.com]\nSent: 24 January 2002 14:43\nTo: IETF DAV\nSubject: Preventing a resource from being written\n\n\nHi,\n\nSuppose that I want to prevent a resource from being modified, just read.\nAnd I use only what Webdav or ACL offers, not DeltaV.\nWhat can I do ?\nI can't set a infinite lock on that resource : it's \"dangerous\" and not nice\n;o)\nI could use the access control protocol, maybe, but I don't know how to\nproceed : must I create juste one principal, that represent anyone, and has\na \"read-only\" right ?\nWhat would be a good solution ?\n\nthanx\n\n\n\n", "id": "lists-007-2537996"}, {"subject": "LABEL compariso", "content": "Hi,\n\nthe spec says in chapter 8 [1]:\n\n\"...SHOULD use a case-sensitive octet-by-octet comparison of the two label\nnames.\"\n\nI think this must be \"character-by-character comparison\". The term \"octet\"\nisn't meaningful here because we have XML based marshalling.\n\nFurthermore, I'm not convinced that [2]:\n\n\"The value of a label header is the name of a label, encoded using UTF-8.\nFor example, the label \"release-2.0\" is identified by the following header:\"\n\nis compatible with HTTP and existing servlet engines. Has anybody *tested*\nthis? Maybe it would be better to specify URL-encoded UTF-8 instead.\n\nJulian\n\n\n\n[1]\n<http://www.webdav.org/deltav/protocol/draft-ietf-deltav-versioning-20.htm#_\nToc524830601>\n[2]\n<http://www.webdav.org/deltav/protocol/draft-ietf-deltav-versioning-20.htm#_\nToc524830606>\n\n\n\n", "id": "lists-007-2547194"}, {"subject": "RE: Parallel Developmen", "content": "Is there a DeltaV defined response body for a checkin failing du to the\nDAV:overwrite-by-auto-update postcondition? Or the other way around: How\ndoes a server tell the client wich version has to be added to the\npredecessor-set in order to successfully checkin the working resource?\n\n>-----Original Message-----\n>From: Clemm, Geoff [mailto:gclemm@rational.com]\n>Sent: Freitag, 14. Dezember 2001 05:56\n>To: Ietf-Dav-Versioning (E-mail)\n>Subject: RE: Parallel Development\n>\n>\n>   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n>\n>   Suppose a development environment where the development codeline is\n>   kept in a workspace. Within this Workspace there is a VCR /DEV/a.c\n>   the checked-in property points to version V1. Now there is a\n>   checkout of the checked-in version of /DEV/a.c into a\n>   working-resource WR1.\n>\n>I will assume this CHECKOUT was done by applying a CHECKOUT to\n>/DEV/a.c, with the DAV:apply-to-version flag.  (As Tim points out,\n>this has slightly different behavior from explicitly applying the\n>CHECKOUT to a version resource).\n>\n>   In my understanding of DeltaV the checked-in property of the VCR is\n>   not changed by this action.\n>\n>Correct.\n>\n>   Now another checkout of the checked-in version into a\n>   working-resource WR2 is done (i.e. two developer working parallel\n>   on the same source). Rigth so far?\n>\n>Yes.  Again, I will assume that this was a CHECKOUT of /DEV/a.c with\n>the DAV:apply-to-version flag.\n>\n>   Now WR1 is checked in. WR1 disappears the version history (VH) of\n>/DEV/a.c\n>   contains a new version V2 that is a descendant of V1. In my \n>understanding\n>   the checked-in property of the VCR is set to V2 during this checkin.\n>Still\n>   right?\n>\n>Yes, if WR1 resulted from checking out /DEV/a.c with the\n>DAV:apply-to-version flag.\n>\n>   Now WR2 is checked in. Checkin fork is forbidden. Because there is a\n>   descendent to V1 allready and the checkin fork is forbidden.\n>\n>Actually, there is no need to have Checkin-fork to be forbidden\n>(although it doesn't hurt to have it set to be that).  The\n>DAV:no-overwrite-by-auto-update postcondition of CHECKIN will\n>force the CHECKIN to fail.\n>\n>   So a merge must be forced (how?).\n>\n>I'm not sure if you are asking \"how is it forced\" or \"how do you do\n>the merge\"?  It is forced, because every time you try to CHECKIN, it\n>will fail with the postcondition identified above.  The client does\n>the merge by downloading the current content of /DEV/a.c, merging that\n>into the content of WR2, and then adding the DAV:checked-in version to\n>the DAV:predecessor set of WR2.  Then the CHECKIN will succeed,\n>because the DAV:overwrite-by-auto-update condition is no longer true.\n>\n>   After that done the checked-in property of the VCR points\n>   to the merged version of V2 and the checked in version of \n>WR2. Right?\n>\n>Actually, the checked-in property of the VCR points to the version\n>that resulted from checking in WR2, where the content of WR2 is the\n>merge of the previous state of WR2 with the state of the checked-in\n>version of /DEV/a.c.\n>\n>\n>   Background:\n>   I have a development codeline. A file to edit is a VCR. I want the\n>   possibility of two (or more) developers working parallel with this\n>   file. But I want them to do a merge of their work at the second\n>   checkin (the checkin of the first developer causes no\n>   problems). And I want the VCR point to the most current checked-in\n>   version of its VH automatically. Is this achieveable? I think it\n>   must be, since this is what can be done using Perforce.\n>\n>Yes, it is.  Just have the developers client apply CHECKOUT with\n>DAV:apply-to-version to a version-controlled resource.\n>\n>Cheers,\n>Geoff\n>\n\n\n\n", "id": "lists-007-2555493"}, {"subject": "RE: LABEL compariso", "content": "This is one of the reasons that baselines should be used instead of\nlabels, whenever possible (baselines are identified by URL's, not text\nstrings, so they have none of these problems).\n\nAs I recall, the \"octet-by-octet\" phrasing was written with the\nlabel header in mind, but I agree that this phrasing doesn't work\nso well with XML.  Perhaps some of the folks that care about labels\ncould comment here?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@gmx.de]\nSent: Thursday, January 24, 2002 10:00 AM\nTo: ietf-dav-versioning@w3.org\nSubject: LABEL comparison\n\n\nHi,\n\nthe spec says in chapter 8 [1]:\n\n\"...SHOULD use a case-sensitive octet-by-octet comparison of the two label\nnames.\"\n\nI think this must be \"character-by-character comparison\". The term \"octet\"\nisn't meaningful here because we have XML based marshalling.\n\nFurthermore, I'm not convinced that [2]:\n\n\"The value of a label header is the name of a label, encoded using UTF-8.\nFor example, the label \"release-2.0\" is identified by the following header:\"\n\nis compatible with HTTP and existing servlet engines. Has anybody *tested*\nthis? Maybe it would be better to specify URL-encoded UTF-8 instead.\n\nJulian\n\n\n\n[1]\n<http://www.webdav.org/deltav/protocol/draft-ietf-deltav-versioning-20.htm#_\nToc524830601>\n[2]\n<http://www.webdav.org/deltav/protocol/draft-ietf-deltav-versioning-20.htm#_\nToc524830606>\n\n\n\n", "id": "lists-007-2566965"}, {"subject": "Delta-V command compatible tabl", "content": "Hello,\n\nWe have lately created a table showing a compatible matrix of resources (in\ndifferent states) with all the Delta-V commands (included the WebDAV class\n1/2 commands). The table is far away from being perfect or complete\n(especially in the Delta-V advanced area, which was mostly created by simple\ncut/paste operations), but Julian's question about the \"compatibility of\nReport and a non-versioned resource\" motivated me to post the matrix. (we\nhad this column questioned too).\nThe table contains \"ok\", an explicit error code, the string \"error\" or \"?\".\nThe \"ok\" was chosen when we felt, that this command is compatible with the\nresource, \"error\" was chosen, when we felt it was not compatible but did not\nfind a direct reference in the standard. The exact/explicit error code was\nchosen, when we found a reference in the standard. Please have a look at the\n\"short terms\"  sheet for more explanations.\n\nWill such a compatible matrix makes sense to you? Would anyone be interested\nin giving feed-back and possibly even modifying this matrix. Would the\nDelta-V group be interested to take over the ownership?\n\nBest regards\n\nJuergen Pill\nSoftware AG ++49 6151 92 1831\nUhlandstr. 12\nD 64297 Darmstadt\n\n\n\n\n\n\n\napplication/vnd.ms-excel attachment: WebDAV_commands_compatible_table.xls\n\n\n\n\n", "id": "lists-007-2576013"}, {"subject": "RE: COPY, MOVE and VCR'", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   I wonder what happens when I copy or move a VCR? \n\nSee section 3.14 (Additional COPY Semantics) and section 3.15\n(Additional MOVE Semantics).\n\n   For COPY I'd expect to got a new VCR at the destination with an exact\ncopy\n   of properties.\n\nNo.  See the DAV:must-not-copy-versioning-property postcondition\ndefined in 3.14.  Versioning properties are not copied by COPY.\nThe resource created by the COPY is the same\nas would be created by a GET/PROPFIND(dead properties)/PUT/PROPPATCH\ncombination (i.e. it is not version-controlled,\nunless the server automatically puts all resources\nunder version control, and in the latter case, a new version history\nis created for the new resource).\n\n   This implies that the new created VCR must share the\n   version-history with the source VCR.\n\nNo, this would never be the case.\n\n   Is this correct? Is this desireable?\n\nNo, and no.\n\n   Defining this behavior as not expected by the user, I'd say COPY\n   means creation of a new version-history and copy of the checked-in\n   version to that new VH.  With that the checked-in property of the\n   copied VCR must change.\n\nClose.  COPY of a VCR creates a new resource whose content and dead\nproperties are the same as the source for the COPY.  A new version\nhistory is created only if the server automatically puts every new\nresource (such as the result of a PUT) under version control.  In this\ncase, the checked-in property is guaranteed to be different.\n\n   Same for MOVE except for the deletion of the source. \n\nNo, MOVE is totally different.  A MOVE is just a \"rename\", so the\nresource (including all its versioning properties) remain the same,\nbut it is now mapped to a new URL.  See section 3.15.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2584059"}, {"subject": "RE: COPY, MOVE and VCR'", "content": "   From: Peter Raymond [mailto:Peter.Raymond@merant.com]\n\n   [Daniel said:] \n   >For COPY I'd expect to got a new VCR at the destination with an\n   >exact copy of properties. This implies that the new created VCR\n   >must share the version-history with the source VCR. Is this\n   >correct? Is this desirable?\n\n   I think this is desirable and correct but with one caveat... \n\nWell, one can debate whether or not it is desirable, but it definitely\nis not correct.  COPY does not create a new VCR, unless the server\nautomatically puts all new resources under version control, and in\nthat case, a new version history will be created for it.\n\n   Both in section 1.3 (where the workspace term is defined) and in\n   section 6 the DeltaV specification says that you can only have one\n   VCR for a given version history in a workspace.  If copy created a\n   new VCR but pointed to the original VHR then this rule could be\n   violated if the destination is in the same workspace as the source\n   of the copy.  If the copy does not break this rule then it would be\n   fine to have two VCRs pointing to the same version history.\n\nYes, but you need to use the VERSION-CONTROl request (identifying\na version) to make this be the case, not a COPY.\n\n   I certainly wouldn't have thought that moving a VCR would create a\n   new history resource.\n\nThat is correct.  A MOVE is very different from a COPY, since it\neffectively just renames the resource, but otherwise leaves it\nunmodified.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2592979"}, {"subject": "RE: COPY, MOVE and VCR'", "content": "Just to make sure there is no confusion on this point,\nthe behavior of COPY is independent of whether or not\nthe destination is in a workspace.  In either case, a new\nresource is created at the destination, which has no\nrelationship to the source resource, other than having the\nsame content and dead properties.\n\nThe behavior of MOVE is also independent of whether or not\nthe destination is a workspace, except that a MOVE from one\nworkspace to another will fail if there already is a VCR\nfor that version history in the target workspace.\n\nNote: This means that Daniels first assumption was incorrect,\nbut instead the defined behavior is closer to the behavior\nthat he wished was the case.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Thursday, January 24, 2002 9:20 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: COPY, MOVE and VCR's\n\n\nSo my first assumption was right - except for workspaces\nThanks for clarification\nDaniel\n\n-----Original Message-----\nFrom: Peter Raymond [mailto:Peter.Raymond@merant.com]\nSent: Donnerstag, 24. Januar 2002 15:12\nTo: Kirmse, Daniel; Ietf-Dav-Versioning (E-mail)\nSubject: RE: COPY, MOVE and VCR's\n\n\nHi, \n[Daniel said:] \n>For COPY I'd expect to got a new VCR at the destination with an exact copy \n>of properties. This implies that the new created VCR must share the \n>version-history with the source VCR. Is this correct? Is this desirable? \nI think this is desirable and correct but with one caveat... \nBoth in section 1.3 (where the workspace term is defined) and in section 6 \nthe DeltaV specification says that you can only have one VCR for a given \nversion history in a workspace.  If copy created a new VCR but pointed to \nthe original VHR then this rule could be violated if the destination is in \nthe same workspace as the source of the copy. \nIf the copy does not break this rule then it would be fine to have two VCRs \npointing to the same version history. \nI certainly wouldn't have thought that moving a VCR would create a new \nhistory resource. \n  \nRegards, \n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n\n\n\n-----Original Message----- \nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com] \nSent: 24 January 2002 13:56 \nTo: Ietf-Dav-Versioning (E-mail) \nSubject: COPY, MOVE and VCR's \n\n\nHi, \nI wonder what happens when I copy or move a VCR? \nDefining this behavior as not expected by the user, I'd say COPY means \ncreation of a new version-history and copy of the checked-in version to that\n\nnew VH. With that the checked-in property of the copied VCR must change. \nSame for MOVE except for the deletion of the source. \nRegards, \nDaniel \n\n\n\n", "id": "lists-007-2601624"}, {"subject": "RE: Parallel Developmen", "content": "The version that needs to be added to the predecessor-set\n(preferably after merging its content to the working resource)\nis the version identified by the DAV:checked-in property of\nthe VCR.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Thursday, January 24, 2002 10:51 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Parallel Development\n\n\nIs there a DeltaV defined response body for a checkin failing du to the\nDAV:overwrite-by-auto-update postcondition? Or the other way around: How\ndoes a server tell the client wich version has to be added to the\npredecessor-set in order to successfully checkin the working resource?\n\n>-----Original Message-----\n>From: Clemm, Geoff [mailto:gclemm@rational.com]\n>Sent: Freitag, 14. Dezember 2001 05:56\n>To: Ietf-Dav-Versioning (E-mail)\n>Subject: RE: Parallel Development\n>\n>\n>   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n>\n>   Suppose a development environment where the development codeline is\n>   kept in a workspace. Within this Workspace there is a VCR /DEV/a.c\n>   the checked-in property points to version V1. Now there is a\n>   checkout of the checked-in version of /DEV/a.c into a\n>   working-resource WR1.\n>\n>I will assume this CHECKOUT was done by applying a CHECKOUT to\n>/DEV/a.c, with the DAV:apply-to-version flag.  (As Tim points out,\n>this has slightly different behavior from explicitly applying the\n>CHECKOUT to a version resource).\n>\n>   In my understanding of DeltaV the checked-in property of the VCR is\n>   not changed by this action.\n>\n>Correct.\n>\n>   Now another checkout of the checked-in version into a\n>   working-resource WR2 is done (i.e. two developer working parallel\n>   on the same source). Rigth so far?\n>\n>Yes.  Again, I will assume that this was a CHECKOUT of /DEV/a.c with\n>the DAV:apply-to-version flag.\n>\n>   Now WR1 is checked in. WR1 disappears the version history (VH) of\n>/DEV/a.c\n>   contains a new version V2 that is a descendant of V1. In my \n>understanding\n>   the checked-in property of the VCR is set to V2 during this checkin.\n>Still\n>   right?\n>\n>Yes, if WR1 resulted from checking out /DEV/a.c with the\n>DAV:apply-to-version flag.\n>\n>   Now WR2 is checked in. Checkin fork is forbidden. Because there is a\n>   descendent to V1 allready and the checkin fork is forbidden.\n>\n>Actually, there is no need to have Checkin-fork to be forbidden\n>(although it doesn't hurt to have it set to be that).  The\n>DAV:no-overwrite-by-auto-update postcondition of CHECKIN will\n>force the CHECKIN to fail.\n>\n>   So a merge must be forced (how?).\n>\n>I'm not sure if you are asking \"how is it forced\" or \"how do you do\n>the merge\"?  It is forced, because every time you try to CHECKIN, it\n>will fail with the postcondition identified above.  The client does\n>the merge by downloading the current content of /DEV/a.c, merging that\n>into the content of WR2, and then adding the DAV:checked-in version to\n>the DAV:predecessor set of WR2.  Then the CHECKIN will succeed,\n>because the DAV:overwrite-by-auto-update condition is no longer true.\n>\n>   After that done the checked-in property of the VCR points\n>   to the merged version of V2 and the checked in version of \n>WR2. Right?\n>\n>Actually, the checked-in property of the VCR points to the version\n>that resulted from checking in WR2, where the content of WR2 is the\n>merge of the previous state of WR2 with the state of the checked-in\n>version of /DEV/a.c.\n>\n>\n>   Background:\n>   I have a development codeline. A file to edit is a VCR. I want the\n>   possibility of two (or more) developers working parallel with this\n>   file. But I want them to do a merge of their work at the second\n>   checkin (the checkin of the first developer causes no\n>   problems). And I want the VCR point to the most current checked-in\n>   version of its VH automatically. Is this achieveable? I think it\n>   must be, since this is what can be done using Perforce.\n>\n>Yes, it is.  Just have the developers client apply CHECKOUT with\n>DAV:apply-to-version to a version-controlled resource.\n>\n>Cheers,\n>Geoff\n>\n\n\n\n", "id": "lists-007-2612322"}, {"subject": "RE: Missing &lt;status&gt; elements from examples in the DeltaV specifi cati o", "content": "I agree that the examples should be updated.\nI will do so in the final editing pass.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\nSent: Thursday, January 24, 2002 5:50 AM\nTo: Peter Raymond\nCc: ietf-dav-versioning@w3.org; ietf-dav-versioning-request@w3.org;\nw3c-dist-auth@w3c.org\nSubject: Re: Missing <status> elements from examples in the DeltaV\nspecificati on\n\n\nThe examples should be updated.\nThere is no good reason to depart from that DTD.\n\nRegards,\n\nTim Ellison\nJava Technology Centre, MP146\nIBM UK Laboratory, Hursley Park, Winchester, UK. SO21 2JN\ntel: +44 (0)1962 819872  internal: 249872  MOBx: 270452\n\n\n\n\nPeter Raymond <Peter.Raymond@merant.com>\nSent by: ietf-dav-versioning-request@w3.org\n2002-01-24 09:59\n\n \n        To:     ietf-dav-versioning@w3.org\n        cc:     w3c-dist-auth@w3c.org\n        Subject:        Missing <status> elements from examples in the\nDeltaV specificati       on\n\n \n\nHi, \nSection 12.9.1 of RFC2518 gives a DTD for the response element of \nmultistatus: \n<!ELEMENT response (href, ((href*, status)|(propstat+)), \nresponsedescription?) > \nBut in the examples in section 7.1.1 and 11.2.1 in the deltav \nspecification \nwe have multistatus responses with <href> elements but no <status> or \n<propstat> \nelements.  These are invalid given the above DTD. \nSo, are the examples missing <status> elements or is the DTD wrong and \nshould we \nallow responses without status and assume 200 OK? \nRegards, \n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n\n\n\n", "id": "lists-007-2624148"}, {"subject": "RE: deltav-2", "content": "I've just posted a copy of the \"final edited\" draft of deltav-20\nto the web site.  I left \"change bars\" on, so that you can more\neasily see/find the changes.  Note: this is not an internet draft,\nsince deltav-20 is the final draft, but rather a document summarizing\nthe changes I will be making in the \"author's 48 hour final review\".\n\nAlso, I updated the changes-and-issues file to identify these changes.\nPlease let me know if you think I missed any that we agreed to make.\n\nAs for where we are in the queue ... we appear to be at the \"top\" of\nthe queue, in that there are no other documents ahead of us that are\nin \"EDIT\" (i.e. pending RFC editor processing) state, and there\nis one document submitted a couple of weeks later than us that is\nalready in AUTH48 (author's 48 hour review) state.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Sunday, January 06, 2002 2:39 PM\nTo: Geoff Clemm\nSubject: deltav-20\n\n\nGeoff,\n\ntwo questions:\n\n1) AFAIK the draft that actually was submitted to the IETF differs from the\nlast public draft in some minor changes in the marshalling for\nsupported-method-set and supported-report-set. Would it be possible to\nupdate the deltaV home page with the \"right\" text?\n\n2) What's the status anyway? I haven't been following these things before,\nbut 3 months seem to be quite a long time...\n\nRegards, Julian\n\n\n\n", "id": "lists-007-2635726"}, {"subject": "RE: LABEL compariso", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> gclemm@rational.com\n> Sent: Thursday, January 24, 2002 4:57 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: LABEL comparison\n>\n>\n> This is one of the reasons that baselines should be used instead of\n> labels, whenever possible (baselines are identified by URL's, not text\n> strings, so they have none of these problems).\n>\n> As I recall, the \"octet-by-octet\" phrasing was written with the\n> label header in mind, but I agree that this phrasing doesn't work\n> so well with XML.  Perhaps some of the folks that care about labels\n> could comment here?\n\nI just re-read the lable header thread from almost one year ago.\n\nWhile I agree that language information isn't relevant, I have serious\nconcerns about how it's currently described in the spec.\n\n1) The matching should not refer to octets. This doesn't make sense if the\nlabel has been set using XML marshalling.\n\n2) I'd really like to see a working example of of a label containing\nnon-ASCII characters being passed through an HTTP header into a server. If\nthe description in the spec is sufficient, it should be easy to come up with\nan example, right?\n\n2b) As an alternative, I'd suggest URL-encoding the label's UTF-8 octet\nrepresentation (we know *this* works).\n\nJulian\n\n\n\n", "id": "lists-007-2643776"}, {"subject": "RE: LABEL compariso", "content": "It appears to me that the DAV:href element value has all the same problems\nas\na label (i.e. the value appears both in header contexts and in\nXML element values), but 2518 didn't feel obliged to say anything about it.\nHas this caused interoperability problems?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, January 24, 2002 4:49 PM\nTo: gclemm@Rational.Com; ietf-dav-versioning@w3.org\nSubject: RE: LABEL comparison\n\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> gclemm@rational.com\n> Sent: Thursday, January 24, 2002 4:57 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: LABEL comparison\n>\n>\n> This is one of the reasons that baselines should be used instead of\n> labels, whenever possible (baselines are identified by URL's, not text\n> strings, so they have none of these problems).\n>\n> As I recall, the \"octet-by-octet\" phrasing was written with the\n> label header in mind, but I agree that this phrasing doesn't work\n> so well with XML.  Perhaps some of the folks that care about labels\n> could comment here?\n\nI just re-read the lable header thread from almost one year ago.\n\nWhile I agree that language information isn't relevant, I have serious\nconcerns about how it's currently described in the spec.\n\n1) The matching should not refer to octets. This doesn't make sense if the\nlabel has been set using XML marshalling.\n\n2) I'd really like to see a working example of of a label containing\nnon-ASCII characters being passed through an HTTP header into a server. If\nthe description in the spec is sufficient, it should be easy to come up with\nan example, right?\n\n2b) As an alternative, I'd suggest URL-encoding the label's UTF-8 octet\nrepresentation (we know *this* works).\n\nJulian\n\n\n\n", "id": "lists-007-2653408"}, {"subject": "RE: Response marshalling for activity checki", "content": "   From: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\n\n   \"Roy Seto\" <Roy.Seto@oracle.com> wrote:\n\n   > How should the response for an activity checkin (as defined by\n   > 13.11) be marshalled? \n   > \n   > Should the response code be 201 or 207? Should there be a Location\n   > header containing the URL for each new version resource created?\n   > Should the response body be a DAV:multistatus element with a\n   > DAV:href for each new version resource created?\n\n   Well it isn't defined, so I guess it can be whatever you like<g>.\n\nYeah, we appeared to have omitted defining this case.\nI'm tempted to squeeze something into the final edit pass for this\n(assuming we can agree on what it should be :-).\n\n   The only requirement is that:\n   \"If a response body is included, it MUST be a DAV:checkin-response\n   XML element.\n       <!ELEMENT checkin-response ANY>\"\n\n   The method is being applied to a single resource (the activity) with no \n   depth implications, so a 207 does not 'feel' right.  I realize that there\n\n   are multiple resources affected, but would expect problems with them to\nbe \n   marshalled in the error response element.\n\n   So if all is well, return '201 Created'.\n   I wouldn't return multiple Location: headers.  How would you know which \n   checked-out resource led to which location?\n\nI agree.  Also, you can't return multiple Location headers, because\nthat would require that the syntax of the Location header allow\na comma separated list, which it does not.\n\n   If there are checkin failures, you could return something like\n   409 Conflict\n\n   <DAV:checkin-response>\n     <DAV:checkin-activity/>\n     <DAV:multi-status>\n       <DAV:...\n     </DAV:multi-status>\n   </DAV:checkin-response>\n\nNote: One of the changes in the final editing pass clarifies that \nDAV:checkin-response is only returned on a successful request.\nSo a 207 response on failure would be fine, indicating which checkin's\nfailed (or for servers that support atomic activity checkin, which\ncheckin's would have failed), and why.  (I assume that like COPY/MOVE,\nonly the error responses would appear in the 207).\n\nSo to make this clear, we would need to say:\n- The Location header is not returned on an activity checkin\n- If the activity checkin fails, a 207 status must be returned,\n  with a response for each checked-out resource that could not\n  be checked in.\n\nDoes anyone object to this?\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2664059"}, {"subject": "RE: LABEL compariso", "content": "Geoff,\n\n1) yes, it has caused interoperability problems, because the convention to\n\"UTF-8 encode first, then URL-encode\" of URIs is relatively new. For\ninstance, some Microsoft client implementations use ISO8859-1 encoding,\nwhich causes the client to fail if the server only supports UTF-8 (like it\nshould).\n\n2) however, the main difference is that a URI *always* is encoded -- there\nis no such think like a URI containing non-ASCII characters (so the problems\nI have with LABEL do not apply here -- actually, I'm proposing to use the\nsame format used for the URI).\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> gclemm@rational.com\n> Sent: Thursday, January 24, 2002 11:40 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: LABEL comparison\n>\n>\n> It appears to me that the DAV:href element value has all the same problems\n> as\n> a label (i.e. the value appears both in header contexts and in\n> XML element values), but 2518 didn't feel obliged to say anything\n> about it.\n> Has this caused interoperability problems?\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Thursday, January 24, 2002 4:49 PM\n> To: gclemm@Rational.Com; ietf-dav-versioning@w3.org\n> Subject: RE: LABEL comparison\n>\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> > gclemm@rational.com\n> > Sent: Thursday, January 24, 2002 4:57 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: RE: LABEL comparison\n> >\n> >\n> > This is one of the reasons that baselines should be used instead of\n> > labels, whenever possible (baselines are identified by URL's, not text\n> > strings, so they have none of these problems).\n> >\n> > As I recall, the \"octet-by-octet\" phrasing was written with the\n> > label header in mind, but I agree that this phrasing doesn't work\n> > so well with XML.  Perhaps some of the folks that care about labels\n> > could comment here?\n>\n> I just re-read the lable header thread from almost one year ago.\n>\n> While I agree that language information isn't relevant, I have serious\n> concerns about how it's currently described in the spec.\n>\n> 1) The matching should not refer to octets. This doesn't make sense if the\n> label has been set using XML marshalling.\n>\n> 2) I'd really like to see a working example of of a label containing\n> non-ASCII characters being passed through an HTTP header into a server. If\n> the description in the spec is sufficient, it should be easy to\n> come up with\n> an example, right?\n>\n> 2b) As an alternative, I'd suggest URL-encoding the label's UTF-8 octet\n> representation (we know *this* works).\n>\n> Julian\n>\n>\n>\n\n\n\n", "id": "lists-007-2673825"}, {"subject": "Checkout, put, checki", "content": "Hi,\n\nThere's something I find strange for a long time about the chekout-put-checkin mechanism :\nfirst, you CHECKOUT the resource you want to modify (OK... but you GET it it the same time I suppose... no ?)\nthen, you PUT the modified resource (arg ! that, I can't imagine it : where is this new resource, since it may not overwrite the old one ?)\nand then you CHECKIN the resource, so that the server records it as a new version...\n\nI seem maybe very stupid, but I don't care ;o)\n\nThanx\n\n\n\n", "id": "lists-007-2686918"}, {"subject": "Re: Checkout, put, checki", "content": "\"Elodie Tasia\" <e.tasia@ever-team.com> wrote:\n\n> There's something I find strange for a long time about the \nchekout-put-checkin\n> mechanism :\n> first, you CHECKOUT the resource you want to modify (OK... but you GET \nit it\n> the same time I suppose... no ?)\n> then, you PUT the modified resource (arg ! that, I can't imagine it : \nwhere is\n> this new resource, since it may not overwrite the old one ?)\n> and then you CHECKIN the resource, so that the server records it as a \nnew version...\n> \n>  seem maybe very stupid, but I don't care ;o)\n\nA reasonable question...\n\nthere is nothing in the CHECKOUT / CHECKIN cycle to prevent the 'lost \nupdate' problem that is addressed by locks.  You can think of CHECKOUT and \nCHECKIN as state-changes on the resource mutability 'bit'.  Where there is \nlikely to be contention on a resource, the steps to modify a checked-in \nversion-controlled resource safely will be:\n\n(1) LOCK  /foo\n    locks it so nobody can modify it's content & dead properties.  Since \nthe resource is checked in, it cannot be modified anyway, but the lock is \nnow in place so that you can...\n\n(2) CHECKOUT /foo\n    the checkout marks it as mutable, but since it is locked, the resource \ncontent and dead properties can only be modified by clients holding the \nlock token.  This ensures that nobody else will modify the resource and \nyou will overwrite their changes (or vice versa).\n\n(3) GET /foo\n    PROPFIND /foo\n    yes, if the updated contents or properties are based on the current \nvalues, then you will likely be GETting and PROPFINDing them first.\n\n(4) PUT /foo\n    PROPPATCH /foo\n    Now you can modify the resource, passing in the token to indicate you \nhave the lock on that resource.\n\n(5) CHECKIN /foo\n    Finally, when you have the resource in a state that you want to commit \nto version history, you can check it back in -- which marks it immutable \nagain.\n\n(6) UNLOCK /foo\n    Discard the lock to free it up for others to get in and do their \nchanges.  If others had started the update sequence during your update, \nthey will be stuck at step (1) trying to acquire the lock, and once you \nhave completed this step they will be free to continue.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-2694107"}, {"subject": "RE: LABEL compariso", "content": "UTF-8 first followed by URL-encoding sounds fine to me.\n\nRegards,\nTim\n\n\n\n\n\"Julian Reschke\" <julian.reschke@greenbytes.de>\nSent by: ietf-dav-versioning-request@w3.org\n2002-01-25 08:31\n\n \n        To:     <gclemm@rational.com>, <ietf-dav-versioning@w3.org>\n        cc: \n        Subject:        RE: LABEL comparison\n\n \n\nGeoff,\n\n1) yes, it has caused interoperability problems, because the convention to\n\"UTF-8 encode first, then URL-encode\" of URIs is relatively new. For\ninstance, some Microsoft client implementations use ISO8859-1 encoding,\nwhich causes the client to fail if the server only supports UTF-8 (like it\nshould).\n\n2) however, the main difference is that a URI *always* is encoded -- there\nis no such think like a URI containing non-ASCII characters (so the \nproblems\nI have with LABEL do not apply here -- actually, I'm proposing to use the\nsame format used for the URI).\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> gclemm@rational.com\n> Sent: Thursday, January 24, 2002 11:40 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: LABEL comparison\n>\n>\n> It appears to me that the DAV:href element value has all the same \nproblems\n> as\n> a label (i.e. the value appears both in header contexts and in\n> XML element values), but 2518 didn't feel obliged to say anything\n> about it.\n> Has this caused interoperability problems?\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Thursday, January 24, 2002 4:49 PM\n> To: gclemm@Rational.Com; ietf-dav-versioning@w3.org\n> Subject: RE: LABEL comparison\n>\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> > gclemm@rational.com\n> > Sent: Thursday, January 24, 2002 4:57 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: RE: LABEL comparison\n> >\n> >\n> > This is one of the reasons that baselines should be used instead of\n> > labels, whenever possible (baselines are identified by URL's, not text\n> > strings, so they have none of these problems).\n> >\n> > As I recall, the \"octet-by-octet\" phrasing was written with the\n> > label header in mind, but I agree that this phrasing doesn't work\n> > so well with XML.  Perhaps some of the folks that care about labels\n> > could comment here?\n>\n> I just re-read the lable header thread from almost one year ago.\n>\n> While I agree that language information isn't relevant, I have serious\n> concerns about how it's currently described in the spec.\n>\n> 1) The matching should not refer to octets. This doesn't make sense if \nthe\n> label has been set using XML marshalling.\n>\n> 2) I'd really like to see a working example of of a label containing\n> non-ASCII characters being passed through an HTTP header into a server. \nIf\n> the description in the spec is sufficient, it should be easy to\n> come up with\n> an example, right?\n>\n> 2b) As an alternative, I'd suggest URL-encoding the label's UTF-8 octet\n> representation (we know *this* works).\n>\n> Julian\n>\n>\n>\n\n\n\n", "id": "lists-007-2703316"}, {"subject": "RE: LABEL compariso", "content": "This is fine with me as well.\n\nDoes anyone object to the following two changes to address this issue:\n\n- In section 8.2, Replace \"SHOULD use an octet-by-octet case-sensitive\ncomparision\" with \"SHOULD use a case-sensitive comparison\".\n\n- In section 8.3, replace \"encoded using UTF-8\" with \"encoded using\nURI-escaped UTF-8\".\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Tim Ellison [mailto:Tim_Ellison@uk.ibm.com]\nSent: Friday, January 25, 2002 6:11 AM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: LABEL comparison\n\n\nUTF-8 first followed by URL-encoding sounds fine to me.\n\nRegards,\nTim\n\n\n\n\n\"Julian Reschke\" <julian.reschke@greenbytes.de>\nSent by: ietf-dav-versioning-request@w3.org\n2002-01-25 08:31\n\n \n        To:     <gclemm@rational.com>, <ietf-dav-versioning@w3.org>\n        cc: \n        Subject:        RE: LABEL comparison\n\n \n\nGeoff,\n\n1) yes, it has caused interoperability problems, because the convention to\n\"UTF-8 encode first, then URL-encode\" of URIs is relatively new. For\ninstance, some Microsoft client implementations use ISO8859-1 encoding,\nwhich causes the client to fail if the server only supports UTF-8 (like it\nshould).\n\n2) however, the main difference is that a URI *always* is encoded -- there\nis no such think like a URI containing non-ASCII characters (so the \nproblems\nI have with LABEL do not apply here -- actually, I'm proposing to use the\nsame format used for the URI).\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> gclemm@rational.com\n> Sent: Thursday, January 24, 2002 11:40 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: LABEL comparison\n>\n>\n> It appears to me that the DAV:href element value has all the same \nproblems\n> as\n> a label (i.e. the value appears both in header contexts and in\n> XML element values), but 2518 didn't feel obliged to say anything\n> about it.\n> Has this caused interoperability problems?\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Thursday, January 24, 2002 4:49 PM\n> To: gclemm@Rational.Com; ietf-dav-versioning@w3.org\n> Subject: RE: LABEL comparison\n>\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> > gclemm@rational.com\n> > Sent: Thursday, January 24, 2002 4:57 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: RE: LABEL comparison\n> >\n> >\n> > This is one of the reasons that baselines should be used instead of\n> > labels, whenever possible (baselines are identified by URL's, not text\n> > strings, so they have none of these problems).\n> >\n> > As I recall, the \"octet-by-octet\" phrasing was written with the\n> > label header in mind, but I agree that this phrasing doesn't work\n> > so well with XML.  Perhaps some of the folks that care about labels\n> > could comment here?\n>\n> I just re-read the lable header thread from almost one year ago.\n>\n> While I agree that language information isn't relevant, I have serious\n> concerns about how it's currently described in the spec.\n>\n> 1) The matching should not refer to octets. This doesn't make sense if \nthe\n> label has been set using XML marshalling.\n>\n> 2) I'd really like to see a working example of of a label containing\n> non-ASCII characters being passed through an HTTP header into a server. \nIf\n> the description in the spec is sufficient, it should be easy to\n> come up with\n> an example, right?\n>\n> 2b) As an alternative, I'd suggest URL-encoding the label's UTF-8 octet\n> representation (we know *this* works).\n>\n> Julian\n>\n>\n>\n\n\n\n", "id": "lists-007-2717543"}, {"subject": "compare-baseline report with subbaseline", "content": "Hi,\nin 12.7.1 there is a nice example of a compare-baseline report.\nBut how does it look with subbaselines ?\nAdded or deleted subbaselines won't be a problem.\nBut how do we describe changed subbaselines ? Here some recursion\nseems to be necessary (Depth infinity).\nAnother remark (not wanting to change that in the current draft):\nIn 12.12 (one-version-per-history-per-baseline) we extend this\nto the subbaselines. I remember this restriction coming from merging problems.\nI feel this isn't necessary if merging has a configuration scope (excluding\nsubconfigurations). \n\nCheers, Edgar\n\n\n\n\n-- \nedgar@edgarschwarz.de                    http://www.edgarschwarz.de\n*          DOSenfreie Zone.        Running Active Oberon.         *\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-2732139"}, {"subject": "Propagation of change", "content": "Hi,\n\nsuppose I have two workspaces A and B. Both of them are under\nbaseline-control. Furthermore I work with working resources and activities\nand version-controlled collections (to track namespace operations).\nFurther Suppose workspace A contains my current development and workspace B\nis a consolidation place. Workspace B was created with reference to a\nbaseline of A. \nThe development was going on. Changes were made. Files were added and\ndeleted.\n\nNow I want to do an update of the consolidation refering to a newer baseline\nof A.\n\nHow could this be done?\n\nFirst I would use the compare-baseline report to get a diff of the baseline\nA used for creation of B and the newer baseline of A. (Could I compare a\nbaseline of workspace B with a baseline of A [well, of course comparing\nbaselines of the version-controlled configurations of B and A]).\nBut how do I get the changes \"merged\" into workspace B?\nIs this in scope of DeltaV?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2740001"}, {"subject": "RE: Propagation of change", "content": "To merge a baseline into a workspace, you use the\nMERGE request, i.e.\n\nMERGE /ws/B\n<D:merge> <D:source> \n  <D:href>/repo/bl/1573</D:href>\n  </D:source> </D:merge>\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Monday, January 28, 2002 9:48 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Propagation of changes\n\n\nHi,\n\nsuppose I have two workspaces A and B. Both of them are under\nbaseline-control. Furthermore I work with working resources and activities\nand version-controlled collections (to track namespace operations).\nFurther Suppose workspace A contains my current development and workspace B\nis a consolidation place. Workspace B was created with reference to a\nbaseline of A. \nThe development was going on. Changes were made. Files were added and\ndeleted.\n\nNow I want to do an update of the consolidation refering to a newer baseline\nof A.\n\nHow could this be done?\n\nFirst I would use the compare-baseline report to get a diff of the baseline\nA used for creation of B and the newer baseline of A. (Could I compare a\nbaseline of workspace B with a baseline of A [well, of course comparing\nbaselines of the version-controlled configurations of B and A]).\nBut how do I get the changes \"merged\" into workspace B?\nIs this in scope of DeltaV?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2748291"}, {"subject": "RE: compare-baseline report with subbaseline", "content": "Good point.  We did neglect to define the DAV:compare-baseline\nbehavior on subbaselines.  We could:\n\n- Have subbaselines appear in DAV:added-version, DAV:deleted-version,\nand DAV:changed-version elements.  This is reasonable, since a baseline\nis a special kind of version\n\n- Have DAV:compare-baseline \"recurse\" into subbaselines, and report on the\nversions of those subbaselines.\n\nI probably prefer the former behavior, since otherwise the behavior of\nadding a\nsubbaseline or deleting a subbaseline gratuitously inflates the size of\nthe report.\n\nA variant of the second approach would be to just report added and deleted\nbaselines in added-version and deleted-version elements, but to\nautomatically \nrecurse into baselines that appear in DAV:changed-version elements.\n\nA variant of this variant would be to have this \"recurse\" behavior\ncontrolled\nby an explicit parameter to DAV:compare-baseline.\n\nBut I'd probably still go for the simple version of the second behavior\n(i.e. never\nrecurse), since a client could always recurse itself, if it wanted to.\n\nThis probably counts as \"clarifying an ambiguity\", \nrather than \"adding or changing behavior\", so\nan argument could be made to add this wording during the final edit pass.\nWould anyone object to this?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Edgar@EdgarSchwarz.de [mailto:Edgar@EdgarSchwarz.de]\nSent: Sunday, January 27, 2002 5:12 PM\nTo: ietf-dav-versioning@w3.org\nCc: Edgar@EdgarSchwarz.de\nSubject: compare-baseline report with subbaselines\n\n\nHi,\nin 12.7.1 there is a nice example of a compare-baseline report.\nBut how does it look with subbaselines ?\nAdded or deleted subbaselines won't be a problem.\nBut how do we describe changed subbaselines ? Here some recursion\nseems to be necessary (Depth infinity).\nAnother remark (not wanting to change that in the current draft):\nIn 12.12 (one-version-per-history-per-baseline) we extend this\nto the subbaselines. I remember this restriction coming from merging\nproblems.\nI feel this isn't necessary if merging has a configuration scope (excluding\nsubconfigurations). \n\nCheers, Edgar\n\n\n\n\n-- \nedgar@edgarschwarz.de                    http://www.edgarschwarz.de\n*          DOSenfreie Zone.        Running Active Oberon.         *\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-2756832"}, {"subject": "Re (2): compare-baseline report with subbaseline", "content": "> Good point.  We did neglect to define the DAV:compare-baseline\n> behavior on subbaselines.\nIt seems I'm the first one to try implementing compare-baseline with subbaselines :-)\n\n> We could:\n> - Have subbaselines appear in DAV:added-version, DAV:deleted-version,\n> and DAV:changed-version elements.  This is reasonable, since a baseline\n> is a special kind of version\nI would prefer to have DAV:added-baseline, DAV:deleted-baseline,\nand DAV:changed-baseline elements. If not, the baseline aware client has the\nunnecessary work to find out whether it's a resource or a configuration version. \nAnd the non baseline client could be confused. Getting a DAV:<x>-baseline element\nwould be easier to detect.\n\n> - Have DAV:compare-baseline \"recurse\" into subbaselines, and report on the\n> versions of those subbaselines.\nDoesn't make much sense for added and deleted subbaselines.\n\n> I probably prefer the former behavior, since otherwise the behavior of adding a\n> subbaseline or deleting a subbaseline gratuitously inflates the size of\n> the report.\n> A variant of the second approach would be to just report added and deleted\n> baselines in added-version and deleted-version elements, but to\n> automatically recurse into baselines that appear in DAV:changed-version elements.\nThat's what I will do at the moment. It's what I think is the logical way.\nThe danger of inflation isn't that great if you only recurse the changed baselines.\n\n> A variant of this variant would be to have this \"recurse\" behavior controlled\n> by an explicit parameter to DAV:compare-baseline.\nUnnecessary complexity.\n\n> But I'd probably still go for the simple version of the second behavior\n> (i.e. never  recurse), since a client could always recurse itself, if it wanted to.\nThat's possible. But I expect a compare-baseline to give me the complete difference\ninformation. And for that I need to recurse changed baselines.\n\nCheers, Edgar\n\n  \n\n\n\n-- \nedgar@edgarschwarz.de                    http://www.edgarschwarz.de\n*          DOSenfreie Zone.        Running Active Oberon.         *\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-2767133"}, {"subject": "Re (2): Propagation of change", "content": "From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n> Now I want to do an update of the consolidation refering to a newer baseline\n> of A.\n> How could this be done? \n> First I would use the compare-baseline report to get a diff of the baseline\n> A used for creation of B and the newer baseline of A. (Could I compare a\n> baseline of workspace B with a baseline of A [well, of course comparing\n> baselines of the version-controlled configurations of B and A]).\n> But how do I get the changes \"merged\" into workspace B?\nIf you mean by \"merge\" that in the meantime you created a newer (Hopefully better)\nbaseline in A and want to take over this baseline in your consolidation workspace\nB replacing the old baseline I guess you don't need MERGE like Geoff wrote but\nreally want an UPDATE for the baseline-controlled configuration in B.\nBut perhaps Geoff was right. I'm not sure.\n\nCheers, Edgar\n\n\n-- \nedgar@edgarschwarz.de                    http://www.edgarschwarz.de\n*          DOSenfreie Zone.        Running Active Oberon.         *\nMake it as simple as possible, but not simpler.     Albert Einstein\n--- start of oberon mail ---\n<Z@h7`Pa0>dgFGiVfb:gH2CG>eajFGJDgBW?8=X0OZH;[LO[KS9<M10:06`7\\9DP?X00=050H0l2\nD06060305P20T900C20@T00<800KM0DP?H0H0lI4P;U0JDinffZC@^dd:gf>gbbB@Bd`jfdFFf2b\n]ff`VFfBggZCb6Fg@G^fd:72di6Fhjbanfffe6jC@jdgNG@VD@Ng`jFj2BjnF@Bfg2b`jF@FGhBf\n`Bgb2bgJF@BGdFF@>fgjfinFfVFb6FjVfgjF@:gbJfb:gdjfc2BjnF@6F@jfbNgb:G@:f`>gbbfd\njfbf@O2bgJF@6DGf@O2BTnfk2banfjbFb2BjRfd>G@:fb2BbnFgFfO2b6jC@Jdd:giBG@VD@NggF\nGfHMWKI19MAKIHKQKHUKIKYH3kL;32BiFFhnFiBG@B7?KIY;83;89KJ=[I1iK=Cj@a6fi0KP15Te\nM^UU\\Pd\\_E^PL\\b]\\QU^Ym=nFcDXP<\\^U\\PT^X]<MKI001iK=cP4TXLX_]^\\aTL\\_12b`f@O2Ba6\n60l^_E^[M^`=\\S]\\PDXPl^YU^X5TQ5TR=<0H@1iF_KII;KI98O[I1iHOKMUkL;;87kK`djV=dWPD\n<0W;8O[I19MXM;[LWKJO[KKiHO[KY[LO;KIKI9;87kKM[ICkI[[L3;MCkK>G@nFcD8`PfeDjb6jS\n2]^d5TXm]g5TTm=C:8?KIYCj`aRf`jfcFfi2BAffb:gcFFb:B@VFgBgg2bknFiPSQo\\Q9e\\P<__]\n^P\\]U=\\^5TR=_PDT]]<DTPT^X=\\d5TYe]PT^X]<K3YKJKKI1INOKM>FiF6;;I1IH1YKPX4Y_5^Ue\n\\eU]\\=_PD\\UU^d]\\b=U=D\\QM>@@VFg2bP2b`jFbl^Qe=@j6feFF@nFkFFi2BjRfd``>70VggD^PL\n\\_e]c1PPl^_1H35:8UKIQ;K3kHC[K?;8Rfbl]\\U\\PD\\QM>P95TW]^UM^c5Tim]e5TTm=?9M1YK;K\nI9;8KJAUjA;:8IKJGKI1iA;kK=[I1iMUkKYKI1YH[;MKXL;KHI;Kcck666Fg2bZ2ER6DZFD@Jfg:\nWd5]UYH33H;7kKM3PSAc0PYe]PDX^\\Q2]^d5T`]\\b5]Q5^c5T7]\\_13kL1YLCkIA;MM98Cj9K;8M\nkKY;8WKMUKIMI3Kh@AKI;[LW;;1IA9kI3[LKH3KH;K98KHI9kI3CPFFbNf`L^S5]g=\\bE_^T\\U5T\nP4TP44004]dU^`EW_lUgm^geUUU<00KX:19819811TX?M:M[IUKICKI1YFO[K;[;1981A@@YFGgj\nfdjfc2bP>FjVFkFF@nDaFFiX;1981A@PZ\\Q==\\[]\\P<]d5TQM^PL^Y]]`U]U5TQM^P4^_M^c=]RU\n]UUUPD\\eU^Pd]_U>Vff@ijB@221I@I[H;[LY;8;JJMkLYKIC[K0%\n\n\n\n", "id": "lists-007-2776561"}, {"subject": "RE: Re (2): compare-baseline report with subbaseline", "content": "I agree with Edgar that separate DAV:added-baseline and\nDAV:deleted-baseline elements would make things easier for\nclients, since they would not have to retrieve the\nDAV:resourcetype for each added or deleted version to apply\nspecial processing for subbaselines.\n\nThe same applies for DAV:changed-baseline over DAV:changed-version\nif the server does not automatically recurse into changed\nsubbaselines. I don't have a strong opinion whether this recursion\nshould be done on client or server.\n\nRoy\n\n-----Original Message-----\nFrom: Edgar@EdgarSchwarz.de\n\n> We could:\n> - Have subbaselines appear in DAV:added-version,\nDAV:deleted-version,\n> and DAV:changed-version elements.  This is reasonable, since a\nbaseline\n> is a special kind of version\nI would prefer to have DAV:added-baseline, DAV:deleted-baseline,\nand DAV:changed-baseline elements. If not, the baseline aware\nclient has the\nunnecessary work to find out whether it's a resource or a\nconfiguration version.\nAnd the non baseline client could be confused. Getting a\nDAV:<x>-baseline element\nwould be easier to detect.\n\n\n\n", "id": "lists-007-2786173"}, {"subject": "RE: Propagation of change", "content": "o.k. so far, but take a look at some details:\n\ncommon base:\n------------\nsuppose I have two workspaces A and B. Both of them are under\nbaseline-control (with auto-version). Furthermore I work with working\nresources \nand activities\nand version-controlled collections (to track namespace operations).\nFurther Suppose workspace A contains my current development \nand workspace B\nis a consolidation place. Workspace B was created with reference to a\nbaseline of A. \nI have a VCR a located at workspace A and a VCR b located at workspace B\nboth sharing a version history VH-AB.\nAt time of creation of workspace B from a baseline of workspace A. VCR a and\nVCR b had checked-in version V1 of VH-AB.\n\ncase 0:\n-------\nno further developments took place on neither side -> MERGE does not have\nanything to do here\n\ncase 1:\n-------\nVCR a has a checked-in version V-A2 (successor/descendant of V1). No changes\nmade to VCR b, so b still has checked-in version V1.\n\nNow there is a MERGE. /repo/bl/1573 is the new baseline of A\n\nMERGE /ws/B\n<D:merge>\n  <D:source> \n    <D:href>/repo/bl/1573</D:href>\n  </D:source>\n</D:merge>\n\nso merge takes version V-A2 (merge source) and merges it to VCR b (merge\ntarget) because V-A2 is a descendant of checked-in version V1 of VCR b a\nauto-merge could be done setting checked-in version of VCR b to V-A2.\nRight?\n(This would suit my needs. Works as I expect it to do.)\n\ncase 2:\n-------\nVCR b has a checked-in version V-B2 (successor/descendant of V1). No changes\nmade to VCR A, so a still has checked-in version V1.\n\nNow there is a MERGE. /repo/bl/1573 is the baseline of A\n\nMERGE /ws/B\n<D:merge>\n  <D:source> \n    <D:href>/repo/bl/1573</D:href>\n  </D:source>\n</D:merge>\n\nso merge takes version V1 (merge source) and merges it to VCR b (merge\ntarget) because V1 is an anchestor of checked-in version V-B2 of VCR b a\nauto-merge could be done setting checked-in version of VCR b to V1.\nRight?\n(This is not quite what I would expect/need. A change of the target would be\nlost without further notice. I'd rather the server would fail this here to\nlet the user take the decision what version to keep for VCR b.)\n\ncase 3:\n-------\nVCR a has checked-in version V-A2 (successor of V1). VCR b has checked-in\nversion V-B2 (succesor of V1).\n\nNow there is a MERGE. /repo/bl/1573 is the baseline of A\n\nMERGE /ws/B\n<D:merge>\n  <D:source> \n    <D:href>/repo/bl/1573</D:href>\n  </D:source>\n</D:merge>\n\nso merge takes version V-A2 (merge source) and merges it to VCR b (merge\ntarget) because V-A2 is no anchestor or descandant of checked-in version\nV-B2 of VCR b a auto-merge could not be done. The request fails. User has to\ndo a manual merge on its own.\nRight?\n\nRegards,\nDaniel\n\n>-----Original Message-----\n>From: gclemm@rational.com [mailto:gclemm@rational.com]\n>Sent: Montag, 28. Januar 2002 20:01\n>To: ietf-dav-versioning@w3.org\n>Subject: RE: Propagation of changes\n>\n>\n>To merge a baseline into a workspace, you use the\n>MERGE request, i.e.\n>\n>MERGE /ws/B\n><D:merge> <D:source> \n>  <D:href>/repo/bl/1573</D:href>\n>  </D:source> </D:merge>\n>\n>Cheers,\n>Geoff\n>\n>\n>-----Original Message-----\n>From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n>Sent: Monday, January 28, 2002 9:48 AM\n>To: Ietf-Dav-Versioning (E-mail)\n>Subject: Propagation of changes\n>\n>\n>Hi,\n>\n>suppose I have two workspaces A and B. Both of them are under\n>baseline-control. Furthermore I work with working resources \n>and activities\n>and version-controlled collections (to track namespace operations).\n>Further Suppose workspace A contains my current development \n>and workspace B\n>is a consolidation place. Workspace B was created with reference to a\n>baseline of A. \n>The development was going on. Changes were made. Files were added and\n>deleted.\n>\n>Now I want to do an update of the consolidation refering to a \n>newer baseline\n>of A.\n>\n>How could this be done?\n>\n>First I would use the compare-baseline report to get a diff of \n>the baseline\n>A used for creation of B and the newer baseline of A. (Could I \n>compare a\n>baseline of workspace B with a baseline of A [well, of course comparing\n>baselines of the version-controlled configurations of B and A]).\n>But how do I get the changes \"merged\" into workspace B?\n>Is this in scope of DeltaV?\n>\n>Regards,\n>Daniel\n>\n\n\n\n", "id": "lists-007-2794449"}, {"subject": "RE: Propagation of change", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   common base:\n   ------------\n   suppose I have two workspaces A and B. Both of them are under\n   baseline-control (with auto-version).  Furthermore I work with\n   working resources and activities and version-controlled collections\n   (to track namespace operations).  Further Suppose workspace A\n   contains my current development and workspace B is a consolidation\n   place. Workspace B was created with reference to a baseline of A.\n   I have a VCR a located at workspace A and a VCR b located at\n   workspace B both sharing a version history VH-AB.  At time of\n   creation of workspace B from a baseline of workspace A. VCR a and\n   VCR b had checked-in version V1 of VH-AB.\n\n   case 1:\n   -------\n   VCR a has a checked-in version V-A2 (successor/descendant of V1).\n   No changes made to VCR b, so b still has checked-in version V1.\n\n   Now there is a MERGE. /repo/bl/1573 is the new baseline of A\n\n   MERGE /ws/B\n   <D:merge>\n     <D:source> \n       <D:href>/repo/bl/1573</D:href>\n     </D:source>\n   </D:merge>\n\n   so merge takes version V-A2 (merge source) and merges it to VCR b (merge\n   target) because V-A2 is a descendant of checked-in version V1 of VCR b a\n   auto-merge could be done setting checked-in version of VCR b to V-A2.\n   Right?\n   (This would suit my needs. Works as I expect it to do.)\n\nYes.  We don't use the term \"auto-merge\" here though, since we've been\nusing auto-merge to mean \"neither version is a descendent of the other,\nand the server has automatically done a merge into the checked out\ntarget, that is to be reviewed by the client\" (i.e. your case 3 below,\nexcept that the server is being helpful).\n\n   case 2:\n   -------\n   VCR b has a checked-in version V-B2 (successor/descendant of V1).\n   No changes made to VCR A, so a still has checked-in version V1.\n\n   Now there is a MERGE. /repo/bl/1573 is the baseline of A\n\n   MERGE /ws/B\n   <D:merge>\n     <D:source> \n       <D:href>/repo/bl/1573</D:href>\n     </D:source>\n   </D:merge>\n\n   so merge takes version V1 (merge source) and merges it to VCR b (merge\n   target) because V1 is an anchestor of checked-in version V-B2 of VCR b a\n   auto-merge could be done setting checked-in version of VCR b to V1.\n   Right?\n\nNo, if the merge souce is an ancestor of the merge target, the merge\ntarget is left unchanged.\n\n   (This is not quite what I would expect/need. A change of the target would\nbe\n   lost without further notice. I'd rather the server would fail this here\nto\n   let the user take the decision what version to keep for VCR b.)\n\nThe semantics are the one need, although there is no failure.\nThe merge target is a descendent of the merge source, which by the\nsemantics of line of descent, means that result of the merge leaves\nthe target unchanged.\n\n   case 3:\n   -------\n   VCR a has checked-in version V-A2 (successor of V1). VCR b has checked-in\n   version V-B2 (succesor of V1).\n\n   Now there is a MERGE. /repo/bl/1573 is the baseline of A\n\n   MERGE /ws/B\n   <D:merge>\n     <D:source> \n       <D:href>/repo/bl/1573</D:href>\n     </D:source>\n   </D:merge>\n\n   so merge takes version V-A2 (merge source) and merges it to VCR b (merge\n   target) because V-A2 is no anchestor or descandant of checked-in version\n   V-B2 of VCR b a auto-merge could not be done. The request fails. User has\nto\n   do a manual merge on its own.\n   Right?\n\nThe request doesn't \"fail\", it succeeds, but VCR b is left checked-out,\nwith a DAV:merge-set identifying version V-A2 (or if the server\nis auto-merging, in the DAV:auto-merge-set).  The client must merge the\ncontent of V-A2 into VCR b (or confirm that the server has correctly\nauto-merged the contents of V-A2 into VCR b), and move the reference to\nV-A2 from the DAV:merge-set to the DAV:predecessor-set of VCR b,\nbefore it can check in VCR b.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2807230"}, {"subject": "UPDATE/MERG", "content": "Hi,\n\n   common base:\n   ------------\n   suppose I have two workspaces A and B. Both of them are under\n   baseline-control (with auto-version).  Furthermore I work with\n   working resources and activities and version-controlled collections\n   (to track namespace operations).  Further Suppose workspace A\n   contains my current development and workspace B is a consolidation\n   place. Workspace B was created with reference to a baseline of A.\n   I have a VCR a located at workspace A and a VCR b located at\n   workspace B both sharing a version history VH-AB.  At time of\n   creation of workspace B from a baseline of workspace A. VCR a and\n   VCR b had checked-in version V1 of VH-AB.\n\nNow VCR a was changed and a new version V-A2 appeared. Even so VCR b was\nchanged and a new version V-B2 appeard.\n\nNow some time later I want to discard version V-B2 cause it was kind of a\nblind alley.\n\nI use UPDATE to set the checked-in property of VCR b to V-A2.\nWhat puzzles me is that there is no predecessor/successor relation in the\nversion-history expressing this UPDATE (at least this my understandig of the\nUPDATE chapter).\n\nThe use of MERGE (with DAV:no-checkout) would fail, because V-A2 and V-B2\nare sibblings.\n\nSo the question is: How can this discard be done WITH keeping the\ninformation, that the predecessor of V-A2 in the context of VCR b is V-B2?\n\nBy the way: Is the version-history report kind of context dependend? The\nquestion arises due to the update problem. I want to know the\nversion-history  of a vcr (respectively the line of descent of the currently\nchecked-in version of that VCR).\n\nThis Information is needed to revert the UPDATE of VCR b. This must end with\nV-B2 beeing the checked-in version of VCR b again.\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2818078"}, {"subject": "Revert a Deletion of a VCR using version-controlled Collection", "content": "Hi,\n\nwhat about this one here:\n\n   /src/a\n\n/src is a version-controlled collection (VCC). a is a VCR. By now there is a\nversion V1 of VCC /src that contains the binding (a) and a \"pointer\" to the\nversion-history of a.\n\nNow I delete VCR a. Doing this I get a new version V2 of VCC /src that does\nnot contain the binding for a anymore.\n\nSo far so good. Sometime later I want to revert the deletion of VCR a. So I\ndo an update of VCC /src so that V1 becomes the checked-in version of VCC\n/src again. VCR a will be created again. It points to the right\nversion-history. But what is the checked-in version of VCR a by now? This\nproperty was gone to the dump earlier at deletion time. The only guess would\nbe, the checked-in version of VCR a is the root version of the\nversion-history. Well I my eyes this would be no real revert of the\ndeletion, cause the state before the deletion and the state after the revert\nare not equal.\n\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2826758"}, {"subject": "RE: UPDATE/MERG", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n      common base:\n      ------------\n      suppose I have two workspaces A and B. Both of them are under\n      baseline-control (with auto-version).  Furthermore I work with\n      working resources and activities and version-controlled\n      collections (to track namespace operations).  Further Suppose\n      workspace A contains my current development and workspace B is a\n      consolidation place. Workspace B was created with reference to a\n      baseline of A.  I have a VCR a located at workspace A and a VCR\n      b located at workspace B both sharing a version history VH-AB.\n      At time of creation of workspace B from a baseline of workspace\n      A. VCR a and VCR b had checked-in version V1 of VH-AB.\n\n   Now VCR a was changed and a new version V-A2 appeared. Even so VCR\n   b was changed and a new version V-B2 appeard.\n\n   Now some time later I want to discard version V-B2 cause it was kind of a\n   blind alley.\n\n   I use UPDATE to set the checked-in property of VCR b to V-A2.  What\n   puzzles me is that there is no predecessor/successor relation in\n   the version-history expressing this UPDATE (at least this my\n   understandig of the UPDATE chapter).\n\nThat is correct.\n\n   The use of MERGE (with DAV:no-checkout) would fail, because V-A2 and V-B2\n   are sibblings.\n\nYes.\n\n   So the question is: How can this discard be done WITH keeping the\n   information, that the predecessor of V-A2 in the context of VCR b\n   is V-B2?\n\nMERGE V-A2 to VCR b without the DAV:no-checkout.\nThen copy the content of V-A2 to VCR b, and CHECKIN VCR b.\n\n   By the way: Is the version-history report kind of context dependend?\n\nNo, it gives you all versions from the version history of the VCR.\n\n   The question arises due to the update problem. I want to know the\n   version-history of a vcr (respectively the line of descent of the\n   currently checked-in version of that VCR).  This Information is\n   needed to revert the UPDATE of VCR b. This must end with V-B2\n   beeing the checked-in version of VCR b again.\n\nThe version-history report is not a \"line of descent\" report.  To get\nthe line of descent, trace back through the DAV:predecessor-set of the\nversion you are interested in.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-2834535"}, {"subject": "RE: Revert a Deletion of a VCR using version-controlled Collectio n", "content": "Reverting to a previous state of the workspace will often involve \nreverting to earlier states of several resources.  In the particular\ncase described below, you need to remember the state of two resources:\nthat of /src (so that you revert back to when it had a member called \"a\"),\nand that of /src/a (so that you revert to a particular state of /src/a.\n\nIf you want to capture the state of several resources in a workspace,\nyou can use a \"baseline\", which would have remembered both the state\nof /src, and the state of /src/a.  If you only wanted to revert back to\npart of the state captured by a baseline, you can use the\nDAV:baseline-collection of that baseline to identify what versions were\nselected by that baseline, and then use UPDATE requests to bring back\nthe parts of the baseline you are interested in.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Wednesday, January 30, 2002 10:44 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Revert a Deletion of a VCR using version-controlled Collections\n\n\nHi,\n\nwhat about this one here:\n\n   /src/a\n\n/src is a version-controlled collection (VCC). a is a VCR. By now there is a\nversion V1 of VCC /src that contains the binding (a) and a \"pointer\" to the\nversion-history of a.\n\nNow I delete VCR a. Doing this I get a new version V2 of VCC /src that does\nnot contain the binding for a anymore.\n\nSo far so good. Sometime later I want to revert the deletion of VCR a. So I\ndo an update of VCC /src so that V1 becomes the checked-in version of VCC\n/src again. VCR a will be created again. It points to the right\nversion-history. But what is the checked-in version of VCR a by now? This\nproperty was gone to the dump earlier at deletion time. The only guess would\nbe, the checked-in version of VCR a is the root version of the\nversion-history. Well I my eyes this would be no real revert of the\ndeletion, cause the state before the deletion and the state after the revert\nare not equal.\n\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2843723"}, {"subject": "Definition of DAV:error and it's use in multistatus..", "content": "Hi,\n\nSection 1.6 of the DeltaV specification defines how the pre and post\ncondition XML \nelements should be returned.  It says:\n\n\"the appropriate XML element MUST be returned as the child of a top-level\nDAV:error \nelement in the response body, unless otherwise negotiated by the request.\nIn a 207 \nMulti-Status response, the DAV:error element would appear in the appropriate\nDAV:responsedescription element.\"\n\nThis is the only definiton of DAV:error, there is no DTD for this element as\nfar\nas I can tell and no examples of it's use within a multistatus response.\nIt would seem to violate the DTD defined in RFC2518 for\nDAV:responsedescription.\n\nAm I correct in thinking that the syntax should be:\n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:multistatus xmlns:D=\"DAV:\">\n    <D:response>\n      <D:href>http://www.merant.com/webdav/ws1/test.html</D:href>\n      <D:status>HTTP/1.1 409 CONFLICT</D:status>\n      <D:responsedescription>\n        <D:error>\n          <D:label-must-exist/>\n        </D:error>\n        Label specified does not exist\n      </D:responsedescription>\n    </D:response>\n  </D:multistatus>\n\nThe human readable text describing the error and the DAV:error element are\nchildren\nof the DAV:responsedescription element.  This seems very odd.  Why not have\nthe\nDAV:error element as a child of the DAV:response element?\n\nRegards,\n--\nPeter Raymond - MERANT\nPrincipal Architect (PVCS)\nTel: +44 (0)1727 813362\nFax: +44 (0)1727 869804\nmailto:Peter.Raymond@merant.com\nWWW: http://www.merant.com\n\n\n\n", "id": "lists-007-2852933"}, {"subject": "RE: Definition of DAV:error and it's use in multistatus..", "content": "The rationale\nfor putting it in the DAV:responsedescription node\nis that the DAV:responsedescription corresponds to\nthe \"body\" of a non-multi-status response, and\nthat is where the DAV:error node appears in a\nnon-multi-status response.\n\nThis does not violate the DTD for DAV:responsedescription,\nbecause a client is required to ignore any node that it\ndoesn't understand, so it doesn't matter where you put it.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Peter Raymond [mailto:Peter.Raymond@merant.com]\nSent: Tuesday, February 05, 2002 4:13 PM\nTo: ietf-dav-versioning@w3.org\nSubject: Definition of DAV:error and it's use in multistatus...\n\n\nHi, \nSection 1.6 of the DeltaV specification defines how the pre and post\ncondition XML \nelements should be returned.  It says: \n\"the appropriate XML element MUST be returned as the child of a top-level\nDAV:error \nelement in the response body, unless otherwise negotiated by the request.\nIn a 207 \nMulti-Status response, the DAV:error element would appear in the appropriate\n\nDAV:responsedescription element.\" \nThis is the only definiton of DAV:error, there is no DTD for this element as\nfar \nas I can tell and no examples of it's use within a multistatus response. \nIt would seem to violate the DTD defined in RFC2518 for\nDAV:responsedescription. \nAm I correct in thinking that the syntax should be: \n<?xml version=\"1.0\" encoding=\"utf-8\" ?> \n  <D:multistatus xmlns:D=\"DAV:\"> \n    <D:response> \n      <D:href>http://www.merant.com/webdav/ws1/test.html</D:href> \n      <D:status>HTTP/1.1 409 CONFLICT</D:status> \n      <D:responsedescription> \n        <D:error> \n          <D:label-must-exist/> \n        </D:error> \n        Label specified does not exist \n      </D:responsedescription> \n    </D:response> \n  </D:multistatus> \nThe human readable text describing the error and the DAV:error element are\nchildren \nof the DAV:responsedescription element.  This seems very odd.  Why not have\nthe \nDAV:error element as a child of the DAV:response element? \nRegards, \n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n\n\n\n", "id": "lists-007-2862801"}, {"subject": "RE: Definition of DAV:error and it's use in multistatus..", "content": "Hi,\n\nThe DTD for DAV:responsedescription is:\n\n<!ELEMENT responsedescription (#PCDATA) >\n\nIf you want to put the DAV:error element beneath DAV:responsedescription\nthen the DTD should be modified to something like:\n\n<!ELEMENT responsedescription (#PCDATA | error)* >\n\nThis would allow a mix of character data and the DAV:error element.\nAs the DTD stands today it only allows character data.\n\nRegards,\n--\nPeter Raymond - MERANT\nPrincipal Architect (PVCS)\nTel: +44 (0)1727 813362\nFax: +44 (0)1727 869804\nmailto:Peter.Raymond@merant.com\nWWW: http://www.merant.com\n\n\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: 06 February 2002 13:06\nTo: ietf-dav-versioning@w3.org\nSubject: RE: Definition of DAV:error and it's use in multistatus...\n\n\nThe rationale\nfor putting it in the DAV:responsedescription node\nis that the DAV:responsedescription corresponds to\nthe \"body\" of a non-multi-status response, and\nthat is where the DAV:error node appears in a\nnon-multi-status response.\n\nThis does not violate the DTD for DAV:responsedescription,\nbecause a client is required to ignore any node that it\ndoesn't understand, so it doesn't matter where you put it.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Peter Raymond [mailto:Peter.Raymond@merant.com]\nSent: Tuesday, February 05, 2002 4:13 PM\nTo: ietf-dav-versioning@w3.org\nSubject: Definition of DAV:error and it's use in multistatus...\n\n\nHi, \nSection 1.6 of the DeltaV specification defines how the pre and post\ncondition XML \nelements should be returned.  It says: \n\"the appropriate XML element MUST be returned as the child of a top-level\nDAV:error \nelement in the response body, unless otherwise negotiated by the request.\nIn a 207 \nMulti-Status response, the DAV:error element would appear in the appropriate\n\nDAV:responsedescription element.\" \nThis is the only definiton of DAV:error, there is no DTD for this element as\nfar \nas I can tell and no examples of it's use within a multistatus response. \nIt would seem to violate the DTD defined in RFC2518 for\nDAV:responsedescription. \nAm I correct in thinking that the syntax should be: \n<?xml version=\"1.0\" encoding=\"utf-8\" ?> \n  <D:multistatus xmlns:D=\"DAV:\"> \n    <D:response> \n      <D:href>http://www.merant.com/webdav/ws1/test.html</D:href> \n      <D:status>HTTP/1.1 409 CONFLICT</D:status> \n      <D:responsedescription> \n        <D:error> \n          <D:label-must-exist/> \n        </D:error> \n        Label specified does not exist \n      </D:responsedescription> \n    </D:response> \n  </D:multistatus> \nThe human readable text describing the error and the DAV:error element are\nchildren \nof the DAV:responsedescription element.  This seems very odd.  Why not have\nthe \nDAV:error element as a child of the DAV:response element? \nRegards, \n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n\n\n\n", "id": "lists-007-2873551"}, {"subject": "RE: Definition of DAV:error and it's use in multistatus..", "content": "RE: Definition of DAV:error and it's use in multistatus...Peter,\n\nthe DTD isn't normative. It can't be. I think this was discussed to great\nlength on the ACL mailing list in December, but for some odd reason, the\narchive for this particular month is missing...\n\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Peter Raymond\n  Sent: Wednesday, February 06, 2002 6:14 PM\n  To: Clemm, Geoff; ietf-dav-versioning@w3.org\n  Subject: RE: Definition of DAV:error and it's use in multistatus...\n\n\n  Hi,\n\n  The DTD for DAV:responsedescription is:\n\n  <!ELEMENT responsedescription (#PCDATA) >\n\n  If you want to put the DAV:error element beneath DAV:responsedescription\n  then the DTD should be modified to something like:\n\n  <!ELEMENT responsedescription (#PCDATA | error)* >\n\n  This would allow a mix of character data and the DAV:error element.\n  As the DTD stands today it only allows character data.\n\n  Regards,\n  --\n  Peter Raymond - MERANT\n  Principal Architect (PVCS)\n  Tel: +44 (0)1727 813362\n  Fax: +44 (0)1727 869804\n  mailto:Peter.Raymond@merant.com\n  WWW: http://www.merant.com\n\n\n\n\n  -----Original Message-----\n  From: Clemm, Geoff [mailto:gclemm@rational.com]\n  Sent: 06 February 2002 13:06\n  To: ietf-dav-versioning@w3.org\n  Subject: RE: Definition of DAV:error and it's use in multistatus...\n\n\n\n  The rationale\n  for putting it in the DAV:responsedescription node\n  is that the DAV:responsedescription corresponds to\n  the \"body\" of a non-multi-status response, and\n  that is where the DAV:error node appears in a\n  non-multi-status response.\n\n  This does not violate the DTD for DAV:responsedescription,\n  because a client is required to ignore any node that it\n  doesn't understand, so it doesn't matter where you put it.\n\n  Cheers,\n  Geoff\n\n  -----Original Message-----\n  From: Peter Raymond [mailto:Peter.Raymond@merant.com]\n  Sent: Tuesday, February 05, 2002 4:13 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: Definition of DAV:error and it's use in multistatus...\n\n\n\n  Hi,\n  Section 1.6 of the DeltaV specification defines how the pre and post\n  condition XML\n  elements should be returned.  It says:\n  \"the appropriate XML element MUST be returned as the child of a top-level\n  DAV:error\n  element in the response body, unless otherwise negotiated by the request.\n  In a 207\n  Multi-Status response, the DAV:error element would appear in the\nappropriate\n\n  DAV:responsedescription element.\"\n  This is the only definiton of DAV:error, there is no DTD for this element\nas\n  far\n  as I can tell and no examples of it's use within a multistatus response.\n  It would seem to violate the DTD defined in RFC2518 for\n  DAV:responsedescription.\n  Am I correct in thinking that the syntax should be:\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <D:multistatus xmlns:D=\"DAV:\">\n      <D:response>\n        <D:href>http://www.merant.com/webdav/ws1/test.html</D:href>\n        <D:status>HTTP/1.1 409 CONFLICT</D:status>\n        <D:responsedescription>\n          <D:error>\n            <D:label-must-exist/>\n          </D:error>\n          Label specified does not exist\n        </D:responsedescription>\n      </D:response>\n    </D:multistatus>\n  The human readable text describing the error and the DAV:error element are\n  children\n  of the DAV:responsedescription element.  This seems very odd.  Why not\nhave\n  the\n  DAV:error element as a child of the DAV:response element?\n  Regards,\n  --\n  Peter Raymond - MERANT\n  Principal Architect (PVCS)\n  Tel: +44 (0)1727 813362\n  Fax: +44 (0)1727 869804\n  mailto:Peter.Raymond@merant.com\n  WWW: http://www.merant.com\n\n\n\n", "id": "lists-007-2886883"}, {"subject": "RE: Definition of DAV:error and it's use in multistatus..", "content": "I agree that if DeltaV had a DTD for DAV:responsedescription,\nthen it should take the form that you describe below,\nbut my point was that this does not violate the 2518 DTD for\nDAV:responsedescription, because you would first strip out\nall \"unknown\" element types (such as DAV:error) before checking\nit against the 2518 DTD.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Peter Raymond [mailto:Peter.Raymond@merant.com]\nSent: Wednesday, February 06, 2002 12:14 PM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: Definition of DAV:error and it's use in multistatus...\n\n\nHi, \nThe DTD for DAV:responsedescription is: \n<!ELEMENT responsedescription (#PCDATA) > \nIf you want to put the DAV:error element beneath DAV:responsedescription \nthen the DTD should be modified to something like: \n<!ELEMENT responsedescription (#PCDATA | error)* > \nThis would allow a mix of character data and the DAV:error element. \nAs the DTD stands today it only allows character data. \nRegards, \n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n\n\n\n-----Original Message----- \nFrom: Clemm, Geoff [mailto:gclemm@rational.com] \nSent: 06 February 2002 13:06 \nTo: ietf-dav-versioning@w3.org \nSubject: RE: Definition of DAV:error and it's use in multistatus... \n\n\nThe rationale \nfor putting it in the DAV:responsedescription node \nis that the DAV:responsedescription corresponds to \nthe \"body\" of a non-multi-status response, and \nthat is where the DAV:error node appears in a \nnon-multi-status response. \nThis does not violate the DTD for DAV:responsedescription, \nbecause a client is required to ignore any node that it \ndoesn't understand, so it doesn't matter where you put it. \nCheers, \nGeoff \n\n-----Original Message----- \nFrom: Peter Raymond [mailto:Peter.Raymond@merant.com] \nSent: Tuesday, February 05, 2002 4:13 PM \nTo: ietf-dav-versioning@w3.org \nSubject: Definition of DAV:error and it's use in multistatus... \n\n\nHi, \nSection 1.6 of the DeltaV specification defines how the pre and post \ncondition XML \nelements should be returned.  It says: \n\"the appropriate XML element MUST be returned as the child of a top-level \nDAV:error \nelement in the response body, unless otherwise negotiated by the request. \nIn a 207 \nMulti-Status response, the DAV:error element would appear in the appropriate\n\nDAV:responsedescription element.\" \nThis is the only definiton of DAV:error, there is no DTD for this element as\n\nfar \nas I can tell and no examples of it's use within a multistatus response. \nIt would seem to violate the DTD defined in RFC2518 for \nDAV:responsedescription. \nAm I correct in thinking that the syntax should be: \n<?xml version=\"1.0\" encoding=\"utf-8\" ?> \n  <D:multistatus xmlns:D=\"DAV:\"> \n    <D:response> \n      <D:href>http://www.merant.com/webdav/ws1/test.html</D:href> \n      <D:status>HTTP/1.1 409 CONFLICT</D:status> \n      <D:responsedescription> \n        <D:error> \n          <D:label-must-exist/> \n        </D:error> \n        Label specified does not exist \n      </D:responsedescription> \n    </D:response> \n  </D:multistatus> \nThe human readable text describing the error and the DAV:error element are \nchildren \nof the DAV:responsedescription element.  This seems very odd.  Why not have \nthe \nDAV:error element as a child of the DAV:response element? \nRegards, \n-- \nPeter Raymond - MERANT \nPrincipal Architect (PVCS) \nTel: +44 (0)1727 813362 \nFax: +44 (0)1727 869804 \nmailto:Peter.Raymond@merant.com \nWWW: http://www.merant.com \n\n\n\n", "id": "lists-007-2901846"}, {"subject": "COPY metho", "content": "Hi !\n\nI've two questions about the copy method :\n\n1) first, I've seen such an exemple :\n\nCOPY /~fielding/index.html HTTP/1.1\nHost : www.foo.bar\nDestination : http://www.foo.bar/users/f/fielding/index.html\n\nDoes that mean that I could, by copiyng the file index.html, rename it ?\nFor example, could I write :\n\nCOPY /~fielding/index.html HTTP/1.1\nHost : www.ics.uci.edu\nDestination : http://www.ics.uci.edu/users/f/fielding/summary.html\n\n\n2) then, it's about copy of collections.\n \nImagine we have a collection named 'container', with one internal member : index.html.\nIf I call this method :\n\nCOPY /container/ HTTP/1.1\nHost : www.foo.bar\nDestination : http://www.foo.bar/othercontainer/\nDepth : infinity\n...\n\nWhat will be the result ?\nI will have a new collection named 'othercontainer', with the member 'index.html', or the new collection 'othercontainer', containing itself the collection 'container' ?\n\n\nThanx\n\n\n\n", "id": "lists-007-2915103"}, {"subject": "RE: COPY metho", "content": "1) Yes, COPY choses the name of the destination resource.\n\n2) The former, i.e. you will have a new collection called\n\"othercontainer\" with a single internal member named index.html.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Elodie Tasia [mailto:e.tasia@ever-team.com]\nSent: Thursday, February 07, 2002 3:38 AM\nTo: IETF DAV\nSubject: COPY method\n\n\nHi !\n \nI've two questions about the copy method :\n \n1) first, I've seen such an exemple :\n \nCOPY /~fielding/index.html HTTP/1.1\nHost : www.foo.bar\nDestination : http://www.foo.bar/users/f/fielding/index.html\n \nDoes that mean that I could, by copiyng the file index.html, rename it ?\nFor example, could I write :\n \nCOPY /~fielding/index.html HTTP/1.1\nHost : www.ics.uci.edu\nDestination : http://www.ics.uci.edu/users/f/fielding/summary.html\n\n\n2) then, it's about copy of collections.\n\nImagine we have a collection named 'container', with one internal member :\nindex.html.\nIf I call this method :\n\nCOPY /container/ HTTP/1.1\nHost : www.foo.bar\nDestination : http://www.foo.bar/othercontainer/\nDepth : infinity\n...\n\nWhat will be the result ?\nI will have a new collection named 'othercontainer', with the member\n'index.html', or the new collection 'othercontainer', containing itself the\ncollection 'container' ?\n\n\nThanx\n\n\n\n", "id": "lists-007-2922826"}, {"subject": "Changelists and Propagation of the", "content": "Hi,\n\nsuppose this scenario:\n\nA developer collects its logical related work in a changelist. Once he/she\nis through with the work he/she submits the changelist. The changes then are\nvisible to all other developers. The changelist is closed, that is no more\ncheck-outs and changes can be done using this changelist. \nSome time later all relevant changes shall be propagated to a consolidation\ncode base. To get this done the relevant closed changelists will be\npropageted.\n\nIn terms of DeltaV a changelist would be an activity. The code bases for\ndevelopment and consolidation would be workspaces.\n\nImplementation of the process using DeltaV:\n\n1.Choice\nused features: workspaces, activities (no baselines used here)\nIn this implementation an activity must only contain working resources of\nvcr's of one workspace (in diffrence to the deltaV draft, but this behavior\nis within the boundries of deltaV as stateted on this list eralier). Once a\ncheckin is made on an activity the server will prevent any further\ncheck-outs to this activity. The activity is said to be closed. It is still\nin existence to use it for propagation purposes.\nThe consolidation workspace will be build using MERGE of an activity into a\nworkspace. (Would MERGE create a VCR in the destination workspace, if it\nwould not exist, to successfully merge a version of a vcr of the source\nworkspace into the destination?)\nA serious flaw in this implementation is the obvious violation of the deltaV\nactivity definition.\n\n2.Choice\nused features: workspaces, activities, baselines, labels\nIn this implementation an activity still must contain working resources of\none workspace only. After checkin of an activity the server creates a new\nbaseline of the workspace (due to the auto-version behavior of the version\ncontrolled configuration). This baseline gets an server defined label (a\nunique number of the \"changelist\") to identify a given changelist later. Due\nto the definition of the auto-version (checkout-checkin) behavior every\nchecked-in activity is represented by a single baseline. To propagate the\nchanges the labeled baselines are used.\nThe consolidation workspaces will be created using MKWORKSAPCE with\nreference to a baseline of the development workspace. Change propagation is\ndone with MERGE of a baseline into destination.\nProblems here: \na) How could a client get the server generated number of the changelist?\nb) To be precise an activity is not realy represented ba a baseline. Instead\nan activity is the difference between the baseline created at checkin of the\nactivity and the direct predecessor baseline. But if the server does a\ndifference storage of baselines this is no problem. A problem is the fact\nthat a merge of a baseline means a merge of the complete baseline. Resources\nwill be merged that are not part of the activity. And thats clearly not the\nthing thats meant by propagating a changelist. The latter would be achieved\nby the propagation of the diff instead.\n\nSo you see me a little confused. How to achieve the behavior I have in mind.\nBut maybe I oversee the easy way. Maybe there is just a little change in the\nprocess and everything falls into place easily instead.\nSo whats your experience concerning this process? Any hint is highly\nappreciated.\n\nThanks in advance\nDaniel\n\n\n\n", "id": "lists-007-2931014"}, {"subject": "RE: Changelists and Propagation of the", "content": "An activity would be a change list, yes.\nTo make an activity useful for change propagation,\neverything checked out to that activity should\nbe checked in, at which point the activity contains\na set of versions, and can be closed.\n\nTo propagate the changelist to a workspace,\nyou just MERGE that activity to that workspace.\n\nI would think at this point, you are done modeling\na changelist.  Perhaps I don't understand the problem\nyou are trying to solve?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Saturday, February 09, 2002 7:21 AM\nTo: 'ietf-dav-versioning@w3.org'\nSubject: Changelists and Propagation of them\n\n\nHi,\n\nsuppose this scenario:\n\nA developer collects its logical related work in a changelist. Once he/she\nis through with the work he/she submits the changelist. The changes then are\nvisible to all other developers. The changelist is closed, that is no more\ncheck-outs and changes can be done using this changelist. \nSome time later all relevant changes shall be propagated to a consolidation\ncode base. To get this done the relevant closed changelists will be\npropageted.\n\nIn terms of DeltaV a changelist would be an activity. The code bases for\ndevelopment and consolidation would be workspaces.\n\nImplementation of the process using DeltaV:\n\n1.Choice\nused features: workspaces, activities (no baselines used here)\nIn this implementation an activity must only contain working resources of\nvcr's of one workspace (in diffrence to the deltaV draft, but this behavior\nis within the boundries of deltaV as stateted on this list eralier). Once a\ncheckin is made on an activity the server will prevent any further\ncheck-outs to this activity. The activity is said to be closed. It is still\nin existence to use it for propagation purposes.\nThe consolidation workspace will be build using MERGE of an activity into a\nworkspace. (Would MERGE create a VCR in the destination workspace, if it\nwould not exist, to successfully merge a version of a vcr of the source\nworkspace into the destination?)\nA serious flaw in this implementation is the obvious violation of the deltaV\nactivity definition.\n\n2.Choice\nused features: workspaces, activities, baselines, labels\nIn this implementation an activity still must contain working resources of\none workspace only. After checkin of an activity the server creates a new\nbaseline of the workspace (due to the auto-version behavior of the version\ncontrolled configuration). This baseline gets an server defined label (a\nunique number of the \"changelist\") to identify a given changelist later. Due\nto the definition of the auto-version (checkout-checkin) behavior every\nchecked-in activity is represented by a single baseline. To propagate the\nchanges the labeled baselines are used.\nThe consolidation workspaces will be created using MKWORKSAPCE with\nreference to a baseline of the development workspace. Change propagation is\ndone with MERGE of a baseline into destination.\nProblems here: \na) How could a client get the server generated number of the changelist?\nb) To be precise an activity is not realy represented ba a baseline. Instead\nan activity is the difference between the baseline created at checkin of the\nactivity and the direct predecessor baseline. But if the server does a\ndifference storage of baselines this is no problem. A problem is the fact\nthat a merge of a baseline means a merge of the complete baseline. Resources\nwill be merged that are not part of the activity. And thats clearly not the\nthing thats meant by propagating a changelist. The latter would be achieved\nby the propagation of the diff instead.\n\nSo you see me a little confused. How to achieve the behavior I have in mind.\nBut maybe I oversee the easy way. Maybe there is just a little change in the\nprocess and everything falls into place easily instead.\nSo whats your experience concerning this process? Any hint is highly\nappreciated.\n\nThanks in advance\nDaniel\n\n\n\n", "id": "lists-007-2941606"}, {"subject": "DAV:workspac", "content": "Hi,\n\nas the DeltaV draft 20 states in the property sections 22.xx a version owns,\nbesides others, all properties of a DeltaV compoliant resource. Such a\nresource does have a DAV:workspace property. \nWhat happens to this property if there are two vcr's in differet workspaces\nhaving the same checked in version? Which value must be stored in\nDAV.workspace???\n\n\nRegards, \nDaniel \n\n\n\n", "id": "lists-007-2953096"}, {"subject": "Namespace Operations and Activitie", "content": "Hi,\n\nto track namespace operations I use version-controlled collections (vcc). I\nwant to track them additionally with activities. The obvious way to achieve\nthis is to checkout the collection(s) effected by this operation with an\nactivity, perform the operation and checkin the activity.\n\nQuestion:Is it allowed to give a DAV:activity-set in the body of the MOVE to\nautomatically checkout the collection with the given activity? Advantage:\nPerforming a MOVE it is ensured to have source and destination collection\ncehecked out into the same activity.\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2959910"}, {"subject": "RE: Version-controlled collection CHECKOU", "content": "Some more detail:\n\nI've checked out a collection. So I get a working collection. Now I put a\nfile to the working collection (adding a file to the repository). At checkin\na vcr for the newly added file is created (with all its dependend resources)\nthe checked in version of the collection is written to the\nactivity-version-set. What about the checked in version of the added file?\nIs it written to the DAV:activity-version-set property too?\n\nRegards,\nDaniel\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Mittwoch, 16. Januar 2002 15:59\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Version-controlled collection CHECKOUT\n\n\nYes.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Wednesday, January 16, 2002 8:36 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Version-controlled collection CHECKOUT\n\n\nHi,\n\ndoes the checkout behavior of a version-controlled collection be the same as\nthe checkout behavior of a version-controlled resource with\nDAV:apply-to-version flag? (Because of working-collection sounds similar to\nworking-resource) \nIs there the same behavior for parallel development (parallel checkouts,\ncheckin behavior) as for working-resources?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2967592"}, {"subject": "RE: workspac", "content": "Good catch, Daniel!\n\nThis is an error.  The DAV:workspace and\nDAV:version-controlled-configuration\nproperties should be defined on version-controlled and version-controllable\nresources, not on any resource.\n\nI propose that sections 22.2, 22.4, and 22.5 be updated to reflect this.\nAnyone object?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Monday, February 11, 2002 8:17 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: DAV:workspace\n\n\nHi,\n\nas the DeltaV draft 20 states in the property sections 22.xx a version owns,\nbesides others, all properties of a DeltaV compoliant resource. Such a\nresource does have a DAV:workspace property. \nWhat happens to this property if there are two vcr's in differet workspaces\nhaving the same checked in version? Which value must be stored in\nDAV.workspace???\n\n\nRegards, \nDaniel \n\n\n\n", "id": "lists-007-2976668"}, {"subject": "RE: Namespace Operations and Activitie", "content": "No, that is not functionality defined in the current protocol.\n\nThe closest you can come is to set the DAV:current-activity-set\nof the workspace, which means that all checkouts against VCR's\nin that workspace will be in those activities.\n\nOne reason this approach was taken is that it allows you to \nset the DAV:current-activity-set in an activity aware client,\nand then use activity unaware clients for all the other operations.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Monday, February 11, 2002 8:24 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Namespace Operations and Activities\n\n\nHi,\n\nto track namespace operations I use version-controlled collections (vcc). I\nwant to track them additionally with activities. The obvious way to achieve\nthis is to checkout the collection(s) effected by this operation with an\nactivity, perform the operation and checkin the activity.\n\nQuestion:Is it allowed to give a DAV:activity-set in the body of the MOVE to\nautomatically checkout the collection with the given activity? Advantage:\nPerforming a MOVE it is ensured to have source and destination collection\ncehecked out into the same activity.\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2984106"}, {"subject": "RE: Version-controlled collection CHECKOU", "content": "Good question.  The protocol does not explicitly require this,\nbut it sounds like a sensible thing for a server to do.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Monday, February 11, 2002 8:32 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Version-controlled collection CHECKOUT\n\n\nSome more detail:\n\nI've checked out a collection. So I get a working collection. Now I put a\nfile to the working collection (adding a file to the repository). At checkin\na vcr for the newly added file is created (with all its dependend resources)\nthe checked in version of the collection is written to the\nactivity-version-set. What about the checked in version of the added file?\nIs it written to the DAV:activity-version-set property too?\n\nRegards,\nDaniel\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Mittwoch, 16. Januar 2002 15:59\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Version-controlled collection CHECKOUT\n\n\nYes.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Wednesday, January 16, 2002 8:36 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Version-controlled collection CHECKOUT\n\n\nHi,\n\ndoes the checkout behavior of a version-controlled collection be the same as\nthe checkout behavior of a version-controlled resource with\nDAV:apply-to-version flag? (Because of working-collection sounds similar to\nworking-resource) \nIs there the same behavior for parallel development (parallel checkouts,\ncheckin behavior) as for working-resources?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-2992406"}, {"subject": "Creation of Workspace", "content": "Hi,\n\none way to create a workspace in reference to an existing one is to use\nMKWORKSPACE with referencing a baseline of the baseline-controlled source\nworkspace.\n\nIf I don't support baselines at all. How is this done then? (Given that a\nworkspace (collection) is under version-controll as well as all subordinate\ncollections.)\nIs it allowed that a workspace as collection (it is per definitionem) is\nunder version-control in terms of version-controlled collection? Would COPY\nprovide me the result I'm loking for?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3001659"}, {"subject": "RE: Creation of Workspace", "content": "If you don't support baselines, the only way to create a workspace\nthat has VCR's that select versions from existing VHR's is to issue\na separate VERSION-CONTROL request (identifying the desired version)\nto create each VCR.\n\n(And if you think, \"isn't that a fairly costly way of creating such\na workspace\", the answer is yes, and to avoid the cost, your server\ncan support baselines :-).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Monday, February 11, 2002 11:37 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Creation of Workspaces\n\n\nHi,\n\none way to create a workspace in reference to an existing one is to use\nMKWORKSPACE with referencing a baseline of the baseline-controlled source\nworkspace.\n\nIf I don't support baselines at all. How is this done then? (Given that a\nworkspace (collection) is under version-controll as well as all subordinate\ncollections.)\nIs it allowed that a workspace as collection (it is per definitionem) is\nunder version-control in terms of version-controlled collection? Would COPY\nprovide me the result I'm loking for?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3009612"}, {"subject": "RE: Creation of Workspace", "content": "Aplogies for following up on my own message, I neglected\nto observe a key element of Daniel's message, i.e. that\nthe collections are under version control.  In this case,\nyou would issue a single VERSION-CONTROL request on the\nworkspace (to select the version of the root collection),\nand then issue UPDATE requests against all the members of\nthe workspace, to select the desired versions of the members.\n\nAnd if you wanted to fake baselines with labels, you could\nlabel all the versions in the original workspace, and then\nuse a single UPDATE with a Depth:infinity and Label header.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@Rational.Com]\nSent: Monday, February 11, 2002 12:54 PM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Creation of Workspaces\n\n\nIf you don't support baselines, the only way to create a workspace\nthat has VCR's that select versions from existing VHR's is to issue\na separate VERSION-CONTROL request (identifying the desired version)\nto create each VCR.\n\n(And if you think, \"isn't that a fairly costly way of creating such\na workspace\", the answer is yes, and to avoid the cost, your server\ncan support baselines :-).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Monday, February 11, 2002 11:37 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Creation of Workspaces\n\n\nHi,\n\none way to create a workspace in reference to an existing one is to use\nMKWORKSPACE with referencing a baseline of the baseline-controlled source\nworkspace.\n\nIf I don't support baselines at all. How is this done then? (Given that a\nworkspace (collection) is under version-controll as well as all subordinate\ncollections.)\nIs it allowed that a workspace as collection (it is per definitionem) is\nunder version-control in terms of version-controlled collection? Would COPY\nprovide me the result I'm loking for?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3017909"}, {"subject": "RE: Creation of Workspace", "content": "That sounds good (not so good as using baselines, thats true). But the\nchecked in versions of the created version controlled resources/collections\nleft blank? set to version 1 of the version history? simply undefined?\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Montag, 11. Februar 2002 19:49\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Creation of Workspaces\n\n\nAplogies for following up on my own message, I neglected\nto observe a key element of Daniel's message, i.e. that\nthe collections are under version control.  In this case,\nyou would issue a single VERSION-CONTROL request on the\nworkspace (to select the version of the root collection),\nand then issue UPDATE requests against all the members of\nthe workspace, to select the desired versions of the members.\n\nAnd if you wanted to fake baselines with labels, you could\nlabel all the versions in the original workspace, and then\nuse a single UPDATE with a Depth:infinity and Label header.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@Rational.Com]\nSent: Monday, February 11, 2002 12:54 PM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Creation of Workspaces\n\n\nIf you don't support baselines, the only way to create a workspace\nthat has VCR's that select versions from existing VHR's is to issue\na separate VERSION-CONTROL request (identifying the desired version)\nto create each VCR.\n\n(And if you think, \"isn't that a fairly costly way of creating such\na workspace\", the answer is yes, and to avoid the cost, your server\ncan support baselines :-).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Monday, February 11, 2002 11:37 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Creation of Workspaces\n\n\nHi,\n\none way to create a workspace in reference to an existing one is to use\nMKWORKSPACE with referencing a baseline of the baseline-controlled source\nworkspace.\n\nIf I don't support baselines at all. How is this done then? (Given that a\nworkspace (collection) is under version-controll as well as all subordinate\ncollections.)\nIs it allowed that a workspace as collection (it is per definitionem) is\nunder version-control in terms of version-controlled collection? Would COPY\nprovide me the result I'm loking for?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3027252"}, {"subject": "MERGE of Activit", "content": "Hi,\n\nsuppose this (strange) case:\n\n1. A file F was added to the repository.\nWith checking out the version-controlled collection  C with an activity A1\nwith apply-to-version, putting the file to the working collection, checking\nin the activity (new version CV2 of the collection  and first version FV1 of\nthe added file going to activity-version-set property)\n\n2. Change a property of the collection C \nWith checking out C with activity A2 with apply-to-version, proppatch and\ncheckin of A2. Version CV3 goes to the activity-version-set.\n\n3. Now MERGE activity A2 to a collection C' in a different workspace. C'\ndoes not contain the file F yet, because activity A1 was not merged to C'.\nWhat happens here? Well the merge of CV3 into C' would succeed. But what\nabout the binding to F? Will there be a new VCR for F pointing to the\nversion-history of F with checked in version of that vcr is undefined?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3037414"}, {"subject": "RE: Subversion/WebDA", "content": "   From: Julian Reschke [mailto:julian.reschke@gmx.de]\n\n   > From: Greg Stein [mailto:gstein@lyra.org]\n   >\n   > On Mon, Feb 11, 2002 at 11:47:51AM +0100, Julian Reschke wrote:\n\n   > > Subversion reports the DAV:version-name property for VCRs. This\n   > > breaks our WebDAV adapter which assumes that the presence of\n   > > this property indicates that this is a version resource.\n\n   > Hmm. It isn't supposed to do that? I thought a VCR was supposed\n   > to have a copy of all the version's properties. Is\n   > DAV:version-name excluded from that? Am I mis-remembering\n   > something?\n\n   Good question. Maybe this needs to be clarified in DeltaV\n   (Geoff?). As I said, we are using the presence of this property to\n   detect that something is a version resource.\n\nA VCR should have a copy of all the version's *dead* properties,\nbut definitely should not have a copy of the version's live\nproperties (since, as in Julian's case, clients will use the\npresence and absence of these live properties to determine\nwhat kind of resource is there).\n\nIn particular, you will note in 22.5 that a VCR does not have\na DAV:version-name, while in 22.6, it states that a version does.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3045221"}, {"subject": "MERGE von Collection", "content": "Hi,\n\nsimple question: How is a MERGE of collection versions done? Is it just a\nproppatch to DAV:version-controlled-binding-set?\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3053734"}, {"subject": "RE: Creation of Workspace", "content": "The checked-in version of a member of the \nversion-controlled collection is server-defined\n(could be version 1, but doesn't have to be),\nuntil the client explicitly specifies the version\nin the UPDATE request.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Tuesday, February 12, 2002 5:25 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Creation of Workspaces\n\n\nThat sounds good (not so good as using baselines, thats true). But the\nchecked in versions of the created version controlled resources/collections\nleft blank? set to version 1 of the version history? simply undefined?\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Montag, 11. Februar 2002 19:49\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Creation of Workspaces\n\n\nAplogies for following up on my own message, I neglected\nto observe a key element of Daniel's message, i.e. that\nthe collections are under version control.  In this case,\nyou would issue a single VERSION-CONTROL request on the\nworkspace (to select the version of the root collection),\nand then issue UPDATE requests against all the members of\nthe workspace, to select the desired versions of the members.\n\nAnd if you wanted to fake baselines with labels, you could\nlabel all the versions in the original workspace, and then\nuse a single UPDATE with a Depth:infinity and Label header.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@Rational.Com]\nSent: Monday, February 11, 2002 12:54 PM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: Creation of Workspaces\n\n\nIf you don't support baselines, the only way to create a workspace\nthat has VCR's that select versions from existing VHR's is to issue\na separate VERSION-CONTROL request (identifying the desired version)\nto create each VCR.\n\n(And if you think, \"isn't that a fairly costly way of creating such\na workspace\", the answer is yes, and to avoid the cost, your server\ncan support baselines :-).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Monday, February 11, 2002 11:37 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Creation of Workspaces\n\n\nHi,\n\none way to create a workspace in reference to an existing one is to use\nMKWORKSPACE with referencing a baseline of the baseline-controlled source\nworkspace.\n\nIf I don't support baselines at all. How is this done then? (Given that a\nworkspace (collection) is under version-controll as well as all subordinate\ncollections.)\nIs it allowed that a workspace as collection (it is per definitionem) is\nunder version-control in terms of version-controlled collection? Would COPY\nprovide me the result I'm loking for?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3061390"}, {"subject": "RE: MERGE of Activit", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   suppose this (strange) case:\n\n   1. A file F was added to the repository.  With checking out the\n   version-controlled collection C with an activity A1 with\n   apply-to-version, putting the file to the working collection,\n   checking in the activity (new version CV2 of the collection and\n   first version FV1 of the added file going to activity-version-set\n   property)\n\n   2. Change a property of the collection C \n   With checking out C with activity A2 with apply-to-version, proppatch and\n   checkin of A2. Version CV3 goes to the activity-version-set.\n\n   3. Now MERGE activity A2 to a collection C' in a different workspace. C'\n   does not contain the file F yet, because activity A1 was not merged to\nC'.\n   What happens here? Well the merge of CV3 into C' would succeed. But what\n   about the binding to F? Will there be a new VCR for F pointing to the\n   version-history of F with checked in version of that vcr is undefined?\n\nYes.\n\nNote that some CM systems will say \"CV3 depends on CV2, and CV2\nis produced by A1, so you can't MERGE A2 unless you also MERGE A1\",\nbut that is not required by DeltaV.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3071772"}, {"subject": "RE: MERGE von Collection", "content": "The DAV:version-controlled-binding-set is a readonly property\non a collection version.\n\nTo merge a collection version:\n\nTo merge members of the collection version CV1\ninto working collection WC2, you\nwould checkout CV1 (to get WC1), MOVE the members of\nWC1 that you want into WC2, and then DELETE WC1.\n\nTo merge members of the collection version CV1\ninto checked-out version-controlled collection, VC2,\nyou would need to select particular versions of\nthe version histories identified by the \nDAV:version-controlled-binding-set of CV1,\nand then use VERSION-CONTROL requests to create\nversion-controlled resources for those versions\nin VC2.  Or if you are lucky, your server supports\n\"auto-merge\" for collections, and the server does this\nall for you.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Tuesday, February 12, 2002 8:14 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: MERGE von Collections\n\n\nHi,\n\nsimple question: How is a MERGE of collection versions done? Is it just a\nproppatch to DAV:version-controlled-binding-set?\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3079821"}, {"subject": "3 workspaces and merge", "content": "Hi,\n\nthis one is a bit more tricky. Look at this:\n\nThere are 3 workspaces WS1,WS2,WS3. \nIn WS1 there is a tree of resources as follows:\n\nWS1 (checked-in: WS1V1)\n |\n       +-- A (checked-in: AV1)\n           |\n           +-- B (checked-in: BV1)\n           |   |\n           |   +-- F (checked-in: FV1)\n           |\n           +-- X (checked-in: XV1)\n\nWS2 was created in reference to W1. WS3 was created in reference to WS2.\nAll workspaces containing version-controlled resources/collections sharing\ntheir version-histories. Noc changes made in WS2 and WS3 after creation.\n\nNow there is a change in WS1: A gets a new member Y and B is deleted,\nresulting in a new version of A (AV2) and a version for Y (YV1). This change\nwas made using activity ACT1.\n\nNow workspace WS1 looks this way:\n\nWS1 (checked-in: WS1V1)\n |\n       +-- A (checked-in: AV2)\n           |\n           +-- X (checked-in: XV1)\n           |\n           +-- Y (checked-in: YV1)\n\nWS2 and WS3 still not changed at all. Now the change in WS1 has to be\npropageted to WS3. This is done with MERGE oft ACT1 into WS3. With that WS3\nlooks like WS1:\n\nWS3 (checked-in: WS1V1)\n |\n       +-- A (checked-in: AV2)\n           |\n           +-- X (checked-in: XV1)\n           |\n           +-- Y (checked-in: YV1)\n\nSo far so good nothing strange happend til now.\nIn WS2 in ACT2 a new version of /WS2/A/B/F was checked in. \nIn ACT3 A gets a new member C. With all that WS2 looks this way:\n\nWS2 (checked-in: WS1V1)\n |\n       +-- A (checked-in: AV3)\n           |\n           +-- B (checked-in: BV1)\n           |   |\n           |   +-- F (checked-in: FV2)\n           |\n           +-- X (checked-in: XV1)\n           |\n           +-- C (checked-in: CV1)\n\nAfter all that actions there is a version tree of A looking this way:\n\n AV1\n | \\\n       |  \\\n     AV2   AV3\n \nWith checked-in version of /WS1/A and /WS3/A is AV2 and checked-in version\nof /WS2/A is AV3.\n\nSo finally the starting point is constructed. Let the show begin:\n\nMERGE ACT3 into WS3\nThat is the new member C of A has to appear in WS3. Due to the fact that\nversion AV3 of the merge source /WS2/A is not a successor of the version AV2\nof the merge destination /WS3/A the MERGE will fail (no-checkout flag is\nset). Although the appearence of could be handled by the server\nautomatically. But what about /WS3/A/B? Depending on the merge applied B is\nstill deleted or B is alive again. If B is alive again, what happens to the\nchecked-in version of B? Must it be set manually to the \"right\" version?\nWould the complete subtree rooted at B appear again? (Suppose yes)\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3088075"}, {"subject": "RE: 3 workspaces and merge", "content": "When merging ACT3 into WS3, you are telling the server that you just\nwant the \"delta\" implied by ACT3.  The delta is that there is a new\nmember of A (called C) and that there is a new version of C (CV1).  If\nthe client (or the server) decides to \"restore\" A/B as part of the\nmerge, the server has no way of guessing which version of B should be\nrestored, so it just picks some arbitrary version (possibly the\ninitial version).\n\nIf on the other hand, baselines were created and merged (instead of\nthe activities), the baseline from WS2 would know what version of B\nwas selected at the time the baseline was created, and would select\nthat version to be the result of restoring A/B.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Tuesday, February 12, 2002 8:56 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: 3 workspaces and merges\n\n\nHi,\n\nthis one is a bit more tricky. Look at this:\n\nThere are 3 workspaces WS1,WS2,WS3. \nIn WS1 there is a tree of resources as follows:\n\nWS1 (checked-in: WS1V1)\n |\n       +-- A (checked-in: AV1)\n           |\n           +-- B (checked-in: BV1)\n           |   |\n           |   +-- F (checked-in: FV1)\n           |\n           +-- X (checked-in: XV1)\n\nWS2 was created in reference to W1. WS3 was created in reference to WS2.\nAll workspaces containing version-controlled resources/collections sharing\ntheir version-histories. Noc changes made in WS2 and WS3 after creation.\n\nNow there is a change in WS1: A gets a new member Y and B is deleted,\nresulting in a new version of A (AV2) and a version for Y (YV1). This change\nwas made using activity ACT1.\n\nNow workspace WS1 looks this way:\n\nWS1 (checked-in: WS1V1)\n |\n       +-- A (checked-in: AV2)\n           |\n           +-- X (checked-in: XV1)\n           |\n           +-- Y (checked-in: YV1)\n\nWS2 and WS3 still not changed at all. Now the change in WS1 has to be\npropageted to WS3. This is done with MERGE oft ACT1 into WS3. With that WS3\nlooks like WS1:\n\nWS3 (checked-in: WS1V1)\n |\n       +-- A (checked-in: AV2)\n           |\n           +-- X (checked-in: XV1)\n           |\n           +-- Y (checked-in: YV1)\n\nSo far so good nothing strange happend til now.\nIn WS2 in ACT2 a new version of /WS2/A/B/F was checked in. \nIn ACT3 A gets a new member C. With all that WS2 looks this way:\n\nWS2 (checked-in: WS1V1)\n |\n       +-- A (checked-in: AV3)\n           |\n           +-- B (checked-in: BV1)\n           |   |\n           |   +-- F (checked-in: FV2)\n           |\n           +-- X (checked-in: XV1)\n           |\n           +-- C (checked-in: CV1)\n\nAfter all that actions there is a version tree of A looking this way:\n\n AV1\n | \\\n       |  \\\n     AV2   AV3\n \nWith checked-in version of /WS1/A and /WS3/A is AV2 and checked-in version\nof /WS2/A is AV3.\n\nSo finally the starting point is constructed. Let the show begin:\n\nMERGE ACT3 into WS3\nThat is the new member C of A has to appear in WS3. Due to the fact that\nversion AV3 of the merge source /WS2/A is not a successor of the version AV2\nof the merge destination /WS3/A the MERGE will fail (no-checkout flag is\nset). Although the appearence of could be handled by the server\nautomatically. But what about /WS3/A/B? Depending on the merge applied B is\nstill deleted or B is alive again. If B is alive again, what happens to the\nchecked-in version of B? Must it be set manually to the \"right\" version?\nWould the complete subtree rooted at B appear again? (Suppose yes)\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3097639"}, {"subject": "Cascading creation of collection", "content": "HI,\n\nthis is just for clearification of my understanding:\n\nEnvironment:\nworkspaces WS1 and WS2\nversion-controlled collections. MKCOL creates version-controlled collectins\nby default.\n\nSuppose following sequence of changes each made with a single activity\n\nActivity A1  MKCOL /WS1/A       Version WSV1 w. binding A, Version AV1 w.\nbinding NULL\nActivity A2 MKCOL /WS1/A/B     Version AV2 w. binding B, Version BV1 w.\nbinding NULL\nActivity A3  MKCOL /WS1/A/B/C   Version BV2 w. binding C, Version CV1 w.\nbinding NULL\nActivity A4  MKCOL /WS1/A/D     Version AV3 w. binding B,D  Version DV1 w.\nbinding NULL\n\nDespite the d?pendecies of the activities/changes perfromed above activity\nA4 is merged into WS2 w/o merging A1 trough A3.\n\nActivity A4 contains versions AV3 and DV1.\nDue to the MERGE behavior this MERGE must fail cause collection /WS2/A does\nnot exist yet. Therefore no merge target exists. That is, to propagate\nactivity A4 first activity A1 has to be propagated, what would cause the\ncreation of /WS2/A. A subsequent MERGE of activity A4 would cause the\ncreation of /WS2/A/D. In this case the server can even set the checked-in\nversion to the \"right\" one, cause the activity contains the \"right\" version\nfor /WS2/A/D in its activity-version-set property. \nFor the other binding B there is no version known. If the server does no\nguessing of versions and just sets it to version BV1 or leave it blank. The\ncascade of creations would stop here.\nIf the server would look up the MERGE source and uses the checked-in version\nthere to guess the checked-in version of /WS2/A/B then the cascade would go\non.\n\nRight so far?\n\nThis rises a question dealing with populating a workspace with reference to\nanother worksapce using VERSION-CONTROL Geoff described few days ago. If the\nserver does no guessing then the cascading creation of the resource tree\nwould stop after depth 1???\n\nOr do I miss a detail here?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3108094"}, {"subject": "RE: Cascading creation of collection", "content": "Apologies!\nI forgot to remark that the problem partly arises due to the out of order\nrespectivly incomplete propagation of dependent changes. \n\n-----Original Message-----\nFrom: Kirmse, Daniel \nSent: Mittwoch, 13. Februar 2002 10:10\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Cascading creation of collections\n\n\nHI,\n\nthis is just for clearification of my understanding:\n\nEnvironment:\nworkspaces WS1 and WS2\nversion-controlled collections. MKCOL creates version-controlled collectins\nby default.\n\nSuppose following sequence of changes each made with a single activity\n\nActivity A1  MKCOL /WS1/A       Version WSV1 w. binding A, Version AV1 w.\nbinding NULL\nActivity A2 MKCOL /WS1/A/B     Version AV2 w. binding B, Version BV1 w.\nbinding NULL\nActivity A3  MKCOL /WS1/A/B/C   Version BV2 w. binding C, Version CV1 w.\nbinding NULL\nActivity A4  MKCOL /WS1/A/D     Version AV3 w. binding B,D  Version DV1 w.\nbinding NULL\n\nDespite the d?pendecies of the activities/changes perfromed above activity\nA4 is merged into WS2 w/o merging A1 trough A3.\n\nActivity A4 contains versions AV3 and DV1.\nDue to the MERGE behavior this MERGE must fail cause collection /WS2/A does\nnot exist yet. Therefore no merge target exists. That is, to propagate\nactivity A4 first activity A1 has to be propagated, what would cause the\ncreation of /WS2/A. A subsequent MERGE of activity A4 would cause the\ncreation of /WS2/A/D. In this case the server can even set the checked-in\nversion to the \"right\" one, cause the activity contains the \"right\" version\nfor /WS2/A/D in its activity-version-set property. \nFor the other binding B there is no version known. If the server does no\nguessing of versions and just sets it to version BV1 or leave it blank. The\ncascade of creations would stop here.\nIf the server would look up the MERGE source and uses the checked-in version\nthere to guess the checked-in version of /WS2/A/B then the cascade would go\non.\n\nRight so far?\n\nThis rises a question dealing with populating a workspace with reference to\nanother worksapce using VERSION-CONTROL Geoff described few days ago. If the\nserver does no guessing then the cascading creation of the resource tree\nwould stop after depth 1???\n\nOr do I miss a detail here?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3117469"}, {"subject": "Selective propagation of change", "content": "Hi,\n\nsuppose in workspace WS1 there is a collection C containing two Files F1,\nF2. F1 was created with activity A1 and F2 was created with activity A2.\nSubsequent changes to F1 were made with activity A3 and for F2 activity A4\nwas used for this purpose.\n\nfurther suppose in WS2 there allready is a collection C w/o any members\n(created with earlier MERGES).\n\nFor some reasons I only want to propagate F2 (cause F1 is not ready yet or\nsecret or ...). The MERGE of A4 into WS2 would fail cause F2 does not exist.\nSo first I have to MERGE activity A2. Doing this I MERGE a version of /WS1/C\ninto WS2 that contains a binding to F1. Due to that a vcr for F1 has to be\ncreated. Thats definitely not what I want to have. \n\nSo merging the Activity A2 is not an good idea. Only with activity A2 there\nwas just the creation of F2. And I just want to propagate this creation. But\nI get other stuff as well. Is this a) right b) \"sensible\"\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3126956"}, {"subject": "RE: MERGE von Collection", "content": "-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Dienstag, 12. Februar 2002 14:41\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: MERGE von Collections\n\n\nThe DAV:version-controlled-binding-set is a readonly property\non a collection version.\n\nTo merge a collection version:\n\nTo merge members of the collection version CV1\ninto working collection WC2, you\nwould checkout CV1 (to get WC1), MOVE the members of\nWC1 that you want into WC2, and then DELETE WC1.\n\nThis method applies if the server supports working resources / working\ncollections, right?\n\nTo merge members of the collection version CV1\ninto checked-out version-controlled collection, VC2,\nyou would need to select particular versions of\nthe version histories identified by the \nDAV:version-controlled-binding-set of CV1,\nand then use VERSION-CONTROL requests to create\nversion-controlled resources for those versions\nin VC2.  Or if you are lucky, your server supports\n\"auto-merge\" for collections, and the server does this\nall for you.\n\nAnd this if it does not support this, right?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Tuesday, February 12, 2002 8:14 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: MERGE von Collections\n\n\nHi,\n\nsimple question: How is a MERGE of collection versions done? Is it\njust a\nproppatch to DAV:version-controlled-binding-set?\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3135323"}, {"subject": "RE: MERGE von Collection", "content": ">To merge members of the collection version CV1\n>into working collection WC2, you\n>would checkout CV1 (to get WC1), MOVE the members of\n>WC1 that you want into WC2, and then DELETE WC1.\n\nAnd this would apply independently of the fact wether the collection\nversions are versions of the same version-controlled collection or they are\nversions of two independent version-controlled collections?\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Dienstag, 12. Februar 2002 14:41\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: MERGE von Collections\n\n\nThe DAV:version-controlled-binding-set is a readonly property\non a collection version.\n\nTo merge a collection version:\n\nTo merge members of the collection version CV1\ninto working collection WC2, you\nwould checkout CV1 (to get WC1), MOVE the members of\nWC1 that you want into WC2, and then DELETE WC1.\n\nTo merge members of the collection version CV1\ninto checked-out version-controlled collection, VC2,\nyou would need to select particular versions of\nthe version histories identified by the \nDAV:version-controlled-binding-set of CV1,\nand then use VERSION-CONTROL requests to create\nversion-controlled resources for those versions\nin VC2.  Or if you are lucky, your server supports\n\"auto-merge\" for collections, and the server does this\nall for you.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Tuesday, February 12, 2002 8:14 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: MERGE von Collections\n\n\nHi,\n\nsimple question: How is a MERGE of collection versions done? Is it just a\nproppatch to DAV:version-controlled-binding-set?\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3144382"}, {"subject": "Philosophical: Batch processin", "content": "Hi,\n\nI have a philosophical question dealing with batch processing in DeltaV. Is\nit right to suppose that batch processing functionality must be provided by\nthe client? \nWell lets take an example. Merging a workspace (containing a complete\ncodeline) into another workspace may be a huge task to fullfill. Typically\nsuch tasks/jobs would be startet in batch mode. So a client could or would\nhave to provide a scheduler that is the tool for scheduling batch jobs.\nProblem is that the server would reply instantly when the request is\ncompletely performed. The client would have to store the replies to provide\nthem as soon as they are requested.\nThis is definitly a way to it. But what about this MERGE above? Typically\nthe reply contains failed merges that have to be handled somehow. Performing\nsuch a MERGE would raise failures that different developers have to handle.\nSo a central batch processing support would be a nice thing. Anyway you\nstill could have an administrator client that provides batch processing and\nmessaging of failures to the developer responsible.\n\nDoes anyone has experiences with this topic? Oppinons?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3153667"}, {"subject": "RE: Cascading creation of collection", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   Environment: workspaces WS1 and WS2 version-controlled\n   collections. MKCOL creates version-controlled collectins by\n   default.\n\n   Suppose following sequence of changes each made with a single activity\n\n   Activity A1  MKCOL /WS1/A       Version WSV1 w. binding A, Version AV1 w.\n   binding NULL\n   Activity A2 MKCOL /WS1/A/B     Version AV2 w. binding B, Version BV1 w.\n   binding NULL\n   Activity A3  MKCOL /WS1/A/B/C   Version BV2 w. binding C, Version CV1 w.\n   binding NULL\n   Activity A4  MKCOL /WS1/A/D     Version AV3 w. binding B,D  Version DV1\nw.\n   binding NULL\n\n   Despite the d?pendecies of the activities/changes perfromed above\n   activity A4 is merged into WS2 w/o merging A1 trough A3.\n\n   Activity A4 contains versions AV3 and DV1.  Due to the MERGE\n   behavior this MERGE must fail cause collection /WS2/A does not\n   exist yet. Therefore no merge target exists.\n\nThe MERGE of A4 into WS2 succeeds, but produces no effect on WS2\n(because there are not VCR's for the version histories of AV3 or DV1\nin WS2).  If the client wants to detect this, it needs to first use\nthe DAV:merge-preview REPORT, which will return AV3 and DV1 in\nignore-preview elements.\n\n   That is, to propagate\n   activity A4 first activity A1 has to be propagated, what would cause the\n   creation of /WS2/A.\n\nYes, if by \"propagate\" you mean \"expose the versions in the\nDAV:activity-version-set\".\n\n   A subsequent MERGE of activity A4 would cause the creation of\n   /WS2/A/D.  In this case the server can even set the checked-in\n   version to the \"right\" one, cause the activity contains the \"right\"\n   version for /WS2/A/D in its activity-version-set property.\n\nYes.\n\n   For the other binding B there is no version known. If the server does no\n   guessing of versions and just sets it to version BV1 or leave it blank.\n\nActually, it can't leave it \"blank\" ... it has to pick some version,\nand if BV1 is the only version, that will be the one it will have to\npick.\n\n   The cascade of creations would stop here.\n\nYes.\n\n   If the server would look up the MERGE source and uses the\n   checked-in version there to guess the checked-in version of\n   /WS2/A/B then the cascade would go on. Right so far?\n\nCan you be more specific about what you mean by \"look up the MERGE source\",\nand how that would help it guess the checked-in version of /WS2/A/B?\n\n   This rises a question dealing with populating a workspace with\n   reference to another worksapce using VERSION-CONTROL Geoff\n   described few days ago. If the server does no guessing then the\n   cascading creation of the resource tree would stop after depth 1???\n\n   Or do I miss a detail here?\n\nSuppose you did VERSION-CONTROL to set the version selected\nby /WS2/A to be AV2.  The server will automatically create the VCR\n/WS2/A/B.  The server gets to pick which version to initialize the\nnew VCR with, and suppose it picks BV2.  Then it has to automatically\ncreate the VCR /WS2/A/B/C, has to pick which version to initialize\nthis new VCR with.  So in general, if the server picks versions\nthat have members, it can end up populating an entire tree as\nthe result of a single VERSION-CONTROl request.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3161885"}, {"subject": "RE: MERGE von Collection", "content": "Yes, to both questions.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Wednesday, February 13, 2002 4:42 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: MERGE von Collections\n\n\n\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Dienstag, 12. Februar 2002 14:41\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: MERGE von Collections\n\n\nThe DAV:version-controlled-binding-set is a readonly property\non a collection version.\n\nTo merge a collection version:\n\nTo merge members of the collection version CV1\ninto working collection WC2, you\nwould checkout CV1 (to get WC1), MOVE the members of\nWC1 that you want into WC2, and then DELETE WC1.\n\nThis method applies if the server supports working resources / working\ncollections, right?\n\nTo merge members of the collection version CV1\ninto checked-out version-controlled collection, VC2,\nyou would need to select particular versions of\nthe version histories identified by the \nDAV:version-controlled-binding-set of CV1,\nand then use VERSION-CONTROL requests to create\nversion-controlled resources for those versions\nin VC2.  Or if you are lucky, your server supports\n\"auto-merge\" for collections, and the server does this\nall for you.\n\nAnd this if it does not support this, right?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Tuesday, February 12, 2002 8:14 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: MERGE von Collections\n\n\nHi,\n\nsimple question: How is a MERGE of collection versions done? Is it\njust a\nproppatch to DAV:version-controlled-binding-set?\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3172513"}, {"subject": "RE: MERGE von Collection", "content": "Yes.\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Wednesday, February 13, 2002 5:37 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: RE: MERGE von Collections\n\n\n>To merge members of the collection version CV1\n>into working collection WC2, you\n>would checkout CV1 (to get WC1), MOVE the members of\n>WC1 that you want into WC2, and then DELETE WC1.\n\nAnd this would apply independently of the fact wether the collection\nversions are versions of the same version-controlled collection or they are\nversions of two independent version-controlled collections?\n\n\n\n", "id": "lists-007-3181881"}, {"subject": "RE: Philosophical: Batch processin", "content": "I wouldn't really call this \"batch processing\", but in case the\nresponse to a request (such as MERGE) implies a series of actions\nthat need to be done by a client (such as resolving the merge\nconflicts), it would be friendly for a client to guide the user\nwrt what actions still need to be performed.  In the case of the\nMERGE method, the information about what actions still need to\nbe performed is maintained on the server (in the DAV:merge-set and\nDAV:auto-merge-set of the VCRs in a workspace), so a client can\nalways retrieve this information from the server (e.g. by a\nDepth:infinity PROPFIND on the workspace for the DAV:merge-set\nand DAV:auto-merge-set properties).\n\nCheers,\nGeoff \n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Wednesday, February 13, 2002 7:52 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: Philosophical: Batch processing\n\n\nHi,\n\nI have a philosophical question dealing with batch processing in DeltaV. Is\nit right to suppose that batch processing functionality must be provided by\nthe client? \nWell lets take an example. Merging a workspace (containing a complete\ncodeline) into another workspace may be a huge task to fullfill. Typically\nsuch tasks/jobs would be startet in batch mode. So a client could or would\nhave to provide a scheduler that is the tool for scheduling batch jobs.\nProblem is that the server would reply instantly when the request is\ncompletely performed. The client would have to store the replies to provide\nthem as soon as they are requested.\nThis is definitly a way to it. But what about this MERGE above? Typically\nthe reply contains failed merges that have to be handled somehow. Performing\nsuch a MERGE would raise failures that different developers have to handle.\nSo a central batch processing support would be a nice thing. Anyway you\nstill could have an administrator client that provides batch processing and\nmessaging of failures to the developer responsible.\n\nDoes anyone has experiences with this topic? Oppinons?\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3189404"}, {"subject": "RE: Cascading creation of collection", "content": "> -----Original Message-----\n> From: Clemm, Geoff [mailto:gclemm@rational.com]\n> Sent: Mittwoch, 13. Februar 2002 14:51\n> To: Ietf-Dav-Versioning (E-mail)\n> Subject: RE: Cascading creation of collections\n> \n> \n>    From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n> \n>    Environment: workspaces WS1 and WS2 version-controlled\n>    collections. MKCOL creates version-controlled collectins by\n>    default.\n> \n>    Suppose following sequence of changes each made with a \n> single activity\n> \n>    Activity A1  MKCOL /WS1/A       Version WSV1 w. binding A, \n> Version AV1 w.\n>    binding NULL\n>    Activity A2 MKCOL /WS1/A/B     Version AV2 w. \n> binding B, Version BV1 w.\n>    binding NULL\n>    Activity A3  MKCOL /WS1/A/B/C   Version BV2 w. binding C, \n> Version CV1 w.\n>    binding NULL\n>    Activity A4  MKCOL /WS1/A/D     Version AV3 w. binding B,D \n>  Version DV1\n> w.\n>    binding NULL\n> \n>    Despite the d?pendecies of the activities/changes perfromed above\n>    activity A4 is merged into WS2 w/o merging A1 trough A3.\n> \n>    Activity A4 contains versions AV3 and DV1.  Due to the MERGE\n>    behavior this MERGE must fail cause collection /WS2/A does not\n>    exist yet. Therefore no merge target exists.\n> \n> The MERGE of A4 into WS2 succeeds, but produces no effect on WS2\n> (because there are not VCR's for the version histories of AV3 or DV1\n> in WS2).  If the client wants to detect this, it needs to first use\n> the DAV:merge-preview REPORT, which will return AV3 and DV1 in\n> ignore-preview elements.\n> \n>    That is, to propagate\n>    activity A4 first activity A1 has to be propagated, what \n> would cause the\n>    creation of /WS2/A.\n> \n> Yes, if by \"propagate\" you mean \"expose the versions in the\n> DAV:activity-version-set\".\n> \n\nPropagate = MERGE\n\n>    A subsequent MERGE of activity A4 would cause the creation of\n>    /WS2/A/D.  In this case the server can even set the checked-in\n>    version to the \"right\" one, cause the activity contains the \"right\"\n>    version for /WS2/A/D in its activity-version-set property.\n> \n> Yes.\n> \n>    For the other binding B there is no version known. If the \n> server does no\n>    guessing of versions and just sets it to version BV1 or \n> leave it blank.\n> \n> Actually, it can't leave it \"blank\" ... it has to pick some version,\n> and if BV1 is the only version, that will be the one it will have to\n> pick.\n> \n>    The cascade of creations would stop here.\n> \n> Yes.\n> \n>    If the server would look up the MERGE source and uses the\n>    checked-in version there to guess the checked-in version of\n>    /WS2/A/B then the cascade would go on. Right so far?\n> \n> Can you be more specific about what you mean by \"look up the \n> MERGE source\",\n> and how that would help it guess the checked-in version of /WS2/A/B?\n\nWell the MERGE request gives source and destination. So if WS1 is merged\ninto WS2 the source is clear to be WS1. With that I know the VCR's/VCC's of\nWS1 for instance /WS1/A, /WS1/A/B, /WS1/A/D. For every binding stored with\ncollection version AV2 (that is B and D I could find the corresponding vcr\nin WS1 and read the checked-in version property)\n\nBut anyway the MERGE done above was made merging an activity into an\nworkspace. In this case there is no way of guessing right, cause the\nchecked-in version of /WS1/A/B is not stored anywhere and the VCC that was\nused for checkout of the collection version AV2 is not known within the\nactivity.\nTo give the server a chance of right guessing in this case, there has to be\nsome more informaton to be maintained by the server internally. But even\nthat could be ambigious in some cases. And maybe the effort implementing it\nwould not equal the income ...\n\n> \n>    This rises a question dealing with populating a workspace with\n>    reference to another worksapce using VERSION-CONTROL Geoff\n>    described few days ago. If the server does no guessing then the\n>    cascading creation of the resource tree would stop after depth 1???\n> \n>    Or do I miss a detail here?\n> \n> Suppose you did VERSION-CONTROL to set the version selected\n> by /WS2/A to be AV2.  The server will automatically create the VCR\n> /WS2/A/B.  The server gets to pick which version to initialize the\n> new VCR with, and suppose it picks BV2.  Then it has to automatically\n> create the VCR /WS2/A/B/C, has to pick which version to initialize\n> this new VCR with.  So in general, if the server picks versions\n> that have members, it can end up populating an entire tree as\n> the result of a single VERSION-CONTROl request.\n> \n\nSo it is the way I expected it. Leaving the checked-in version blank would\nhave been very obscure.\n\n\nRegards\nDaniel\n\n\n\n", "id": "lists-007-3198495"}, {"subject": "RE: Selective propagation of change", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   suppose in workspace WS1 there is a collection C containing two\n   Files F1, F2. F1 was created with activity A1 and F2 was created\n   with activity A2.  Subsequent changes to F1 were made with activity\n   A3 and for F2 activity A4 was used for this purpose.\n\n   further suppose in WS2 there allready is a collection C w/o any\n   members (created with earlier MERGES).\n\n   For some reasons I only want to propagate F2 (cause F1 is not ready\n   yet or secret or ...). The MERGE of A4 into WS2 would fail cause F2\n   does not exist.\n\nActually, it would succeed, but would have no effect on WS2.\n\n   So first I have to MERGE activity A2. Doing this I MERGE a version\n   of /WS1/C into WS2 that contains a binding to F1. Due to that a vcr\n   for F1 has to be created. Thats definitely not what I want to have.\n\n   So merging the Activity A2 is not an good idea. Only with activity\n   A2 there was just the creation of F2. And I just want to propagate\n   this creation. But I get other stuff as well. Is this a) right b)\n   \"sensible\"\n\nOK, this is a good news/bad news kind of thing.  The good news (a) you\nare right and (b) you are sensible.  In addition, DeltaV provides the\nobject you need for this (an activity).  The bad news is that there is\nno standard method defined by DeltaV for this, so you'll need a custom\nmethod if you want to have your server provide this service.\n\nI would suggest the method name DELTA, and if you want to be fully\ngeneral, it would take a list of \"add\" activities (i.e. those whose\ndeltas you want to add) and a list of \"subtract\" activities\n(i.e. those deltas you want to remove).\n\nUnlike MERGE (which only performs a checkout if the versions are\non different lines of descent), DELTA will always checkout the\ntarget, and will always have the server compute the results of\nadding/deleting the specified deltas (i.e. that's the whole point\nof the DELTA request).\n\nNote that a MERGE of an activity (which effectively merges an \nentire line of descent) is very different from a DELTA of an\nactivity (which only applies the differences captured by an activity).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3211006"}, {"subject": "FW: Selective propagation of change", "content": "this one was wrongly replied, sorry Geoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel \nSent: Mittwoch, 13. Februar 2002 16:16\nTo: 'Clemm, Geoff'\nSubject: RE: Selective propagation of changes\n\n\n\n\n> -----Original Message-----\n> From: Clemm, Geoff [mailto:gclemm@rational.com]\n> Sent: Mittwoch, 13. Februar 2002 15:29\n> To: Ietf-Dav-Versioning (E-mail)\n> Subject: RE: Selective propagation of changes\n> \n> \n>    From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n> \n>    suppose in workspace WS1 there is a collection C containing two\n>    Files F1, F2. F1 was created with activity A1 and F2 was created\n>    with activity A2.  Subsequent changes to F1 were made with activity\n>    A3 and for F2 activity A4 was used for this purpose.\n> \n>    further suppose in WS2 there allready is a collection C w/o any\n>    members (created with earlier MERGES).\n> \n>    For some reasons I only want to propagate F2 (cause F1 is not ready\n>    yet or secret or ...). The MERGE of A4 into WS2 would fail cause F2\n>    does not exist.\n> \n> Actually, it would succeed, but would have no effect on WS2.\n> \n>    So first I have to MERGE activity A2. Doing this I MERGE a version\n>    of /WS1/C into WS2 that contains a binding to F1. Due to that a vcr\n>    for F1 has to be created. Thats definitely not what I want to have.\n> \n>    So merging the Activity A2 is not an good idea. Only with activity\n>    A2 there was just the creation of F2. And I just want to propagate\n>    this creation. But I get other stuff as well. Is this a) right b)\n>    \"sensible\"\n> \n> OK, this is a good news/bad news kind of thing.  The good news (a) you\n> are right and (b) you are sensible.  In addition, DeltaV provides the\n> object you need for this (an activity).  The bad news is that there is\n> no standard method defined by DeltaV for this, so you'll need a custom\n> method if you want to have your server provide this service.\n> \n> I would suggest the method name DELTA, and if you want to be fully\n> general, it would take a list of \"add\" activities (i.e. those whose\n> deltas you want to add) and a list of \"subtract\" activities\n> (i.e. those deltas you want to remove).\n> \n> Unlike MERGE (which only performs a checkout if the versions are\n> on different lines of descent), DELTA will always checkout the\n> target, and will always have the server compute the results of\n> adding/deleting the specified deltas (i.e. that's the whole point\n> of the DELTA request).\n> \n> Note that a MERGE of an activity (which effectively merges an \n> entire line of descent) is very different from a DELTA of an\n> activity (which only applies the differences captured by an activity).\n> \n\nThat sounds good. Only it would be propriatry for the server that invents\nthis. What do you think, is this a feature that is worth of being part of\nthe DeltaV? Was this in discussion yet and skip due to some reason?\nI don't like the propriatry thing that much. But if its not worth of being\npart of the standard, so it is and then its proprietary.\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3220573"}, {"subject": "RE: Selective propagation of change", "content": "I think it is worth making part of the standard.\n\nBut since only a few servers support this kind of DELTA\ncapability (but there definitely are some),\nso it was lower priority than the MERGE functionality,\nand didn't make it into the final \"what we include in the\nfirst version\" cut.  There are other things, like \"variants\",\nthat are in the same category.\n\nIf anyone has the time to write up the DELTA proposal,\nthat would be great (we would post it to the \"proposed extensions\"\nsection of the DeltaV site).\n\nCheers,\nGeoff\n\n> -----Original Message-----\n> From: Clemm, Geoff [mailto:gclemm@rational.com]\n> I would suggest the method name DELTA, and if you want to be fully\n> general, it would take a list of \"add\" activities (i.e. those whose\n> deltas you want to add) and a list of \"subtract\" activities\n> (i.e. those deltas you want to remove).\n> \n> Unlike MERGE (which only performs a checkout if the versions are\n> on different lines of descent), DELTA will always checkout the\n> target, and will always have the server compute the results of\n> adding/deleting the specified deltas (i.e. that's the whole point\n> of the DELTA request).\n> \n> Note that a MERGE of an activity (which effectively merges an \n> entire line of descent) is very different from a DELTA of an\n> activity (which only applies the differences captured by an activity).\n> \n\nThat sounds good. Only it would be propriatry for the server that invents\nthis. What do you think, is this a feature that is worth of being part of\nthe DeltaV? Was this in discussion yet and skip due to some reason?\nI don't like the propriatry thing that much. But if its not worth of being\npart of the standard, so it is and then its proprietary.\n\n\n\n", "id": "lists-007-3231568"}, {"subject": "MERGE &amp; BASELINE", "content": "Hi,\n\nsuppose this:\n\nThree Workspaces under baseline-control, versioned collections.\nWS1 was used to create a collection hierarchy:\n\n    WS1                   WS2                  WS3                   WS4\n     |                     |                    |                     |\n     +-- A            \n     |                \n     +-- B            \n     |                \n     +-- C            \n\n    WS1-BL1\n\nThis hierarchy was merged (using a baseline of WS1) into WS2 and WS3. \n\n    WS1                   WS2                  WS3                   WS4\n     |                     |                    |                     |\n     +-- A                 +-- A                +-- A \n     |                     |                    |\n     +-- B                 +-- B                +-- B\n     |                     |                    |\n     +-- C                 +-- C                +-- C\n\n    WS1-BL1               WS2-BL1              WS3-BL1\n\nWS1, WS2 and WS3 are subject to changes (addition of files etc.) Finally\nthere is a state like this:\n(A,B,C - collections; F1,F2,F3 - files)\n\n    WS1                   WS2                  WS3                   WS4\n     |                     |                    |                     |\n     +-- A                 +-- A                +-- A \n     |   |                 |                    |\n     |   +-- F1            |                    |\n     |                     |                    |\n     +-- B                 +-- B                +-- B\n     |                     |   |                |\n     |                     |   +-- F2           |\n     |                     |                    |\n     +-- C                 +-- C                +-- C\n                                                    |\n                                                    +-- F3\n\n    WS1-BL2               WS2-BL2              WS3-BL2\n\nNow WS4 the changes should be merged into WS4. First I merge baseline\nWS1-BL2 into WS4, this would cause this:\n\n    WS1                   WS2                  WS3                   WS4\n     |                     |                    |                     |\n     +-- A                 +-- A                +-- A                 +-- A\n     |   |                 |                    |                     |   |\n     |   +-- F1            |                    |                     |\n+-- F1\n     |                     |                    |                     |\n     +-- B                 +-- B                +-- B                 +-- B\n     |                     |   |                |                     |\n     |                     |   +-- F2           |                     |\n     |                     |                    |                     |\n     +-- C                 +-- C                +-- C                 +-- C\n                                                    |                     \n                                                    +-- F3                \n\n    WS1-BL2               WS2-BL2              WS3-BL2               WS4-BL1\n\nwith alle versioned resources existing in WS1 are created in WS4 and\npointing to the same checked-in versions. Now it's getting interessting.\nWhat happens when I merge baseline WS2-BL2 into WS4? Would this cause this:\n\n    WS1                   WS2                  WS3                   WS4\n     |                     |                    |                     |\n     +-- A                 +-- A                +-- A                 +-- A\n     |   |                 |                    |                     |   |\n     |   +-- F1            |                    |                     |\n+-- F1\n     |                     |                    |                     |\n     +-- B                 +-- B                +-- B                 +-- B\n     |                     |   |                |                     |   |\n     |                     |   +-- F2           |                     |\n+-- F2\n     |                     |                    |                     |\n     +-- C                 +-- C                +-- C                 +-- C\n                                                    |                     \n                                                    +-- F3                \n\n    WS1-BL2               WS2-BL2              WS3-BL2               WS4-BL2\n\nwith F2 created and set to the same checked-in version as WS2/B/F2. /WS4/B's\nchecked-in version \"updated\" to be the same as in WS2/B? And /WS4/A\nuntouched even if it is part of the baseline WS2-BL2, cause the checked-in\nversion of WS4/A is a successor of that of WS2/A?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3240428"}, {"subject": "RE: MERGE &amp; BASELINE", "content": "Yes, the result of merging WS2 into WS4 is as described below.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\nSent: Friday, February 15, 2002 9:50 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: MERGE & BASELINES\n\n\nHi,\n\nsuppose this:\n\nThree Workspaces under baseline-control, versioned collections.\nWS1 was used to create a collection hierarchy:\n\n    WS1                   WS2                  WS3                   WS4\n     |                     |                    |                     |\n     +-- A            \n     |                \n     +-- B            \n     |                \n     +-- C            \n\n    WS1-BL1\n\nThis hierarchy was merged (using a baseline of WS1) into WS2 and WS3. \n\n    WS1                   WS2                  WS3                   WS4\n     |                     |                    |                     |\n     +-- A                 +-- A                +-- A \n     |                     |                    |\n     +-- B                 +-- B                +-- B\n     |                     |                    |\n     +-- C                 +-- C                +-- C\n\n    WS1-BL1               WS2-BL1              WS3-BL1\n\nWS1, WS2 and WS3 are subject to changes (addition of files etc.) Finally\nthere is a state like this:\n(A,B,C - collections; F1,F2,F3 - files)\n\n    WS1                   WS2                  WS3                   WS4\n     |                     |                    |                     |\n     +-- A                 +-- A                +-- A \n     |   |                 |                    |\n     |   +-- F1            |                    |\n     |                     |                    |\n     +-- B                 +-- B                +-- B\n     |                     |   |                |\n     |                     |   +-- F2           |\n     |                     |                    |\n     +-- C                 +-- C                +-- C\n                                                    |\n                                                    +-- F3\n\n    WS1-BL2               WS2-BL2              WS3-BL2\n\nNow WS4 the changes should be merged into WS4. First I merge baseline\nWS1-BL2 into WS4, this would cause this:\n\n    WS1                   WS2                  WS3                   WS4\n     |                     |                    |                     |\n     +-- A                 +-- A                +-- A                 +-- A\n     |   |                 |                    |                     |   |\n     |   +-- F1            |                    |                     |\n+-- F1\n     |                     |                    |                     |\n     +-- B                 +-- B                +-- B                 +-- B\n     |                     |   |                |                     |\n     |                     |   +-- F2           |                     |\n     |                     |                    |                     |\n     +-- C                 +-- C                +-- C                 +-- C\n                                                    |                     \n                                                    +-- F3                \n\n    WS1-BL2               WS2-BL2              WS3-BL2               WS4-BL1\n\nwith alle versioned resources existing in WS1 are created in WS4 and\npointing to the same checked-in versions. Now it's getting interessting.\nWhat happens when I merge baseline WS2-BL2 into WS4? Would this cause this:\n\n    WS1                   WS2                  WS3                   WS4\n     |                     |                    |                     |\n     +-- A                 +-- A                +-- A                 +-- A\n     |   |                 |                    |                     |   |\n     |   +-- F1            |                    |                     |\n+-- F1\n     |                     |                    |                     |\n     +-- B                 +-- B                +-- B                 +-- B\n     |                     |   |                |                     |   |\n     |                     |   +-- F2           |                     |\n+-- F2\n     |                     |                    |                     |\n     +-- C                 +-- C                +-- C                 +-- C\n                                                    |                     \n                                                    +-- F3                \n\n    WS1-BL2               WS2-BL2              WS3-BL2               WS4-BL2\n\nwith F2 created and set to the same checked-in version as WS2/B/F2. /WS4/B's\nchecked-in version \"updated\" to be the same as in WS2/B? And /WS4/A\nuntouched even if it is part of the baseline WS2-BL2, cause the checked-in\nversion of WS4/A is a successor of that of WS2/A?\n\n\nRegards,\nDaniel\n\n\n\n", "id": "lists-007-3251993"}, {"subject": "DTD of supported-method-set propert", "content": "Hi,\n\nthis is very basic question compared to what is currently beeing discussed\non this list - (ashamed ;-)\n\nComparing 3.1.3, 3.1.4 and 3.1.5 of the spec, I wonder why \"name\" is an\n*attribute* of element \"supported-method-set\" while it is a *child* element\nin the cases of \"supported-live-property-set\" and \"supported-report-set\".\nWhy is that so?\n\nRegards,\n- Peter\n\n\n\n", "id": "lists-007-3263807"}, {"subject": "RE: DTD of supported-method-set propert", "content": "Peter,\n\nactually in the latest edit ([1]), it changed to be the attribute \"name\" for\nmethods, the element <report> for reports and the element <prop> fpr\nproperties.\n\nI think that supported-method-set uses an attribute because you can't\nmarshall all legal method names as element names.\n\nJulian\n\n\n[1]\n<http://www.greenbytes.de/tech/webdav/draft-ietf-deltav-versioning-20.1.htm#\n_Toc524830525>\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Nevermann, Dr.,\n> Peter\n> Sent: Monday, February 18, 2002 2:34 PM\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: DTD of supported-method-set property\n>\n>\n> Hi,\n>\n> this is very basic question compared to what is currently beeing discussed\n> on this list - (ashamed ;-)\n>\n> Comparing 3.1.3, 3.1.4 and 3.1.5 of the spec, I wonder why \"name\" is an\n> *attribute* of element \"supported-method-set\" while it is a\n> *child* element\n> in the cases of \"supported-live-property-set\" and \"supported-report-set\".\n> Why is that so?\n>\n> Regards,\n> - Peter\n>\n>\n>\n\n\n\n", "id": "lists-007-3271890"}, {"subject": "RE: DTD of supported-method-set propert", "content": "OK, that clarifies. Thanks, Julian!\n- Peter.\n\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Monday, February 18, 2002 14:40\n> To: Nevermann, Dr., Peter; ietf-dav-versioning@w3.org\n> Subject: RE: DTD of supported-method-set property\n> \n> \n> Peter,\n> \n> actually in the latest edit ([1]), it changed to be the \n> attribute \"name\" for\n> methods, the element <report> for reports and the element <prop> fpr\n> properties.\n> \n> I think that supported-method-set uses an attribute because you can't\n> marshall all legal method names as element names.\n> \n> Julian\n> \n> \n> [1]\n> <http://www.greenbytes.de/tech/webdav/draft-ietf-deltav-versio\n> ning-20.1.htm#\n> _Toc524830525>\n> \n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of \n> Nevermann, Dr.,\n> > Peter\n> > Sent: Monday, February 18, 2002 2:34 PM\n> > To: 'ietf-dav-versioning@w3.org'\n> > Subject: DTD of supported-method-set property\n> >\n> >\n> > Hi,\n> >\n> > this is very basic question compared to what is currently \n> beeing discussed\n> > on this list - (ashamed ;-)\n> >\n> > Comparing 3.1.3, 3.1.4 and 3.1.5 of the spec, I wonder why \n> \"name\" is an\n> > *attribute* of element \"supported-method-set\" while it is a\n> > *child* element\n> > in the cases of \"supported-live-property-set\" and \n> \"supported-report-set\".\n> > Why is that so?\n> >\n> > Regards,\n> > - Peter\n> >\n> >\n> >\n> \n> \n\n\n\n", "id": "lists-007-3281705"}, {"subject": "RE: COPY, MOVE and VCR'", "content": "Hi,\n\n-----Original Message-----\nFrom: Peter Raymond [mailto:Peter.Raymond@merant.com]\nSent: Donnerstag, 24. Januar 2002 15:12\nTo: Kirmse, Daniel; Ietf-Dav-Versioning (E-mail)\nSubject: RE: COPY, MOVE and VCR's\n\n\n>Hi, \n>[Daniel said:] \n>>For COPY I'd expect to got a new VCR at the destination with an exact copy\n\n>>of properties. This implies that the new created VCR must share the \n>>version-history with the source VCR. Is this correct? Is this desirable? \n>I think this is desirable and correct but with one caveat... \n>Both in section 1.3 (where the workspace term is defined) and in section 6 \n>the DeltaV specification says that you can only have one VCR for a given \n>version history in a workspace.  If copy created a new VCR but pointed to \n>the original VHR then this rule could be violated if the destination is in \n>the same workspace as the source of the copy. \n>If the copy does not break this rule then it would be fine to have two VCRs\n\n>pointing to the same version history. \n\nBut 3.14 states\n (DAV:copy-creates-new-resource): If the source of a COPY is a\nversion-controlled resource or version, and if there is no resource at the\ndestination of the COPY, then the COPY creates a new non-version-controlled\nresource at the destination of the COPY.  The new resource MAY automatically\nbe put under version control, but the resulting version-controlled resource\nMUST be associated with a new version history created for that new\nversion-controlled resource, and all postconditions for VERSION-CONTROL\napply to the request.\n\nso there would be a new version-history for the copy-target. What is right\nhere???\nI certainly wouldn't have thought that moving a VCR would create a new\nhistory resource. \n  \nRegards,\nDaniel\n\n-----Original Message----- \nFrom: Kirmse, Daniel [mailto:daniel.kirmse@sap.com] \nSent: 24 January 2002 13:56 \nTo: Ietf-Dav-Versioning (E-mail) \nSubject: COPY, MOVE and VCR's \n\n\nHi, \nI wonder what happens when I copy or move a VCR? \nDefining this behavior as not expected by the user, I'd say COPY means \ncreation of a new version-history and copy of the checked-in version to that\n\nnew VH. With that the checked-in property of the copied VCR must change. \nSame for MOVE except for the deletion of the source. \nRegards, \nDaniel \n\n\n\n", "id": "lists-007-3292416"}, {"subject": "DELETE on version resourc", "content": "Is it allowed to DELETE a version resource which appears in the checkout or\ncheckin property of a VCR?\n\nIf so, what happens to the checkin/checkout property?\n\nJulian\n\n\n\n", "id": "lists-007-3302571"}, {"subject": "Update of a version-controlled collection with a checked-out membe", "content": "What should happen if an UPDATE request is made for a version-controlled\ncollection which has a version-controlled internal member that is a\nchecked-out resource, and the DAV:version in the UPDATE request does not\nidentify the checked-out resource version-history in it's\nDAV:version-controlled-binding-set? Should the UPDATE request fail, or\nshould the checked-out resource be deleted (by post condition\nDAV:update-version-controlled-collection-members)?\n\nSimilarly, what should happen if the checked-out resource is a member\n(but not an internal member) of the collection,  and the UPDATE request\nattempts to remove the collection resource that it is an internal member\nof?\n\nThanks,\nAlison.\n--\n -------------------------------------------------------------\n The statements and opinions expressed here are my own\n and do not necessarily represent those of Oracle Corporation.\n -------------------------------------------------------------\n\n\n\n", "id": "lists-007-3310274"}, {"subject": "DAV:comment vs auto-versionin", "content": "Hi,\n\nwhat's the best treatment for DAV:comment when a resource get's checked in\ndue to auto-versioning?\n\n1) no special treatment (old value),\n\n2) remote it (set it to empty string),\n\n3) generate a server-specific comment (\"checked in due to auto versioning\non...\")?\n\nJulian\n\n\n\n", "id": "lists-007-3318228"}, {"subject": "Re: DELETE on version resourc", "content": "On Thu, Feb 21, 2002 at 02:19:36PM +0100, Julian Reschke wrote:\n> Is it allowed to DELETE a version resource which appears in the checkout or\n> checkin property of a VCR?\n\nImplementation-defined, I'd think.\n\n(SVN doesn't allow it)\n\n> If so, what happens to the checkin/checkout property?\n\nI'd say that it just gets left around. If somebody tries to use it, then\nthey get a 404. I'd also be happy with language that states a MAY or SHOULD\n(but not a MUST; IMO, we shouldn't force the server to fix dangling links)\n\nCheers,\n-g\n\n-- \nGreg Stein, http://www.lyra.org/\n\n\n\n", "id": "lists-007-3325461"}, {"subject": "RE: COPY, MOVE and VCR'", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   From: Peter Raymond [mailto:Peter.Raymond@merant.com]\n   >[Daniel said:] \n   >>For COPY I'd expect to got a new VCR at the destination with an\n   >>exact copy of properties. This implies that the new created VCR\n   >>must share the version-history with the source VCR. Is this\n   >>correct? Is this desirable?\n\n   >I think this is desirable and correct but with one caveat... \n\nOne could debate whether it is desireable, but it definitely is not\ncorrect (:-) ... see section 3.14 that Daniel quotes below.\n\n\n   But 3.14 states\n\n   (DAV:copy-creates-new-resource): If the source of a COPY is a\n   version-controlled resource or version, and if there is no resource\n   at the destination of the COPY, then the COPY creates a new\n   non-version-controlled resource at the destination of the COPY.\n   The new resource MAY automatically be put under version control,\n   but the resulting version-controlled resource MUST be associated\n   with a new version history created for that new version-controlled\n   resource, and all postconditions for VERSION-CONTROL apply to the\n   request.\n\n   so there would be a new version-history for the copy-target. What\n   is right here???\n\nThe spec (:-).\n\n   I certainly wouldn't have thought that moving a VCR would create a new\n   history resource. \n\nMOVE does not, but COPY does.  This is true in general for MOVE and\nCOPY, i.e. that MOVE just gives a resource a new name (URL), while\nCOPY creates a new resource.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3333142"}, {"subject": "RE: DELETE on version resourc", "content": "It is server-defined.  Some servers will disallow the DELETE in\nthose cases, while others want to leave them dangling.  We couldn't\nget consensus on either behavior so, it is left as server-defined.\n\nCheers,\nGeoff \n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, February 21, 2002 8:20 AM\nTo: Ietf-Dav-Versioning (E-mail)\nSubject: DELETE on version resource\n\n\nIs it allowed to DELETE a version resource which appears in the checkout or\ncheckin property of a VCR?\n\nIf so, what happens to the checkin/checkout property?\n\nJulian\n\n\n\n", "id": "lists-007-3341859"}, {"subject": "RE: comment vs auto-versionin", "content": "It's up to the server, but I'd probably go with (3), as it probably\nprovides the most value.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, February 21, 2002 12:52 PM\nTo: ietf-dav-versioning@w3.org\nSubject: DAV:comment vs auto-versioning\n\n\nHi,\n\nwhat's the best treatment for DAV:comment when a resource get's checked in\ndue to auto-versioning?\n\n1) no special treatment (old value),\n\n2) remote it (set it to empty string),\n\n3) generate a server-specific comment (\"checked in due to auto versioning\non...\")?\n\nJulian\n\n\n\n", "id": "lists-007-3349675"}, {"subject": "RE: Update of a version-controlled collection with a checked-out  membe", "content": "The result of applying an UPDATE to \nIf the UPDATE succeeds, the server must delete the\nchecked-out version-controlled member,\nbut a server could very reasonably fail the request, in which case it\nshould return a DAV:update-version-controlled-collection-members element\nin the DAV:error element.  Note that it could return additional information\nto identify the checked-out resources that blocked the UPDATE, but we have\nnot defined any interoperable mechanism for doing so.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Alison Macmillan [mailto:alison.macmillan@oracle.com]\nSent: Thursday, February 21, 2002 11:39 AM\nTo: ietf-dav-versioning@w3.org\nSubject: Update of a version-controlled collection with a checked-out\nmember\n\n\nWhat should happen if an UPDATE request is made for a version-controlled\ncollection which has a version-controlled internal member that is a\nchecked-out resource, and the DAV:version in the UPDATE request does not\nidentify the checked-out resource version-history in it's\nDAV:version-controlled-binding-set? Should the UPDATE request fail, or\nshould the checked-out resource be deleted (by post condition\nDAV:update-version-controlled-collection-members)?\n\nSimilarly, what should happen if the checked-out resource is a member\n(but not an internal member) of the collection,  and the UPDATE request\nattempts to remove the collection resource that it is an internal member\nof?\n\nThanks,\nAlison.\n--\n -------------------------------------------------------------\n The statements and opinions expressed here are my own\n and do not necessarily represent those of Oracle Corporation.\n -------------------------------------------------------------\n\n\n\n", "id": "lists-007-3357186"}, {"subject": "No-checkout MERGE and version-controlled configuration", "content": "Consider a MERGE request whose request-URL has baseline-\ncontrolled members, and which includes a DAV:no-checkout\nelement in the request body. Also, the DAV:auto-version\nproperty value for the baseline-controlled members' \nversion-controlled configuration is DAV:checkout.\n\nSuppose the MERGE would cause an UPDATE to be applied to \nsome of the members of the request-URL by MERGE \npostcondition DAV:descendant-version. Baseline \nautoversioning would cause the corresponding version-\ncontrolled configuration to be checked out by the first\nsuch UPDATE. Would this CHECKOUT attempt cause the MERGE\nrequest to fail due to the DAV:no-checkout request-body\nelement?\n\nI'd like clarification because I'm not sure whether the \nversion-controlled configuration qualifies as a \"merge\ntarget\" in this situation. From the 11.2 preconditions:\n\n       (DAV:checkout-not-allowed): If DAV:no-checkout \n       is specified in the request body, it MUST be \n       possible to perform the merge without checking \n       out any of the merge targets.\n\nThanks,\nRoy\n\n\n\n", "id": "lists-007-3366284"}, {"subject": "RE: No-checkout MERGE and version-controlled configuration", "content": "I would not call the auto-versioned VCCn a merge target,\ntherefore I would not consider this auto-checkout as a\nviolation of the DAV:checkout-not-allowed precondition.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Roy Seto [mailto:Roy.Seto@oracle.com]\nSent: Wednesday, February 27, 2002 6:20 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: No-checkout MERGE and version-controlled configurations\n\n\nConsider a MERGE request whose request-URL has baseline-\ncontrolled members, and which includes a DAV:no-checkout\nelement in the request body. Also, the DAV:auto-version\nproperty value for the baseline-controlled members' \nversion-controlled configuration is DAV:checkout.\n\nSuppose the MERGE would cause an UPDATE to be applied to \nsome of the members of the request-URL by MERGE \npostcondition DAV:descendant-version. Baseline \nautoversioning would cause the corresponding version-\ncontrolled configuration to be checked out by the first\nsuch UPDATE. Would this CHECKOUT attempt cause the MERGE\nrequest to fail due to the DAV:no-checkout request-body\nelement?\n\nI'd like clarification because I'm not sure whether the \nversion-controlled configuration qualifies as a \"merge\ntarget\" in this situation. From the 11.2 preconditions:\n\n       (DAV:checkout-not-allowed): If DAV:no-checkout \n       is specified in the request body, it MUST be \n       possible to perform the merge without checking \n       out any of the merge targets.\n\nThanks,\nRoy\n\n\n\n", "id": "lists-007-3374630"}, {"subject": "VERSION-CONTROL in an activit", "content": "Suppose I wanted to capture that adding a resource to version control was part of an activity. \n\nIt seems to me that this could be reflected by making the VERSION-CONTROL method create a VCR whose DAV:checked-in version included that activity in its DAV:activity-set property value. It looks like the spec allows but does not require servers to do this (for example) if the VERSION-CONTROL request includes a DAV:activity-set element, or if the request-URL for VERSION-CONTROL is the member of a workspace with a nonempty DAV:current-activity-set property value.\n\nIs this interpretation correct?\n\nThanks,\nRoy\n\n\n\n", "id": "lists-007-3383430"}, {"subject": "RE: VERSION-CONTROL in an activit", "content": "That is correct.  It probably would be very reasonable to define\nboth of these behaviors as being required in the next rev of the\nprotocol.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Roy Seto [mailto:Roy.Seto@oracle.com]\nSent: Wednesday, March 06, 2002 6:46 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: VERSION-CONTROL in an activity\n\n\nSuppose I wanted to capture that adding a resource to version control was\npart of an activity. \n\nIt seems to me that this could be reflected by making the VERSION-CONTROL\nmethod create a VCR whose DAV:checked-in version included that activity in\nits DAV:activity-set property value. It looks like the spec allows but does\nnot require servers to do this (for example) if the VERSION-CONTROL request\nincludes a DAV:activity-set element, or if the request-URL for\nVERSION-CONTROL is the member of a workspace with a nonempty\nDAV:current-activity-set property value.\n\nIs this interpretation correct?\n\nThanks,\nRoy\n\n\n\n", "id": "lists-007-3391121"}, {"subject": "locate-by-history report vs. Depth heade", "content": "Hi,\n\nsection 5.4 currently doesn't say anything about the relation between the locate-by-history report and the Depth header (which defaults to \"0\" as per definition of REPORT method).\n\nClearly, the report only makes sense for depth = 1. So what would we expect for other values?\n\n0: empty multistatus response?\ninfinity: forbidden?\n\nRegards, Julian\n\n\n\n[1] <http://greenbytes.de/tech/webdav/draft-ietf-deltav-versioning-20.1.htm#_Toc524830576>\n\n\n\n", "id": "lists-007-3399612"}, {"subject": "VERSION-CONTROL for version-history resourc", "content": "version-history feature\n\n5.9 Additional VERSION-CONTROL Semantics\n\n     Additional Postconditions:\n\n       (DAV:new-version-history): If the request created a new version\n       history, the request MUST have allocated a new server-defined URL\n       for that version history that MUST NOT have previously identified\n       any other resource, and MUST NOT ever identify a resource other\n       than this version history.\n \ndoes this means copying a version history resource (of course with a new\nserver created unique URL)? copy method directly is not allowed.\nhas the new version history the same version controlled resource the the\nolder one?\n\nthanx\njens\n\n-- \nGMX - Die Kommunikationsplattform im Internet.\nhttp://www.gmx.net\n\n\n\n", "id": "lists-007-3408013"}, {"subject": "RE: locate-by-history report vs. Depth heade", "content": "Actually, the report clearly makes the most sense for depth=0 (perhaps\nthat's what you\nmeant to type?).\n\nOne instance where a non-zero depth parameter would make sense for this\nreport was if\nyou had a collection of workspaces (i.e. each internal member of the\ncollection is a\nworkspace).  You could do a Depth:1 locate-by-history report, in order to\nfind out where\na given version history is in each of those workspaces.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, March 07, 2002 8:29 AM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: locate-by-history report vs. Depth header\n\n\nHi,\n\nsection 5.4 currently doesn't say anything about the relation between the\nlocate-by-history report and the Depth header (which defaults to \"0\" as per\ndefinition of REPORT method).\n\nClearly, the report only makes sense for depth = 1. So what would we expect\nfor other values?\n\n0: empty multistatus response?\ninfinity: forbidden?\n\nRegards, Julian\n\n\n\n[1]\n<http://greenbytes.de/tech/webdav/draft-ietf-deltav-versioning-20.1.htm#_Toc\n524830576>\n\n\n\n", "id": "lists-007-3415959"}, {"subject": "RE: locate-by-history report vs. Depth heade", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Thursday, March 07, 2002 9:49 PM\n> To: Ietf-Dav-Versioning@W3. Org\n> Subject: RE: locate-by-history report vs. Depth header\n> \n> \n> Actually, the report clearly makes the most sense for depth=0 (perhaps\n> that's what you\n> meant to type?).\n\nYou managed to confuse me :-) It the request URI is the parent collection, and the scope is the member of this collection, only depth = 1 seems to make sense. Depth 0's scope would be just the parent collection, correct?\n\n\n\n", "id": "lists-007-3424914"}, {"subject": "RE: locate-by-history report vs. Depth heade", "content": "The locate-by-history report logically runs against the entire configuration\nrooted at the request-URL.  So in that sense, it is a \"depth:infinity\"\noperation.\nBut that isn't how REPORT is defined.  REPORT is defined as \"being run\nseparately\nagainst every resource that satisfies the depth parameter\".  Depth:1 says to\n\"run the request against the resource identified by the request-URL,\nand then again on each of the internal members of the request-URL.\"\nBut that is never what you want, because you only want the REPORT run once\nagainst\nthe configuration identified by the request-URL.\n\nAnd that one case where I said that Depth:1 might make sense was just wrong.\nYou still run Depth:0 (i.e. just run the REPORT once), and the REPORT will\nfind all VCR's that match that version history in any of the workspaces.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, March 07, 2002 5:42 PM\nTo: Clemm, Geoff; Ietf-Dav-Versioning@W3. Org\nSubject: RE: locate-by-history report vs. Depth header\n\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Thursday, March 07, 2002 9:49 PM\n> To: Ietf-Dav-Versioning@W3. Org\n> Subject: RE: locate-by-history report vs. Depth header\n> \n> \n> Actually, the report clearly makes the most sense for depth=0 (perhaps\n> that's what you\n> meant to type?).\n\nYou managed to confuse me :-) It the request URI is the parent collection,\nand the scope is the member of this collection, only depth = 1 seems to make\nsense. Depth 0's scope would be just the parent collection, correct?\n\n\n\n", "id": "lists-007-3433792"}, {"subject": "RE: VERSION-CONTROL for version-history resourc", "content": "   From: Jens Grote [mailto:Grote.Jens@gmx.de]\n\n   version-history feature\n\n   5.9 Additional VERSION-CONTROL Semantics\n\nAdditional Postconditions:\n\n  (DAV:new-version-history): If the request created a new version\n  history, the request MUST have allocated a new server-defined URL\n  for that version history that MUST NOT have previously identified\n  any other resource, and MUST NOT ever identify a resource other\n  than this version history.\n\n   does this means copying a version history resource (of course\n   with a new server created unique URL)? copy method directly is\n   not allowed.\n\nNo, this Postcondition would apply to a VERSION-CONTROL request\n(when the section is \"Additional XXX Semantics\", it means additional\nsemantics for an XXX request.\n\n   has the new version history the same version controlled resource\n   the the older one?\n\nA version history does not really \"have\" a version-controlled\nresource, i.e. it is the other way round: a version-controlled\nresource has a version history.  Since a version-controlled resource\ncan only refer to a single version history, a given version-controlled\nresource could not refer to both an old and a newer version history.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3443831"}, {"subject": "Help, pleas", "content": "Any chance that I could get off this list? Unsubscribing doesn't seem to\nwork.\n\nRegards and thanks,\nPeter\n\n\n\n", "id": "lists-007-3452111"}, {"subject": "RE: locate-by-history report vs. Depth heade", "content": "I see.\n\nSo:\n\ndepth = 0: the REPORT affects just the request URI, but as the report itself is defined to have \"colllection member scope\", this will return all direct members of the collection at the request URI having matching version histories?\n\ndepth = 1: also includes collections that are members of the collection at the request URI.\n\n..\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, March 08, 2002 12:14 AM\n> To: Ietf-Dav-Versioning@W3. Org\n> Subject: RE: locate-by-history report vs. Depth header\n> \n> \n> The locate-by-history report logically runs against the entire \n> configuration\n> rooted at the request-URL.  So in that sense, it is a \"depth:infinity\"\n> operation.\n> But that isn't how REPORT is defined.  REPORT is defined as \"being run\n> separately\n> against every resource that satisfies the depth parameter\".  \n> Depth:1 says to\n> \"run the request against the resource identified by the request-URL,\n> and then again on each of the internal members of the request-URL.\"\n> But that is never what you want, because you only want the REPORT run once\n> against\n> the configuration identified by the request-URL.\n> \n> And that one case where I said that Depth:1 might make sense was \n> just wrong.\n> You still run Depth:0 (i.e. just run the REPORT once), and the REPORT will\n> find all VCR's that match that version history in any of the workspaces.\n> \n> Cheers,\n> Geoff\n> \n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Thursday, March 07, 2002 5:42 PM\n> To: Clemm, Geoff; Ietf-Dav-Versioning@W3. Org\n> Subject: RE: locate-by-history report vs. Depth header\n> \n> \n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Thursday, March 07, 2002 9:49 PM\n> > To: Ietf-Dav-Versioning@W3. Org\n> > Subject: RE: locate-by-history report vs. Depth header\n> > \n> > \n> > Actually, the report clearly makes the most sense for depth=0 (perhaps\n> > that's what you\n> > meant to type?).\n> \n> You managed to confuse me :-) It the request URI is the parent collection,\n> and the scope is the member of this collection, only depth = 1 \n> seems to make\n> sense. Depth 0's scope would be just the parent collection, correct?\n> \n> \n> \n> \n\n\n\n", "id": "lists-007-3458478"}, {"subject": "RE: locate-by-history report vs. Depth heade", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   So: depth = 0: the REPORT affects just the request URI, but as the\n   report itself is defined to have \"colllection member scope\", this\n   will return all direct members of the collection at the request URI\n   having matching version histories?\n\nNo, the REPORT affects (is applied to) the configuration rooted at a URL\nwhich includes *all* members of the collection identified\nby that URL not just \"direct\" (what RFC 2518 calls \"internal\") members.\n\n   depth = 1: also includes collections that are members of the\n   collection at the request URI.\n\nYes, if by \"includes\", you mean \"repeats the REPORT on\".  The Depth:0\nreport \"includes\" (in the sense of \"looks at\") all members of the\ncollection, but it only runs the report once.\n\nCheers,\nGeoff\n\n   > From: ietf-dav-versioning-request@w3.org\n   > \n   > The locate-by-history report logically runs against the entire\n   > configuration rooted at the request-URL.  So in that sense, it is\n   > a \"depth:infinity\" operation.  But that isn't how REPORT is\n   > defined.  REPORT is defined as \"being run separately against\n   > every resource that satisfies the depth parameter\".  Depth:1 says\n   > to \"run the request against the resource identified by the\n   > request-URL, and then again on each of the internal members of\n   > the request-URL.\"  But that is never what you want, because you\n   > only want the REPORT run once against the configuration\n   > identified by the request-URL.\n   > \n   > And that one case where I said that Depth:1 might make sense was\n   > just wrong.  You still run Depth:0 (i.e. just run the REPORT\n   > once), and the REPORT will find all VCR's that match that version\n   > history in any of the workspaces.\n\n   > From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n   > \n   > > From: ietf-dav-versioning-request@w3.org\n   > > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n   > > \n   > > Actually, the report clearly makes the most sense for depth=0\n   > > (perhaps that's what you meant to type?).\n   > \n   > You managed to confuse me :-) It the request URI is the parent\n   > collection, and the scope is the member of this collection, only\n   > depth = 1 seems to make sense. Depth 0's scope would be just the\n   > parent collection, correct?\n\n\n\n", "id": "lists-007-3470415"}, {"subject": "draft-reschke-deltav-compute-checkin-ur", "content": "Hi.\n\nI have updated our proposal for specifying the expected version URI (upon CHECKIN) to properly refer to RFC3253 (deltaV).\n\nAt this point we think the protocol extension works well (and have implemented it in SAP Portals' Enterprise Portal WebDAV implementation). We would be interested to head from other implementors,\n\n- whether they feel it solves a real-world problem (we certainly think so), and\n\n- whether somebody is planning to adopt it (in which case we'd be interested in doing interop testing).\n\nThe plan is to submit the new draft after the IETF meetings are finished (and then later to submit it as informational or experimental RFC).\n\nJulian\n\n\n\n[1] <http://greenbytes.de/tech/webdav/draft-reschke-deltav-compute-checkin-uri-latest.html>\n\n\n\n", "id": "lists-007-3481586"}, {"subject": "Clarifications on DAV:expand-property repor", "content": "Hi,\n\ntwo questions regarding the DAV:expand-property REPORT [1]:\n\n1) Scoping (depth header)\n\nAccording to section 3.6 (definition of REPORT method), the depth header will work just as for PROPFIND (depth 0: only request-URI, depth 1: request-URI + internal members, depth infinity: request-URI + all children)?\n\n2) expanding properties that do not contain DAV:href elements\n\nIs this an error condition, or should the REPORT just return the non-expanded property value?\n\n3) expanding non-live properties\n\nIs the server required to expand dead properties which contain DAV:href child elements as well?\n\n\nJulian\n\n\n\n[1] <http://greenbytes.de/tech/webdav/draft-ietf-deltav-versioning-20.1.htm#_Toc524830544>\n\n\n\n", "id": "lists-007-3489977"}, {"subject": "DAV:version-tree report vs Version History Resource", "content": "Hi,\n\nis a VHR supposed to support the DAV:version-tree report? Section 3.7 is silent on this...\n\nJulian\n\n\n\n", "id": "lists-007-3498730"}, {"subject": "RE: Clarifications on DAV:expand-property repor", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   two questions regarding the DAV:expand-property REPORT [1]:\n\n   1) Scoping (depth header)\n   According to section 3.6 (definition of REPORT method), the depth\n   header will work just as for PROPFIND (depth 0: only request-URI,\n   depth 1: request-URI + internal members, depth infinity:\n   request-URI + all children)?\n\nYes, the report will be run (separately) on each of the resources\nthat satisfy the Depth header, and the results will be returned\nin a multistatus response.\n\n   2) expanding properties that do not contain DAV:href elements\n\n   Is this an error condition, or should the REPORT just return the\n   non-expanded property value?\n\nJust return the non-expanded property value.\n\n   3) expanding non-live properties\n\n   Is the server required to expand dead properties which contain\n   DAV:href child elements as well?\n\nThe report makes no distinction between live and dead properties,\nso yes, it needs to expand those as well.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3506275"}, {"subject": "RE: version-tree report vs Version History Resource", "content": "No, the VHR is not required to support the DAV:version-tree report.\nA server could allow it, but this would be a non-standard extension.\n(Note that the DAV:version-tree report is just a restricted form of\nthe DAV:expand-property report, and is redundant if a server supports\nversion history resources).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Monday, March 11, 2002 12:21 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: DAV:version-tree report vs Version History Resources\n\n\nHi,\n\nis a VHR supposed to support the DAV:version-tree report? Section 3.7 is\nsilent on this...\n\nJulian\n\n\n\n", "id": "lists-007-3515118"}, {"subject": "RE: Clarifications on DAV:expand-property repor", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Monday, March 11, 2002 6:36 PM\n> To: Ietf-Dav-Versioning@W3. Org\n> Subject: RE: Clarifications on DAV:expand-property report\n> \n> \n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> \n>    two questions regarding the DAV:expand-property REPORT [1]:\n> \n>    1) Scoping (depth header)\n>    According to section 3.6 (definition of REPORT method), the depth\n>    header will work just as for PROPFIND (depth 0: only request-URI,\n>    depth 1: request-URI + internal members, depth infinity:\n>    request-URI + all children)?\n> \n> Yes, the report will be run (separately) on each of the resources\n> that satisfy the Depth header, and the results will be returned\n> in a multistatus response.\n> \n>    2) expanding properties that do not contain DAV:href elements\n> \n>    Is this an error condition, or should the REPORT just return the\n>    non-expanded property value?\n> \n> Just return the non-expanded property value.\n> \n>    3) expanding non-live properties\n> \n>    Is the server required to expand dead properties which contain\n>    DAV:href child elements as well?\n> \n> The report makes no distinction between live and dead properties,\n> so yes, it needs to expand those as well.\n\nOK, assuming I have a dead property like:\n\n<dead-property>\n<href xmns='DAV:'>http://foobar.com/xyz</href>\n<href xmns='DAV:'>/xyz</href>\n<other-markup>sasasas</other-markup>\nplain text\n</dead-property>\n\non the resource http://server/abc\n\nHow does it expand? Like this?\n\n<dead-property>\n<response xmlns=\"DAV:\">\n<href>http://foobar.com/xyz</href>\n<status>HTTP/1.1 502 Bad Gateway</status>\n</response>\n<response xmlns=\"DAV:\">\n<href>/xyz</href>\n<propstat>\n....\n</propstat>\n</response>\n<other-markup>sasasas</other-markup>\nplain text\n</dead-property>\n\n\n\n", "id": "lists-007-3522790"}, {"subject": "RE: Clarifications on DAV:expand-property repor", "content": "Yup.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Tuesday, March 12, 2002 12:04 PM\nTo: Clemm, Geoff; Ietf-Dav-Versioning@W3. Org\nSubject: RE: Clarifications on DAV:expand-property report\n\n\nOK, assuming I have a dead property like:\n\n<dead-property>\n<href xmns='DAV:'>http://foobar.com/xyz</href>\n<href xmns='DAV:'>/xyz</href>\n<other-markup>sasasas</other-markup>\nplain text\n</dead-property>\n\non the resource http://server/abc\n\nHow does it expand? Like this?\n\n<dead-property>\n<response xmlns=\"DAV:\">\n<href>http://foobar.com/xyz</href>\n<status>HTTP/1.1 502 Bad Gateway</status>\n</response>\n<response xmlns=\"DAV:\">\n<href>/xyz</href>\n<propstat>\n....\n</propstat>\n</response>\n<other-markup>sasasas</other-markup>\nplain text\n</dead-property>\n\n\n\n", "id": "lists-007-3533692"}, {"subject": "changeability of propertie", "content": "Hi,\n\na (probably stupid) question about preconditions for modification of any\nproperty (live or dead) by the client:\n\nare there any properties of the following resources\n*version resource\n*VCR\n*version controlled configuration\nwhich can be modified by the client without checking out the resource ? \n\nI expect this is not possible but I didn't find this explicitly in the spec.\n\nregards\nMatthias\n\n\n\n", "id": "lists-007-3542341"}, {"subject": "RE: changeability of propertie", "content": "The only constraint is that a server must not allow modifications to\ndead properties on a version or a checked-in VCR (a version-controlled\nconfiguration is just a special kind of VCR, so the VCR constraints apply).\n\nOn the other hand, a server is free to decide how it is going to control\nthe behavior of live properties.  There are some live properties that\ninherently are mutable (such as the DAV:successor-set of a version).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Sohn, Matthias [mailto:matthias.sohn@sap.com]\nSent: Wednesday, March 13, 2002 12:33 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: changeability of properties\n\n\nHi,\n\na (probably stupid) question about preconditions for modification of any\nproperty (live or dead) by the client:\n\nare there any properties of the following resources\n*version resource\n*VCR\n*version controlled configuration\nwhich can be modified by the client without checking out the resource ? \n\nI expect this is not possible but I didn't find this explicitly in the spec.\n\nregards\nMatthias\n\n\n\n", "id": "lists-007-3549797"}, {"subject": "how to perform undeletio", "content": "Hi,\n\nhow can undelete of a versioned resource (residing in a versioned\ncollection) \nwhich has been deleted somewhen in the past be done using DeltaV ?\n\nThere are two things which have to be solved here:\n*find the deleted resource(s) under a given path  \n*undelete resource(s)\nI would like to do it with using an activity and working resources so that\nthe undeletion is tracked in the activity.\n\nHow can the browsing for deleted resources (or collections) be done in an\nefficient way, i.e. how can the client\nfind out which resources have been deleted let's say recursively under\n/a/b/c/... ?\n\nregards\nMatthias\n\n\n\n", "id": "lists-007-3557814"}, {"subject": "WG: how to perform undeletio", "content": "Hi\n\nI think when the resource version to be revived in order to undelete the \nresource has been found the undelete operation can be done in the following\nway :\n\n- check out the collection which shall contain the resource to be undeleted,\n\n  this yields a working collection which is bound to an activity (since I\nwant to \n  track all changes in activities)\n- issue VERSION-CONTROL on the resource version contained in the old\ncollection \n  version before the deletion of the resource took place like specified in \n  the DeltaV spec : \n\n>>> citation from DeltaV spec <<<\n\n6.7.1Example - VERSION-CONTROL (using an existing version\nhistory)\n>>REQUEST\n\n  VERSION-CONTROL /ws/public/bar.html HTTP/1.1 \n  Host: www.webdav.org\n  Content-Type: text/xml; charset=\"utf-8\"\n  Content-Length: xxxx\n\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:version-control xmlns:D=\"DAV:\">\n    <D:version>\n      <D:href>http://repo.webdav.org/his/12/ver/V3</D:href>\n    </D:version>\n  </D:version-control>\n   \n>>RESPONSE\n\n  HTTP/1.1 201 Created\n  Cache-Control: no-cache\n\n>>> end citation from DeltaV spec <<<\n\n  In this request specify the URL under which the VCR for the resource to be\n\n  undeleted shall reappear.\n\n- check in the activity containing the working collection which now has a \n  binding pointing to the newly created VCR for the undeleted resource.\n- if since the resource has been deleted another resource has been created \n  with the same URL the VERSION-CONTROL request given above will fail. \n  In this case the client has to reissue VERSION-CONTROL specifying \n  another request URL which uniquely identifies the URL of the resource \n  to be undeleted.\n\nIs this approach compliant to the DeltaV spec ?\n\nStill it is an open question (for me) how to find deleted resources in a\ngiven \ncollection in an efficient way using DeltaV protocol.\n\nregards\nMatthias\n\n-----Urspr?ngliche Nachricht-----\nVon: Sohn, Matthias \nGesendet: Freitag, 15. M?rz 2002 14:29\nAn: Ietf-Dav-Versioning@W3. Org\nBetreff: how to perform undeletion\n\n\nHi,\n\nhow can undelete of a versioned resource (residing in a versioned\ncollection) \nwhich has been deleted somewhen in the past be done using DeltaV ?\n\nThere are two things which have to be solved here:\n*find the deleted resource(s) under a given path  \n*undelete resource(s)\nI would like to do it with using an activity and working resources so that\nthe undeletion is tracked in the activity.\n\nHow can the browsing for deleted resources (or collections) be done in an\nefficient way, i.e. how can the client\nfind out which resources have been deleted let's say recursively under\n/a/b/c/... ?\n\nregards\nMatthias\n\n\n\n", "id": "lists-007-3565730"}, {"subject": "RE: how to perform undeletio", "content": "   From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n\n   how can undelete of a versioned resource (residing in a versioned\n   collection) which has been deleted somewhen in the past be done\n   using DeltaV ?\n\n   There are two things which have to be solved here:\n   *find the deleted resource(s) under a given path  \n   *undelete resource(s)\n   I would like to do it with using an activity and working resources\n   so that the undeletion is tracked in the activity.\n\nNote that tracking the undeletion requires that your server support\neither versioned collections or baselines (or both).  If your server\ndoes not support in-place-checkout, then it has to support versioned\ncollections in order to track the undeletion.\n\nAlso note that tracking the undeletion in an activity requires that\nyour server support versioned collections (baselines aren't enough)\nand activities.\n\nAlso note that using a working resource (i.e. a client side workspace)\nis not needed for either tracking the undeletion, or for tracking the\nundeletion in an activity, but that it does affect the requests you\nneed to issue in order to do the undeletion.\n\n   How can the browsing for deleted resources (or collections) be done\n   in an efficient way, i.e. how can the client find out which\n   resources have been deleted let's say recursively under\n   /a/b/c/... ?\n\nThe easiest way to find deleted resources is if the server supports\nbaselines.  In this case, you can just browse the collections identified\nby the DAV:baseline-collection property of the baselines to find\nthe resource you want to undelete.  Alternatively, if the server\nsupports versioned collections, you could browse through versions\nof visible collections to find the version history of the deleted resource.\nAnd finally, you could scan through the DAV:version-history-collection-set,\nbut that would be an extreme last resource, since it is likely to be\nhard to find the version history you want from the set of all version\nhistories.\n\nOnce you have found the version you want to restore, what you do\ndepends on whether the server supports the checkout-in-place or the\nworking-resource option.  If it supports checkout-in-place, you just\ndo a VERSION-CONTROL request that identifies the version you want\nrestored.  If it supports the working-resource option, you need to\ncheckout a collection containing the version history of the resource\nyou want to restore, checkout a destination collection, MOVE the\ndesired resource from the first working collection to the second,\ndelete the first working collection, and CHECKIN the second working\ncollection.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3575121"}, {"subject": "RE: how to perform undeletio", "content": "   From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n\n   I think when the resource version to be revived in order to\n   undelete the resource has been found the undelete operation can be\n   done in the following way :\n\n   - check out the collection which shall contain the resource to be\n     undeleted,\n\nYes.\n\n   this yields a working collection which is bound to an activity\n   (since I want to track all changes in activities)\n\nYes.\n\n   - issue VERSION-CONTROL on the resource version contained in the\n   old collection version before the deletion of the resource took\n   place\n\nA collection version does not contain resource versions, it contains\na DAV:version-controlled-binding-set property that contains a set of\nname/version-history pairs.\n\nAlso, you don't issue VERSION-CONTROL requests to members of a working\ncollection, because a working collection does not contain\nversion-controlled resources (and VERSION-CONTROL creates a\nversion-controlled resource).  The VERSION-CONTROL request is used to\nrestore resources to checked-out collections (i.e. to collections that\ncan be checked-out in place), not to working collections.\n\n     In this request specify the URL under which the VCR for the resource to\nbe\n     undeleted shall reappear.\n\n   - check in the activity containing the working collection which now has a\n\n     binding pointing to the newly created VCR for the undeleted resource.\n\nWorking collections cannot contain a VCR.\n\n   - if since the resource has been deleted another resource has been\ncreated \n     with the same URL the VERSION-CONTROL request given above will fail. \n     In this case the client has to reissue VERSION-CONTROL specifying \n     another request URL which uniquely identifies the URL of the resource \n     to be undeleted.\n\n   Is this approach compliant to the DeltaV spec ?\n\nNo, with working resources, you have to CHECKOUT a collection version\nthat identifies the version history of the desired version in its\nDAV:version-controlled-binding-set.  Then you can MOVE that version\nhistory from that working collection into the destination working\ncollection, DELETE the source working collection, and then CHECKIN\nthe destination working collection.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3584965"}, {"subject": "Copy/Overwrite (section 1.7", "content": "Hi,\n\ngiven two collections with version controlled members:\n\n- a with member VCRs m1 and m2\n- b with member VCRs m2 and m3\n\nWhat is the expected result for\n\nCOPY a\nDestination-URI: b\nOverwrite: T\n\n?\n\n(let's assume no auto-versioning for now)\n\nBased on RFC2518 only I would expect a collection b with members \"m1\" and\n\"m2\". However, RFC3253 clarifies that COPY/Overwrite updates (and doesn't\nreplace), so I'd expect the following members of \"b\":\n\n- m1 (newly created, whether it's versioned or not depends on the automatic\nversioning behaviour of the server)\n- m2 (updated when m2 already was checked out, untouched when checked-in)\n- m3 (unchanged)\n\nJulian\n\n\n\n", "id": "lists-007-3594629"}, {"subject": "AW: how to perform undeletio", "content": "      I think when the resource version to be revived in order to\n      undelete the resource has been found the undelete operation can be\n      done in the following way :\n   \n      - check out the collection which shall contain the resource to be\n        undeleted,\n   \n   Yes.\n   \n      this yields a working collection which is bound to an activity\n      (since I want to track all changes in activities)\n   \n   Yes.\n   \n      - issue VERSION-CONTROL on the resource version contained in the\n      old collection version before the deletion of the resource took\n      place\n   \n   A collection version does not contain resource versions, it contains\n   a DAV:version-controlled-binding-set property that contains a set of\n   name/version-history pairs.\n\nSorry it seems that my sentence was too sloppy. \n- I meant that by using some report provided by my server I can find out \nto which version of the deleted resource the VCR has pointed to just \nbefore the resource has been deleted. \n- Since the resource has been deleted before the undeletion is done\nthere is no VCR for the version history of the deleted resource in \nmy workspace. By issueing VERSION-CONTROL on the version I want to put \nback to life I thought I can create a new VCR in the checked out collection\n(which belongs to my workspace) which will then point again to the \nsame version the old VCR pointed to before it has been deleted.\n   \n   Also, you don't issue VERSION-CONTROL requests to members of \n   a working\n   collection, because a working collection does not contain\n   version-controlled resources (and VERSION-CONTROL creates a\n   version-controlled resource).  The VERSION-CONTROL request is used to\n   restore resources to checked-out collections (i.e. to \n   collections that\n   can be checked-out in place), not to working collections.\n\nI don't want to issue VERSION-CONTROL to a member of the working\ncollection but to the resource version I want to revive in order \nto create a new VCR for it. This version I found using a report. \nI only want to checkout the target collection in order to allow the\nrecreation of the resource (which shall become a member of \nthe checked out collection).\n   \n        In this request specify the URL under which the VCR for \n   the resource to\n   be\n        undeleted shall reappear.\n   \n      - check in the activity containing the working collection \n   which now has a\n   \n        binding pointing to the newly created VCR for the \n   undeleted resource.\n   \n   Working collections cannot contain a VCR.\n   \n      - if since the resource has been deleted another resource has been\n   created \n        with the same URL the VERSION-CONTROL request given \n   above will fail. \n        In this case the client has to reissue VERSION-CONTROL \n   specifying \n        another request URL which uniquely identifies the URL \n   of the resource \n        to be undeleted.\n   \n      Is this approach compliant to the DeltaV spec ?\n   \n   No, with working resources, you have to CHECKOUT a collection version\n   that identifies the version history of the desired version in its\n   DAV:version-controlled-binding-set.  Then you can MOVE that version\n   history from that working collection into the destination working\n   collection, DELETE the source working collection, and then CHECKIN\n   the destination working collection.\n   \nHuh, I feel this partial move is ugly. \n\nFirst this needs 5 requests to do a simple undeletion:\n- two CHECKOUTs (of the source and target collection versions) \n- (partial) MOVE \n- DELETE (or UNCHECKOUT) on the source working collection \n- and a CHECKIN on the target collection. \n\nIn addition this would require that MOVE is not an atomic\noperation (either done completely or not at all). If MOVE is\nnot atomic I expect that the probability of inconsistencies \non the server will increase if some client issues a similar \npartial MOVE for a different purpose. Since we use a stateless\nprotocol it's no option for the server to wait for the DELETE\nand CHECKIN until the transaction doing the MOVE is committed.\nWithout waiting for DELETE and CHECKIN the server has no chance\nto find out that this request sequence is an undelete operation \n(which should be atomic as well).\n\nI would prefer if there is some solution which only needs CHECKOUT \nand CHECKIN of the target collection (this seems to be necessary \nwith versioned collections) and only one atomic command (e.g. UNDELETE \nor VERSION-CONTROL with additional semantics) which does recreate \nthe deleted VCR and ensures that the same version is revived which \nhas been in the workspace just before the resource has been deleted. \n\nThis would mean 3 requests instead of 5, less chance for \ninconsistencies (since MOVE is atomic) and clearer semantics \nfor the sake of an additional method (or additional semantics \nfor VERSION-CONTROL ?).\n\n\n\n", "id": "lists-007-3602642"}, {"subject": "RE: Copy/Overwrite (section 1.7", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   given two collections with version controlled members:\n\n   - a with member VCRs m1 and m2\n   - b with member VCRs m2 and m3\n\n   What is the expected result for\n\n   COPY a\n   Destination-URI: b\n   Overwrite: T\n\n   (let's assume no auto-versioning for now)\n\n   Based on RFC2518 only I would expect a collection b with members \"m1\" and\n   \"m2\".\n\nThat is correct.\n\n   However, RFC3253 clarifies that COPY/Overwrite updates (and doesn't\n   replace),\n\nThat is only for the case where there is a destination resource\ncorresponding to a source resource.  In case the destination resource\ndoes not correspond to the source resource, the expected (from 2518)\nthing happens, i.e. the destination resource is removed.  So for\nexample, since there is no \"m3\" resource in \"a\", following the\nCOPY, there is no \"m3\" resource in \"b\".\n\n so I'd expect the following members of \"b\":\n\n   - m1 (newly created, whether it's versioned or not depends on the\nautomatic\n   versioning behaviour of the server)\nYes.\n   - m2 (updated when m2 already was checked out, untouched when checked-in)\nb/m2 must be updated to have the content and dead properties of a/m2,\nor else the COPY (or at least, that part of the COPY if your COPY does\nbest effort) MUST fail, and be reported as failing in the COPY response.\n   - m3 (unchanged)\nNo, b/m3 must not be mapped to any resource following the COPY.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3614045"}, {"subject": "RE: how to perform undeletio", "content": "   From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n\n I think when the resource version to be revived in order to\n undelete the resource has been found the undelete operation can be\n done in the following way :\n\n - check out the collection which shall contain the resource\n to be undeleted, this yields a working collection which is\n bound to an activity (since I want to track all changes in\n activities)\n\n - issue VERSION-CONTROL on the resource version contained in\n the old collection version before the deletion of the\n resource took place\n\n      A collection version does not contain resource versions, it\n      contains a DAV:version-controlled-binding-set property that\n      contains a set of name/version-history pairs.\n\n   Sorry it seems that my sentence was too sloppy. \n   - I meant that by using some report provided by my server I can\n   find out to which version of the deleted resource the VCR has\n   pointed to just before the resource has been deleted.\n\nYes, you could define such a custom report.\n\n   - Since the resource has been deleted before the undeletion is done\n   there is no VCR for the version history of the deleted resource in \n   my workspace. \n\nAgreed.\n\n   By issueing VERSION-CONTROL on the version I want to put back to\n   life.  I thought I can create a new VCR in the checked out\n   collection (which belongs to my workspace) which will then point\n   again to the same version the old VCR pointed to before it has been\n   deleted.\n\nIf your server supports workspaces (with checked-out\nversion-controlled collections), then yes, that is exactly what you\nwould do.  But if you are using working collections, you need to use a\ndifferent set of requests, because working collections do not contain\nversion-controlled resources, and therefore cannot have members added\nto them with the VERSION-CONTROl request.\n\n      Also, you don't issue VERSION-CONTROL requests to members of a\n      working collection, because a working collection does not\n      contain version-controlled resources (and VERSION-CONTROL\n      creates a version-controlled resource).  The VERSION-CONTROL\n      request is used to restore resources to checked-out collections\n      (i.e. to collections that can be checked-out in place), not to\n      working collections.\n\n   I don't want to issue VERSION-CONTROL to a member of the working\n   collection but to the resource version I want to revive in order to\n   create a new VCR for it.  This version I found using a report.\n\nThis VERSION-CONTROL request takes two parameters: the request-URL\n(indicating where the new version-controlled resource should be\ncreated), and the version (indicating what should be the\nDAV:checked-in version of the new VCR).  So yes, you do indicate\nthe version, but you also have to indicate where the new VCR should\nbe located.  And it can't be located in a working collection,\nbecause working collections do not contain VCRs.\n\n   I only want to checkout the target collection in order to allow the\n   recreation of the resource (which shall become a member of \n   the checked out collection).\n\nA VCR can be a member of a checked-out version-controlled collection,\nbut it cannot be a member of a working collection.  So the requests\nyou need to issue to manipulate working collections will be different\nfrom the requests you need to issue to manipulate checked-out\nversion-controlled collections.\n\n      ... with working resources, you have to CHECKOUT a collection\n      version that identifies the version history of the desired\n      version in its DAV:version-controlled-binding-set.  Then you can\n      MOVE that version history from that working collection into the\n      destination working collection, DELETE the source working\n      collection, and then CHECKIN the destination working collection.\n\n   Huh, I feel this partial move is ugly. \n\n   First this needs 5 requests to do a simple undeletion:\n   - two CHECKOUTs (of the source and target collection versions) \n   - (partial) MOVE \nThis is a regular MOVE, not a \"partial\" MOVE.\n   - DELETE (or UNCHECKOUT) on the source working collection \n   - and a CHECKIN on the target collection. \n\nThe working group did not believe that this \"restore of a deleted\nresource\" is sufficiently common to merit defining a special request\nfor the purpose.\n\n   In addition this would require that MOVE is not an atomic\n   operation (either done completely or not at all).\n\nThere are no \"partial\" or \"non-atomic\" MOVEs here.  The only sense\nin which the MOVE is partial is that the working collection that is\nthe source of the MOVE is deleted following the MOVE. \n\n   If MOVE is\n   not atomic I expect that the probability of inconsistencies \n   on the server will increase if some client issues a similar \n   partial MOVE for a different purpose. Since we use a stateless\n   protocol it's no option for the server to wait for the DELETE\n   and CHECKIN until the transaction doing the MOVE is committed.\n   Without waiting for DELETE and CHECKIN the server has no chance\n   to find out that this request sequence is an undelete operation \n   (which should be atomic as well).\n\nI see no reason for the \"undelete\" operation to be atomic.  To the\ncontrary, a user is likely to have several adjustments they want to\nmake to the collection before committing the changes via a \"CHECKIN\".\n\n   I would prefer if there is some solution which only needs CHECKOUT \n   and CHECKIN of the target collection (this seems to be necessary \n   with versioned collections) and only one atomic command (e.g. UNDELETE \n   or VERSION-CONTROL with additional semantics) which does recreate \n   the deleted VCR and ensures that the same version is revived which \n   has been in the workspace just before the resource has been deleted. \n\nThe version that appeared in the workspace at the time the VCR was\ndeleted is not necessarily an especially interesting version, since\nsomeone in a different workspace (that hasn't seen the deletion yet)\nmight have produced a variety of more interesting successors to that\nversion.  We discussed whether or not to require that a particular\nversion be restored, and the consensus was that this should be left\nup to the server.  So your server is welcome to restore the version\nthat was visible before it was deleted, but clients cannot assume\nthat to be the case (nor can the assume that a server will keep track\nof that version).\n\n   This would mean 3 requests instead of 5,\n\nThis was not considered a sufficiently common use case to warrant\nconcern over an additional couple of round trips.\n\n   less chance for inconsistencies (since MOVE is atomic)\n\nOnly normal (atomic) MOVE semantics are used here.\n\n   and clearer semantics for the sake of an additional method (or\n   additional semantics for VERSION-CONTROL ?).\n\nIt is highly desireable for a particular request to have\nconsistent semantics.  In the case of VERSION-CONTROL, one of the\npostconditions is that a version-controlled resource exist at the\nrequest URL when the request succeeds.  We could have made that\npostcondition context sensitive (i.e. creates a VCR normally, but\ncreates a version history in a working collection), but this use case\nwas not considered sufficiently common to merit introducing a new\nmethod or increasing the complexity of VERSION-CONTROL, just to avoid\na couple of round trips for an infrequent use case.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3622823"}, {"subject": "how to specify extension features in response to OPTIONS reques", "content": "Hi,\n\nis it possible to specify extension features (that are not defined in the\nDeltaV spec) in the response to a OPTIONS request ?\n\nWe want to use this kind of extension to allow usage of our client against\nour server (which \nwill support some extensions which are not in the standard) but it should\nalso work against\nother servers which clearly will not have these extensions. Therefore we\nneed some mechanism\nto find out which extension features are supported by a given server. Some\nnamespace mechanism could be used to prevent name clashes between extension\nfeatures defined by different servers. E.g. our extension could be named\nSAP:ourSpecialExtension.\n\nregards\nMatthias\n\n\n\n", "id": "lists-007-3637304"}, {"subject": "RE: how to specify extension features in response to OPTIONS reques", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Sohn, Matthias\n> Sent: Tuesday, March 19, 2002 10:20 AM\n> To: Ietf-Dav-Versioning@W3. Org\n> Subject: how to specify extension features in response to OPTIONS\n> request\n>\n>\n> Hi,\n>\n> is it possible to specify extension features (that are not defined in the\n> DeltaV spec) in the response to a OPTIONS request ?\n\nIt's possible, but I would strongly recommend not to do that.\n\nIf you need a non-intrusive way to signal server extensions, use a custom\nlive property.\n\n\n\n", "id": "lists-007-3645729"}, {"subject": "AW: how to specify extension features in response to OPTIONS requ es", "content": "   -----Urspr?ngliche Nachricht-----\n   Von: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n   Gesendet: Dienstag, 19. M?rz 2002 10:59\n   An: Sohn, Matthias; Ietf-Dav-Versioning@W3. Org\n   Betreff: RE: how to specify extension features in response to OPTIONS\n   request\n   \n   \n   > From: ietf-dav-versioning-request@w3.org\n   > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of \n   Sohn, Matthias\n   > Sent: Tuesday, March 19, 2002 10:20 AM\n   > To: Ietf-Dav-Versioning@W3. Org\n   > Subject: how to specify extension features in response to OPTIONS\n   > request\n   >\n   >\n   > Hi,\n   >\n   > is it possible to specify extension features (that are not \n   defined in the\n   > DeltaV spec) in the response to a OPTIONS request ?\n   \n   It's possible, but I would strongly recommend not to do that.\n\nWhy ?\n   \n   If you need a non-intrusive way to signal server extensions, \n   use a custom\n   live property.\n   \n   \n\n\n\n", "id": "lists-007-3655381"}, {"subject": "RE: how to specify extension features in response to OPTIONS requ es", "content": ">    > From: ietf-dav-versioning-request@w3.org\n>    > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n>    Sohn, Matthias\n>    > Sent: Tuesday, March 19, 2002 10:20 AM\n>    > To: Ietf-Dav-Versioning@W3. Org\n>    > Subject: how to specify extension features in response to OPTIONS\n>    > request\n>    >\n>    >\n>    > Hi,\n>    >\n>    > is it possible to specify extension features (that are not\n>    defined in the\n>    > DeltaV spec) in the response to a OPTIONS request ?\n>\n>    It's possible, but I would strongly recommend not to do that.\n>\n> Why ?\n>\n>    If you need a non-intrusive way to signal server extensions,\n>    use a custom\n>    live property.\n\nBecause OPTIONS headers don't have a concept of namespaces -- it's just a\nflat namespace. WebDAV properties are identified by (namespace, name), so by\ndefinition there won't be any confusion. Finally, the PROPFIND semantics\ndefined in RFC3253 allow you not to report your extension property unless\nsomebody (your client) is specifically asking for it.\n\n\n\n", "id": "lists-007-3665513"}, {"subject": "version history resource classifi questio", "content": "hi,\n\nin 22.11 is the classification of version history.\n\nimagine i have\n\n/files/test.xml\n\nunder version control and the belonging history\n\n/his/9\n\nmaybe with one version\n\n/his/9/1.0\n\nin 22.11 stands, that the DeltaV compliant resource props and methods also\nbelong to version history. does version history means version history resource\n( in my case /his/9 )and is it possible to have a property like\nsupported-method-set for it? or is it only version-set and root-version? or am i somehow\ntotally wrong?\n\nthanx\njens\n\n-- \nGMX - Die Kommunikationsplattform im Internet.\nhttp://www.gmx.net\n\n\n\n", "id": "lists-007-3675894"}, {"subject": "AW: how to specify extension features in response to OPTIONS requ  es", "content": "   -----Urspr?ngliche Nachricht-----\n   Von: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n   Gesendet: Dienstag, 19. M?rz 2002 11:32\n   An: Sohn, Matthias; Ietf-Dav-Versioning@W3. Org\n   Betreff: RE: how to specify extension features in response to OPTIONS\n   requ est\n   \n   \n   \n   >    > From: ietf-dav-versioning-request@w3.org\n   >    > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n   >    Sohn, Matthias\n   >    > Sent: Tuesday, March 19, 2002 10:20 AM\n   >    > To: Ietf-Dav-Versioning@W3. Org\n   >    > Subject: how to specify extension features in \n   response to OPTIONS\n   >    > request\n   >    >\n   >    >\n   >    > Hi,\n   >    >\n   >    > is it possible to specify extension features (that are not\n   >    defined in the\n   >    > DeltaV spec) in the response to a OPTIONS request ?\n   >\n   >    It's possible, but I would strongly recommend not to do that.\n   >\n   > Why ?\n   >\n   >    If you need a non-intrusive way to signal server extensions,\n   >    use a custom\n   >    live property.\n   \n   Because OPTIONS headers don't have a concept of namespaces \n   -- it's just a\n   flat namespace. WebDAV properties are identified by \n   (namespace, name), so by\n   definition there won't be any confusion. Finally, the \n   PROPFIND semantics\n   defined in RFC3253 allow you not to report your extension \n   property unless\n   somebody (your client) is specifically asking for it.\n   \nDo you think it would be ok to use OPTIONS in the following way to \nsignal server extensions ? In this approach XML namespaces would be\nused to prevent name clashes :\n\n>>REQUEST\n\nOPTIONS /doc HTTP/1.1 \n  Host: www.webdav.org\n  Content-Type: text/xml; charset=\"utf-8\"\n  Content-Length: xxxx\n\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:options xmlns:D=\"DAV:\"\nxmlns:x=\"http:/www.sap.com/xyz/DAVExtensionSchema.xsd\">\n    <x:extension-feature-set/>\n  </D:options>\n   \n>>RESPONSE\n\n  HTTP/1.1 200 OK\n  DAV: 1, version-control, checkout-in-place, version-history, workspace\n  Content-Type: text/xml; charset=\"utf-8\"\n  Content-Length: xxxx\n\n  <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n  <D:options-response xmlns:D=\"DAV:\">\n    <x:extension-feature-set>\n      <x:my-special-feature-1/>\n      <x:my-special-feature-2/>\n      <x:my-special-feature-3/>\n    </x:extension-feature-set>\n  </D:options-response>   \n\n\n\n", "id": "lists-007-3683470"}, {"subject": "RE: how to specify extension features in response to OPTIONS requ  es", "content": ">    >    > From: ietf-dav-versioning-request@w3.org\n>    >    > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n>    >    Sohn, Matthias\n>    >    > Sent: Tuesday, March 19, 2002 10:20 AM\n>    >    > To: Ietf-Dav-Versioning@W3. Org\n>    >    > Subject: how to specify extension features in\n>    response to OPTIONS\n>    >    > request\n>    >    >\n>    >    >\n>    >    > Hi,\n>    >    >\n>    >    > is it possible to specify extension features (that are not\n>    >    defined in the\n>    >    > DeltaV spec) in the response to a OPTIONS request ?\n>    >\n>    >    It's possible, but I would strongly recommend not to do that.\n>    >\n>    > Why ?\n>    >\n>    >    If you need a non-intrusive way to signal server extensions,\n>    >    use a custom\n>    >    live property.\n>\n>    Because OPTIONS headers don't have a concept of namespaces\n>    -- it's just a\n>    flat namespace. WebDAV properties are identified by\n>    (namespace, name), so by\n>    definition there won't be any confusion. Finally, the\n>    PROPFIND semantics\n>    defined in RFC3253 allow you not to report your extension\n>    property unless\n>    somebody (your client) is specifically asking for it.\n>\n> Do you think it would be ok to use OPTIONS in the following way to\n> signal server extensions ? In this approach XML namespaces would be\n> used to prevent name clashes :\n>\n> >>REQUEST\n>\n> OPTIONS /doc HTTP/1.1\n>   Host: www.webdav.org\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:options xmlns:D=\"DAV:\"\n> xmlns:x=\"http:/www.sap.com/xyz/DAVExtensionSchema.xsd\">\n>     <x:extension-feature-set/>\n>   </D:options>\n>\n> >>RESPONSE\n>\n>   HTTP/1.1 200 OK\n>   DAV: 1, version-control, checkout-in-place, version-history, workspace\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:options-response xmlns:D=\"DAV:\">\n>     <x:extension-feature-set>\n>       <x:my-special-feature-1/>\n>       <x:my-special-feature-2/>\n>       <x:my-special-feature-3/>\n>     </x:extension-feature-set>\n>   </D:options-response>\n\nI would object to this for the same reasons why I think RFC3253 should not\nhave touched OPTIONS request / response bodies.\n\nThere's no technical reason why you would need to extend OPTIONs to do\nsomething a live property can do as well.\n\n\n\n", "id": "lists-007-3695223"}, {"subject": "Re: how to specify extension features in response to OPTIONS reques", "content": "On Tue, Mar 19, 2002 at 10:58:32AM +0100, Julian Reschke wrote:\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Sohn, Matthias\n>...\n> > is it possible to specify extension features (that are not defined in the\n> > DeltaV spec) in the response to a OPTIONS request ?\n> \n> It's possible, but I would strongly recommend not to do that.\n> \n> If you need a non-intrusive way to signal server extensions, use a custom\n> live property.\n\nThere was some amount of consensus a while back on the DAV WG list that the\nDAV: header should allow Coded-URLs in it. mod_dav took this approach, so an\nOPTIONS response looks like:\n\nHTTP/1.1 200 OK\nDate: Tue, 19 Mar 2002 13:10:17 GMT\nServer: Apache/1.3.19 (Unix) DAV/1.0.2\nContent-Length: 0\nMS-Author-Via: DAV\nAllow: OPTIONS, GET, HEAD, POST, DELETE, TRACE, PROPFIND, PROPPATCH, COPY, MOVE, LOCK, UNLOCK\nDAV: 1,2,<http://apache.org/dav/propset/fs/1>\nConnection: close\nContent-Type: text/plain\n\n\nCheers,\n-g\n\n-- \nGreg Stein, http://www.lyra.org/\n\n\n\n", "id": "lists-007-3706627"}, {"subject": "RE: how to specify extension features in response to OPTIONS requ es", "content": "If you hope other servers will\nstart supporting some aspects of your proprietary extensions, you might\nwant to consider using DAV:supported-method-set,\nDAV:supported-live-property-set,\nand DAV:supported-report-set.  This allows a client to determine whether\nor not a given server supports the features it needs, as opposed to looking\nfor a particular bundle of functionality that one server chose to implement.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Tuesday, March 19, 2002 7:29 AM\nTo: Sohn, Matthias; Ietf-Dav-Versioning@W3. Org\nSubject: RE: how to specify extension features in response to OPTIONS\nrequ est\n\n\n>    >    > From: ietf-dav-versioning-request@w3.org\n>    >    > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n>    >    Sohn, Matthias\n>    >    > Sent: Tuesday, March 19, 2002 10:20 AM\n>    >    > To: Ietf-Dav-Versioning@W3. Org\n>    >    > Subject: how to specify extension features in\n>    response to OPTIONS\n>    >    > request\n>    >    >\n>    >    >\n>    >    > Hi,\n>    >    >\n>    >    > is it possible to specify extension features (that are not\n>    >    defined in the\n>    >    > DeltaV spec) in the response to a OPTIONS request ?\n>    >\n>    >    It's possible, but I would strongly recommend not to do that.\n>    >\n>    > Why ?\n>    >\n>    >    If you need a non-intrusive way to signal server extensions,\n>    >    use a custom\n>    >    live property.\n>\n>    Because OPTIONS headers don't have a concept of namespaces\n>    -- it's just a\n>    flat namespace. WebDAV properties are identified by\n>    (namespace, name), so by\n>    definition there won't be any confusion. Finally, the\n>    PROPFIND semantics\n>    defined in RFC3253 allow you not to report your extension\n>    property unless\n>    somebody (your client) is specifically asking for it.\n>\n> Do you think it would be ok to use OPTIONS in the following way to\n> signal server extensions ? In this approach XML namespaces would be\n> used to prevent name clashes :\n>\n> >>REQUEST\n>\n> OPTIONS /doc HTTP/1.1\n>   Host: www.webdav.org\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:options xmlns:D=\"DAV:\"\n> xmlns:x=\"http:/www.sap.com/xyz/DAVExtensionSchema.xsd\">\n>     <x:extension-feature-set/>\n>   </D:options>\n>\n> >>RESPONSE\n>\n>   HTTP/1.1 200 OK\n>   DAV: 1, version-control, checkout-in-place, version-history, workspace\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:options-response xmlns:D=\"DAV:\">\n>     <x:extension-feature-set>\n>       <x:my-special-feature-1/>\n>       <x:my-special-feature-2/>\n>       <x:my-special-feature-3/>\n>     </x:extension-feature-set>\n>   </D:options-response>\n\nI would object to this for the same reasons why I think RFC3253 should not\nhave touched OPTIONS request / response bodies.\n\nThere's no technical reason why you would need to extend OPTIONs to do\nsomething a live property can do as well.\n\n\n\n", "id": "lists-007-3716362"}, {"subject": "RE: version history resource classifi questio", "content": "Yes, \"version history\" means \"version history resource\".\n\nSee the definition of \"version history resource\":\n   A \"version history resource\", or simply \"version history\", is a resource\n   that contains all the versions of a particular version-controlled\nresource.\n\nSo, yes, a version history resource has all DeltaV-compliant resource\nproperties, including DAV:supported-method-set, DAV:supported-report-set,\nand DAV:supported-live-property-set.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Jens Grote [mailto:Grote.Jens@gmx.de]\nSent: Tuesday, March 19, 2002 7:15 AM\nTo: ietf-dav-versioning@w3.org\nSubject: version history resource classifi question\n\n\nhi,\n\nin 22.11 is the classification of version history.\n\nimagine i have\n\n/files/test.xml\n\nunder version control and the belonging history\n\n/his/9\n\nmaybe with one version\n\n/his/9/1.0\n\nin 22.11 stands, that the DeltaV compliant resource props and methods also\nbelong to version history. does version history means version history\nresource\n( in my case /his/9 )and is it possible to have a property like\nsupported-method-set for it? or is it only version-set and root-version? or\nam i somehow\ntotally wrong?\n\nthanx\njens\n\n-- \nGMX - Die Kommunikationsplattform im Internet.\nhttp://www.gmx.net\n\n\n\n", "id": "lists-007-3728790"}, {"subject": "RE: how to specify extension features in response to OPTIONS requ es", "content": "Yes,\n\nI was going to mention that myself.\n\nIf your extensions implement new methods, reports or live properties, the\ncomplete discovery framework is already there. Don't abuse OPTIONS for it.\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Tuesday, March 19, 2002 2:18 PM\n> To: Ietf-Dav-Versioning@W3. Org\n> Subject: RE: how to specify extension features in response to OPTIONS\n> requ est\n>\n>\n> If you hope other servers will\n> start supporting some aspects of your proprietary extensions, you might\n> want to consider using DAV:supported-method-set,\n> DAV:supported-live-property-set,\n> and DAV:supported-report-set.  This allows a client to determine whether\n> or not a given server supports the features it needs, as opposed\n> to looking\n> for a particular bundle of functionality that one server chose to\n> implement.\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Tuesday, March 19, 2002 7:29 AM\n> To: Sohn, Matthias; Ietf-Dav-Versioning@W3. Org\n> Subject: RE: how to specify extension features in response to OPTIONS\n> requ est\n>\n>\n> >    >    > From: ietf-dav-versioning-request@w3.org\n> >    >    > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> >    >    Sohn, Matthias\n> >    >    > Sent: Tuesday, March 19, 2002 10:20 AM\n> >    >    > To: Ietf-Dav-Versioning@W3. Org\n> >    >    > Subject: how to specify extension features in\n> >    response to OPTIONS\n> >    >    > request\n> >    >    >\n> >    >    >\n> >    >    > Hi,\n> >    >    >\n> >    >    > is it possible to specify extension features (that are not\n> >    >    defined in the\n> >    >    > DeltaV spec) in the response to a OPTIONS request ?\n> >    >\n> >    >    It's possible, but I would strongly recommend not to do that.\n> >    >\n> >    > Why ?\n> >    >\n> >    >    If you need a non-intrusive way to signal server extensions,\n> >    >    use a custom\n> >    >    live property.\n> >\n> >    Because OPTIONS headers don't have a concept of namespaces\n> >    -- it's just a\n> >    flat namespace. WebDAV properties are identified by\n> >    (namespace, name), so by\n> >    definition there won't be any confusion. Finally, the\n> >    PROPFIND semantics\n> >    defined in RFC3253 allow you not to report your extension\n> >    property unless\n> >    somebody (your client) is specifically asking for it.\n> >\n> > Do you think it would be ok to use OPTIONS in the following way to\n> > signal server extensions ? In this approach XML namespaces would be\n> > used to prevent name clashes :\n> >\n> > >>REQUEST\n> >\n> > OPTIONS /doc HTTP/1.1\n> >   Host: www.webdav.org\n> >   Content-Type: text/xml; charset=\"utf-8\"\n> >   Content-Length: xxxx\n> >\n> >   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> >   <D:options xmlns:D=\"DAV:\"\n> > xmlns:x=\"http:/www.sap.com/xyz/DAVExtensionSchema.xsd\">\n> >     <x:extension-feature-set/>\n> >   </D:options>\n> >\n> > >>RESPONSE\n> >\n> >   HTTP/1.1 200 OK\n> >   DAV: 1, version-control, checkout-in-place, version-history, workspace\n> >   Content-Type: text/xml; charset=\"utf-8\"\n> >   Content-Length: xxxx\n> >\n> >   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> >   <D:options-response xmlns:D=\"DAV:\">\n> >     <x:extension-feature-set>\n> >       <x:my-special-feature-1/>\n> >       <x:my-special-feature-2/>\n> >       <x:my-special-feature-3/>\n> >     </x:extension-feature-set>\n> >   </D:options-response>\n>\n> I would object to this for the same reasons why I think RFC3253 should not\n> have touched OPTIONS request / response bodies.\n>\n> There's no technical reason why you would need to extend OPTIONs to do\n> something a live property can do as well.\n>\n>\n\n\n\n", "id": "lists-007-3737581"}, {"subject": "RE: how to specify extension features in response to OPTIONS requ es", "content": "> From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> Sent: Wednesday, March 20, 2002 3:28 AM\n> To: 'Julian Reschke'; 'Clemm, Geoff'; 'Ietf-Dav-Versioning@W3. Org'\n> Subject: RE: how to specify extension features in response to OPTIONS\n> requ est\n>\n>\n>\n> > If your extensions implement new methods, reports or live\n> > properties, the\n> > complete discovery framework is already there. Don't abuse\n> > OPTIONS for it.\n>\n> I don't agree with that recommendation.  The framework may be there for\n> DeltaV, but it's not a general part of WebDAV.  If the people\n> that asked the\n> original question need to interoperate with clients that don't already use\n> the DeltaV framework, then it may not be trivial or \"already there\" for\n> them.\n\nLisa,\n\n1) The question was initially raised on the delta-V list.\n\n2) OPTIONS (as defined in RFC2518) doesn't define any way to advertise\nprivate extensions. OPTIONS as defined in RFC2616 does not define any way to\nextend it except by inventing new headers (with the obvious problems in name\nscoping).\n\n3) Any server supporting RFC3253 (or ACL) MUST support the live properties\nDAV:supported-method-set, DAV:supported-reports-set and\nDAV:supported-live-property-set. If a protocol extension affects live\nproperties, new methods (sigh!) or new reports, the discovery algorithm is\nalready defined, MUST be defined anyway, and there's no need to invent\nanother one.\n\n4) Could you please explain why a client would have any problems using the\nnew RFC3253 live properties for feature discovery? It's no different from\nPROPFINDing DAV:supportedlock to discover which locking features are\navailable.\n\n> I also fail to see why using OPTIONS for its original purpose is abuse.\n\nBecause there's no RFC-sanctioned way to extend it except by inventing new\nHTTP headers.\n\n\n\n", "id": "lists-007-3751888"}, {"subject": "RE: how to specify extension features in response to OPTIONS reques", "content": "> From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> Sent: Wednesday, March 20, 2002 3:24 AM\n> To: 'Greg Stein'; 'Julian Reschke'; 'Sohn, Matthias'\n> Cc: ietf-dav-versioning@w3.org; w3c-dist-auth@w3.org\n> Subject: RE: how to specify extension features in response to OPTIONS\n> request\n>\n>\n> > There was some amount of consensus a while back on the DAV WG\n> > list that the\n> > DAV: header should allow Coded-URLs in it. mod_dav took this\n> > approach, so an\n> > OPTIONS response looks like:\n>\n> If Greg's approach is taken to avoid conflicts, then I see no\n> strong reason\n> to prefer live properties over OPTIONS header values in the general case.\n\n...other that in this case this way to extend the DASL header must be\ndocumented somewhere...?\n\n> However, if the feature is one which relates only to some resources (e.g.\n> all collections support the feature, or all resources in the\n> directory foo,\n> etc) then it might be helpful to advertise support for the feature only on\n> those resources, using a live property as suggested.\n>\n> OPTIONS * still seems to be the most appropriate place to marshall\n> server-wide features, with the conflict-avoidance caveats already\n> mentioned.\n\nHow can this be the appropriate place if RFC2518 doesn't document how to do\nthat?\n\n\n\n", "id": "lists-007-3762304"}, {"subject": "Clarification: extended baseline semantics of UPDAT", "content": "Section 12.14, which defines the extended baseline semantics of MERGE, includes the statement\n\n   If the merge source is a baseline, the merge target is a version-\n   controlled configuration for the baseline history of that baseline,\n   where the baseline-controlled collection of that version-controlled\n   configuration is a member of the collection identified by the\n   request-URL.\n\nSection 12.13, which defines the extended baseline semantics of UPDATE, does not include a similar statement, but I think it should. \n\nIs this the working group's intention? Would this be a reasonable edit to make in the next rev of the spec?\n\nRoy\n\n\n\n", "id": "lists-007-3773455"}, {"subject": "RE: Clarification: extended baseline semantics of UPDAT", "content": "The UPDATE method explicitly identifies the \"update target\"\nfor the \"update source\", so there is no need for such a rule\n(i.e. you can only update a version-controlled-configuration\nwith a baseline from the baseline history of that \nversion-controlled configiguration).\n\nSo this statement (which is about how to find the merge target\nfor a baseline MERGE request) is not needed for UPDATE.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Roy Seto [mailto:Roy.Seto@oracle.com]\nSent: Wednesday, March 20, 2002 2:34 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: Clarification: extended baseline semantics of UPDATE\n\n\nSection 12.14, which defines the extended baseline semantics of MERGE,\nincludes the statement\n\n   If the merge source is a baseline, the merge target is a version-\n   controlled configuration for the baseline history of that baseline,\n   where the baseline-controlled collection of that version-controlled\n   configuration is a member of the collection identified by the\n   request-URL.\n\nSection 12.13, which defines the extended baseline semantics of UPDATE, does\nnot include a similar statement, but I think it should. \n\nIs this the working group's intention? Would this be a reasonable edit to\nmake in the next rev of the spec?\n\nRoy\n\n\n\n", "id": "lists-007-3781520"}, {"subject": "RE: Clarification: extended baseline semantics of UPDAT", "content": "Suppose I have a workspace that includes several baseline-controlled collections. My client can MERGE a new baseline into the appropriate baseline-controlled-collection within that workspace by issuing a MERGE request where the merge source is the baseline, and where the request-URL is the workspace.\n\nSimilarly, I would like my client to be able to UPDATE a workspace with a new baseline by sending an UPDATE request where the version is the baseline, and where the request-URL is the workspace. Would this work if the version-controlled configurations associated with the workspace's baseline-controlled collections were not members of the workspace? \n\nI'm trying to avoid the extra roundtrip and client complexity to retrieve the DAV:version-controlled-configurations of the DAV:baseline-controlled-collection-set of the workspace in this case, and figuring out which of those DAV:version-controlled-configuration's DAV:version-history property values is the same as the DAV:version-history for the baseline I want to UPDATE my workspace with.\n\nSo I'd like an UPDATE whose version is a baseline and whose request-URL includes baseline-controlled members to automatically apply to the version-controlled configuration for the appropriate baseline-controlled collection, even if that VCCfg isn't a member of the request-URL.\n\nRoy\n\n-----Original Message-----\nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\nSent: Wednesday, March 20, 2002 2:22 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: RE: Clarification: extended baseline semantics of UPDATE\n\n\nThe UPDATE method explicitly identifies the \"update target\"\nfor the \"update source\", so there is no need for such a rule\n(i.e. you can only update a version-controlled-configuration\nwith a baseline from the baseline history of that \nversion-controlled configiguration).\n\nSo this statement (which is about how to find the merge target\nfor a baseline MERGE request) is not needed for UPDATE.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Roy Seto [mailto:Roy.Seto@oracle.com]\nSent: Wednesday, March 20, 2002 2:34 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: Clarification: extended baseline semantics of UPDATE\n\n\nSection 12.14, which defines the extended baseline semantics of MERGE,\nincludes the statement\n\n   If the merge source is a baseline, the merge target is a version-\n   controlled configuration for the baseline history of that baseline,\n   where the baseline-controlled collection of that version-controlled\n   configuration is a member of the collection identified by the\n   request-URL.\n\nSection 12.13, which defines the extended baseline semantics of UPDATE, does\nnot include a similar statement, but I think it should. \n\nIs this the working group's intention? Would this be a reasonable edit to\nmake in the next rev of the spec?\n\nRoy\n\n\n\n", "id": "lists-007-3790703"}, {"subject": "RE: Clarification: extended baseline semantics of UPDAT", "content": "That isn't anything that we ever discussed, but I agree\nthat it would be a very reasonable extension.\nIf you could write this up, we could add it to \nthe \"proposed extensions\" list.\n\nCheers,\nGeoff \n\n-----Original Message-----\nFrom: Roy Seto [mailto:Roy.Seto@oracle.com]\nSent: Wednesday, March 20, 2002 10:01 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: RE: Clarification: extended baseline semantics of UPDATE\n\n\nSuppose I have a workspace that includes several baseline-controlled\ncollections. My client can MERGE a new baseline into the appropriate\nbaseline-controlled-collection within that workspace by issuing a MERGE\nrequest where the merge source is the baseline, and where the request-URL is\nthe workspace.\n\nSimilarly, I would like my client to be able to UPDATE a workspace with a\nnew baseline by sending an UPDATE request where the version is the baseline,\nand where the request-URL is the workspace. Would this work if the\nversion-controlled configurations associated with the workspace's\nbaseline-controlled collections were not members of the workspace? \n\nI'm trying to avoid the extra roundtrip and client complexity to retrieve\nthe DAV:version-controlled-configurations of the\nDAV:baseline-controlled-collection-set of the workspace in this case, and\nfiguring out which of those DAV:version-controlled-configuration's\nDAV:version-history property values is the same as the DAV:version-history\nfor the baseline I want to UPDATE my workspace with.\n\nSo I'd like an UPDATE whose version is a baseline and whose request-URL\nincludes baseline-controlled members to automatically apply to the\nversion-controlled configuration for the appropriate baseline-controlled\ncollection, even if that VCCfg isn't a member of the request-URL.\n\nRoy\n\n-----Original Message-----\nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\nSent: Wednesday, March 20, 2002 2:22 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: RE: Clarification: extended baseline semantics of UPDATE\n\n\nThe UPDATE method explicitly identifies the \"update target\"\nfor the \"update source\", so there is no need for such a rule\n(i.e. you can only update a version-controlled-configuration\nwith a baseline from the baseline history of that \nversion-controlled configiguration).\n\nSo this statement (which is about how to find the merge target\nfor a baseline MERGE request) is not needed for UPDATE.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Roy Seto [mailto:Roy.Seto@oracle.com]\nSent: Wednesday, March 20, 2002 2:34 PM\nTo: Ietf-Dav-Versioning@W3. Org\nSubject: Clarification: extended baseline semantics of UPDATE\n\n\nSection 12.14, which defines the extended baseline semantics of MERGE,\nincludes the statement\n\n   If the merge source is a baseline, the merge target is a version-\n   controlled configuration for the baseline history of that baseline,\n   where the baseline-controlled collection of that version-controlled\n   configuration is a member of the collection identified by the\n   request-URL.\n\nSection 12.13, which defines the extended baseline semantics of UPDATE, does\nnot include a similar statement, but I think it should. \n\nIs this the working group's intention? Would this be a reasonable edit to\nmake in the next rev of the spec?\n\nRoy\n\n\n\n", "id": "lists-007-3801815"}, {"subject": "RFC3253 HTML/XML version", "content": "...are now available from our WebDAV resources home page:\n\n[1] <http://greenbytes.de/tech/webdav/rfc3253.html>\n[2] <http://greenbytes.de/tech/webdav/rfc3253.xml>\n\n\n\n", "id": "lists-007-3813792"}, {"subject": "server defined activity URL", "content": "Hi,\n\nsuppose we want to implement a distributed DeltaV server which allows\npropagation \nbetween workspaces residing on different servers. In order to ensure unique\nactivity names\n(needed to ensure activity URL uniqueness if activities are also\ndistributed) in this scenario \nwe would like to have server defined activity URLs.\n\nWould it be DeltaV compliant to achieve that by using the response defined \nin section \"10.3.2 301 Moved Permanently\" of the HTTP 1.1 spec (rfc2616) ?\n\n   >>REQUEST\n\n     MKACTIVITY /act/test-23 HTTP/1.1\n     Host: repo.webdav.org\n     Content-Length: 0\n\ninstead of\n\n   >>RESPONSE\n\n     HTTP/1.1 201 Created\n     Cache-Control: no-cache\n\nwe would like to use\n\n   >>RESPONSE\n\n     HTTP/1.1 301 Moved Permanently\n     Location: /act/test-23-9C0BC5DA776811D5B3490001021DCD13\n     Cache-Control: no-cache\n\n     <HTML body containing href to new URL>\n\nregards\nMatthias\n\n\n\n", "id": "lists-007-3820988"}, {"subject": "PUT/MKCOL on a Working Collectio", "content": "Hi,\nLets say I have a working collection wcoll.  Now, I need to place a file,\nfile1,  into this working collection. And to update the content in the next\ncall. I am assuming that NO auto-version policies are used. The sequence of\noperations would typically be:\n\n1.  PUT /wcoll/file1     //created the file here.\n2.  PUT /wcoll/file1     //updated the content here.\n\nMy doubt is whether a first version (and version history and\nversion-controlled resources) are created in step (1).  If so, then the\nsequence of operations required would be:\n\n1.  PUT /wcoll/file1     //created the file here - and placed it into\nversion control\n2.  CHECKOUT /wcoll/file1 //create a working resource of the file\n3.  PUT /wcoll/file1     //updated the content here.\n\nIs this what RFC3253 specifies? If so, can somebody point out to me where in\nthe spec this is specified.\n\nSection 14.10 of RFC3253 says that at the time of checkin of a working\ncollection, all non-version-controlled members of the working collection\nhave to be placed under version control.  If this is understood, then at\nstep (1) above, the server need not place the file under version control and\ncan wait until the time of checkin of wcoll1.  So the checkout in step (2)\nabove would not be required.\nAm I getting the specifications correctly here?\n\nIf I am getting it right, then if I want to add a new collection coll2 under\nwcoll, and a file file1 under coll2, then the sequence of operations would\nbe:\n\n1.  MKCOL /wcoll/coll2     //created the collection here.\n2.  PUT /wcoll/coll2/file1     //created a file under coll1. No checkout of\ncoll1 is required.\n\nSo, when wcoll is checkedin, coll2 and its members are placed under version\ncontrol. Is this right?\n\nGirish\n\n\n\n", "id": "lists-007-3828457"}, {"subject": "RE: PUT/MKCOL on a Working Collectio", "content": "   From: B H, Girish [mailto:g.b.h@sap.com]\n\n   Lets say I have a working collection wcoll.  Now, I need to place a\n   file, file1, into this working collection. And to update the\n   content in the next call. I am assuming that NO auto-version\n   policies are used. The sequence of operations would typically be:\n\n   1.  PUT /wcoll/file1     //created the file here.\n   2.  PUT /wcoll/file1     //updated the content here.\n\n   My doubt is whether a first version (and version history and\n   version-controlled resources) are created in step (1).\n\nThat is correct, no new version-controlled resources (or version\nhistories) are created until /wcoll is checked in.  Note that a more\nrealistic working collection URL would be something like\n/repo/wcoll/16734.\n\n   If so, then the\n   sequence of operations required would be:\n\n   1.  PUT /wcoll/file1     //created the file here - and placed it into\n   version control\n\nNo, the PUT does not put it under version control.  A CHECKIN of\n/wcoll is required.\n\n   2.  CHECKOUT /wcoll/file1 //create a working resource of the file\n\nSince /wcoll/file1 is not under version control, the CHECKOUT would fail.\n\n   3.  PUT /wcoll/file1     //updated the content here.\n\n   Is this what RFC3253 specifies? If so, can somebody point out to me\n   where in the spec this is specified.\n\nIt doesn't, so nobody can (:-).\n\n   Section 14.10 of RFC3253 says that at the time of checkin of a working\n   collection, all non-version-controlled members of the working collection\n   have to be placed under version control.  If this is understood, then at\n   step (1) above, the server need not place the file under version control\nand\n   can wait until the time of checkin of wcoll1.  So the checkout in step\n(2)\n   above would not be required.\n   Am I getting the specifications correctly here?\n\nYes, that is right.  In particular, section 14.0 states: \"a working\ncollection contains bindings to version history resources and\nnon-version-controlled resources\".  So a server is not even allowed to\nplace a member of a working collection under version control\n(until that working collection is checked in, at which time the\nworking collection is deleted, so the working collection never \nactually contains a version-controlled resource).\n\n   If I am getting it right, then if I want to add a new collection\n   coll2 under wcoll, and a file file1 under coll2, then the sequence\n   of operations would be:\n\n   1.  MKCOL /wcoll/coll2     //created the collection here.\n   2.  PUT /wcoll/coll2/file1     //created a file under coll1. No checkout\nof\n   coll1 is required.\n\n   So, when wcoll is checkedin, coll2 and its members are placed under\nversion\n   control. Is this right?\n\nYes, that is right.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3837513"}, {"subject": "Merging from a descendant of an existing merge-set membe", "content": "Suppose version /v2 is a descendant of version /v1, and that version-controlled resource /vcr's DAV:merge-set property value is <href>/v1</href>. Now the server receives a request\n\nMERGE /vcr \n<source><href>/v2</href></source>\n\nIs the server allowed to set /vcr's DAV:merge-set property value to <href>/v2</href> instead of <href>/v1</href><href>/v2</href> because it understands that /v2 is a descendant of /v1?\n\nRoy\n\n\n\n", "id": "lists-007-3848164"}, {"subject": "draft-reschke-deltav-compute-checkin-uri-0", "content": "From the abstract:\n\n\"In many cases, a versioning-aware client might want to display/include the\nURI of the version it's editing while it's being edited. For instance, an\neditor might include this as meta information, or the author of a document\nmight want to know the URI of the version before it's checked in. A\nwell-known example is the W3C way of referring to document versions in\nrecommendations: it contains references to \"the current version\", to \"this\nversion\" and to the \"previous version\". Something like this is currently\nimpossible with WebDAV deltaV [RFC3253], as the version URI is determined at\nthe time of CHECKIN.\"\n\nFrom the change log:\n\nMade the document element for responses upon failed CHECKIN DAV:error rather\nthan DAV:checkin-response.\nUpdated reference to [RFC3253].\nMoved extension elements out of DAV: namespace.\nChanged examples to explicitly use utf-8 encoding for HTTP content type and\nXML encoding.\nGlobally replaced the term \"CHECKIN URI\" by \"version URI\"\nAdded note about how to discover whether the server actually applied the\nexpected version URI.\nMade sure artwork (figures) fits into 72 columns.\n\nLinks:\n\nSubmitted version in HTML format:\n<http://greenbytes.de/tech/webdav/draft-reschke-deltav-compute-checkin-uri-0\n1.html>\nCurrent version:\n<http://greenbytes.de/tech/webdav/draft-reschke-deltav-compute-checkin-uri-l\natest.html>\n\n\n\n", "id": "lists-007-3855321"}, {"subject": "[ietf-dav-versioning] &lt;none&gt", "content": "Hi,\n\nFrom the spec:\n\n  When a server supports the working-resource feature, a client can check\nout a\n  collection version to create a working collection.  Unlike a\nversion-controlled\n  collection, which contains bindings to version-controlled resources and\n  non-version-controlled resources, a working collection contains bindings\nto\n  version history resources and non-version-controlled resources.  ...\n\nSo, version controlled collection contains bindings to version controlled\nresources ?\nWhich property of a version controlled collection contains these bindings ?\nFurther, if a binding points to a version controlled resource does that mean\nthat every version controlled resource is stored under some unique URL ?\n\nSasha \n\n\n\n", "id": "lists-007-3863910"}, {"subject": "RE: [ietf-dav-versioning] &lt;none&gt", "content": "   From: Zivkov, Sasa [mailto:sasa.zivkov@sap.com]\n\n   So, version controlled collection contains bindings to version\n   controlled resources ?\n\nYes.\n\n   Which property of a version controlled collection contains these bindings\n?\n\nA \"binding\" is defined in the definition of \"collection\".  In particular:\n\n A \"collection\" is a resource whose state consists of not only content\n and properties, but also a set of named \"bindings\", where a binding\n identifies what RFC 2518 calls an \"internal member\" of the collection.\n\nSo this was just a way of saying that the version-controlled resources\ncan be internal members of version-controlled collections.  This info\nis not retrieved from a property, but rather from a Depth=1 PROPFIND.\n\n   Further, if a binding points to a version controlled resource does that\nmean\n   that every version controlled resource is stored under some unique URL ?\n\nAgain, from the definition of \"collection\":\n\n Note that a binding is not a resource, but rather is a part of the\n state of a collection that defines a mapping from a binding name (a\n URL segment) to a resource (an internal member of the collection).\n\nSo the version-controlled resource is just an internal member of\nthe version-controlled collection, and it is stored under the URL of\nthe version-controlled collection.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-3872080"}, {"subject": "Additional OPTIONS semantics for version-history featur", "content": "Hi,\n\nI'm looking at the description for the additional OPTIONS semantics for the\nversion-history feature ([1]), but I don't really understand what problem\nthis feature is supposed to solve. Given a specific resource on a Delta-V\nserver, I can find one (or more) collections that may contain version\nhistories on this server. What is a client supposed to do with this\ninformation?\n\nAssuming that there is a use case for this feature -- will a future RFC\ndefine an additional live property for this as well?\n\n\n[1] <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.5.5>\n\n\n\n", "id": "lists-007-4022277"}, {"subject": "RE: Additional OPTIONS semantics for version-history featur", "content": "Hi,\n\nI was just trying to implement 5.5 in our server and came across the\nfollowing issue:\n\n- the request body is optional, so I check for the presence of a\nXML-wellformed request body. If there is none - fine.\n\n- if there is an XML request body, the protocol *requires* that it has a\ncertain document element.\n\nThis basically means that RFC3253 has occupied the format for *any* OPTIONS\nrequest body -- no other HTTP-extending protocol can go out and specify\nsimilar requirements without being in conflict with RFC3253. In particular,\nRFC3253 is in conflict with a potential HTTP revision that specifies request\nbodies for OPTIONS (!).\n\nSo, at a minimum, the protocol MUST allow to ignore the request body if the\ndocument element is not DAV:options. In the long run, I'd like to see this\nremoved from the protocol, and possibly changed into a live property.\n\nJulian\n\n\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Julian Reschke\n> Sent: Thursday, July 04, 2002 4:24 PM\n> To: 'Deltav WG'\n> Subject: Additional OPTIONS semantics for version-history feature\n>\n>\n>\n> Hi,\n>\n> I'm looking at the description for the additional OPTIONS\n> semantics for the\n> version-history feature ([1]), but I don't really understand what problem\n> this feature is supposed to solve. Given a specific resource on a Delta-V\n> server, I can find one (or more) collections that may contain version\n> histories on this server. What is a client supposed to do with this\n> information?\n>\n> Assuming that there is a use case for this feature -- will a future RFC\n> define an additional live property for this as well?\n>\n>\n> [1] <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.5.5>\n>\n>\n\n\n\n", "id": "lists-007-4030311"}, {"subject": "RE: Replacing the Label header with a DAV:labeled-version repor", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > From: Clemm, Geoff\n   >\n   > Julian didn't like the marshalling of this report, because it\n   > makes it look like the properties are those of the VCR, when they\n   > actually are properties of the version\n\n   Yes, that's the problem, and I fear the new format doesn't address\n   this.\n\n   If the multistatus/response format is re-used for a REPORT (basically a\ngood\n   thing), it must not break the existing semantics, in particular:\n\n   - the properties reported must actually be the properties of the resource\n   identified by the reported URI (DAV:href) and\n   - the properties reported actually must be properties (!).\n\n   If this is not the case, the response seems to indicate that there's a\n   DAV:labeled-version-report property, which isn't the case.\n\nIf this is a problem, it is a problem with the 3253 definition of REPORT.\nIn particular, section 3.6 states:\n\n   \"If a Depth request header is included, the response MUST be a 207\n   Multi-Status.  The request MUST be applied separately to the\n   collection itself and to all members of the collection that satisfy\n   the Depth value.  The DAV:prop element of a DAV:response for a\n   given resource MUST contain the requested report for that resource.\"\n\nSo according to 3253, the DAV:prop elements MUST contain the requested\nreport (as if it were a property).\n\nSince this was not considered a problem during any of the reviews of\n3253, I'd need to hear some compelling reasons why this marshalling\nhas become a problem.  In particular, there is no rule that I know of\nthat states that the interpretation of a DAV:multistatus element must\nbe the same in all contexts in which it appears.  I know that this is\ndefinitely not the case for other XML elements used by WebDAV (e.g.\nthe way the property elements are used in the request and response\nbodies of a PROPPATCH differ significantly).\n\n   So how about properly extending the response element, for instance:\n\n     <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n     <D:multistatus xmlns:D=\"DAV:\">\n\n       <D:response>\n <D:href>http://www.webdav.org/folder/</D:href>\n <D:labeled-version-report>\n   <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n   <D:propstat>\n     <D:prop>\n       <D:version-name>V5</D:version-name>\n     </D:prop>\n     <D:status>HTTP/1.1 200 OK</D:status>\n   </Dpropstat>\n </D:labeled-version-report>\n <D:status>HTTP/1.1 200 OK</D:status>\n       </D:response>\n\n      <D:response>\n <D:href>http://www.webdav.org/folder/foo.html</D:href>\n <D:labeled-version-report>\n   <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n     <D:propstat>\n       <D:prop>\n <D:version-name>V8</D:version-name>\n     </D:prop>\n     <D:status>HTTP/1.1 200 OK</D:status>\n   </D:propstat>\n </D:labeled-version-report>\n <D:status>HTTP/1.1 200 OK</D:status>\n       </D:response>\n\n     </D:multistatus>\n\nThat would be fine with me (and arguably is cleaner than what is\ndefined in 3253), but it is inconsistent with 3253, so unless there\nis something seriously wrong with the 3253 marshalling, I think\nconsistency is more important here than aesthetics.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4040435"}, {"subject": "Marshalling DAV:xxx-collection-set as a live property, and not an  OPTIONS request", "content": "Since I was not able to convince the ACL working group to marshall\nthis kind of information as an OPTIONS request, we should probably\nconsider changing the versioning protocol to also marshall this\nkind of information (i.e. DAV:workspace-collection-set,\nDAV:activity-collection-set, and DAV:version-history-collection-set)\nas live properties, and not as OPTIONS requests.\n\nSo I'd like to poll the mailing list (especially DeltaV client and/or\nserver implementors:\n\nDo you prefer to:\n(a) leave xxx-collection-set as it is (marshalled only as OPTIONS)\n(b) support marshalling both as OPTIONS and as live properties\n(c) marshal only as live properties and deprecate the OPTIONS marshalling\n\nI vote for (c), as it simplifies the spec, and makes it consistent\nwith the ACL protocol.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4052533"}, {"subject": "RE: Additional OPTIONS semantics for version-history featur", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   I'm looking at the description for the additional OPTIONS semantics\n   for the version-history feature ([1]), but I don't really\n   understand what problem this feature is supposed to solve. Given a\n   specific resource on a Delta-V server, I can find one (or more)\n   collections that may contain version histories on this server. What\n   is a client supposed to do with this information?\n\nThe main use case for DAV:version-history-collection-set is when you\nhave deleted the last VCR for a version history, and now you want to\nretrieve the content of a version from that version history.  You can\nbrowse for that version history in the\nDAV:version-history-collection-set.  If your server supports baselines\nor version-controlled collections, it is likely to be much more\neffective to search for that version history in the baseline histories\nor collection histories, so I agree that the case for\nDAV:version-history-collection-set is not all that compelling.\n\n   Assuming that there is a use case for this feature -- will a future\n   RFC define an additional live property for this as well?\n\nWe certainly could.  Would anyone object to doing so?\n\n   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   ...  if there is an XML request body for OPTIONS, the protocol\n   *requires* that it has a certain document element.\n\n   This basically means that RFC3253 has occupied the format for *any*\n   OPTIONS request body -- no other HTTP-extending protocol can go out\n   and specify similar requirements without being in conflict with\n   RFC3253. In particular, RFC3253 is in conflict with a potential\n   HTTP revision that specifies request bodies for OPTIONS (!).\n\n   So, at a minimum, the protocol MUST allow to ignore the request\n   body if the document element is not DAV:options.\n\nI agree.\n\n   In the long run, I'd like to see this removed from the protocol,\n   and possibly changed into a live property.\n\nGiven that the ACL spec has decisively moved towards marshalling this\nkind of information as a property, and not as an OPTIONS request, the\ncleanest thing to do would be to update 3253 to also not use OPTIONS\nto marshall this information.  This would then address the OPTIONS\nrequest body issue as well.  I'll start a separate thread on this, to\nmaximize the chance that folks will notice and respond to this\nproposal.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4061235"}, {"subject": "RE: Marshalling DAV:xxx-collection-set as a live property, and not an  OPTIONS request", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Sunday, July 07, 2002 2:59 PM\n> To: DeltaV (E-mail)\n> Subject: Marshalling DAV:xxx-collection-set as a live property, and not\n> an OPTIONS request.\n> \n> \n> \n> Since I was not able to convince the ACL working group to marshall\n> this kind of information as an OPTIONS request, we should probably\n> consider changing the versioning protocol to also marshall this\n> kind of information (i.e. DAV:workspace-collection-set,\n> DAV:activity-collection-set, and DAV:version-history-collection-set)\n> as live properties, and not as OPTIONS requests.\n> \n> So I'd like to poll the mailing list (especially DeltaV client and/or\n> server implementors:\n> \n> Do you prefer to:\n> (a) leave xxx-collection-set as it is (marshalled only as OPTIONS)\n> (b) support marshalling both as OPTIONS and as live properties\n> (c) marshal only as live properties and deprecate the OPTIONS marshalling\n> \n> I vote for (c), as it simplifies the spec, and makes it consistent\n> with the ACL protocol.\n\nSame for me (c).\n\n\n\n", "id": "lists-007-4071528"}, {"subject": "RE: Replacing the Label header with a DAV:labeled-version repor", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Sunday, July 07, 2002 1:34 AM\n> To: 'Deltav WG'\n> Subject: RE: Replacing the Label header with a DAV:labeled-version\n> report\n>\n>\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    > From: Clemm, Geoff\n>    >\n>    > Julian didn't like the marshalling of this report, because it\n>    > makes it look like the properties are those of the VCR, when they\n>    > actually are properties of the version\n>\n>    Yes, that's the problem, and I fear the new format doesn't address\n>    this.\n>\n>    If the multistatus/response format is re-used for a REPORT (basically a\ngood\n>    thing), it must not break the existing semantics, in particular:\n>\n>    - the properties reported must actually be the properties of  the\nresource\n>    identified by the reported URI (DAV:href) and\n>    - the properties reported actually must be properties (!).\n>\n>    If this is not the case, the response seems to indicate that there's a\n>    DAV:labeled-version-report property, which isn't the case.\n>\n> If this is a problem, it is a problem with the 3253 definition of REPORT.\n> In particular, section 3.6 states:\n>\n>    \"If a Depth request header is included, the response MUST be a 207\n>    Multi-Status.  The request MUST be applied separately to the\n>    collection itself and to all members of the collection that satisfy\n>    the Depth value.  The DAV:prop element of a DAV:response for a\n>    given resource MUST contain the requested report for that resource.\"\n>\n> So according to 3253, the DAV:prop elements MUST contain the requested\n> report (as if it were a property).\n\nGood catch. So, taking both RFC3253 and RFC2518 in account, the requested\nreport must be contained inside DAV:prop, and DAV:prop must contain WebDAV\nproperties of the resource identified by DAV:href.\n\nThis works fine for things like DAV:version-tree, but obviously fails here,\nso we need to find a resolution.\n\n> Since this was not considered a problem during any of the reviews of\n> 3253, I'd need to hear some compelling reasons why this marshalling\n> has become a problem.  In particular, there is no rule that I know of\n\n*I* didn't consider this a problem because none of the reports defined by\nRFC3253 actually breaks RFC2518 semantics -- so everytime the multistatus\nformat is used, the contents of DAV:prop actually *are* WebDAV properties.\nSo if the *intent* of the text you quoted is to allow *arbitary* reports to\nbe marshalled *inside* DAV:prop, why wasn't this feature used by any of the\nreports defined in RFC3253 (or ACL)?\n\n> that states that the interpretation of a DAV:multistatus element must\n> be the same in all contexts in which it appears.  I know that this is\n> definitely not the case for other XML elements used by WebDAV (e.g.\n> the way the property elements are used in the request and response\n> bodies of a PROPPATCH differ significantly).\n\nThat's correct, but I don't think that's the point. When people see a\nmultistatus response body, up until now they *always* could assume that\nsomething that they see inside DAV:prop actually *is* a WebDAV property of\nthe resource identified by DAV:href. In particular, one would assume that if\nit appear inside a DAV:response/DAV:propstat/DAV:prop element, you can also\nquery it using PROPFIND.\n\nBesides: every time you define a report-specific element for inclusion into\nDAV:prop, you basically block any usage of this name as \"real\" WebDAV\nproperty. In this particular case, using DAV:labeled-version-report as\n\"container\" element makes it impossible to actually have a property called\nDAV:labeled-version-report (and to have it returned by this report). While\nthis may not seem to be a real-world problem here, it would mean that an\nambiguity is introduced into the namespaces of WebDAV property names  --\nsuddenly there's an overlap with marshalling elements for specific reports.\n\nSo why not use a marshalling format that has none of these problems?\n\n>    So how about properly extending the response element, for instance:\n>\n>      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>      <D:multistatus xmlns:D=\"DAV:\">\n>\n>        <D:response>\n>  <D:href>http://www.webdav.org/folder/</D:href>\n>  <D:labeled-version-report>\n>    <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n>    <D:propstat>\n>      <D:prop>\n>        <D:version-name>V5</D:version-name>\n>      </D:prop>\n>      <D:status>HTTP/1.1 200 OK</D:status>\n>    </Dpropstat>\n>  </D:labeled-version-report>\n>  <D:status>HTTP/1.1 200 OK</D:status>\n>        </D:response>\n>\n>       <D:response>\n>  <D:href>http://www.webdav.org/folder/foo.html</D:href>\n>  <D:labeled-version-report>\n>    <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n>      <D:propstat>\n>        <D:prop>\n>  <D:version-name>V8</D:version-name>\n>      </D:prop>\n>      <D:status>HTTP/1.1 200 OK</D:status>\n>    </D:propstat>\n>  </D:labeled-version-report>\n>  <D:status>HTTP/1.1 200 OK</D:status>\n>        </D:response>\n>\n>      </D:multistatus>\n>\n> That would be fine with me (and arguably is cleaner than what is\n\n...thanks...\n\n> defined in 3253), but it is inconsistent with 3253, so unless there\n\nWhy would that be inconsistent with RFC3253? The format you proposed earlier\ndefinitively is inconsistent with RFC2518, and I'm not aware of another case\nin RFC3253 that has this problem.\n\n> is something seriously wrong with the 3253 marshalling, I think\n> consistency is more important here than aesthetics.\n\nI think the RFC3253 marshalling as explained by you in seriously\ninconsistent with RFC2518 *and* not very aesthetical. I'm happy it hasn't\nbeen used before :-) I have the feeling I'm overseeing something, and I'm\nsure you'll educate me...\n\n\n\n", "id": "lists-007-4081788"}, {"subject": "RE: Marshalling DAV:xxx-collection-set as a live property, and not an  OPTIONS request", "content": "> Since I was not able to convince the ACL working group to marshall\n> this kind of information as an OPTIONS request, we should probably\n> consider changing the versioning protocol to also marshall this\n> kind of information (i.e. DAV:workspace-collection-set,\n> DAV:activity-collection-set, and DAV:version-history-collection-set)\n> as live properties, and not as OPTIONS requests.\n\nThe big picture here is that we're making OPTIONS less useful. In\nparticular, we're saying that OPTIONS * is too hard for servers to\nimplement correctly with a bunch of extra headers and body information,\nbecause * is too ambiguous.  That's probably fair enough; it's a result\nof the early decision that not all resources on a HTTP server need be\nWebDAV-capable resources.  Should we go so far as to say that clients\nSHOULD NOT use OPTIONS *?\n\nMy concern with going in this direction is that a client accessing a\nWebDAV server may be configured initially with only the server's domain\nname. How does the client start figuring out what is where on the\nserver?  Does \"OPTIONS /\" + \"PROPFIND /\" (or the same requests to\nwhatever path is given) solve this problem for the client instead?  \n\nIf the client does OPTIONS only on particular resources, how *does* the\nserver show capabilities? E.g. support for MKCOL can *never* show up as\nan allowed method on any existing resource.  My take is that MKCOL shows\nup in OPTIONS * and not in any other OPTIONS request. Thus OPTIONS *\nserves an important role.\n\nDoes the client need some way to ask the server \"do you support WebDAV\nanywhere on the server, and if so, where?\"  This would be similar to the\nquestion of asking a server \"do you support HTTP on some port, and if\nso, which\"...\n\nBTW, I'm curious what you mean by \"changing the version protocol\".  RFC\n3253 can't be changed now. Are you proposing a new internet-draft to\neventually obsolete 3253?  Servers compliant with 3253 will continue to\nbe so even if the WG decides to replace OPTIONS marshalling with\nproperty marshalling. I'm sure I'm stating the obvious, but I'm\nsurprised to see talk of changing DeltaV so recently after the RFC was\nissued, particularly \"for consistency\" with documents that aren't yet\nRFCs.\n\nLisa\n\n\n\n", "id": "lists-007-4097462"}, {"subject": "RE: Marshalling DAV:xxx-collection-set as a live property, and no t an  OPTIONS request", "content": "Hi,\n\nI vote for (c)\n\nI am not sure on which resources these live properties \nspecifying server wide properties (which in general are not a property of \na specific resource) should be exposed, I would appreciate some standardized\nway to define these server wide features.\n\nIn addition I would like to see that the same mechanism can be used to\nadvertise \nserver specific extension features preventing name clashes by the namespace \nof the respective live property\n\nregards\nMatthias\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Sonntag, 7. Juli 2002 14:59\nTo: DeltaV (E-mail)\nSubject: Marshalling DAV:xxx-collection-set as a live property, and not\nan OPTIONS request.\n\n\n\nSince I was not able to convince the ACL working group to marshall\nthis kind of information as an OPTIONS request, we should probably\nconsider changing the versioning protocol to also marshall this\nkind of information (i.e. DAV:workspace-collection-set,\nDAV:activity-collection-set, and DAV:version-history-collection-set)\nas live properties, and not as OPTIONS requests.\n\nSo I'd like to poll the mailing list (especially DeltaV client and/or\nserver implementors:\n\nDo you prefer to:\n(a) leave xxx-collection-set as it is (marshalled only as OPTIONS)\n(b) support marshalling both as OPTIONS and as live properties\n(c) marshal only as live properties and deprecate the OPTIONS marshalling\n\nI vote for (c), as it simplifies the spec, and makes it consistent\nwith the ACL protocol.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4108572"}, {"subject": "RE: Marshalling DAV:xxx-collection-set as a live property, and not an  OPTIONS request", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Lisa Dusseault\n> Sent: Monday, July 08, 2002 2:36 AM\n> To: Clemm, Geoff; DeltaV (E-mail)\n> Subject: RE: Marshalling DAV:xxx-collection-set as a live property, and\n> not an OPTIONS request.\n>\n>\n>\n> > Since I was not able to convince the ACL working group to marshall\n> > this kind of information as an OPTIONS request, we should probably\n> > consider changing the versioning protocol to also marshall this\n> > kind of information (i.e. DAV:workspace-collection-set,\n> > DAV:activity-collection-set, and DAV:version-history-collection-set)\n> > as live properties, and not as OPTIONS requests.\n>\n> The big picture here is that we're making OPTIONS less useful. In\n> particular, we're saying that OPTIONS * is too hard for servers to\n> implement correctly with a bunch of extra headers and body information,\n> because * is too ambiguous.  That's probably fair enough; it's a result\n> of the early decision that not all resources on a HTTP server need be\n> WebDAV-capable resources.  Should we go so far as to say that clients\n> SHOULD NOT use OPTIONS *?\n\nI think the main issue is that this is a usage of OPTIONS that doesn't seem\nto be in line with HTTP 1.1, which says:\n\n\"If the Request-URI is an asterisk (\"*\"), the OPTIONS request is intended to\napply to the server in general rather than to a specific resource. Since a\nserver's communication options typically depend on the resource, the \"*\"\nrequest is only useful as a \"ping\" or \"no-op\" type of method; it does\nnothing beyond allowing the client to test the capabilities of the server.\nFor example, this can be used to test a proxy for HTTP/1.1 compliance (or\nlack thereof).\"\n\nConsequently, the servlet API doesn't offer my any simple mechanism to\ninfluence the result of \"OPTIONS *\" (or am I missing something).\n\nSo the feature is under discussion because it's extremely hard if not\nimpossible to implement, and thus will be questioned once when RFC3253 takes\nthe next RFC standardization step.\n\n> My concern with going in this direction is that a client accessing a\n> WebDAV server may be configured initially with only the server's domain\n> name. How does the client start figuring out what is where on the\n\nI think that's a configuration a bug. If only part of the URL namespace on a\nserver talks WebDAV, you'll need the URL prefix of this namespace partition.\nThere's no way to avoid that right now.\n\n> server?  Does \"OPTIONS /\" + \"PROPFIND /\" (or the same requests to\n> whatever path is given) solve this problem for the client instead?\n\nNo.\n\n> If the client does OPTIONS only on particular resources, how *does* the\n> server show capabilities? E.g. support for MKCOL can *never* show up as\n> an allowed method on any existing resource.  My take is that MKCOL shows\n> up in OPTIONS * and not in any other OPTIONS request. Thus OPTIONS *\n> serves an important role.\n\n...would serve an important role, if it could be implemented. If you think\nthat discovery of MKCOL using \"OPTIONS *\" is an important feature, we should\nfind out whether there are interoperable implementations supporting that.\n\nHTTP 1.1 clearly states that if you do OPTIONS * and look at the allowed\nmethods, you CAN NOT take the absence of MKCOL (in Allow:) as sign that no\npart of the URL namespace supports this method. If your client assumes that,\nit's buggy.\n\n> Does the client need some way to ask the server \"do you support WebDAV\n> anywhere on the server, and if so, where?\"  This would be similar to the\n> question of asking a server \"do you support HTTP on some port, and if\n> so, which\"...\n\nI'm not sure why a client would need that. If the WebDAV-enabled namespace\ndoesn't start at \"/\", the client will have to be configured to know the\ncomplete prefix. To change this, the process implementing the root resource\nwill need to have knowledge of all other descendants in it's namespace, and\na *new* protocol is needed to marshall this information.\n\n> BTW, I'm curious what you mean by \"changing the version protocol\".  RFC\n> 3253 can't be changed now. Are you proposing a new internet-draft to\n\nThe RFC can't be changed, but the protocol can (in the future).\n\n> eventually obsolete 3253?  Servers compliant with 3253 will continue to\n\nMy take is that with RFC3253, we should try to get the next revision\n(proposed -> draft) out as soon as we have multiple interoperable\nimplementations. So it absolutely makes sense to discuss these issues right\nnow rather than waiting too long (as it happened with RFC2518).\n\n> be so even if the WG decides to replace OPTIONS marshalling with\n> property marshalling. I'm sure I'm stating the obvious, but I'm\n> surprised to see talk of changing DeltaV so recently after the RFC was\n> issued, particularly \"for consistency\" with documents that aren't yet\n> RFCs.\n\nBut then, what's the point in delaying this work? The sooner an issue is\ndiscussed, the earlier we can add it to the errata document (preferrably\nwith a resolution of the issue). We all benefit from that: the WG, because\nthings get resolved when they are raised (instead of years later), and\nimplementors (because they can use *both* RFC3253 and a draft of a deltaV\nrevision) to implement their servers.\n\n\n\n", "id": "lists-007-4118701"}, {"subject": "RE: Marshalling DAV:xxx-collection-set as a live property, and no t an  OPTIONS request", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Sohn, Matthias\n> Sent: Monday, July 08, 2002 7:49 AM\n> To: 'Clemm, Geoff'; DeltaV (E-mail)\n> Subject: RE: Marshalling DAV:xxx-collection-set as a live property, and\n> no t an OPTIONS request.\n>\n>\n>\n> Hi,\n>\n> I vote for (c)\n>\n> I am not sure on which resources these live properties\n> specifying server wide properties (which in general are not a property of\n> a specific resource) should be exposed, I would appreciate some\n> standardized\n> way to define these server wide features.\n\nIn general, they *aren't* server wide. They only apply to a partition of the\nnamespace on that server. If these live properties are the same for all\nresources on a server, you'll likely PROPFIND them on \"/\".\n\n> In addition I would like to see that the same mechanism can be used to\n> advertise\n> server specific extension features preventing name clashes by the\n> namespace\n> of the respective live property\n\nCould you please give an example of what you're trying to achieve? If your\nserver implements a specific extension, you can advertise it using\nDAV:supported-method-set (not recommended :-),\nDAV:supported-live-property-set or DAV:supported-report-set. If it doesn't\nfit ito any of the categories, just define a new live property that acts as\na container element into which you can put all your extension information.\n\n\n\n", "id": "lists-007-4133460"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > From: Clemm, Geoff\n   >\n   > If you've deleted the version history, you have effectively\n   > trashed any historical references (e.g. in collection versions)\n   > to that version history.\n\n   Nope. I have deleted the binding to the version history, not\n   necessarily the information itself. In particular, my server may be\n   able to reconstruct it upon UNCHECKOUT of the versioned collection\n   \"/a\" (using the same URI).\n\nI'm not sure how an UNCHECKOUT of a VCCl is related to this thread,\nsince an UNCHECKOUT request has no effect on a version history\nresource.  But in any case, postcondition DAV:delete-version-set in\nSection 5.6 states that deleting a version history resource deletes\nall versions in that version history.  So your server would not be\nable to reconstruct the version history once it was deleted.  Note\nthat the errata issue 14_DIFFERENT_VH_DELETION_SEMANTICS_REQUIRED\nclarifies that deleting a member of a working collection just removes\na binding to a VHR, but doesn't delete the VHR.\n\n   > If you are going to let that deletion\n   > happen even when there is a VCR for that version history in\n   > some workspace, I don't see that it makes any sense to worry\n   > about whether or not the collection containing that VCR is\n   > checked in or checked out.\n\n   The issue is that RFC3253 doesn't define a method to switch off\n   version control on a resource, and therefore people are using\n   deletion on VHRs to switch off versioning (I couldn't find any\n   mention of this in the spec, though).\n\nI don't recall hearing of this approach, and don't see how it could be\ncompatible with the spec, giving the DAV:delete-version-set\npostcondition.\n\n   This conflates to separate things, but there doesn't seem to be\n   better way to do it (please don't say COPY/DELETE/MOVE, because\n   this creates a *new* resource).\n\nCOPY/DELETE/MOVE is the only interoperable way of removing something\nfrom version control.  If you need a mechanism that doesn't create a\nnew resource, I'd suggest something like allowing a PROPPATCH to\nremove the DAV:version-history property of the VCR, rather than trying\nanything related to VHR deletion.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4144174"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "Geoff,\n\nthanks for taking the time to look into these issues...\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Tuesday, July 09, 2002 12:27 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: error condition for delete of VHR when VCR is in checked-in\n> c ollection\n>\n>\n>\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    > From: Clemm, Geoff\n>    >\n>    > If you've deleted the version history, you have effectively\n>    > trashed any historical references (e.g. in collection versions)\n>    > to that version history.\n>\n>    Nope. I have deleted the binding to the version history, not\n>    necessarily the information itself. In particular, my server may be\n>    able to reconstruct it upon UNCHECKOUT of the versioned collection\n>    \"/a\" (using the same URI).\n>\n> I'm not sure how an UNCHECKOUT of a VCCl is related to this thread,\n> since an UNCHECKOUT request has no effect on a version history\n> resource.  But in any case, postcondition DAV:delete-version-set in\n> Section 5.6 states that deleting a version history resource deletes\n> all versions in that version history.  So your server would not be\n> able to reconstruct the version history once it was deleted.  Note\n> that the errata issue 14_DIFFERENT_VH_DELETION_SEMANTICS_REQUIRED\n> clarifies that deleting a member of a working collection just removes\n> a binding to a VHR, but doesn't delete the VHR.\n\nMy theories goes like this :-)\n\n- by checking in a VCC that contains a VCR member, I am effectively creating\na new binding to the VHR of this VCR member. This binding may not be visible\nin my \"public\" URL namespace, but it's still there\n- a subsequent delete on the VHR URL just deletes the original binding to\nthe VHR, but the version history resource (and the versions inside the\nversion history) is not affected\n- thus, upon UNCHECKOUT of the VCC, I can reconstruct the VHR (re-creating\nthe original binding)\n\nMaybe these problems go away when we remove connection between deleting the\nVHR and un-versioning a resource, but this is how it looks right now.\n\n>    > If you are going to let that deletion\n>    > happen even when there is a VCR for that version history in\n>    > some workspace, I don't see that it makes any sense to worry\n>    > about whether or not the collection containing that VCR is\n>    > checked in or checked out.\n>\n>    The issue is that RFC3253 doesn't define a method to switch off\n>    version control on a resource, and therefore people are using\n>    deletion on VHRs to switch off versioning (I couldn't find any\n>    mention of this in the spec, though).\n>\n> I don't recall hearing of this approach, and don't see how it could be\n> compatible with the spec, giving the DAV:delete-version-set\n> postcondition.\n\nOK. It was originally suggested in section 4.2 of\ndraft-dusseault-deltav-subset-00 [1], and up until some time ago, it made a\nlot of sense to me.\n\n>    This conflates to separate things, but there doesn't seem to be\n>    better way to do it (please don't say COPY/DELETE/MOVE, because\n>    this creates a *new* resource).\n>\n> COPY/DELETE/MOVE is the only interoperable way of removing something\n> from version control.  If you need a mechanism that doesn't create a\n> new resource, I'd suggest something like allowing a PROPPATCH to\n> remove the DAV:version-history property of the VCR, rather than trying\n> anything related to VHR deletion.\n\nSounds good, and we'll look into this.\n\nHowever, I now have a new question:\n\nIf - after the deletion of a VCR's VHR - the VCR is still\nversion-controlled - where does it's DAV:version-history property point to?\nSimilarily, if the delete of the VHR deleted all versions, where does\nDAV:checked-in/DAV:checked-out point to?\n\n-> Seems that we need to clarify the post-conditions for deletions of VHRs,\nright?\n\n\n\n\n[1]\n<http://www.sharemation.com/~milele/public/dav/draft-dusseault-deltav-subset\n-00.txt>\n\n\n\n", "id": "lists-007-4155888"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": ">    The issue is that RFC3253 doesn't define a method to switch off\n>    version control on a resource, and therefore people are using\n>    deletion on VHRs to switch off versioning (I couldn't find any\n>    mention of this in the spec, though).\n>\n> I don't recall hearing of this approach, and don't see how it could be\n> compatible with the spec, giving the DAV:delete-version-set\n> postcondition.\n\nClarification: people use deletion of the VHR to both delete the VHR and\nun-version-control the VCR. How would that violate the DELETE sematics for\nVHRs?\n\n\n\n", "id": "lists-007-4169775"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   >    > If you've deleted the version history, you have effectively\n   >    > trashed any historical references (e.g. in collection\n   >    > versions) to that version history.\n   >\n   >    Nope. I have deleted the binding to the version history, not\n   >    necessarily the information itself. In particular, my server\n   >    may be able to reconstruct it upon UNCHECKOUT of the versioned\n   >    collection \"/a\" (using the same URI).\n   >\n   > I'm not sure how an UNCHECKOUT of a VCCl is related to this\n   > thread, since an UNCHECKOUT request has no effect on a version\n   > history resource.  But in any case, postcondition\n   > DAV:delete-version-set in Section 5.6 states that deleting a\n   > version history resource deletes all versions in that version\n   > history.  So your server would not be able to reconstruct the\n   > version history once it was deleted.  Note that the errata issue\n   > 14_DIFFERENT_VH_DELETION_SEMANTICS_REQUIRED clarifies that\n   > deleting a member of a working collection just removes a binding\n   > to a VHR, but doesn't delete the VHR.\n\n   My theories goes like this :-)\n\n   - by checking in a VCC that contains a VCR member, I am effectively\n   creating a new binding to the VHR of this VCR member. This binding\n   may not be visible in my \"public\" URL namespace, but it's still\n   there\n\nI try to reserve the term \"binding\" for the sense in which it is\nused in the Bind protocol, namely the connection between a collection\nand one of its internal members.  In that sense, checking in a VCC\nnever creates a binding to a VHR, but rather just creates a reference\nto the VHR in its DAV:version-controlled-binding-set property\n(i.e. it doesn't create a new name for that VHR, but just uses an\nexisting name to create a reference).\n\n   - a subsequent delete on the VHR URL just deletes the original binding to\n   the VHR, but the version history resource (and the versions inside the\n   version history) is not affected\n\nSince the DAV:version-controlled-binding-set just has a reference to\nthat VHR using its server-assigned URL, if you DELETE that URL, you\nbreak all references to that VHR from the DAV:v-c-b-s properties of\ncollection versions.\n\n   - thus, upon UNCHECKOUT of the VCC, I can reconstruct the VHR\n   (re-creating the original binding)\n\nThe members of the VCC also refer to the VHR via the server-assigned\nURL, so even if UNCHECKOUT could restore the version-controlled\nmember of the VCC, the DAV:version-history property of that member\nwould contain the VHR URL that was deleted.\n\n   Maybe these problems go away when we remove connection between\n   deleting the VHR and un-versioning a resource, but this is how it\n   looks right now.\n\nDeleting a VHR to \"un-version\" a resource is fine; it's just\nrestoring it which is a problem.\n\n   >    > If you are going to let that deletion\n   >    > happen even when there is a VCR for that version history in\n   >    > some workspace, I don't see that it makes any sense to worry\n   >    > about whether or not the collection containing that VCR is\n   >    > checked in or checked out.\n   >\n   >    The issue is that RFC3253 doesn't define a method to switch off\n   >    version control on a resource, and therefore people are using\n   >    deletion on VHRs to switch off versioning (I couldn't find any\n   >    mention of this in the spec, though).\n   >\n   > I don't recall hearing of this approach, and don't see how it could be\n   > compatible with the spec, giving the DAV:delete-version-set\n   > postcondition.\n\n   OK. It was originally suggested in section 4.2 of\n   draft-dusseault-deltav-subset-00 [1], and up until some time ago,\n   it made a lot of sense to me.\n\n   Clarification: people use deletion of the VHR to both delete the\n   VHR and un-version-control the VCR. How would that violate the\n   DELETE sematics for VHRs?\n\nOK, I think I see where things may have gotten confused.\nThe approach I was referring to (i.e. the one I didn't recall hearing\nabout) was not the \"unversion by delete VHR\" approach (which I do\nremember), but rather the \"restore by UNCHECKOUT\".  If you are\nwilling to permanently destroy the history for that resource, I \nagree that deleting the VHR is a reasonable/interoperable way to do so.\n\n   >    This conflates to separate things, but there doesn't seem to\n   >    be better way to do it (please don't say COPY/DELETE/MOVE,\n   >    because this creates a *new* resource).\n   >\n   > COPY/DELETE/MOVE is the only interoperable way of removing\n   > something from version control.  If you need a mechanism that\n   > doesn't create a new resource, I'd suggest something like\n   > allowing a PROPPATCH to remove the DAV:version-history property\n   > of the VCR, rather than trying anything related to VHR deletion.\n\n   Sounds good, and we'll look into this.\n\nNote: As indicated above, if you are willing to permanently destroy\nthe history, deleting the VHR is a good interoperable way of taking\na resource out of version control.  The PROPPATCH proposal is only\nneeded if you want to retain the history while un-version-controlling\nthe resource.\n\n   However, I now have a new question:\n\n   If - after the deletion of a VCR's VHR - the VCR is still\n   version-controlled - where does it's DAV:version-history property\n   point to?  Similarily, if the delete of the VHR deleted all\n   versions, where does DAV:checked-in/DAV:checked-out point to?\n\nI agree that the simplest model for deleting the VHR would be to\nun-version-control any VCR for that history, and remove any entries\nin DAV:version-controlled-binding-set that refer to that VHR.\nAlternatively, the server could just keep all those references,\nand return errors on all versioning operations, but that would\nleave things in a pretty broken state.\n\n   -> Seems that we need to clarify the post-conditions for deletions\n   of VHRs, right?\n\nIt sounds like we actually agree on this one ... it was just the\n\"restore via UNCHECKOUT\" that was confusing things.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4178614"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "Geoff,\n\nlet me try to summarize.\n\nIn the presence of BINDs, DELETE is defined as\n\n1) removing the binding specified in the request URI,\n\n2) optional deletion of the resource identified by the URI if there are no\nreferences left to it. Note that references may be in other namespaces, on\nother servers and even in different URI schemes.\n\nAny spec that wants to cooperate with bindings can NOT change this semantics\nof DELETE (or does RFC3253 explicitly say that a VHR can have only a single\nbinding???).\n\n\nSo we have a VCR that refers to a VHR through the DAV:version-history\nproperty. The client issues a DELETE on the VHR URI. Possible results:\n\na) the server may refuse to perform the Delete, either because deletion of\nVHRs is not supported, or because a VCR still refers to the VHR.\n\nb) the server deletes the VHR and un-version-controls the VCR (to avoid\nbreaking the live versioning properties).\n\nc) the server deletes the VHR and keeps the VCR version-controlled - in\nwhich case the spec should say what happens to the\nDAV:checked-in/DAV:checked-out and DAV:version-history.\n\nI think RFC3253 needs to either forbid b) and c) or properly define the\nsemantics.\n\nMore below...\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Tuesday, July 09, 2002 2:10 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: error condition for delete of VHR when VCR is in checked-in\n> c ollection\n>\n>\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    >    > If you've deleted the version history, you have effectively\n>    >    > trashed any historical references (e.g. in collection\n>    >    > versions) to that version history.\n>    >\n>    >    Nope. I have deleted the binding to the version history, not\n>    >    necessarily the information itself. In particular, my server\n>    >    may be able to reconstruct it upon UNCHECKOUT of the versioned\n>    >    collection \"/a\" (using the same URI).\n>    >\n>    > I'm not sure how an UNCHECKOUT of a VCCl is related to this\n>    > thread, since an UNCHECKOUT request has no effect on a version\n>    > history resource.  But in any case, postcondition\n>    > DAV:delete-version-set in Section 5.6 states that deleting a\n>    > version history resource deletes all versions in that version\n>    > history.  So your server would not be able to reconstruct the\n>    > version history once it was deleted.  Note that the errata issue\n>    > 14_DIFFERENT_VH_DELETION_SEMANTICS_REQUIRED clarifies that\n>    > deleting a member of a working collection just removes a binding\n>    > to a VHR, but doesn't delete the VHR.\n>\n>    My theories goes like this :-)\n>\n>    - by checking in a VCC that contains a VCR member, I am effectively\n>    creating a new binding to the VHR of this VCR member. This binding\n>    may not be visible in my \"public\" URL namespace, but it's still\n>    there\n>\n> I try to reserve the term \"binding\" for the sense in which it is\n> used in the Bind protocol, namely the connection between a collection\n> and one of its internal members.  In that sense, checking in a VCC\n\nBind: A relation between a single path segment (in a collection) and a\nresource. (draft-ietf-webdav-binding-protocol-02)\n\n> never creates a binding to a VHR, but rather just creates a reference\n> to the VHR in its DAV:version-controlled-binding-set property\n> (i.e. it doesn't create a new name for that VHR, but just uses an\n> existing name to create a reference).\n\nI don't think it's really relevant whether the collection version has a\nreference or a binding. Servers may delay the de-allocation of a resource\nuntil there is no reference left, whether it's visible or not.\n\nIf we allow clients to (permanently= destroy VHRs that are referenced in a\ncollection version, there's no way to satisfy the postconditions for an\nUNCHECKOUT of the VCC, right? That's why our implementation keeps the\nreference, and therefore is able to resurrect the VHR when needed.\n\n>    - a subsequent delete on the VHR URL just deletes the original\n> binding to\n>    the VHR, but the version history resource (and the versions inside the\n>    version history) is not affected\n>\n> Since the DAV:version-controlled-binding-set just has a reference to\n> that VHR using its server-assigned URL, if you DELETE that URL, you\n> break all references to that VHR from the DAV:v-c-b-s properties of\n> collection versions.\n\nSo if the VHR can not be re-created, should the server forbid the delete?\n\n>    - thus, upon UNCHECKOUT of the VCC, I can reconstruct the VHR\n>    (re-creating the original binding)\n>\n> The members of the VCC also refer to the VHR via the server-assigned\n> URL, so even if UNCHECKOUT could restore the version-controlled\n> member of the VCC, the DAV:version-history property of that member\n> would contain the VHR URL that was deleted.\n\nBut that's not a problem if the '*same* VHR is reconstructed at the original\nURL.\n\n>    Maybe these problems go away when we remove connection between\n>    deleting the VHR and un-versioning a resource, but this is how it\n>    looks right now.\n>\n> Deleting a VHR to \"un-version\" a resource is fine; it's just\n> restoring it which is a problem.\n>\n>    >    > If you are going to let that deletion\n>    >    > happen even when there is a VCR for that version history in\n>    >    > some workspace, I don't see that it makes any sense to worry\n>    >    > about whether or not the collection containing that VCR is\n>    >    > checked in or checked out.\n>    >\n>    >    The issue is that RFC3253 doesn't define a method to switch off\n>    >    version control on a resource, and therefore people are using\n>    >    deletion on VHRs to switch off versioning (I couldn't find any\n>    >    mention of this in the spec, though).\n>    >\n>    > I don't recall hearing of this approach, and don't see how\n> it could be\n>    > compatible with the spec, giving the DAV:delete-version-set\n>    > postcondition.\n>\n>    OK. It was originally suggested in section 4.2 of\n>    draft-dusseault-deltav-subset-00 [1], and up until some time ago,\n>    it made a lot of sense to me.\n>\n>    Clarification: people use deletion of the VHR to both delete the\n>    VHR and un-version-control the VCR. How would that violate the\n>    DELETE sematics for VHRs?\n>\n> OK, I think I see where things may have gotten confused.\n> The approach I was referring to (i.e. the one I didn't recall hearing\n> about) was not the \"unversion by delete VHR\" approach (which I do\n> remember), but rather the \"restore by UNCHECKOUT\".  If you are\n> willing to permanently destroy the history for that resource, I\n> agree that deleting the VHR is a reasonable/interoperable way to do so.\n>\n>    >    This conflates to separate things, but there doesn't seem to\n>    >    be better way to do it (please don't say COPY/DELETE/MOVE,\n>    >    because this creates a *new* resource).\n>    >\n>    > COPY/DELETE/MOVE is the only interoperable way of removing\n>    > something from version control.  If you need a mechanism that\n>    > doesn't create a new resource, I'd suggest something like\n>    > allowing a PROPPATCH to remove the DAV:version-history property\n>    > of the VCR, rather than trying anything related to VHR deletion.\n>\n>    Sounds good, and we'll look into this.\n>\n> Note: As indicated above, if you are willing to permanently destroy\n> the history, deleting the VHR is a good interoperable way of taking\n> a resource out of version control.  The PROPPATCH proposal is only\n> needed if you want to retain the history while un-version-controlling\n> the resource.\n>\n>    However, I now have a new question:\n>\n>    If - after the deletion of a VCR's VHR - the VCR is still\n>    version-controlled - where does it's DAV:version-history property\n>    point to?  Similarily, if the delete of the VHR deleted all\n>    versions, where does DAV:checked-in/DAV:checked-out point to?\n>\n> I agree that the simplest model for deleting the VHR would be to\n> un-version-control any VCR for that history, and remove any entries\n> in DAV:version-controlled-binding-set that refer to that VHR.\n> Alternatively, the server could just keep all those references,\n> and return errors on all versioning operations, but that would\n> leave things in a pretty broken state.\n>\n>    -> Seems that we need to clarify the post-conditions for deletions\n>    of VHRs, right?\n>\n> It sounds like we actually agree on this one ... it was just the\n> \"restore via UNCHECKOUT\" that was confusing things.\n>\n> Cheers,\n> Geoff\n>\n>\n>\n\n\n\n", "id": "lists-007-4193268"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c  ollectio", "content": "Julian wrote:\n\n> b) the server deletes the VHR and un-version-controls the\n> VCR (to avoid breaking the live versioning properties).\n\nIn what sense would the property be \"broken\"?  Clearly from the server's\npoint of view there is a good reason why it may not want to so this, but\nfrom a protocol point I don't see a problem.  For example, what would be\nthe difference if the version-history resource is unaccessible due to other\ncircumstances, such as authentication or reachability?\n\nThe semantics of a version-controlled resource can be enforced even if the\nversion-history resource does not exist.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-4212041"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c  ollectio", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Tuesday, July 09, 2002 3:18 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: error condition for delete of VHR when VCR is in checked-in\n> c ollection\n>\n>\n>\n>\n> Julian wrote:\n>\n> > b) the server deletes the VHR and un-version-controls the\n> > VCR (to avoid breaking the live versioning properties).\n>\n> In what sense would the property be \"broken\"?  Clearly from the server's\n> point of view there is a good reason why it may not want to so this, but\n> from a protocol point I don't see a problem.  For example, what would be\n> the difference if the version-history resource is unaccessible\n> due to other\n> circumstances, such as authentication or reachability?\n>\n> The semantics of a version-controlled resource can be enforced even if the\n> version-history resource does not exist.\n\nEven if both the resources referenced by  DAV:checked-in and DAV:checked-out\ndo not exist?\n\n\n\n", "id": "lists-007-4220504"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "> > I don't recall hearing of this approach, and don't see how it could\nbe\n> > compatible with the spec, giving the DAV:delete-version-set\n> > postcondition.\n> \n> OK. It was originally suggested in section 4.2 of\n> draft-dusseault-deltav-subset-00 [1], and up until some time ago, it\nmade\n> a\n> lot of sense to me.\n\nFYI, I too have decided it is not a super idea to use DELETE of a VHR to\nturn off versioning (though it's better than COPY/MOVE/DELETE). I still\nbelieve some straightforward mechanism is needed to turn off versioning\nfor a resource.\n\n> > COPY/DELETE/MOVE is the only interoperable way of removing something\n> > from version control.  If you need a mechanism that doesn't create a\n> > new resource, I'd suggest something like allowing a PROPPATCH to\n> > remove the DAV:version-history property of the VCR, rather than\ntrying\n> > anything related to VHR deletion.\n> \n> Sounds good, and we'll look into this.\n\nNo, this is an even worse idea, and has been discussed before. \n1.  The COPY creates a new resource with a new creation date, owner,\netc. This is NOT the same as modifying an existing resource so that it\nis no longer version-controlled.  It involves creating a new resource,\nwhich may mean different access control settings inherited from the\nparent, etc.\n2.  If the server automatically does VERSION-CONTROL, then the client\nends up with TWO version-controlled resources, when it wanted zero. Now\nthe client has to clean up a mess.\n\nAs long as it is possible to turn a non-versioning resource into a\nversioned resource with VERSION-CONTROL, it should be possible to do the\nreverse operation in a way that doesn't involve the creation of new\nresources.\n\nLisa\n\n\n\n", "id": "lists-007-4230550"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c   ollectio", "content": "Julian wrote:\n> > Julian wrote:\n> >\n> > > b) the server deletes the VHR and un-version-controls the\n> > > VCR (to avoid breaking the live versioning properties).\n> >\n> > In what sense would the property be \"broken\"?  Clearly from the\nserver's\n> > point of view there is a good reason why it may not want to so this,\nbut\n> > from a protocol point I don't see a problem.  For example, what would\nbe\n> > the difference if the version-history resource is unaccessible\n> > due to other\n> > circumstances, such as authentication or reachability?\n> >\n> > The semantics of a version-controlled resource can be enforced even if\nthe\n> > version-history resource does not exist.\n>\n> Even if both the resources referenced by  DAV:checked-in and\nDAV:checked-out\n> do not exist?\n\nIn principle, yes.  For example, if a site wanted to allow anonymous users\nto see the current state of the website, by browsing the version-controlled\nresources; but not allow them to view the history or checked-in,\nchecked-out states.  The server may still ensure that the semantics are\nmaintained.\n\nI just wondered what you meant by the properties being 'broken'.  If you\nenvisage that to mean the references cannot be 'de-referenced' then there\nare multiple reasons why that may be the case.  I see DELETE to be the\ninverse of BIND (and agree with your descriptions earlier in the thread),\nplus whatever further semantics we choose to apply to DELETE for\nconvenience.\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-4241354"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "> From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> Sent: Tuesday, July 09, 2002 6:46 PM\n> To: Julian Reschke; Clemm, Geoff; ietf-dav-versioning@w3.org\n> Subject: RE: error condition for delete of VHR when VCR is in checked-in\n> c ollection\n> \n> ...\n>\n> > > COPY/DELETE/MOVE is the only interoperable way of removing something\n> > > from version control.  If you need a mechanism that doesn't create a\n> > > new resource, I'd suggest something like allowing a PROPPATCH to\n> > > remove the DAV:version-history property of the VCR, rather than\n> trying\n> > > anything related to VHR deletion.\n> > \n> > Sounds good, and we'll look into this.\n> \n> No, this is an even worse idea, and has been discussed before. \n> 1.  The COPY creates a new resource with a new creation date, owner,\n> etc. This is NOT the same as modifying an existing resource so that it\n> is no longer version-controlled.  It involves creating a new resource,\n> which may mean different access control settings inherited from the\n> parent, etc.\n\nNobody was proposing COPY (this time),\n\n> 2.  If the server automatically does VERSION-CONTROL, then the client\n> ends up with TWO version-controlled resources, when it wanted zero. Now\n> the client has to clean up a mess.\n> \n> As long as it is possible to turn a non-versioning resource into a\n> versioned resource with VERSION-CONTROL, it should be possible to do the\n> reverse operation in a way that doesn't involve the creation of new\n> resources.\n\nAgreed.\n\n\n\n", "id": "lists-007-4250763"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c   ollectio", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Tuesday, July 09, 2002 6:51 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: error condition for delete of VHR when VCR is in checked-in\n> c ollection\n>\n>\n>\n>\n> Julian wrote:\n> > > Julian wrote:\n> > >\n> > > > b) the server deletes the VHR and un-version-controls the\n> > > > VCR (to avoid breaking the live versioning properties).\n> > >\n> > > In what sense would the property be \"broken\"?  Clearly from the\n> server's\n> > > point of view there is a good reason why it may not want to so this,\n> but\n> > > from a protocol point I don't see a problem.  For example, what would\n> be\n> > > the difference if the version-history resource is unaccessible\n> > > due to other\n> > > circumstances, such as authentication or reachability?\n> > >\n> > > The semantics of a version-controlled resource can be enforced even if\n> the\n> > > version-history resource does not exist.\n> >\n> > Even if both the resources referenced by  DAV:checked-in and\n> DAV:checked-out\n> > do not exist?\n>\n> In principle, yes.  For example, if a site wanted to allow anonymous users\n> to see the current state of the website, by browsing the\n> version-controlled\n> resources; but not allow them to view the history or checked-in,\n> checked-out states.  The server may still ensure that the semantics are\n> maintained.\n\nI think we need to distinguish between\n\na) references to version histories / versions that are correct, but specific\nusers may not dereference/GET them (I don't have any problem with that), and\n\nb) references that are dead (because the resource they point to is gone).\n\nIn case b), there's no way a subsequent CHECKIN or CHECKOUT can satisfy\nRFC3253's postconditions, so I'd consider this a broken state. There\nshouldn't be a protocol-tolerated way to get into this state, right?\n\n> I just wondered what you meant by the properties being 'broken'.  If you\n> envisage that to mean the references cannot be 'de-referenced' then there\n> are multiple reasons why that may be the case.  I see DELETE to be the\n> inverse of BIND (and agree with your descriptions earlier in the thread),\n> plus whatever further semantics we choose to apply to DELETE for\n> convenience.\n>\n> Regards,\n> Tim\n>\n>\n>\n\n\n\n", "id": "lists-007-4260928"}, {"subject": "[ietf-dav-versioning] &lt;none&gt", "content": "UNSUBSCRIBE\n\n\n\n", "id": "lists-007-4273010"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c   ollectio", "content": "> I think we need to distinguish between\n>\n> a) references to version histories / versions that are correct,\n> but specific\n> users may not dereference/GET them (I don't have any problem with\n> that), and\n\nAgreed.\n\n> b) references that are dead (because the resource they point to is gone).\n>\n> In case b), there's no way a subsequent CHECKIN or CHECKOUT can satisfy\n> RFC3253's postconditions, so I'd consider this a broken state. There\n> shouldn't be a protocol-tolerated way to get into this state, right?\n\nAgreed.  ...and there is no way in HTTP to ensure that a resource is gone,\nso we are cool, right?\n\nRegards,\nTim\n\n\n\n", "id": "lists-007-4279532"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   let me try to summarize.\n   In the presence of BINDs, DELETE is defined as\n\n   1) removing the binding specified in the request URI,\n\nYes.\n\n   2) optional deletion of the resource identified by the URI if there\n   are no references left to it. Note that references may be in other\n   namespaces, on other servers and even in different URI schemes.\n\nIf there are no \"bindings\" to it.  A reference (e.g. a redirect\nreference, or a DAV:href reference) is not a binding.\n\n   Any spec that wants to cooperate with bindings can NOT change this\n   semantics of DELETE\n\nCorrect, but it can supplement the definition with additional\nexplicit semantics (RFC3253 does so in a number of places).\n\n   (or does RFC3253 explicitly say that a VHR can have only a single\n   binding???).\n\nNo (in fact, it explicitly introduces other bindings in working\ncollections).\n\n   So we have a VCR that refers to a VHR through the\n   DAV:version-history property. The client issues a DELETE on the VHR\n   URI. Possible results:\n\n   a) the server may refuse to perform the Delete, either because\n   deletion of VHRs is not supported, or because a VCR still refers to\n   the VHR.\n\nOr pretty much for any reason that it wants.\n\n   b) the server deletes the VHR and un-version-controls the VCR (to avoid\n   breaking the live versioning properties).\n\n   c) the server deletes the VHR and keeps the VCR version-controlled - in\n   which case the spec should say what happens to the\n   DAV:checked-in/DAV:checked-out and DAV:version-history.\n\n   I think RFC3253 needs to either forbid b) and c) or properly define the\n   semantics.\n\nWell, (c) is probably what an interoperable client has to assume,\ngiven what is currently stated in the spec (where the semantics is\njust that you get a \"404\" when you try to use the URL in the\nDAV:checked-in/DAV:checked-out and DAV:version-history properties).\n\nThe problem is that we could not achieve consensus on any semantics\nlike \"b\", even though some variant of \"b\" is what some existing\nversioning servers do (where each kind of server has its own variant).\n\n   More below...\n\n   > From:  Clemm, Geoff\n   >\n   > ... checking in a VCC never creates a binding to a VHR, but\n   > rather just creates a reference to the VHR in its\n   > DAV:version-controlled-binding-set property (i.e. it doesn't\n   > create a new name for that VHR, but just uses an existing name to\n   > create a reference).\n\n   I don't think it's really relevant whether the collection version\n   has a reference or a binding.\n\nA binding is very different semantically from a reference (this is\nemphasized in the binding spec).  If you delete a binding to a\nresource, any other binding to that resource can still be used to\nlocate (and apply methods to) that resource.  But a reference just\ncontains a URL, which means that if you delete any of the bindings\nused by that URL, that reference can no longer be used to locate the\nresource.  Similarly, if you MOVE a resource (give it a different\nbinding), that has no effect on other bindings to that resource, while\nreferences will always have the same URL, which means that they will\nidentify whatever resource is currently identified by that URL\n(which changes if you MOVE a different resource to that URL).\n\n   Servers may delay the de-allocation of a resource until there is no\n   reference left, whether it's visible or not.\n\nServers must delay the deallocation of a resource until there are no\nbindings to that resource, but a reference to a resource just contains\na URL, and if you issue a DELETE on that URL, the reference will no\nlonger be usable to locate that resource.  So as far as a reference\nis concerned, the resource is gone as soon as a successful DELETE\nhas been performed on the URL contained by that reference.\n\n   If we allow clients to permanently destroy VHRs that are\n   referenced in a collection version, there's no way to satisfy the\n   postconditions for an UNCHECKOUT of the VCC, right? That's why our\n   implementation keeps the reference, and therefore is able to\n   resurrect the VHR when needed.\n\nFor UNCHECKOUT, it creates a new binding in the VCCl \"when a version\nhistory is identified by the DAV:version-controlled-binding-set\".  But\nif the VHR has been deleted, then that VHR is not longer identified by\nthe DAV:version-controlled-binding-set (i.e. the VHR URL no longer\nidentifies a resource), so no \"restoration\" semantics is implied.\n\n   > - a subsequent delete on the VHR URL just deletes the original\n   > binding to the VHR, but the version history resource (and the\n   > versions inside the version history) is not affected\n   >\n   > Since the DAV:version-controlled-binding-set just has a reference to\n   > that VHR using its server-assigned URL, if you DELETE that URL, you\n   > break all references to that VHR from the DAV:v-c-b-s properties of\n   > collection versions.\n\n   So if the VHR can not be re-created, should the server forbid the delete?\n\nThat is certainly one option.  The other is to allow the delete and\neffectively treat every version-controlled-binding to that VHR as no\nlonger existing.\n\n   >    - thus, upon UNCHECKOUT of the VCC, I can reconstruct the VHR\n   >    (re-creating the original binding)\n   >\n   > The members of the VCC also refer to the VHR via the\n   > server-assigned URL, so even if UNCHECKOUT could restore the\n   > version-controlled member of the VCC, the DAV:version-history\n   > property of that member would contain the VHR URL that was\n   > deleted.\n\n   But that's not a problem if the '*same* VHR is reconstructed at the\n   original URL.\n\nYes, but nothing in the semantics of UNCHECKOUT imply such a\nreconstruction.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4288105"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > > > > b) the server deletes the VHR and un-version-controls the\n   > > > > VCR (to avoid breaking the live versioning properties).\n\n   > > > In what sense would the property be \"broken\"?  Clearly from\n   > > > the server's point of view there is a good reason why it may\n   > > > not want to so this, but from a protocol point I don't see a\n   > > > problem.  For example, what would be the difference if the\n   > > > version-history resource is unaccessible due to other\n   > > > circumstances, such as authentication or reachability?\n   > > > The semantics of a version-controlled resource can be\n   > > > enforced even if the version-history resource does not exist.\n\n   > > Even if both the resources referenced by DAV:checked-in and\n   > > DAV:checked-out do not exist?\n\n   > In principle, yes.  For example, if a site wanted to allow\n   > anonymous users to see the current state of the website, by\n   > browsing the version-controlled resources; but not allow them to\n   > view the history or checked-in, checked-out states.  The server\n   > may still ensure that the semantics are maintained.\n\n   I think we need to distinguish between\n\n   a) references to version histories / versions that are correct, but\n   specific users may not dereference/GET them (I don't have any\n   problem with that), and\n\n   b) references that are dead (because the resource they point to is\n   gone).\n\nI don't see that this makes much of a difference to the protocol\nclient (other than that the error codes may be different when they\ntry to access the VHR/Version URLs).\n\n   In case b), there's no way a subsequent CHECKIN or CHECKOUT can\n   satisfy RFC3253's postconditions, so I'd consider this a broken\n   state. There shouldn't be a protocol-tolerated way to get into this\n   state, right?\n\nWhich CHECKOUT/CHECKIN postconditions couldn't be satisfied?\nI do agree that some operations could not succeed (e.g. UNCHECKOUT).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4302342"}, {"subject": "RE: Marshalling DAV:xxx-collection-set as a live property, and no t an OPTIONS request", "content": "Lisa: Given Julian's explanation below, do you still object\nto changing the marshalling DAV:xxx-collection-set to be a\nlive property?\n\nAnyone else have an opinion?  So far, Lisa is the only one that\nhas objected, and Julian, Matthias, and the ACL design team\nsupport the change.\n\nNote: I also agree with Julian's comment below that it is better\nto resolve issues as they come up, rather than just collecting\nthem and trying to resolve them at some later time.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Monday, July 08, 2002 4:16 AM\nTo: Lisa Dusseault; Clemm, Geoff; DeltaV (E-mail)\nSubject: RE: Marshalling DAV:xxx-collection-set as a live property, and\nnot an OPTIONS request.\n\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Lisa Dusseault\n> Sent: Monday, July 08, 2002 2:36 AM\n> To: Clemm, Geoff; DeltaV (E-mail)\n> Subject: RE: Marshalling DAV:xxx-collection-set as a live property, and\n> not an OPTIONS request.\n>\n>\n>\n> > Since I was not able to convince the ACL working group to marshall\n> > this kind of information as an OPTIONS request, we should probably\n> > consider changing the versioning protocol to also marshall this\n> > kind of information (i.e. DAV:workspace-collection-set,\n> > DAV:activity-collection-set, and DAV:version-history-collection-set)\n> > as live properties, and not as OPTIONS requests.\n>\n> The big picture here is that we're making OPTIONS less useful. In\n> particular, we're saying that OPTIONS * is too hard for servers to\n> implement correctly with a bunch of extra headers and body information,\n> because * is too ambiguous.  That's probably fair enough; it's a result\n> of the early decision that not all resources on a HTTP server need be\n> WebDAV-capable resources.  Should we go so far as to say that clients\n> SHOULD NOT use OPTIONS *?\n\nI think the main issue is that this is a usage of OPTIONS that doesn't seem\nto be in line with HTTP 1.1, which says:\n\n\"If the Request-URI is an asterisk (\"*\"), the OPTIONS request is intended to\napply to the server in general rather than to a specific resource. Since a\nserver's communication options typically depend on the resource, the \"*\"\nrequest is only useful as a \"ping\" or \"no-op\" type of method; it does\nnothing beyond allowing the client to test the capabilities of the server.\nFor example, this can be used to test a proxy for HTTP/1.1 compliance (or\nlack thereof).\"\n\nConsequently, the servlet API doesn't offer my any simple mechanism to\ninfluence the result of \"OPTIONS *\" (or am I missing something).\n\nSo the feature is under discussion because it's extremely hard if not\nimpossible to implement, and thus will be questioned once when RFC3253 takes\nthe next RFC standardization step.\n\n> My concern with going in this direction is that a client accessing a\n> WebDAV server may be configured initially with only the server's domain\n> name. How does the client start figuring out what is where on the\n\nI think that's a configuration a bug. If only part of the URL namespace on a\nserver talks WebDAV, you'll need the URL prefix of this namespace partition.\nThere's no way to avoid that right now.\n\n> server?  Does \"OPTIONS /\" + \"PROPFIND /\" (or the same requests to\n> whatever path is given) solve this problem for the client instead?\n\nNo.\n\n> If the client does OPTIONS only on particular resources, how *does* the\n> server show capabilities? E.g. support for MKCOL can *never* show up as\n> an allowed method on any existing resource.  My take is that MKCOL shows\n> up in OPTIONS * and not in any other OPTIONS request. Thus OPTIONS *\n> serves an important role.\n\n...would serve an important role, if it could be implemented. If you think\nthat discovery of MKCOL using \"OPTIONS *\" is an important feature, we should\nfind out whether there are interoperable implementations supporting that.\n\nHTTP 1.1 clearly states that if you do OPTIONS * and look at the allowed\nmethods, you CAN NOT take the absence of MKCOL (in Allow:) as sign that no\npart of the URL namespace supports this method. If your client assumes that,\nit's buggy.\n\n> Does the client need some way to ask the server \"do you support WebDAV\n> anywhere on the server, and if so, where?\"  This would be similar to the\n> question of asking a server \"do you support HTTP on some port, and if\n> so, which\"...\n\nI'm not sure why a client would need that. If the WebDAV-enabled namespace\ndoesn't start at \"/\", the client will have to be configured to know the\ncomplete prefix. To change this, the process implementing the root resource\nwill need to have knowledge of all other descendants in it's namespace, and\na *new* protocol is needed to marshall this information.\n\n> BTW, I'm curious what you mean by \"changing the version protocol\".  RFC\n> 3253 can't be changed now. Are you proposing a new internet-draft to\n\nThe RFC can't be changed, but the protocol can (in the future).\n\n> eventually obsolete 3253?  Servers compliant with 3253 will continue to\n\nMy take is that with RFC3253, we should try to get the next revision\n(proposed -> draft) out as soon as we have multiple interoperable\nimplementations. So it absolutely makes sense to discuss these issues right\nnow rather than waiting too long (as it happened with RFC2518).\n\n> be so even if the WG decides to replace OPTIONS marshalling with\n> property marshalling. I'm sure I'm stating the obvious, but I'm\n> surprised to see talk of changing DeltaV so recently after the RFC was\n> issued, particularly \"for consistency\" with documents that aren't yet\n> RFCs.\n\nBut then, what's the point in delaying this work? The sooner an issue is\ndiscussed, the earlier we can add it to the errata document (preferrably\nwith a resolution of the issue). We all benefit from that: the WG, because\nthings get resolved when they are raised (instead of years later), and\nimplementors (because they can use *both* RFC3253 and a draft of a deltaV\nrevision) to implement their servers.\n\n\n\n", "id": "lists-007-4312791"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "Geoff,\n\nagain thanks for taking the time. Comments inline.\n\n>    let me try to summarize.\n>    In the presence of BINDs, DELETE is defined as\n>\n>    1) removing the binding specified in the request URI,\n>\n> Yes.\n>\n>    2) optional deletion of the resource identified by the URI if there\n>    are no references left to it. Note that references may be in other\n>    namespaces, on other servers and even in different URI schemes.\n>\n> If there are no \"bindings\" to it.  A reference (e.g. a redirect\n> reference, or a DAV:href reference) is not a binding.\n\nI agree that a reference in the sense of a DAV:href or a redirect reference\ndoes not *require* the server to keep the resource. But my point is that\nwith bindings, there's no way a client can definitively know, and a server\ncan decide to keep a resource as long as it wants. The BIND spec defines how\nlong a resource MUST be kept, but not when it should be cleaned up after all\nclient-visible bindings are gone.\n\nThus, a specific RFC3253 implementation is absolutely free to *treat* a\n\"soft\" reference (like a DAV:href in the DAV:version-controlled-binding-set)\nas internal reference to the resource, and thus keep the resource. In this\nspecific case, this allows the server to resurrect a bind to the VHR at the\noriginal URI although the client has done a DELETE on it in the meantime.\n\nAre you saying that this behaviour breaks the spec in some way?\n\n>    Any spec that wants to cooperate with bindings can NOT change this\n>    semantics of DELETE\n>\n> Correct, but it can supplement the definition with additional\n> explicit semantics (RFC3253 does so in a number of places).\n\nMy point is that these semantics need to distinguish between:\n\n- removing the bind (something the BIND spec defines -- the name is gone,\nthat's all) and\n- removing the resource (and here's the catch --  spec can define what\nremoving the resource means, but it can't define *when* this happens or\nwhether it happens at all)\n\n>    (or does RFC3253 explicitly say that a VHR can have only a single\n>    binding???).\n>\n> No (in fact, it explicitly introduces other bindings in working\n> collections).\n>\n>    So we have a VCR that refers to a VHR through the\n>    DAV:version-history property. The client issues a DELETE on the VHR\n>    URI. Possible results:\n>\n>    a) the server may refuse to perform the Delete, either because\n>    deletion of VHRs is not supported, or because a VCR still refers to\n>    the VHR.\n>\n> Or pretty much for any reason that it wants.\n>\n>    b) the server deletes the VHR and un-version-controls the VCR (to avoid\n>    breaking the live versioning properties).\n>\n>    c) the server deletes the VHR and keeps the VCR version-controlled - in\n>    which case the spec should say what happens to the\n>    DAV:checked-in/DAV:checked-out and DAV:version-history.\n>\n>    I think RFC3253 needs to either forbid b) and c) or properly define the\n>    semantics.\n>\n> Well, (c) is probably what an interoperable client has to assume,\n> given what is currently stated in the spec (where the semantics is\n> just that you get a \"404\" when you try to use the URL in the\n> DAV:checked-in/DAV:checked-out and DAV:version-history properties).\n\nOK with me.\n\n> The problem is that we could not achieve consensus on any semantics\n> like \"b\", even though some variant of \"b\" is what some existing\n> versioning servers do (where each kind of server has its own variant).\n>\n>    More below...\n>\n>    > From:  Clemm, Geoff\n>    >\n>    > ... checking in a VCC never creates a binding to a VHR, but\n>    > rather just creates a reference to the VHR in its\n>    > DAV:version-controlled-binding-set property (i.e. it doesn't\n>    > create a new name for that VHR, but just uses an existing name to\n>    > create a reference).\n>\n>    I don't think it's really relevant whether the collection version\n>    has a reference or a binding.\n>\n> A binding is very different semantically from a reference (this is\n> emphasized in the binding spec).  If you delete a binding to a\n\nAgreed. I wasn't using the term \"reference\" in the sense of \"redirect\nreference\", but in the sense of \"any internal reference that the server may\nhave to the resource\".\n\n> resource, any other binding to that resource can still be used to\n> locate (and apply methods to) that resource.  But a reference just\n> contains a URL, which means that if you delete any of the bindings\n> used by that URL, that reference can no longer be used to locate the\n\nAgreed. In POSIX speak, a \"redirect reference\" is like a symbolic link,\nwhile a bind is like a hard link...\n\n> resource.  Similarly, if you MOVE a resource (give it a different\n> binding), that has no effect on other bindings to that resource, while\n> references will always have the same URL, which means that they will\n> identify whatever resource is currently identified by that URL\n> (which changes if you MOVE a different resource to that URL).\n\nIn the particular case (a DAV:href pointing to a VHR) this is no issue\nbecause RFC3253 clearly states that the URL for a VHR may never be reused\nfor a different resource. May point is that is MAY be reused for the same\nresource, if the server is able to do that after a DELETE.\n\n>    Servers may delay the de-allocation of a resource until there is no\n>    reference left, whether it's visible or not.\n>\n> Servers must delay the deallocation of a resource until there are no\n> bindings to that resource, but a reference to a resource just contains\n> a URL, and if you issue a DELETE on that URL, the reference will no\n> longer be usable to locate that resource.  So as far as a reference\n> is concerned, the resource is gone as soon as a successful DELETE\n> has been performed on the URL contained by that reference.\n\nYes.\n\n>    If we allow clients to permanently destroy VHRs that are\n>    referenced in a collection version, there's no way to satisfy the\n>    postconditions for an UNCHECKOUT of the VCC, right? That's why our\n>    implementation keeps the reference, and therefore is able to\n>    resurrect the VHR when needed.\n>\n> For UNCHECKOUT, it creates a new binding in the VCCl \"when a version\n> history is identified by the DAV:version-controlled-binding-set\".  But\n> if the VHR has been deleted, then that VHR is not longer identified by\n> the DAV:version-controlled-binding-set (i.e. the VHR URL no longer\n> identifies a resource), so no \"restoration\" semantics is implied.\n\nI think that would come as a surprise to the user. It means that the result\nof a UNCHECKOUT may be imcomplete in the sense that the server silently\ndrops a version-controlled member. If this really is the intention (and\nrequired), this should be explained.\n\nAgain the question: if a server is able to reconstruct the VHR at it's\noriginal location, is it *allowed* to do so?\n\n>    > - a subsequent delete on the VHR URL just deletes the original\n>    > binding to the VHR, but the version history resource (and the\n>    > versions inside the version history) is not affected\n>    >\n>    > Since the DAV:version-controlled-binding-set just has a reference to\n>    > that VHR using its server-assigned URL, if you DELETE that URL, you\n>    > break all references to that VHR from the DAV:v-c-b-s properties of\n>    > collection versions.\n>\n>    So if the VHR can not be re-created, should the server forbid\n> the delete?\n>\n> That is certainly one option.  The other is to allow the delete and\n> effectively treat every version-controlled-binding to that VHR as no\n> longer existing.\n>\n>    >    - thus, upon UNCHECKOUT of the VCC, I can reconstruct the VHR\n>    >    (re-creating the original binding)\n>    >\n>    > The members of the VCC also refer to the VHR via the\n>    > server-assigned URL, so even if UNCHECKOUT could restore the\n>    > version-controlled member of the VCC, the DAV:version-history\n>    > property of that member would contain the VHR URL that was\n>    > deleted.\n>\n>    But that's not a problem if the '*same* VHR is reconstructed at the\n>    original URL.\n>\n> Yes, but nothing in the semantics of UNCHECKOUT imply such a\n> reconstruction.\n\nOK, I can live with servers *not* doing that -- what I'd like to know is\nwhether this behaviour (reconstructing the VHR) actually is RFC3253\ncompliant.\n\n\n\n", "id": "lists-007-4327229"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Wednesday, July 10, 2002 2:05 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: error condition for delete of VHR when VCR is in checked-in\n> c ollection\n> \n> ..\n>    In case b), there's no way a subsequent CHECKIN or CHECKOUT can\n>    satisfy RFC3253's postconditions, so I'd consider this a broken\n>    state. There shouldn't be a protocol-tolerated way to get into this\n>    state, right?\n> \n> Which CHECKOUT/CHECKIN postconditions couldn't be satisfied?\n> I do agree that some operations could not succeed (e.g. UNCHECKOUT).\n\nYou are right. CHECKIN/CHECKOUT would continue to work.\n\n\n\n", "id": "lists-007-4344277"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c   ollectio", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Tim Ellison\n> Sent: Tuesday, July 09, 2002 10:39 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: error condition for delete of VHR when VCR is in checked-in\n> c ollection\n>\n>\n>\n> > I think we need to distinguish between\n> >\n> > a) references to version histories / versions that are correct,\n> > but specific\n> > users may not dereference/GET them (I don't have any problem with\n> > that), and\n>\n> Agreed.\n>\n> > b) references that are dead (because the resource they point to\n> is gone).\n> >\n> > In case b), there's no way a subsequent CHECKIN or CHECKOUT can satisfy\n> > RFC3253's postconditions, so I'd consider this a broken state. There\n> > shouldn't be a protocol-tolerated way to get into this state, right?\n>\n> Agreed.  ...and there is no way in HTTP to ensure that a resource is gone,\n> so we are cool, right?\n\nI don't understand this one. So...\n\n- DAV:href references to versions may be broken -- for instance because the\nversioning server is only loosely coupled, and the versions actually live in\na different system. That the references point to non-accessible/gone\nresources isn't really a problem during checking in / checking out -- but\nfor instance UNCHECKOUT or UPDATE may fail later.\n\n- My point is that this is an error condition. Yes, it may happen. But, I\nthink it is wrong that a client can get into this state by just doing\nRFC3253-allowed requests. At the very least, the DELETE sematics for VHRs\nshould *warn* programmers that the side effects of the deletion of a VHR may\nbe surprising :-)\n\n\n\n", "id": "lists-007-4354319"}, {"subject": "WebDAV/DeltaV Face-to-Face Interoperability Testing Even", "content": "WebDAV/DeltaV Interoperability Testing Event\n--------------------------------------------\n\nWhere: Univ. of California, Santa Cruz\n       Baskin Engineering Building\n       \"Jack's Lounge\" (same location as last year)\n       Santa Cruz, California\n\nWhen: September 11-13, 2002\n\nWho: Developers or testers of WebDAV and DeltaV\n     clients and servers.\n\nCost: Still working on this. It will be free for Open Source\n     developers, and a modest fee (TBD, not to exceed USD $500) per\n     organization for commercial implementors, to cover food,\n     computing support, and setup costs. (But let me know if this\n     fee would prevent you from attending).\n\nHow to Register: Send email to Jim Whitehead <ejw@cs.ucsc.edu>.\n\n\nFollowing up on last year's very successful interoperability testing event\nattended by over 50 people, there will be a face-to-face interoperability\ntesting event for WebDAV/DeltaV clients and servers.  The intent of this\nexercise is to gather together, in one physical location, the\ndevelopers/testers of WebDAV/DeltaV clients and servers, to exerce as many\nclient/server pairs as possible. This will quickly surface interoperability\nproblems. Once identified, these problems can sometimes be fixed on the spot\n(if developers have brought source code), or can be targeted for resolution\nin the Draft Standard (i.e., revised) version of RFC 2518.\n\nInteroperability testing events are an extremely efficient way to do\ninteroperability testing against a broad array of clients/servers, allowing\nproblems to be quickly identified and resolved. Most organizations do not\nhave the resources to install and operate the wide range of WebDAV/DeltaV\nclients and servers, and hence only test a small number of the total amount.\nThese events provide a way to test against a wide range of other\nimplementations much faster than would be possible with each organization\ntesting by themselves. Invariably, the net result of an interop. event is a\nset of clients and servers that work better, hence offering better value for\nend-users. After all, the expectation of users is that WebDAV clients and\nservers \"just work\" with each other.\n\nNote that this event is intended to complement the Always on-line\nInteroperability Testing being organized by Jim Luther <luther.j@apple.com>.\n\nSome details about the event:\n\n* Results from the event are NOT intended for distribution to the Press.\nThis is not an interoperability demonstration like those sometimes held at\ntrade shows for marketing purposes. Instead, this is a normal part of the\n*engineering* activity of creating an interoperability standard.\n\n* Since the intended room for this event is not super-big, I request that a\nmaximum of two people attend per independent code base (if this seems too\nrestrictive, let me know).\n\n* You will need to provide your own machines, with the client and/or server\nsoftware installed. UCSC will provide networking capabilities.\n\n* DeltaV clients and servers are encouraged to participate, as are ACL,\nDASL, and Advanced Collections implementations.\n\n* If you're intending on participating, please let me know via email to\n<ejw@cs.ucsc.edu>.\n\n* If you're traveling from afar, you should try and get accommodations as\nearly as you can (I will not be handling accommodations). Santa Cruz is a\npopular vacation location in the summer...\n\nHere is a Web page giving hotels:\n\nhttp://www.scccvc.org/accom/accsearch.cfm\n\nIf it's in your price range, the West Coast Santa Cruz Hotel is nice, and\nmost rooms have an ocean view.\n\nhttp://www.westcoastsantacruz.com/\nWestCoast Santa Cruz Hotel\n175 West Cliff Drive, Santa Cruz, California 95060\n831-426-4330 * 800-426-0670 * FAX 831-427-2025\n\nHere's a list of Bed and Breakfast places as well.\n\nhttp://santacruz.about.com/citiestowns/caus/santacruz/cs/accomscbedbreak/ind\nex.htm\n\n* Some pictures of the location:\n\nA picture of half of the room:\nhttp://www.webdav.org/other/baskin-commons.jpg\nA picture of Baskin Engineering:\nhttp://www.webdav.org/other/baskin-outside.jpg\n\n\n* Some directions to UCSC and Baskin Engineering:\nhttp://www.cse.ucsc.edu/general/find.html\nA virtual tour of campus (QuickTime VR images):\nhttp://www.ucsc.edu/general_info/vtour/index.html\n\n* Pictures from last year's event:\n\nhttp://www.webdav.org/other/interop/interop1.jpg\nhttp://www.webdav.org/other/interop/interop2.jpg\nhttp://www.webdav.org/other/interop/interop3.jpg\nhttp://www.webdav.org/other/interop/interop4.jpg\nhttp://www.webdav.org/other/interop/interop5.jpg\nhttp://www.webdav.org/other/interop/interop6.jpg\n\n- Jim\n\n\n\n", "id": "lists-007-4364981"}, {"subject": "CHECKOUT -&gt; MOVE (rename) -&gt; UNCHECKOU", "content": "Hi,\n\nsuppose I have a checked-in VCR at /foo/a.xml and the following scenario:\n\nCHECKOUT /foo/a.xml\nMOVE /foo/a.xml -> /bar/b.xml (i.e. rename)\nUNCHECKOUT /bar/xml\n\nIs the resource renamed back to /foo/a.xml by the UNCHECKOUT?\n\nOn one side, RFC 3253 specifies that UNCHECKOUT restores the pre-checkout\nstate of the resource (is the URL part of it?). On the other side, it should\nbe possible to rename a checked-in VCR.\n\nThanks in advance,\nPeter.\n\n\n\n", "id": "lists-007-4378832"}, {"subject": "RE: CHECKOUT -&gt; MOVE (rename) -&gt; UNCHECKOU", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Nevermann, Dr.,\n> Peter\n> Sent: Saturday, July 13, 2002 3:51 PM\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: CHECKOUT -> MOVE (rename) -> UNCHECKOUT\n>\n>\n>\n> Hi,\n>\n> suppose I have a checked-in VCR at /foo/a.xml and the following scenario:\n>\n> CHECKOUT /foo/a.xml\n> MOVE /foo/a.xml -> /bar/b.xml (i.e. rename)\n> UNCHECKOUT /bar/xml\n\nYou mean UNCHECKOUT /bar/b.xml?\n\n> Is the resource renamed back to /foo/a.xml by the UNCHECKOUT?\n\nNo.\n\n> On one side, RFC 3253 specifies that UNCHECKOUT restores the pre-checkout\n> state of the resource (is the URL part of it?). On the other\n> side, it should\n> be possible to rename a checked-in VCR.\n\nThe URL is not part of the state of the resource. In fact, a resource may\nhave multiple URIs mapped to it.\n\n\n\n", "id": "lists-007-4387208"}, {"subject": "RE: CHECKOUT -&gt; MOVE (rename) -&gt; UNCHECKOU", "content": "I agree with Julian.  The URL namespace state is captured in the\ncollection state and the baseline state, so your server has to\nsupport versioned collections or baselines to capture namespace\nstate.  For versioned collections, you'd have to CHECKOUT both /foo\nand /bar in order to MOVE /foo/a.xml to /bar/b.xml, but you would\n*not* have to CHECKOUT /foo/a.xml.  If you then did an UNCHECKOUT\nof both /foo and /bar, you would restore the previous state (i.e.\nthe moved resource is named /foo/a.xml and /bar/b.xml does not\nexist).  If instead you did a CHECKIN of /foo and an UNCHECKOUT \nof /bar, you would effectively have deleted the resource.  If instead\nyou did an UNCHECKOUT of /foo and a CHECKIN of /bar, you would have\ntwo bindings to the same resource, and both /foo/a.xml and /bar/b.xml\nwould identify the same version-controlled resource.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n> From: Nevermann, Dr., Peter\n>\n> suppose I have a checked-in VCR at /foo/a.xml and the following scenario:\n>\n> CHECKOUT /foo/a.xml\n> MOVE /foo/a.xml -> /bar/b.xml (i.e. rename)\n> UNCHECKOUT /bar/xml\n\nYou mean UNCHECKOUT /bar/b.xml?\n\n> Is the resource renamed back to /foo/a.xml by the UNCHECKOUT?\n\nNo.\n\n> On one side, RFC 3253 specifies that UNCHECKOUT restores the pre-checkout\n> state of the resource (is the URL part of it?). On the other\n> side, it should\n> be possible to rename a checked-in VCR.\n\nThe URL is not part of the state of the resource. In fact, a resource may\nhave multiple URIs mapped to it.\n\n\n\n", "id": "lists-007-4396874"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   - DAV:href references to versions may be broken -- for instance\n   because the versioning server is only loosely coupled, and the\n   versions actually live in a different system. That the references\n   point to non-accessible/gone resources isn't really a problem\n   during checking in / checking out -- but for instance UNCHECKOUT or\n   UPDATE may fail later.\n\nYes.\n\n   - My point is that this is an error condition. Yes, it may\n   happen. But, I think it is wrong that a client can get into this\n   state by just doing RFC3253-allowed requests. At the very least,\n   the DELETE sematics for VHRs should *warn* programmers that the\n   side effects of the deletion of a VHR may be surprising :-)\n\nThe standard behavior of property values is that they stay unchanged\nunless explicitly changed by some method, so we do not repeat that\nstatement with every property definition.  This is as true for\nDAV:href values as it is for any other value.  Note that we do\nexplicitly state whenever any auto-updating occurs (e.g. various\nspecial DELETE/MOVE postconditions).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4405855"}, {"subject": "RE: error condition for delete of VHR when VCR is in checked-in c ollectio", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > >  - thus, upon UNCHECKOUT of the VCC, I can reconstruct the VHR\n   > > (re-creating the original binding)\n\n   > Yes, but nothing in the semantics of UNCHECKOUT imply such a\n   > reconstruction.\n\n   OK, I can live with servers *not* doing that -- what I'd like to\n   know is whether this behaviour (reconstructing the VHR) actually is\n   RFC3253 compliant.\n\nIt is not compliant, in that no interoperable client will expect this\nbehavior.  It is compliant in that it is not forbidden.  So it really\nis an implementor's judgement call.  If you think the \"restore on\nUNCHECKOUT\" behavior is important, you can resurrect the version\nhistory, and offer that as a \"special feature\" offered by your server.\nBut if the user issued the DELETE on the version history\nexplicitly to prevent this kind of resurrection (or to free up space\non the server), then you will make that user unhappy.\n\nA similar kind of situation exists with versioned collections.\nA collection version lets you resurrect deleted resources, which\nwould could violate the user's desire to free up the space from\nthat resource.  But we minimize that cost by using techniques\nlike delta storage, and we allow the user to control this behavior\nby giving them an explicit VERSION-CONTROL operation.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4414965"}, {"subject": "Does DAV:sucessor-set identifies working resources ", "content": "Hi,\n\nLet's have VCR X, whose DAV:checked-in property identifies version V10,\nchecked-out with apply-to-version option.\nAs a result of that a working resource WR1 was created.\n\nClearly, WR1 identifies V10 in its DAV:predecessor-set.\nDoes V10 also identify WR1 in its DAV:successor-set ?\n\nRegards\nSasha Zivkov\n\n\n\n", "id": "lists-007-4424067"}, {"subject": "RE: Does DAV:sucessor-set identifies working resources ", "content": "   From: Zivkov, Sasa [mailto:sasa.zivkov@sap.com]\n\n   Let's have VCR X, whose DAV:checked-in property identifies version\n   V10, checked-out with apply-to-version option.  As a result of that\n   a working resource WR1 was created.\n\n   Clearly, WR1 identifies V10 in its DAV:predecessor-set.\n   Does V10 also identify WR1 in its DAV:successor-set ?\n\nNo, the DAV:successor-set identifies versions, not checked-out\nresources such as a working resource.  But V10 does identify\nWR1 in its DAV:checkout-set property.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4431769"}, {"subject": "Derived object", "content": "Hello!\n\nAs far as I understood, WebDAV/Delta V is only concerned with\n*version?control* of static components.\n\nMany web pages are however dynamically generated.\nOne could even argue that there is a fundamental granularity problem:\nthe grain suitable for maintenance (and for sharing) is finer than\nthis suitable for navigation.\n\nIs there a provision to cope with this issue?\n\nBest Regards!\nMarc\n\n-- \nMarc Girod        P.O. Box 323        Voice:  +358-71 80 25581\nNokia NBI         00045 NOKIA Group   Mobile: +358-50 38 78415\nTakomo 1 / 4c27   Finland             Fax:    +358-71 80 61604\n\n\n\n", "id": "lists-007-4439568"}, {"subject": "Re: Marshalling DAV:xxx-collection-set as a live property, and not an  OPTIONS request", "content": "> Since I was not able to convince the ACL working group to marshall\n> this kind of information as an OPTIONS request, we should probably\n> consider changing the versioning protocol to also marshall this\n> kind of information (i.e. DAV:workspace-collection-set,\n> DAV:activity-collection-set, and DAV:version-history-collection-set)\n> as live properties, and not as OPTIONS requests.\n>\n> So I'd like to poll the mailing list (especially DeltaV client and/or\n> server implementors:\n>\n> Do you prefer to:\n> (a) leave xxx-collection-set as it is (marshalled only as OPTIONS)\n> (b) support marshalling both as OPTIONS and as live properties\n> (c) marshal only as live properties and deprecate the OPTIONS marshalling\n>\n> I vote for (c), as it simplifies the spec, and makes it consistent\n> with the ACL protocol.\n\nI just noticed that subversion is actually using this feature, so it might\nbe good to get this onto the issues list now :-)\n\n\n\n", "id": "lists-007-4446955"}, {"subject": "Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing the Label header with a DAV:labeled-version repor", "content": "Geoff,\n\nI think we really need to come to a conclusion here.\n\nIMHO, marshalling something that isn't a resource property inside a\nmultistatus/response/propstat/prop element clearly breaks RFC2518 [1] and is\nvery confusing. If this behaviour really was intended by RFC3253 then it was\nextremely hard to discover because there's not a single example in the spec\nwhere this actually happens.\n\nMy proposal would be to put the report result below the response element,\nand to assign it a new name, such as:\n\n<response>\n  <href>...</href>\n  <status>...</status>\n  <report-result>...</report-result>\n<response>\n\n\nRelated question of the day: what's the response format for the version-tree\nreport with depth: 1 applied to a collection that itself is not versioned\nbut contains one version controlled member?\n\nFor depth 0 I'd expect:\n\n409 CONFLICT\n\nwith\n\n<error xmlns=\"DAV:\"><supported-report/></error>\n\n\nSo for depth 1 one would get:\n\n207 MULTISTATUS\n\n<multistatus xmlns=\"DAV:\">\n\n  <response>\n    <href>/collection/</href>\n    <status>HTTP/1.1 409 Conflict</status>\n\n<responsedescription><error><supported-report/></error></responsedescription\n>\n  </response>\n\n  <response>\n    <href>/collection/a</href>\n    <propstat>\n      <prop>\n      ...now what?...\n      </prop>\n      <status>HTTP/1.1 200 OK</status>\n    </propstat>\n  </response>\n\n</multistatus>\n\n\nRFC3253 seems to indicate that the <prop> element for the version controlled\nmember must return the requested report. The format for the version-tree\nreport defines a multistatus response body. So would the <prop> element\ncontain another <multistatus> sub-tree?\n\nQuestion to other implementors: who has implemented all of RFC3253's REPORTs\nfor depths != 0 (where allowed) and feels that the format is well\nunderstood? I certainly don't feel so.\n\nJulian\n\n[1] <http://greenbytes.de/tech/webdav/rfc2518.html#ELEMENT_prop>\n\n\n\n", "id": "lists-007-4455076"}, {"subject": "which special methods are needed on a webdav-server to work with  the sharepoint client extension", "content": "There are special methods like subscribe, invoke...\n\nI search the initial request from the sharepoint client extension to identify the sharepoint server.\n\nhave anyone a idea \n\nthanks\n\n   Andreas\n\n\n\n", "id": "lists-007-4464692"}, {"subject": "RE: which special methods are needed on a webdav-server to work with  the sharepoint client extension", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Andreas Steiner\n> Sent: Saturday, July 27, 2002 3:02 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: which special methods are needed on a webdav-server to work\n> with the sharepoint client extension?\n>\n>\n>\n> There are special methods like subscribe, invoke...\n>\n> I search the initial request from the sharepoint client extension\n> to identify the sharepoint server.\n\nI think it's a mix of\n\n- proprietary, but partly documented methods defined in MS Exchange [1]\n- the proprietary and undocumented \"INVOKE\" method (seems to basically\nmarshall some of the COM methods such as for getting the version history)\n- a set of proprietary live properties\n\nGood luck. Better invest your time in writing clients for servers that\nconform to open standards.\n\n\n\n[1]\n<http://msdn.microsoft.com/library/default.asp?url=/library/en-us/wss/wss/_w\nebdav_methods.asp>\n\n\n\n", "id": "lists-007-4472702"}, {"subject": "Interaction of DAV:auto-version and DAV:checkout-for", "content": "Hi,\n\nconsider the following scenario:\n\n- \"a\" is a version controlled resource with some kind of auto-versioning\nenabled, for instance DAV:checkout-unlocked-checkin,\n\n- it's DAV:checked-in property refers to a version with a DAV:checkout-fork\nproperty of DAV:discouraged and a non-empty DAV:successor-set property.\n\nNon-versioning aware client attempts to modify the resource.\n\n\nPossible outcomes:\n\na) request is rejected (409 with\nDAV:checkout-of-version-with-descendant-is-discouraged),\n\nb) request is accepted and the version history will fork.\n\n\nI think both behaviours are allowed, but which one makes more sense? Right\nnow, I'm preferring to reject the request (standard operations on a\nchecked-in resource shouldn't introduce forks into the version history).\n\nOpinions?\n\n\n\n", "id": "lists-007-4483674"}, {"subject": "RE: Interaction of DAV:auto-version and DAV:checkout-for", "content": "The only behavior that seems to me to be consistent with the standard\nis (a), rejecting the request.  The only way that CHECKOUT can succeed\non a version that has DAV:checkout-fork as DAV:discouraged, and already\nhas a successor, would be if the CHECKOUT had a DAV:fork-ok argument,\nand there is no way for a versioning-unaware client to add a DAV:fork-ok\nargument to the auto-checkout.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Sunday, July 28, 2002 4:37 AM\nTo: ietf-dav-versioning@w3.org\nSubject: Interaction of DAV:auto-version and DAV:checkout-fork\n\n\n\nHi,\n\nconsider the following scenario:\n\n- \"a\" is a version controlled resource with some kind of auto-versioning\nenabled, for instance DAV:checkout-unlocked-checkin,\n\n- it's DAV:checked-in property refers to a version with a DAV:checkout-fork\nproperty of DAV:discouraged and a non-empty DAV:successor-set property.\n\nNon-versioning aware client attempts to modify the resource.\n\n\nPossible outcomes:\n\na) request is rejected (409 with\nDAV:checkout-of-version-with-descendant-is-discouraged),\n\nb) request is accepted and the version history will fork.\n\n\nI think both behaviours are allowed, but which one makes more sense? Right\nnow, I'm preferring to reject the request (standard operations on a\nchecked-in resource shouldn't introduce forks into the version history).\n\nOpinions?\n\n\n\n", "id": "lists-007-4492387"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t he Label header with a DAV:labeled-version repor", "content": "Summary of the issue:\n\nJulian would like to move the marshalling of Depth REPORT responses\nfrom the DAV:prop node in a DAV:response to a new DAV:report-result\nnode in the DAV:response.\n\nSummary of my response:\n\nRFC3253 states that the marshalling is in the DAV:prop node, and\nwe should not change that unless there is some significant problem\nwith that marshalling.  I see no such problem, and therefore vote\nto leave the spec as it is.\n\nDetailed response below:\n\n   From: Julian Reschke [mailto:julian.reschke@gmx.de]\n\n   IMHO, marshalling something that isn't a resource property inside a\n   multistatus/response/propstat/prop element clearly breaks RFC2518\n   [1] and is very confusing.\n\nI disagree on both counts.\n\nRFC2518 says nothing about a REPORT method, so the response format of\na REPORT method cannot break RFC2518.  We have already concluded that\nin earlier threads that each method effectively introduces a new DTD\nfor any XML elements in the response body.\n\nSo that leaves the question of whether it is \"confusing\".  I agree\nthat it is desireable to have consistent DTD's for a standard XML\nelement, across all methods (preferably even across request and\nresponse bodies).  But the only difference between a \"report result\"\nand a \"live property value\" is that a report can take arguments that\nmodify the result (\"value\") of that report for a given resource.  In\nparticular, a report that has a default value for omitted arguments\nacts exactly like a \"live property\".\n\nSo in the interest of keeping the DTD's of standard XML elements\nconsistent, I believe it is desireable to avoid having a standard\nreport result XML element be the same as a standard property value XML\nelement, to avoid having significantly different DTD's for the same\nstandard XML element.  This is what is indicated in RFC3253 by having\nthe report result appear in the same context (i.e. under a DAV:prop\nelement) as property values.\n\n   If this behaviour really was intended by RFC3253 then it was\n   extremely hard to discover because there's not a single example in\n   the spec where this actually happens.\n\nI see no other possible interpretation for the statement in 3.6:\n\n\"The DAV:prop element of a DAV:response for a given resource MUST\ncontain the requested report for that resource.\"\n\nI'm happy to add an example in the next version of the spec, if\nyou feel this needs to be clarified.\n\n   My proposal would be to put the report result below the response element,\n   and to assign it a new name, such as:\n\n   <response>\n     <href>...</href>\n     <status>...</status>\n     <report-result>...</report-result>\n   <response>\n\nWe could do so, but this violates 3253, which requires the report\nto be placed in the DAV:prop element.  I agree that this is a \nreasonable alternative marshalling, and if we didn't have 3253\nsaying otherwise, I'd be pretty happy to do it either way, but\nI'd like to only change 3253 for serious problems.\n\n   Related question of the day: what's the response format for the\n   version-tree report with depth: 1 applied to a collection that\n   itself is not versioned but contains one version controlled member?\n\n   For depth 0 I'd expect:\n   409 CONFLICT\n   with\n   <error xmlns=\"DAV:\"><supported-report/></error>\n\nSounds right.\n\n\n   So for depth 1 one would get:\n   207 MULTISTATUS\n   <multistatus xmlns=\"DAV:\">\n     <response>\n       <href>/collection/</href>\n       <status>HTTP/1.1 409 Conflict</status>\n       <responsedescription><error><supported-report/>\n         </error></responsedescription> </response>\n     <response>\n       <href>/collection/a</href>\n       <propstat>\n <prop>\n ...now what?...\n </prop>\n <status>HTTP/1.1 200 OK</status>\n       </propstat>\n     </response>\n   </multistatus>\n\nYes.\n\n   RFC3253 seems to indicate that the <prop> element for the version\n   controlled member must return the requested report. The format for\n   the version-tree report defines a multistatus response body. So\n   would the <prop> element contain another <multistatus> sub-tree?\n\nYes.\n\n   Question to other implementors: who has implemented all of\n   RFC3253's REPORTs for depths != 0 (where allowed) and feels that\n   the format is well understood? I certainly don't feel so.\n\nClarifying the format is fine with me.  Changing it without\ncompelling motivation would not.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4502048"}, {"subject": "RE: Interaction of DAV:auto-version and DAV:checkout-for", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Sunday, July 28, 2002 3:00 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: Interaction of DAV:auto-version and DAV:checkout-fork\n>\n>\n>\n> The only behavior that seems to me to be consistent with the standard\n> is (a), rejecting the request.  The only way that CHECKOUT can succeed\n> on a version that has DAV:checkout-fork as DAV:discouraged, and already\n> has a successor, would be if the CHECKOUT had a DAV:fork-ok argument,\n> and there is no way for a versioning-unaware client to add a DAV:fork-ok\n> argument to the auto-checkout.\n\nWell, the spec doesn't say anything about the type of checkout that is\nautomatically performed. Not saying anything doesn't mean that anything\ndifferent than a \"default\" CHECKOUT is forbidden, right=\n\nSo I think it would be compliant to default to a CHECKOUT *with*\nDAV:fork-ok, however I personally wouldn't do that.\n\n\n\n", "id": "lists-007-4515948"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t  he Label header with a DAV:labeled-version repor", "content": "   From: Clemm, Geoff [mailto:gclemm@rational.com]\n\n\n      From: Julian Reschke [mailto:julian.reschke@gmx.de]\n\n      Related question of the day: what's the response format for the\n      version-tree report with depth: 1 applied to a collection that\n      itself is not versioned but contains one version controlled member?\n\n      So for depth 1 one would get:\n      207 MULTISTATUS\n      <multistatus xmlns=\"DAV:\">\n<response>\n  <href>/collection/</href>\n  <status>HTTP/1.1 409 Conflict</status>\n  <responsedescription><error><supported-report/>\n    </error></responsedescription> </response>\n<response>\n  <href>/collection/a</href>\n  <propstat>\n    <prop>\n    ...now what?...\n    </prop>\n    <status>HTTP/1.1 200 OK</status>\n  </propstat>\n</response>\n      </multistatus>\n\n      RFC3253 seems to indicate that the <prop> element for the version\n      controlled member must return the requested report. The format for\n      the version-tree report defines a multistatus response body. So\n      would the <prop> element contain another <multistatus> sub-tree?\n\n   Yes.\n\nBTW, I'm not happy with that answer, but it is what RFC3253 says.\nIn retrospect, I wish we had given every REPORT response its own\nxml element such as is done with the DAV:merge-preview-report\n(possibly nesting the multistatus within that).\n\nFor any new reports we define, we definitely should do so.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4525679"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t he Label header with a DAV:labeled-version repor", "content": "Another question:\n\nWhen a Depth > 0 response body contains nested multistatus elements,\nrelative to which URI are nested href elements resolved?\n\na) relative to the request URI?\n\nb) relative to the URI of the resource described by containing response\nelement?\n\n\n\n", "id": "lists-007-4536604"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t he Label header with a DAV:labeled-version repor", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Sunday, July 28, 2002 4:03 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: Marshalling Depth > 0 responses for REPORTs, WAS: Replacing\n> t he Label header with a DAV:labeled-version report\n>\n>\n>\n> Summary of the issue:\n>\n> Julian would like to move the marshalling of Depth REPORT responses\n> from the DAV:prop node in a DAV:response to a new DAV:report-result\n> node in the DAV:response.\n>\n> Summary of my response:\n>\n> RFC3253 states that the marshalling is in the DAV:prop node, and\n> we should not change that unless there is some significant problem\n> with that marshalling.  I see no such problem, and therefore vote\n> to leave the spec as it is.\n\nWell, the most significant problem with this kind of marshalling is that\nit's completely non-obvious, and there's no example in the spec. So again my\nquestion to deltaV-implementors: who has REPORTs with depth != 0 currently\nimplemented and is compatible to RFC3253?\n\n> Detailed response below:\n>\n>    From: Julian Reschke [mailto:julian.reschke@gmx.de]\n>\n>    IMHO, marshalling something that isn't a resource property inside a\n>    multistatus/response/propstat/prop element clearly breaks RFC2518\n>    [1] and is very confusing.\n>\n> I disagree on both counts.\n>\n> RFC2518 says nothing about a REPORT method, so the response format of\n> a REPORT method cannot break RFC2518.  We have already concluded that\n> in earlier threads that each method effectively introduces a new DTD\n> for any XML elements in the response body.\n\nRFC3253 states that for depth != 0, the response must conform to whatever\nRFC2518 has to say about Multi-Status response bodies. Please don't say it\ndoesn't, because in that case the response format is completely undefined.\n\n> So that leaves the question of whether it is \"confusing\".  I agree\n> that it is desireable to have consistent DTD's for a standard XML\n> element, across all methods (preferably even across request and\n> response bodies).  But the only difference between a \"report result\"\n> and a \"live property value\" is that a report can take arguments that\n> modify the result (\"value\") of that report for a given resource.  In\n> particular, a report that has a default value for omitted arguments\n> acts exactly like a \"live property\".\n\nSee, and this exactly the thing that I think is wrong. There should be no\ndoubt whether something is a (live) property or not. To marshall something\nas property because it \"acts exactly like\" a property conflates separate\nthings.\n\n> So in the interest of keeping the DTD's of standard XML elements\n> consistent, I believe it is desireable to avoid having a standard\n> report result XML element be the same as a standard property value XML\n> element, to avoid having significantly different DTD's for the same\n> standard XML element.  This is what is indicated in RFC3253 by having\n> the report result appear in the same context (i.e. under a DAV:prop\n> element) as property values.\n\nWow! Do you say that by this approach RFC3253 forbids other specs to define\nproperties with names matching existing REPORT result elements? If this *is*\nthe intention, it should be made clear.\n\n>    If this behaviour really was intended by RFC3253 then it was\n>    extremely hard to discover because there's not a single example in\n>    the spec where this actually happens.\n>\n> I see no other possible interpretation for the statement in 3.6:\n>\n> \"The DAV:prop element of a DAV:response for a given resource MUST\n> contain the requested report for that resource.\"\n>\n> I'm happy to add an example in the next version of the spec, if\n> you feel this needs to be clarified.\n\nI absolutely feel so.\n\n>    My proposal would be to put the report result below the\n> response element,\n>    and to assign it a new name, such as:\n>\n>    <response>\n>      <href>...</href>\n>      <status>...</status>\n>      <report-result>...</report-result>\n>    <response>\n>\n> We could do so, but this violates 3253, which requires the report\n> to be placed in the DAV:prop element.  I agree that this is a\n> reasonable alternative marshalling, and if we didn't have 3253\n> saying otherwise, I'd be pretty happy to do it either way, but\n> I'd like to only change 3253 for serious problems.\n\nI think by now we can safely assume that we won't get any kind of\ninteroperability for these kinds of reports unless we clarify the format. I\nhaven't seen any server or client implementing the current RFC3253 format\nyet, so I think clarifying *plus* choosing a more logical format makes a lot\nof sense.\n\n> ...\n\n\n\n", "id": "lists-007-4545926"}, {"subject": "RE: realtive URI in DAV:response bodie", "content": "Neither 2518 nor 3253 specify this, but if I were to pick, I'd pick \"b\",\nsince that is the context that is most likely to consistently appear\nwith that reference, and therefore most likely to produce a consistent\nvalue.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Sunday, July 28, 2002 11:18 AM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: Marshalling Depth > 0 responses for REPORTs, WAS: Replacing\nt he Label header with a DAV:labeled-version report\n\n\nAnother question:\n\nWhen a Depth > 0 response body contains nested multistatus elements,\nrelative to which URI are nested href elements resolved?\n\na) relative to the request URI?\n\nb) relative to the URI of the resource described by containing response\nelement?\n\n\n\n", "id": "lists-007-4561356"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t  he Label header with a DAV:labeled-version repor", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > From: Clemm, Geoff\n\n   > RFC3253 states that the marshalling is in the DAV:prop node, and\n   > we should not change that unless there is some significant problem\n   > with that marshalling.\n\n   RFC3253 states that for depth != 0, the response must conform to\n   whatever RFC2518 has to say about Multi-Status response bodies.\n   ...\n   I think by now we can safely assume that we won't get any kind of\n   interoperability for these kinds of reports unless we clarify the\n   format.\n\nI agree that we need to clarify what is intended by 3253 for Depth>0\nREPORT response bodies.  In particular, RFC2518 says that a DAV:prop\nnode should only contain property values, while RFC3253 says that\nthe DAV:prop node in a Depth>0 REPORT response should contain a\nreport.\n\n   I haven't seen any server or client implementing the current\n   RFC3253 format yet, so I think clarifying *plus* choosing a more\n   logical format makes a lot of sense.\n\nI believe we have two alternatives being proposed:\n\n(a) Clarify that the DAV:prop node contains reports instead of\nproperties, when used in a DAV:response node in a top-level\nDAV:multi-status response body for a Depth>0 REPORT.\n\n(b) Change the marshalling defined by RFC3253 so that the report\nappears in a DAV:report node instead of the DAV:prop node.\n\nThe advantage of (a) is that it is consistent with what appears in\nRFC-3253.  This means that there is at least some chance that someone\nimplementing RFC-3253 would pick this alternative.\n\nThe advantage of (b) is that it is more consistent with RFC-2518,\nbut unfortunately is not consistent with RFC-3253 and is not something\nthat anyone would implement based on existing RFC documents (i.e. there\nis no way they could guess to use a DAV:report node).\n\nClearly, Julian prefers (b).  While I prefer (a), I'd be happy to\ngo with (b) if that is the preference of the working group.\n\nAnyone else want to chime in here?  In either case, I will add this\nissue to the ERRATA document.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4569578"}, {"subject": "RE: Derived object", "content": "   From: Marc Girod [mailto:girod@stybba.ntc.nokia.com]\n\n   As far as I understood, WebDAV/Delta V is only concerned with\n   *version?control* of static components.\n\n   Many web pages are however dynamically generated.\n   One could even argue that there is a fundamental granularity problem:\n   the grain suitable for maintenance (and for sharing) is finer than\n   this suitable for navigation.\n\n   Is there a provision to cope with this issue?\n\nThe only support in WebDAV/DeltaV for derived resources is the\nDAV:source property, and there recently has been a significant\namount of debate in the WebDAV mailing list on whether this\nproperty should be kept as is, removed, or changed.\n\nIf you are interested in derived resources, it would be good if\nyou could review this thread, and indicate whether this property\nwould be suitable for the use cases you are concerned with, and\nif not, how it could be changed to be suitable.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4580286"}, {"subject": "RE: RFC3253 XML extensibility, was: LABEL request only allows one  set, one add..", "content": "Non-standard elements can certainly be added by a server to\nany element (following RFC2518 extensibility rules), but \nour design principle for RFC3253 is to add new elements (e.g.\nin later drafts of RFC3253) at the request/response body level,\nrather than modifying any existing (non-top-level) elements.\n\nThis is just based on the request by some implementors to be\nable to implement certain arguments and values as \"booleans\"\nor \"fixed length enumerated types), rather than leaving room\nin the implementation for arbitrary future extensions at these\nlower levels.\n\nSo nothing deep going on here, just an effort to minimize\nrework of existing implementations when new protocol elements\nare introduced.\n\nCheers,\nGeoff  \n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Sunday, June 16, 2002 1:28 PM\nTo: Clemm, Geoff; 'DeltaV (E-mail)'\nSubject: RFC3253 XML extensibility, was: LABEL request only allows one\nset, one add...\n\n\nGeoff,\n\ndoes this basically mean that, for instance, the auto-version property is\n*not* meant to be extensible with new protocol elements?\n\nAs RFC3253 has no specific wording about what the DTD fragments mean, but\nthe DTD fragments *by definition* cannot be normative (for instance, because\nof namespace requirements), I was under the impression that RFC2518's\nextensibility rules apply to RFC3253 as well. Was I wrong?\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Sunday, June 16, 2002 3:54 PM\n> To: 'DeltaV (E-mail)'\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n>\n> Good point ... I should have been more specific.\n>\n> RFC-3253 uses \"ANY\" as the DTD for all method request\n> and response bodies, as we believed that was where\n> extensibility was most required, and so we wanted\n> to emphasize this fact in the protocol.\n>\n> Properties and nested request/response elements\n> within method request/response bodies are defined with\n> the standard DTD's.\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> Sent: Saturday, June 15, 2002 7:49 PM\n> To: 'Clemm, Geoff'; 'DeltaV (E-mail)'\n> Subject: RE: LABEL request only allows one set, one add...\n>\n>\n> RFC2518 already established that validating parsers cannot\n> strictly use the\n> DTD in the specification but must allow unknown elements in any element.\n>\n> If RFC3253 consistently followed what you suggest, then auto-version would\n> also take a value \"ANY\" rather than being defined properly.\n>\n>   <!ELEMENT auto-version (checkout-checkin | checkout-unlocked-checkin\n>      | checkout | locked-checkout)? >\n>\n> RFC3253 has many such \"restrictive\" DTDs.\n>\n> Lisa\n>\n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Saturday, June 15, 2002 3:28 PM\n> > To: 'DeltaV (E-mail)'\n> > Subject: RE: LABEL request only allows one set, one add...\n> >\n> >\n> >\n> > Yes, in RFC3253, \"at most one x, y, or z\" is (x | y | z).\n> > If you were allowed to have an x and a y and a z, it uses\n> > and \"and\", e.g.: \"at most one x, at most one y, and at most\n> > one z\".  So you can do an add, a set, or a remove, but not\n> > more than one in the same request.  The \"sequence of elements\"\n> > is just there for extensibility.\n> >\n> > RFC-3253 has no restrictive DTD statements such as:\n> >  <!ELEMENT label (add | set | remove)>\n> > since if this DTD was used by a validating parser,\n> > it would violate WebDAV semantics, which requires that\n> > unknown element types be ignored, and not cause a parse\n> > error.\n> >\n> > Cheers,\n> > Geoff\n> >\n> > -----Original Message-----\n> > From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> > Sent: Saturday, June 15, 2002 10:10 AM\n> > To: 'Clemm, Geoff'; 'DeltaV (E-mail)'\n> > Subject: RE: LABEL request only allows one set, one add...\n> >\n> >\n> > That's a great point, but it makes me realize I may be reading the\n> > definition wrong.  I had assumed it to be possible to add one\n> > label, remove\n> > a second and set a third, all in the same request. This\n> > assumption was based\n> > on the following language:\n> >\n> >      The request body MUST be a DAV:label element.\n> >\n> >       <!ELEMENT label ANY>\n> >       ANY value: A sequence of elements with at most one DAV:add,\n> >       DAV:set, or DAV:remove element.\n> >\n> > Perhaps this is supposed to mean that only one child element\n> > can be inside\n> > label, but \"a sequence\" does imply more than one.  If you\n> > mean to restrict\n> > it to one only, then the definition should be:\n> >\n> > <!ELEMENT label (add | set | remove)>\n> >\n> > Lisa\n> >\n> > > -----Original Message-----\n> > > From: ietf-dav-versioning-request@w3.org\n> > > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > > Sent: Friday, June 14, 2002 8:24 PM\n> > > To: DeltaV (E-mail)\n> > > Subject: RE: LABEL request only allows one set, one add...\n> > >\n> > >\n> > >\n> > > I wouldn't say it was an oversight, but rather a use\n> > > case that wasn't sufficiently common to warrant making\n> > > the protocol more complicated to support it.\n> > > In particular, you would have to define the semantics\n> > > of what would happen if one part of the request would fail\n> > > and the other would succeed, and how to marshall that\n> > > error information.\n> > >\n> > > Cheers,\n> > > Geoff\n> > >\n> > > -----Original Message-----\n> > > From: Lisa Dusseault [mailto:ldusseault@xythos.com]\n> > > Sent: Friday, June 14, 2002 9:31 PM\n> > > To: DeltaV (E-mail)\n> > > Subject: LABEL request only allows one set, one add...\n> > >\n> > >\n> > >\n> > >\n> > > Is it an oversight that the LABEL request only allows one\n> > > set, one add, or\n> > > one remove at a time (or one of each, but not two of any?)\n> > >\n> > > For example, say I wanted to add <label-name>foo</label-name> and\n> > > <label-name>bar</label-name> to a version in one request.\n> > > The definition of\n> > > the LABEL request body is:\n> > >\n> > >   <!ELEMENT label ANY>\n> > >   ANY value: A sequence of elements with at most one\n> > >   DAV:add, DAV:set, or DAV:remove element.\n> > >\n> > >   <!ELEMENT add (label-name)>\n> > >   <!ELEMENT set (label-name)>\n> > >   <!ELEMENT remove (label-name)>\n> > >\n> > >   <!ELEMENT label-name (#PCDATA)> PCDATA value: string\n> > >\n> > > Since <add> can only contain one label-name, only one label\n> > > can be added per\n> > > each request.  I would have to issue two LABEL requests to\n> > > add both foo and\n> > > bar labels.\n> > >\n> > > Lisa\n> > >\n> >\n>\n>\n>\n\n\n\n", "id": "lists-007-4588592"}, {"subject": "expand-property report, exapnding version-controlled-binding-set  ", "content": "Hi,\n\nThe rfc3253 says:\n\n   Many property values are defined as a DAV:href, or a set of DAV:href\n   elements.  The DAV:expand-property report provides a mechanism for\n   retrieving in one request the properties from the resources\n   identified by those DAV:href elements.  ...\n\nSince DAV:version-controlled-binding-set is list of (binding-name, version-history)\nelements and not list of hrefs it seems to me that it is not possible to\nfurther expand this property.  For example the next request tries to expand\nversion-controlled-binding-set:\n\n     REPORT /foo.html HTTP/1.1\n     Host: www.webdav.org\n     Content-Type: text/xml; charset=\"utf-8\"\n     Content-Length: xxxx\n\n     <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n     <D:expand-property xmlns:D=\"DAV:\">\n       <D:property name=\"version-controlled-binding-set\">\n         <D:property name=\"version-history\">\n           <D:property name=\"creator-displayname\"/>\n         </D:property>\n       </D:property>\n     </D:expand-property>\n\nBut, since members of version-controlled-binding-set are not href's (and they\nare not resources) we can not further expand this property.\n\nIs this correct ?\n\nRegards\nSasha\n\n\n\n", "id": "lists-007-4606790"}, {"subject": "DeltaV methods on locked non-VCR: which response code", "content": "Hi,\n\nassume\n1) a non-collection *non-VCR* resource at /foo.xml which is *locked*\n2) an ordinary collection resource at /bar which is *locked*.\n\nWe are wondering what the response status code should be in these particular\ncases (403, 409, 423, ???):\n\nCHECKOUT /foo.xml\nCHECKIN /foo.xml\nLABEL /foo.xml\nREPORT /foo.xml\nUPDATE /foo.xml\nVERSION-CONTROL /foo.xml\n\nMKWORKSPACE /bar\n\nRegards,\nPeter\n\n\n\n", "id": "lists-007-4615664"}, {"subject": "RE: expand-property report, exapnding version-controlled-binding-set  ", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Zivkov, Sasa\n> Sent: Wednesday, July 31, 2002 5:16 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: expand-property report, exapnding\n> version-controlled-binding-set ?\n>\n>\n>\n> Hi,\n>\n> The rfc3253 says:\n>\n>    Many property values are defined as a DAV:href, or a set of DAV:href\n>    elements.  The DAV:expand-property report provides a mechanism for\n>    retrieving in one request the properties from the resources\n>    identified by those DAV:href elements.  ...\n>\n> Since DAV:version-controlled-binding-set is list of\n> (binding-name, version-history)\n> elements and not list of hrefs it seems to me that it is not possible to\n> further expand this property.  For example the next request tries\n> to expand\n> version-controlled-binding-set:\n>\n>      REPORT /foo.html HTTP/1.1\n>      Host: www.webdav.org\n>      Content-Type: text/xml; charset=\"utf-8\"\n>      Content-Length: xxxx\n>\n>      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>      <D:expand-property xmlns:D=\"DAV:\">\n>        <D:property name=\"version-controlled-binding-set\">\n>          <D:property name=\"version-history\">\n>            <D:property name=\"creator-displayname\"/>\n>          </D:property>\n>        </D:property>\n>      </D:expand-property>\n>\n> But, since members of version-controlled-binding-set are not\n> href's (and they\n> are not resources) we can not further expand this property.\n>\n> Is this correct ?\n\nThe embedded version-history element has the href-format, so you should be\nable to do:\n\n     <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n     <D:expand-property xmlns:D=\"DAV:\">\n       <D:property name=\"version-controlled-binding-set\">\n         <D:property name=\"creator-displayname\"/>\n       </D:property>\n     </D:expand-property>\n\n(if what you're after is the DAV:creator-displayname of the version\nhistory).\n\n\n\n", "id": "lists-007-4624870"}, {"subject": "RE: expand-property report, exapnding version-controlled-binding- set  ", "content": "> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Zivkov, Sasa\n> > Sent: Wednesday, July 31, 2002 5:16 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: expand-property report, exapnding\n> > version-controlled-binding-set ?\n> >\n> >\n> >\n> > Hi,\n> >\n> > The rfc3253 says:\n> >\n> >    Many property values are defined as a DAV:href, or a set of DAV:href\n> >    elements.  The DAV:expand-property report provides a mechanism for\n> >    retrieving in one request the properties from the resources\n> >    identified by those DAV:href elements.  ...\n> >\n> > Since DAV:version-controlled-binding-set is list of\n> > (binding-name, version-history)\n> > elements and not list of hrefs it seems to me that it is not possible to\n> > further expand this property.  For example the next request tries\n> > to expand\n> > version-controlled-binding-set:\n> >\n> >      REPORT /foo.html HTTP/1.1\n> >      Host: www.webdav.org\n> >      Content-Type: text/xml; charset=\"utf-8\"\n> >      Content-Length: xxxx\n> >\n> >      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> >      <D:expand-property xmlns:D=\"DAV:\">\n> >        <D:property name=\"version-controlled-binding-set\">\n> >          <D:property name=\"version-history\">\n> >            <D:property name=\"creator-displayname\"/>\n> >          </D:property>\n> >        </D:property>\n> >      </D:expand-property>\n> >\n> > But, since members of version-controlled-binding-set are not\n> > href's (and they\n> > are not resources) we can not further expand this property.\n> >\n> > Is this correct ?\n> \n> The embedded version-history element has the href-format, so you should be\n> able to do:\n> \n>      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>      <D:expand-property xmlns:D=\"DAV:\">\n>        <D:property name=\"version-controlled-binding-set\">\n>          <D:property name=\"creator-displayname\"/>\n>        </D:property>\n>      </D:expand-property>\n> \n> (if what you're after is the DAV:creator-displayname of the version\n> history).\n\nversion-controlled-binding-set members are version-controlled-binding's\nand version-controlled-binding is even not a resource so we can not\nask it for its properties (creator-displayname is this case).\n\nWhich part of the rfc3253 says that we should use version-history part\nof a version-controlled-binding element for property expansion ?\n\nWhat if version-controlled-binding element (or any other) would have\ntwo href members, which one should be used for expand-property report ?\n\nRegards\nSasa\n\n\n\n", "id": "lists-007-4635820"}, {"subject": "RE: expand-property report, exapnding version-controlled-binding- set  ", "content": "> > > Hi,\n> > >\n> > > The rfc3253 says:\n> > >\n> > >    Many property values are defined as a DAV:href, or a set\n> of DAV:href\n> > >    elements.  The DAV:expand-property report provides a mechanism for\n> > >    retrieving in one request the properties from the resources\n> > >    identified by those DAV:href elements.  ...\n> > >\n> > > Since DAV:version-controlled-binding-set is list of\n> > > (binding-name, version-history)\n> > > elements and not list of hrefs it seems to me that it is not\n> possible to\n> > > further expand this property.  For example the next request tries\n> > > to expand\n> > > version-controlled-binding-set:\n> > >\n> > >      REPORT /foo.html HTTP/1.1\n> > >      Host: www.webdav.org\n> > >      Content-Type: text/xml; charset=\"utf-8\"\n> > >      Content-Length: xxxx\n> > >\n> > >      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> > >      <D:expand-property xmlns:D=\"DAV:\">\n> > >        <D:property name=\"version-controlled-binding-set\">\n> > >          <D:property name=\"version-history\">\n> > >            <D:property name=\"creator-displayname\"/>\n> > >          </D:property>\n> > >        </D:property>\n> > >      </D:expand-property>\n> > >\n> > > But, since members of version-controlled-binding-set are not\n> > > href's (and they\n> > > are not resources) we can not further expand this property.\n> > >\n> > > Is this correct ?\n> >\n> > The embedded version-history element has the href-format, so\n> you should be\n> > able to do:\n> >\n> >      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> >      <D:expand-property xmlns:D=\"DAV:\">\n> >        <D:property name=\"version-controlled-binding-set\">\n> >          <D:property name=\"creator-displayname\"/>\n> >        </D:property>\n> >      </D:expand-property>\n> >\n> > (if what you're after is the DAV:creator-displayname of the version\n> > history).\n>\n> version-controlled-binding-set members are version-controlled-binding's\n> and version-controlled-binding is even not a resource so we can not\n> ask it for its properties (creator-displayname is this case).\n\nAs you said, version-controlled-bindings consists of binding-name\nversion-history. version-history has href format, so you *can* expand that\nif you want to.\n\n> Which part of the rfc3253 says that we should use version-history part\n> of a version-controlled-binding element for property expansion ?\n\nNone. It depends on whose property you want. You can't get the properties of\nthe binding name (it's not a resource), but you *can* get the properties of\nthe version history.\n\n> What if version-controlled-binding element (or any other) would have\n> two href members, which one should be used for expand-property report ?\n\nBoth.\n\n\n\n", "id": "lists-007-4647775"}, {"subject": "RE: expand-property report, exapnding version-controlled-binding-  set  ", "content": "> -----Original Message-----\n> From: Reschke, Julian \n> Sent: Mittwoch, 31. Juli 2002 18:25\n> To: Zivkov, Sasa; ietf-dav-versioning@w3.org\n> Subject: RE: expand-property report, exapnding\n> version-controlled-binding- set ?\n> \n> \n> > > > Hi,\n> > > >\n> > > > The rfc3253 says:\n> > > >\n> > > >    Many property values are defined as a DAV:href, or a set\n> > of DAV:href\n> > > >    elements.  The DAV:expand-property report provides a mechanism for\n> > > >    retrieving in one request the properties from the resources\n> > > >    identified by those DAV:href elements.  ...\n> > > >\n> > > > Since DAV:version-controlled-binding-set is list of\n> > > > (binding-name, version-history)\n> > > > elements and not list of hrefs it seems to me that it is not\n> > possible to\n> > > > further expand this property.  For example the next request tries\n> > > > to expand\n> > > > version-controlled-binding-set:\n> > > >\n> > > >      REPORT /foo.html HTTP/1.1\n> > > >      Host: www.webdav.org\n> > > >      Content-Type: text/xml; charset=\"utf-8\"\n> > > >      Content-Length: xxxx\n> > > >\n> > > >      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> > > >      <D:expand-property xmlns:D=\"DAV:\">\n> > > >        <D:property name=\"version-controlled-binding-set\">\n> > > >          <D:property name=\"version-history\">\n> > > >            <D:property name=\"creator-displayname\"/>\n> > > >          </D:property>\n> > > >        </D:property>\n> > > >      </D:expand-property>\n> > > >\n> > > > But, since members of version-controlled-binding-set are not\n> > > > href's (and they\n> > > > are not resources) we can not further expand this property.\n> > > >\n> > > > Is this correct ?\n> > >\n> > > The embedded version-history element has the href-format, so\n> > you should be\n> > > able to do:\n> > >\n> > >      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> > >      <D:expand-property xmlns:D=\"DAV:\">\n> > >        <D:property name=\"version-controlled-binding-set\">\n> > >          <D:property name=\"creator-displayname\"/>\n> > >        </D:property>\n> > >      </D:expand-property>\n> > >\n> > > (if what you're after is the DAV:creator-displayname of the version\n> > > history).\n> >\n> > version-controlled-binding-set members are version-controlled-binding's\n> > and version-controlled-binding is even not a resource so we can not\n> > ask it for its properties (creator-displayname is this case).\n> \n> As you said, version-controlled-bindings consists of binding-name\n> version-history. version-history has href format, so you *can* expand that\n> if you want to.\n\nAn example:\n<version-controlled-binding-set>\n\n   <version-controlled-binding>\n      <binding-name>abc</binding-name>\n      <version-history><href>/vh11</href></version-history>\n   </version-controlled-binding>\n\n   <version-controlled-binding>\n      <binding-name>def</binding-name>\n      <version-history><href>/vh12</href></version-history>\n   </version-controlled-binding>\n   ...\n</version-controlled-binding-set>\n\nSo the version-history is at the second level after version-controlled-binding-set.\nAnd the members of version-controlled-binding-set are not DAV:href's but elements\nthat contain href's.\nAgain from rfc3253:\n   Many property values are defined as a DAV:href, or a set of DAV:href\n   elements.  The DAV:expand-property report provides a mechanism for\n   retrieving in one request the properties from the resources\n   identified by those DAV:href elements.  ...\n\n> \n> > Which part of the rfc3253 says that we should use version-history part\n> > of a version-controlled-binding element for property expansion ?\n> \n> None. It depends on whose property you want. You can't get the properties of\n> the binding name (it's not a resource), but you *can* get the properties of\n> the version history.\n> \n> > What if version-controlled-binding element (or any other) would have\n> > two href members, which one should be used for expand-property report ?\n> \n> Both.\n\n\n\n", "id": "lists-007-4659228"}, {"subject": "RE: expand-property report, exapnding version-controlled-binding-  set  ", "content": "> > From: Reschke, Julian\n> > Sent: Mittwoch, 31. Juli 2002 18:25\n> > To: Zivkov, Sasa; ietf-dav-versioning@w3.org\n> > Subject: RE: expand-property report, exapnding\n> > version-controlled-binding- set ?\n> >\n> >\n> > > > > Hi,\n> > > > >\n> > > > > The rfc3253 says:\n> > > > >\n> > > > >    Many property values are defined as a DAV:href, or a set\n> > > of DAV:href\n> > > > >    elements.  The DAV:expand-property report provides a\n> mechanism for\n> > > > >    retrieving in one request the properties from the resources\n> > > > >    identified by those DAV:href elements.  ...\n> > > > >\n> > > > > Since DAV:version-controlled-binding-set is list of\n> > > > > (binding-name, version-history)\n> > > > > elements and not list of hrefs it seems to me that it is not\n> > > possible to\n> > > > > further expand this property.  For example the next request tries\n> > > > > to expand\n> > > > > version-controlled-binding-set:\n> > > > >\n> > > > >      REPORT /foo.html HTTP/1.1\n> > > > >      Host: www.webdav.org\n> > > > >      Content-Type: text/xml; charset=\"utf-8\"\n> > > > >      Content-Length: xxxx\n> > > > >\n> > > > >      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> > > > >      <D:expand-property xmlns:D=\"DAV:\">\n> > > > >        <D:property name=\"version-controlled-binding-set\">\n> > > > >          <D:property name=\"version-history\">\n> > > > >            <D:property name=\"creator-displayname\"/>\n> > > > >          </D:property>\n> > > > >        </D:property>\n> > > > >      </D:expand-property>\n> > > > >\n> > > > > But, since members of version-controlled-binding-set are not\n> > > > > href's (and they\n> > > > > are not resources) we can not further expand this property.\n> > > > >\n> > > > > Is this correct ?\n> > > >\n> > > > The embedded version-history element has the href-format, so\n> > > you should be\n> > > > able to do:\n> > > >\n> > > >      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> > > >      <D:expand-property xmlns:D=\"DAV:\">\n> > > >        <D:property name=\"version-controlled-binding-set\">\n> > > >          <D:property name=\"creator-displayname\"/>\n> > > >        </D:property>\n> > > >      </D:expand-property>\n> > > >\n> > > > (if what you're after is the DAV:creator-displayname of the version\n> > > > history).\n> > >\n> > > version-controlled-binding-set members are\n> version-controlled-binding's\n> > > and version-controlled-binding is even not a resource so we can not\n> > > ask it for its properties (creator-displayname is this case).\n> >\n> > As you said, version-controlled-bindings consists of binding-name\n> > version-history. version-history has href format, so you *can*\n> expand that\n> > if you want to.\n>\n> An example:\n> <version-controlled-binding-set>\n>\n>    <version-controlled-binding>\n>       <binding-name>abc</binding-name>\n>       <version-history><href>/vh11</href></version-history>\n>    </version-controlled-binding>\n>\n>    <version-controlled-binding>\n>       <binding-name>def</binding-name>\n>       <version-history><href>/vh12</href></version-history>\n>    </version-controlled-binding>\n>    ...\n> </version-controlled-binding-set>\n>\n> So the version-history is at the second level after\n> version-controlled-binding-set.\n> And the members of version-controlled-binding-set are not\n> DAV:href's but elements\n> that contain href's.\n> Again from rfc3253:\n>    Many property values are defined as a DAV:href, or a set of DAV:href\n>    elements.  The DAV:expand-property report provides a mechanism for\n>    retrieving in one request the properties from the resources\n>    identified by those DAV:href elements.  ...\n\nAnd it goes on saying:\n\n\"... If there are DAV:property elements nested within a DAV:property\nelement, then every DAV:href in the value of the corresponding property is\nreplaced by a DAV:response element whose DAV:prop elements report the values\nof the properties identified by the nested DAV:property elements. The nested\nDAV:property elements can in turn contain DAV:property elements, so that\nmultiple levels of DAV:href expansion can be requested.\"\n\nWhen I implemented the expand-property report I asked this question here\n([1]), and the answer was: all href elements must be expanded, independant\nof the nesting, including dead properties.\n\n[1]\n<http://lists.w3.org/Archives/Public/ietf-dav-versioning/2002JanMar/thread.h\ntml#187>\n\n\n\n", "id": "lists-007-4672220"}, {"subject": "RE: expand-property report, exapnding version-controlled-binding- set  ", "content": "Just wanted to confirm that I agree with Julian on this thread, i.e.\nyou can use the DAV:expand-property report to expand DAV:href\nelements that are nested arbitarily deeply in the property value,\nin particular, to expand the version history DAV:href elements\nin the DAV:version-controlled-binding-set.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Wednesday, July 31, 2002 1:01 PM\nTo: Zivkov, Sasa; ietf-dav-versioning@w3.org\nSubject: RE: expand-property report, exapnding\nversion-controlled-binding- set ?\n\n\n\n> > From: Reschke, Julian\n> > Sent: Mittwoch, 31. Juli 2002 18:25\n> > To: Zivkov, Sasa; ietf-dav-versioning@w3.org\n> > Subject: RE: expand-property report, exapnding\n> > version-controlled-binding- set ?\n> >\n> >\n> > > > > Hi,\n> > > > >\n> > > > > The rfc3253 says:\n> > > > >\n> > > > >    Many property values are defined as a DAV:href, or a set\n> > > of DAV:href\n> > > > >    elements.  The DAV:expand-property report provides a\n> mechanism for\n> > > > >    retrieving in one request the properties from the resources\n> > > > >    identified by those DAV:href elements.  ...\n> > > > >\n> > > > > Since DAV:version-controlled-binding-set is list of\n> > > > > (binding-name, version-history)\n> > > > > elements and not list of hrefs it seems to me that it is not\n> > > possible to\n> > > > > further expand this property.  For example the next request tries\n> > > > > to expand\n> > > > > version-controlled-binding-set:\n> > > > >\n> > > > >      REPORT /foo.html HTTP/1.1\n> > > > >      Host: www.webdav.org\n> > > > >      Content-Type: text/xml; charset=\"utf-8\"\n> > > > >      Content-Length: xxxx\n> > > > >\n> > > > >      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> > > > >      <D:expand-property xmlns:D=\"DAV:\">\n> > > > >        <D:property name=\"version-controlled-binding-set\">\n> > > > >          <D:property name=\"version-history\">\n> > > > >            <D:property name=\"creator-displayname\"/>\n> > > > >          </D:property>\n> > > > >        </D:property>\n> > > > >      </D:expand-property>\n> > > > >\n> > > > > But, since members of version-controlled-binding-set are not\n> > > > > href's (and they\n> > > > > are not resources) we can not further expand this property.\n> > > > >\n> > > > > Is this correct ?\n> > > >\n> > > > The embedded version-history element has the href-format, so\n> > > you should be\n> > > > able to do:\n> > > >\n> > > >      <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n> > > >      <D:expand-property xmlns:D=\"DAV:\">\n> > > >        <D:property name=\"version-controlled-binding-set\">\n> > > >          <D:property name=\"creator-displayname\"/>\n> > > >        </D:property>\n> > > >      </D:expand-property>\n> > > >\n> > > > (if what you're after is the DAV:creator-displayname of the version\n> > > > history).\n> > >\n> > > version-controlled-binding-set members are\n> version-controlled-binding's\n> > > and version-controlled-binding is even not a resource so we can not\n> > > ask it for its properties (creator-displayname is this case).\n> >\n> > As you said, version-controlled-bindings consists of binding-name\n> > version-history. version-history has href format, so you *can*\n> expand that\n> > if you want to.\n>\n> An example:\n> <version-controlled-binding-set>\n>\n>    <version-controlled-binding>\n>       <binding-name>abc</binding-name>\n>       <version-history><href>/vh11</href></version-history>\n>    </version-controlled-binding>\n>\n>    <version-controlled-binding>\n>       <binding-name>def</binding-name>\n>       <version-history><href>/vh12</href></version-history>\n>    </version-controlled-binding>\n>    ...\n> </version-controlled-binding-set>\n>\n> So the version-history is at the second level after\n> version-controlled-binding-set.\n> And the members of version-controlled-binding-set are not\n> DAV:href's but elements\n> that contain href's.\n> Again from rfc3253:\n>    Many property values are defined as a DAV:href, or a set of DAV:href\n>    elements.  The DAV:expand-property report provides a mechanism for\n>    retrieving in one request the properties from the resources\n>    identified by those DAV:href elements.  ...\n\nAnd it goes on saying:\n\n\"... If there are DAV:property elements nested within a DAV:property\nelement, then every DAV:href in the value of the corresponding property is\nreplaced by a DAV:response element whose DAV:prop elements report the values\nof the properties identified by the nested DAV:property elements. The nested\nDAV:property elements can in turn contain DAV:property elements, so that\nmultiple levels of DAV:href expansion can be requested.\"\n\nWhen I implemented the expand-property report I asked this question here\n([1]), and the answer was: all href elements must be expanded, independant\nof the nesting, including dead properties.\n\n[1]\n<http://lists.w3.org/Archives/Public/ietf-dav-versioning/2002JanMar/thread.h\ntml#187>\n\n\n\n", "id": "lists-007-4686010"}, {"subject": "RE: DeltaV methods on locked non-VCR: which response code", "content": "   From: Nevermann, Dr., Peter [mailto:Peter.Nevermann@softwareag.com]\n\n   assume\n   1) a non-collection *non-VCR* resource at /foo.xml which is *locked*\n   2) an ordinary collection resource at /bar which is *locked*.\n\n   We are wondering what the response status code should be in these\nparticular\n   cases (403, 409, 423, ???):\n\n   CHECKOUT /foo.xml\n\n405\n\n   CHECKIN /foo.xml\n\n405\n\n   LABEL /foo.xml\n\n405\n\n   REPORT /foo.xml\n\nDepends on the report request.  Since a report is a read-only\noperation, it doesn't matter that it is write-locked.\n\n   UPDATE /foo.xml\n\n405\n\n   VERSION-CONTROL /foo.xml\n\n423\n\n   MKWORKSPACE /bar\n\n403, with DAV:resource-must-be-null in the DAV:error node.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4700466"}, {"subject": "RE: DeltaV methods on locked non-VCR: which response code", "content": "Thanks, Geoff!\n\nSome of us were assuming that checking for the lock (\"as being WebDAV\") had\npriority over checking of DeltaV precondition violations ... in which case\n423 would be the response in most of the cases below. But, as we can deduce\nfrom your response, that is not the case.\n\nAnother issue, which we find difficult sometimes, is to decide whether to\nuse 403 or 409 as status code on DeltaV precondition violations.\n\n\nExample 1: assume existing collection at /ws/bar then \n\nMKWORKSPACE /ws/bar\n\nreturns 403 with DAV:resource-must-be-null ... as you stated below.\nAccording to section 1.6 of RFC 3253 this means that the request should not\nbe repeated because it will always fail. But it could be 409 because: isn't\nthe user able to resolve the conflict by deleting /ws/bar and then resubmit\nthe request?\n\n\nExample 2: assume checked-in VCR at /foo.xml and \n\nCHECKOUT /foo.xml (without DAV:fork-ok)\n\n(a) violating precondition\nDAV:checkout-of-version-with-descendant-is-discouraged; then I would return\nstatus code 409 since the user can resolve the conflict by passing the\nDAV:fork-ok element.\n\n(b) violating precondition\nDAV:checkout-of-version-with-descendant-is-forbidden; then I would return\nstatus code 403 ... hm, or should it be 409 since the conflict could be\nresolved by proppatching the DAV:checkout-fork property???\n\nRegards,\nPeter\n\n> -----Original Message-----\n> From: Clemm, Geoff [mailto:gclemm@rational.com]\n> Sent: Wednesday, July 31, 2002 23:01\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: RE: DeltaV methods on locked non-VCR: which response code?\n> \n> \n> \n>    From: Nevermann, Dr., Peter [mailto:Peter.Nevermann@softwareag.com]\n> \n>    assume\n>    1) a non-collection *non-VCR* resource at /foo.xml which \n> is *locked*\n>    2) an ordinary collection resource at /bar which is *locked*.\n> \n>    We are wondering what the response status code should be in these\n> particular\n>    cases (403, 409, 423, ???):\n> \n>    CHECKOUT /foo.xml\n> \n> 405\n> \n>    CHECKIN /foo.xml\n> \n> 405\n> \n>    LABEL /foo.xml\n> \n> 405\n> \n>    REPORT /foo.xml\n> \n> Depends on the report request.  Since a report is a read-only\n> operation, it doesn't matter that it is write-locked.\n> \n>    UPDATE /foo.xml\n> \n> 405\n> \n>    VERSION-CONTROL /foo.xml\n> \n> 423\n> \n>    MKWORKSPACE /bar\n> \n> 403, with DAV:resource-must-be-null in the DAV:error node.\n> \n> Cheers,\n> Geoff\n> \n\n\n\n", "id": "lists-007-4709347"}, {"subject": "RE: DeltaV methods on locked non-VCR: which response code", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Nevermann, Dr.,\n> Peter\n> Sent: Thursday, August 01, 2002 10:21 AM\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: RE: DeltaV methods on locked non-VCR: which response code?\n>\n>\n>\n> Thanks, Geoff!\n>\n> Some of us were assuming that checking for the lock (\"as being\n> WebDAV\") had\n> priority over checking of DeltaV precondition violations ... in which case\n> 423 would be the response in most of the cases below. But, as we\n> can deduce\n> from your response, that is not the case.\n\nI'd say that this is higly implementation dependant, and I don't think that\nRFC3253 mandates a specific oder in checking these conditions.\n\n> Another issue, which we find difficult sometimes, is to decide whether to\n> use 403 or 409 as status code on DeltaV precondition violations.\n>\n>\n> Example 1: assume existing collection at /ws/bar then\n>\n> MKWORKSPACE /ws/bar\n>\n> returns 403 with DAV:resource-must-be-null ... as you stated below.\n> According to section 1.6 of RFC 3253 this means that the request\n> should not\n> be repeated because it will always fail. But it could be 409\n> because: isn't\n> the user able to resolve the conflict by deleting /ws/bar and\n> then resubmit\n> the request?\n\nHTTP says about 409:\n\n\"The request could not be completed due to a conflict with the current state\nof the resource.\"\n\nSo I think I agree with you.\n\n> Example 2: assume checked-in VCR at /foo.xml and\n>\n> CHECKOUT /foo.xml (without DAV:fork-ok)\n>\n> (a) violating precondition\n> DAV:checkout-of-version-with-descendant-is-discouraged; then I\n> would return\n> status code 409 since the user can resolve the conflict by passing the\n> DAV:fork-ok element.\n\nBut that would be a different request, right? So you didn't \"fix\" the state\nof the resource, but the nature of your request...\n\n> (b) violating precondition\n> DAV:checkout-of-version-with-descendant-is-forbidden; then I would return\n> status code 403 ... hm, or should it be 409 since the conflict could be\n> resolved by proppatching the DAV:checkout-fork property???\n\nI think so.\n\n\n\n", "id": "lists-007-4721131"}, {"subject": "RE: DeltaV methods on locked non-VCR: which response code", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > From: Nevermann, Dr.,Peter\n   >\n   > Some of us were assuming that checking for the lock (\"as being\n   > WebDAV\") had priority over checking of DeltaV precondition\n   > violations ... in which case 423 would be the response in most of\n   > the cases below. But, as we can deduce from your response, that\n   > is not the case.\n\n   I'd say that this is higly implementation dependant, and I don't\n   think that RFC3253 mandates a specific oder in checking these\n   conditions.\n\nYes, there is no order defined in any of the HTTP or WebDAV RFCs.\nSo if there are multiple reasons for failure, it just depends\non which check is done first by a given implementation.\n\n   > Another issue, which we find difficult sometimes, is to decide\n   > whether to use 403 or 409 as status code on DeltaV precondition\n   > violations.\n\nThere is no rigorous way to decide which of these to return.  The\nheuristic I use is that if there is some operation I can do to the\ncurrent resource associated with that URL that would (or might) make\nthat request succeed, then I'd return a 409, while if I'd have to\nassociate a different resource (or no resource) with the URL to get\nthe request to work, I'd return a 403.\n\n   > Example 1: assume existing collection at /ws/bar then\n   >\n   > MKWORKSPACE /ws/bar\n   >\n   > returns 403 with DAV:resource-must-be-null ... as you stated\n   > below.  According to section 1.6 of RFC 3253 this means that the\n   > request should not be repeated because it will always fail. But\n   > it could be 409 because: isn't the user able to resolve the\n   > conflict by deleting /ws/bar and then resubmit the request?\n\n   HTTP says about 409:\n\n   \"The request could not be completed due to a conflict with the\n   current state of the resource.\"\n\n   So I think I agree with you.\n\nI wouldn't use a 409 here because it is not a conflict with the\n\"current\" state of the resource, because I don't consider \"not\nexisting\" to be a state of the resource.  This is related to my position\nthat the \"identity\" of a resource is not determined by its URI, since\nthat would not allow you to say \"two URI are being mapped to the same\nresource\" (something that RFC2616 explicitly says is allowed).\n\nBut this is definitely a judgement call, so I think it reasonable\nfor an implementation to return either 403 or 409 in this case.\n\n   > Example 2: assume checked-in VCR at /foo.xml and\n   >\n   > CHECKOUT /foo.xml (without DAV:fork-ok)\n   >\n   > (a) violating precondition\n   > DAV:checkout-of-version-with-descendant-is-discouraged; then I\n   > would return status code 409 since the user can resolve the\n   > conflict by passing the DAV:fork-ok element.\n\n   But that would be a different request, right? So you didn't \"fix\"\n   the state of the resource, but the nature of your request...\n\nI agree.\n\n   > (b) violating precondition\n   > DAV:checkout-of-version-with-descendant-is-forbidden; then I\n   > would return status code 403 ... hm, or should it be 409 since\n   > the conflict could be resolved by proppatching the\n   > DAV:checkout-fork property???\n\n   I think so.\n\nI agree.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4732322"}, {"subject": "RE: DeltaV methods on locked non-VCR: which response code", "content": "Hello,\n\nIn case of 405 would you expect the response body to contain a packed\n(DAV:must-be-checked-out, DAV:must-be-checked-in, etc.) or an empty response\nbody?\n\nBest regards\n\nJuergen\n\n\n\n\n\n\n\n -----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com] \nSent:Wednesday, July 31, 2002 23.01 PM\nTo:'ietf-dav-versioning@w3.org'\nSubject:RE: DeltaV methods on locked non-VCR: which response code?\n\n\n   From: Nevermann, Dr., Peter [mailto:Peter.Nevermann@softwareag.com]\n\n   assume\n   1) a non-collection *non-VCR* resource at /foo.xml which is *locked*\n   2) an ordinary collection resource at /bar which is *locked*.\n\n   We are wondering what the response status code should be in these\nparticular\n   cases (403, 409, 423, ???):\n\n   CHECKOUT /foo.xml\n\n405\n\n   CHECKIN /foo.xml\n\n405\n\n   LABEL /foo.xml\n\n405\n\n   REPORT /foo.xml\n\nDepends on the report request.  Since a report is a read-only\noperation, it doesn't matter that it is write-locked.\n\n   UPDATE /foo.xml\n\n405\n\n   VERSION-CONTROL /foo.xml\n\n423\n\n   MKWORKSPACE /bar\n\n403, with DAV:resource-must-be-null in the DAV:error node.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4743416"}, {"subject": "RE: DeltaV methods on locked non-VCR: which response code", "content": "For RFC-3253, the intent was to use 405 as a generic response\nwhen there wasn't anything more specific you could (or wanted)\nto say, and use 403/409 when you wanted to give details.\n\nSo an RFC-3253 client would only expect a DAV:error node in a\n403 or 409 response.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Pill, Juergen [mailto:Juergen.Pill@softwareag.com]\nSent: Thursday, August 01, 2002 11:54 AM\nTo: 'Clemm, Geoff'; 'ietf-dav-versioning@w3.org'; Nevermann, Dr., Peter\nSubject: RE: DeltaV methods on locked non-VCR: which response code?\n\n\nHello,\n\nIn case of 405 would you expect the response body to contain a packed\n(DAV:must-be-checked-out, DAV:must-be-checked-in, etc.) or an empty response\nbody?\n\nBest regards\n\nJuergen\n\n\n\n\n\n\n\n -----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com] \nSent:Wednesday, July 31, 2002 23.01 PM\nTo:'ietf-dav-versioning@w3.org'\nSubject:RE: DeltaV methods on locked non-VCR: which response code?\n\n\n   From: Nevermann, Dr., Peter [mailto:Peter.Nevermann@softwareag.com]\n\n   assume\n   1) a non-collection *non-VCR* resource at /foo.xml which is *locked*\n   2) an ordinary collection resource at /bar which is *locked*.\n\n   We are wondering what the response status code should be in these\nparticular\n   cases (403, 409, 423, ???):\n\n   CHECKOUT /foo.xml\n\n405\n\n   CHECKIN /foo.xml\n\n405\n\n   LABEL /foo.xml\n\n405\n\n   REPORT /foo.xml\n\nDepends on the report request.  Since a report is a read-only\noperation, it doesn't matter that it is write-locked.\n\n   UPDATE /foo.xml\n\n405\n\n   VERSION-CONTROL /foo.xml\n\n423\n\n   MKWORKSPACE /bar\n\n403, with DAV:resource-must-be-null in the DAV:error node.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4754247"}, {"subject": "RE: DeltaV methods on locked non-VCR: which response code", "content": "> Some of us were assuming that checking for the lock (\"as being\nWebDAV\")\n> had\n> priority over checking of DeltaV precondition violations ... in which\ncase\n> 423 would be the response in most of the cases below. But, as we can\n> deduce\n> from your response, that is not the case.\n\nI would have expected that in some cases, many things can be wrong with\na request. The server is not required to check all the cases in a\nparticular order, or at least I am not aware of any requirements. \n\nSo if a resource can't be checked out because it's not a VCR, and\nfurthermore it's locked, and furthermore the user wouldn't have\npermission to edit the resource anyway... then whatever problem the\nserver encounters first could result in a response of 403, 409 or 423.\n\nLisa\n\n\n\n", "id": "lists-007-4765210"}, {"subject": "RE: webdav versioning hel", "content": "Ndele:\n\nI am not familiar with the Jakarta implementation, but I will forward\nthis message to Juergen Pill, who is.\n\nCheers,\nGeoff \n\n-----Original Message-----\nFrom: Sutton, Ndele [mailto:Ndele.Sutton@citadelgroup.com]\nSent: Wednesday, August 07, 2002 5:22 PM\nTo: 'gclemm@rational.com'\nSubject: webdav versioning help\n\n\ni am trying to version resources using the jarkarta slide webdav server\nimplementation.  i am having a problems, and i was wondering if you could\nhelp me out?  basically, i am issuing a VERSION-CONTROL request to the\nserver on a resource that i think is versionable.  my request looks like\nthis:\n\nVERSION-CONTROL /users/ndele/README HTTP/1.1\nHost: sutton2:8081\nConnection: Keep-Alive, TE\nTE: trailers, deflate, gzip, compress\nUser-Agent: RPT-HTTPClient/0.3-3\nAccept-Encoding: deflate, gzip, x-gzip, compress, x-compress\n\nbut i get a response from the server saying \"The request sent by the client\nwas syntactically incorrect (No detailed message).\"  other than the last\nfour headers, my request is identical to the example in rfc 3253 section\n3.5.1 (http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.3.5.1).  i\nbelieve that slide supports versioning.\n\ni was reading a post that you made to ieft-dav-versioning list last july,\nand it seems that you have some means of communicating with the server via a\ncommand line utility.  could you tell me what that utility is?  i had to\nhack up a client that i got from slide guide (it only supported\npropfind/proppatch).\n\nthere is an awful lot of information to sift through, much of it hasn't been\nupdated since 2000 or 2001.  and there are very few concrete examples of how\nto use the version control features.  how do you test/use this stuff?\n\ni appreciate any help that you might be able to give.\n\nthanks,\n\nndele sutton\n\n\n\n", "id": "lists-007-4773646"}, {"subject": "DELETE of a version-controlled Collectio", "content": "Hi,\n\nsuppose you have a collection W that is not version-controlled. Within this collection there is a member collection M that is both version controlled and the root of a tree containing version controlled objects only (collections and files). Now I want to delete M.\n\nMy understanding is that because W is not version controlled I haven't to check it out, but just DELETE M. With that everything below M and M itself is gone with the wind. Right?\n\nThanks,\nDaniel\n\n_____________________________________________________\n\nDaniel Kirmse                                      SAP DB is open source\nSAP DB                                                          www.sapdb.org\n_____________________________________________________\n\n\n\n", "id": "lists-007-4783486"}, {"subject": "RE: DELETE of a version-controlled Collectio", "content": "   From: Kirmse, Daniel [mailto:daniel.kirmse@sap.com]\n\n   suppose you have a collection W that is not\n   version-controlled. Within this collection there is a member\n   collection M that is both version controlled and the root of a tree\n   containing version controlled objects only (collections and\n   files). Now I want to delete M.\n\n   My understanding is that because W is not version controlled I\n   haven't to check it out, but just DELETE M. With that everything\n   below M and M itself is gone with the wind. Right?\n\nWell, it depends on what you have in mind with \"gone with the wind\".\nAll the VCRs are deleted, which means that the modified state of\nany checked-out VCR is lost, but all checked-in state is available\nas versions in the version history resources.  Similarly, if you\nhave any baseline-controlled collections at or above M, then the\nchecked-in state would be available as baselines of those collections.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-4791699"}, {"subject": "RE: Replacing the Label header with a DAV:labeled-version repor", "content": "Geoff,\n\nwith the currently proposed format, how does a server marshall information\nabout failures in retrieving the properties of the selected version (? la\nDAV:propstat/DSAV:status in DAV:response)?\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Saturday, June 29, 2002 12:23 AM\n> To: 'Deltav WG'\n> Subject: RE: Replacing the Label header with a DAV:labeled-version\n> report\n>\n>\n>\n> Julian didn't like the marshalling of this report,\n> because it makes it look like the properties are those of\n> the VCR, when they actually are properties of the version\n> (Basically, I was just being lazy and re-using the D:response\n> element in a bogus fashion).\n>\n> So how about the following instead:\n>\n> -----------------------------------------------\n>\n> 8.3DAV:labeled-version Report\n>\n> The DAV:labeled-version report describes the requested\n> properties of the version with that label in a specified\n> version history.  If the DAV:labeled-version report is\n> applied to a version-controlled resource, it is applied\n> to the DAV:version-history of that version-controlled resource.\n>\n> Marshalling:\n>\n> The request body MUST be a DAV:labeled-version XML element.\n> <!ELEMENT labeled-version ANY>\n> ANY value: a sequence of zero or more elements, with at most\n> one DAV:prop element and with exactly one DAV:label-name element.\n> prop: see RFC 2518, Section 12.11\n>\n> The response body for a successful Depth:0 request MUST be\n> a DAV:labeled-version-report XML element.\n>\n> <!ELEMENT labeled-version-report (href, prop)>\n> prop: see RFC 2518, Section 12.11\n>\n> The DAV:href identifies the selected version, and the DAV:prop\n> contains the requested properties of that version.\n>\n> 8.3.1Example - DAV:labeled-version Report\n> >>REQUEST\n>\n>   REPORT /folder/ HTTP/1.1\n>   Host: www.webdav.org\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>   Depth: 1\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:labeled-version xmlns:D=\"DAV:\">\n>     <D:label-name>tested</D:label-name>\n>     <D:prop>\n>       <D:version-name/>\n>     </D:prop>\n>   </D:labeled-version>\n>\n> >>RESPONSE\n>\n>   HTTP/1.1 207 Multi-Status\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:multistatus xmlns:D=\"DAV:\">\n>     <D:response>\n>       <D:href>http://www.webdav.org/folder/</D:href>\n>       <D:propstat>\n>         <D:prop> <D:labeled-version-report>\n>           <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n>           <D:prop>\n>             <D:version-name>V5</D:version-name>\n>           </D:prop>\n>           </D:labeled-version-report> </D:prop>\n>         <D:status>HTTP/1.1 200 OK</D:status>\n>       </D:propstat>\n>     </D:response>\n>     <D:response>\n>       <D:href>http://www.webdav.org/folder/foo.html</D:href>\n>       <D:propstat>\n>         <D:prop> <D:labeled-version-report>\n>           <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n>           <D:prop>\n>             <D:version-name>V8</D:version-name>\n>           </D:prop>\n>         </D:labeled-version-report> </D:prop>\n>         <D:status>HTTP/1.1 200 OK</D:status>\n>       </D:propstat>\n>     </D:response>\n>   </D:multistatus>\n>\n>\n> -----------------------------------------\n>\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Clemm, Geoff [mailto:gclemm@Rational.Com]\n> Sent: Friday, June 28, 2002 3:18 PM\n> To: 'Deltav WG'\n> Subject: RE: Replacing the Label header with a DAV:labeled-version\n> report\n>\n>\n>\n> So far, everyone has either agreed or remained silent on this topic,\n> so as a motivator for anyone objecting to speak up (:-), I will mark this\n> issue\n> as resolved in the errata, with the resolution being that the Label\n> header will be deprecated, and the DAV:labeled-version REPORT inserted\n> in its place.  In particular, I propose the following definition for\n> the DAV:labeled-version REPORT:\n>\n> -------------------\n>\n> 8.3DAV:labeled-version Report\n> The DAV:labeled-version report describes the requested properties\n> of the version with that label in a specified version history.\n> If the DAV:labeled-version report is applied to a version-controlled\n> resource, it is applied to the DAV:version-history of that\n> version-controlled resource.\n>\n> Marshalling:\n>\n> The request body MUST be a DAV:labeled-version XML element.\n>\n> <!ELEMENT labeled-version ANY>\n>\n> ANY value: a sequence of zero or more elements, with\n> at most one DAV:prop element and with exactly one\n> DAV:label-name element.\n>\n> prop: see RFC 2518, Section 12.11\n>\n> The response body for a successful request MUST be a DAV:multistatus\n> XML element.\n>\n> multistatus: see RFC 2518, Section 12.9\n>\n> The response body for a successful DAV:labeled-version REPORT\n> request MUST contain a DAV:response element for each resource\n> that satisfies the Depth header of the request.\n>\n> 8.3.1Example - DAV:labeled-version Report\n>\n> >>REQUEST\n>\n>   REPORT /folder/ HTTP/1.1\n>   Host: www.webdav.org\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>   Depth: 1\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:labeled-version xmlns:D=\"DAV:\">\n>     <D:label-name>tested</D:label-name>\n>     <D:prop>\n>       <D:version-name/>\n>       <D:version/>\n>     </D:prop>\n>   </D:labeled-version>\n>\n> >>RESPONSE\n>\n>   HTTP/1.1 207 Multi-Status\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:multistatus xmlns:D=\"DAV:\">\n>     <D:response>\n>       <D:href>http://www.webdav.org/folder/</D:href>\n>       <D:propstat>\n>         <D:prop>\n>           <D:version-name>V5</D:version-name>\n>            <D:version>\n>             <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n>           </D:version>\n>         </D:prop>\n>         <D:status>HTTP/1.1 200 OK</D:status>\n>       </D:propstat>\n>     </D:response>\n>     <D:response>\n>       <D:href>http://www.webdav.org/folder/foo.html</D:href>\n>       <D:propstat>\n>         <D:prop>\n>           <D:version-name>V8</D:version-name>\n>           <D:version>\n>             <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n>           </D:version>\n>         </D:prop>\n>         <D:status>HTTP/1.1 200 OK</D:status>\n>       </D:propstat>\n>     </D:response>\n>   </D:multistatus>\n>\n> -----------------------------------------\n>\n> -----Original Message-----\n> From: Clemm, Geoff [mailto:gclemm@Rational.Com]\n> Sent: Sunday, April 28, 2002 9:53 AM\n> To: 'Deltav WG'\n> Subject: Replacing the Label header with a DAV:labeled-version report\n>\n>\n> Since this is a fairly significant change, I'd like to\n> hear from a few more folks before adding this to the 3253 Errata.\n>\n> Thanks,\n> Geoff\n>\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Saturday, April 27, 2002 5:09 AM\n> To: Clemm, Geoff; 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Friday, April 26, 2002 6:06 PM\n> > To: 'Deltav WG'\n> > Subject: RE: Label header vs PROPFIND depth 1\n> >\n> >\n> >    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> >\n> >    - I'd like to see the label *header* deprecated\n> >    - I'm happy with the LABEL method and the label-name-set property\n> >    - I think that PROPFIND/label should be replaced by a specific REPORT\n> >\n> > Is the proposed DAV:labeled-version report OK with you?\n>\n> Yes. But I think it's Tim's turn to say whether this would work for him or\n> not...\n>\n> >    - I'm unsure about other methods that are currently affected by the\n> >    header -- what were the requirements...?\n> >\n> > The other methods are LABEL, CHECKOUT, GET, and COPY.\n> > For Depth:0 variants of these operations, the Label header\n> > just provided an optimization to save one roundtrip\n> > (i.e. first getting the version URL via the DAV:labeled-version report).\n> > I believe we can easily do without that Depth:0 optimization.\n>\n> As stated before, I think that's not the single problem. Having\n> GET return a\n> (representation of a) version rather than (a representation of) the VCR\n> makes the version *by definition* a variant (representation) of the VCR --\n> and it seems that most of us want to avoid that interpretation.\n>\n> > For Depth:infinity (only relevant for LABEL and COPY), the savings\n> > would be more significant, but unfortunately the semantics is broken\n> > (since if the namespace is being versioned, you'll get the wrong\n> > resources if you simply do a Depth operation on the current namespace).\n> >\n> > The Depth:infinity Label header operations are really just a way of\n> > trying to have the client fake workspaces and baselines, instead of\n> > having the server support them directly.  Since it is much more\n> > efficient and reliable to have the server layer these constructs\n> > above a labeling infrastructure, rather than having the client do\n> > so, I believe the cost of maintaining these Depth:infinity Label\n> > header operations in the protocol is not warranted.\n> >\n> > Note though that (depth:0) labeling and baselining go very well\n> > together.  Instead of doing a Depth:infinity LABEL, you can create a\n> > baseline (which under the hood the server may well implement with\n> > reserved labels, but maybe not), and then LABEL that baseline.  Then\n> > when you want to do a Depth:infinity COPY, you retrieve the\n> > DAV:baseline-collection of the labeled baseline (using the\n> > DAV:labeled-version report), and copy that to wherever you want.\n> >\n> > Alternatively, if you want a \"modifiable\" selection, you can create a\n> > workspace (which under the hood the server may well implement with\n> > reserved labels, but maybe not).  When you want to adjust the versions\n> > being selected, you just use UPDATE.  Then when you want to do a\n> > Depth:infinity COPY, you just copy from that workspace to wherever you\n> > want.\n> >\n> >    - Servers that decide to implement LABEL and DAV:label-name-set,\n> >    but no not support the label header should *not* report the LABEL\n> >    feature in OPTIONS.\n> >\n> > That's probably right.  A client can find out if the LABEL operation\n> > is supported by querying the DAV:supported-method-set property values\n> > of a VCR.\n>\n> ...and also use DAV:supported-live-property-set to discover the\n> DAV:label-name-set property.\n>\n>\n\n\n\n", "id": "lists-007-4800206"}, {"subject": "RE: Replacing the Label header with a DAV:labeled-version repor", "content": "Currently, the server can either silently ignore the properties\nit cannot retrieve, or it can fail the entire report.\n\nIf you think it is important to allow a more fine-grained error\nhandling in this case, we could change the marshalling to be:\n\n <!ELEMENT labeled-version-report (response*)>\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Sunday, August 11, 2002 11:53 AM\nTo: Clemm, Geoff; 'Deltav WG'\nSubject: RE: Replacing the Label header with a DAV:labeled-version\nreport\n\n\nGeoff,\n\nwith the currently proposed format, how does a server marshall information\nabout failures in retrieving the properties of the selected version (? la\nDAV:propstat/DSAV:status in DAV:response)?\n\nJulian\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Saturday, June 29, 2002 12:23 AM\n> To: 'Deltav WG'\n> Subject: RE: Replacing the Label header with a DAV:labeled-version\n> report\n>\n>\n>\n> Julian didn't like the marshalling of this report,\n> because it makes it look like the properties are those of\n> the VCR, when they actually are properties of the version\n> (Basically, I was just being lazy and re-using the D:response\n> element in a bogus fashion).\n>\n> So how about the following instead:\n>\n> -----------------------------------------------\n>\n> 8.3DAV:labeled-version Report\n>\n> The DAV:labeled-version report describes the requested\n> properties of the version with that label in a specified\n> version history.  If the DAV:labeled-version report is\n> applied to a version-controlled resource, it is applied\n> to the DAV:version-history of that version-controlled resource.\n>\n> Marshalling:\n>\n> The request body MUST be a DAV:labeled-version XML element.\n> <!ELEMENT labeled-version ANY>\n> ANY value: a sequence of zero or more elements, with at most\n> one DAV:prop element and with exactly one DAV:label-name element.\n> prop: see RFC 2518, Section 12.11\n>\n> The response body for a successful Depth:0 request MUST be\n> a DAV:labeled-version-report XML element.\n>\n> <!ELEMENT labeled-version-report (href, prop)>\n> prop: see RFC 2518, Section 12.11\n>\n> The DAV:href identifies the selected version, and the DAV:prop\n> contains the requested properties of that version.\n>\n> 8.3.1Example - DAV:labeled-version Report\n> >>REQUEST\n>\n>   REPORT /folder/ HTTP/1.1\n>   Host: www.webdav.org\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>   Depth: 1\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:labeled-version xmlns:D=\"DAV:\">\n>     <D:label-name>tested</D:label-name>\n>     <D:prop>\n>       <D:version-name/>\n>     </D:prop>\n>   </D:labeled-version>\n>\n> >>RESPONSE\n>\n>   HTTP/1.1 207 Multi-Status\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:multistatus xmlns:D=\"DAV:\">\n>     <D:response>\n>       <D:href>http://www.webdav.org/folder/</D:href>\n>       <D:propstat>\n>         <D:prop> <D:labeled-version-report>\n>           <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n>           <D:prop>\n>             <D:version-name>V5</D:version-name>\n>           </D:prop>\n>           </D:labeled-version-report> </D:prop>\n>         <D:status>HTTP/1.1 200 OK</D:status>\n>       </D:propstat>\n>     </D:response>\n>     <D:response>\n>       <D:href>http://www.webdav.org/folder/foo.html</D:href>\n>       <D:propstat>\n>         <D:prop> <D:labeled-version-report>\n>           <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n>           <D:prop>\n>             <D:version-name>V8</D:version-name>\n>           </D:prop>\n>         </D:labeled-version-report> </D:prop>\n>         <D:status>HTTP/1.1 200 OK</D:status>\n>       </D:propstat>\n>     </D:response>\n>   </D:multistatus>\n>\n>\n> -----------------------------------------\n>\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Clemm, Geoff [mailto:gclemm@Rational.Com]\n> Sent: Friday, June 28, 2002 3:18 PM\n> To: 'Deltav WG'\n> Subject: RE: Replacing the Label header with a DAV:labeled-version\n> report\n>\n>\n>\n> So far, everyone has either agreed or remained silent on this topic,\n> so as a motivator for anyone objecting to speak up (:-), I will mark this\n> issue\n> as resolved in the errata, with the resolution being that the Label\n> header will be deprecated, and the DAV:labeled-version REPORT inserted\n> in its place.  In particular, I propose the following definition for\n> the DAV:labeled-version REPORT:\n>\n> -------------------\n>\n> 8.3DAV:labeled-version Report\n> The DAV:labeled-version report describes the requested properties\n> of the version with that label in a specified version history.\n> If the DAV:labeled-version report is applied to a version-controlled\n> resource, it is applied to the DAV:version-history of that\n> version-controlled resource.\n>\n> Marshalling:\n>\n> The request body MUST be a DAV:labeled-version XML element.\n>\n> <!ELEMENT labeled-version ANY>\n>\n> ANY value: a sequence of zero or more elements, with\n> at most one DAV:prop element and with exactly one\n> DAV:label-name element.\n>\n> prop: see RFC 2518, Section 12.11\n>\n> The response body for a successful request MUST be a DAV:multistatus\n> XML element.\n>\n> multistatus: see RFC 2518, Section 12.9\n>\n> The response body for a successful DAV:labeled-version REPORT\n> request MUST contain a DAV:response element for each resource\n> that satisfies the Depth header of the request.\n>\n> 8.3.1Example - DAV:labeled-version Report\n>\n> >>REQUEST\n>\n>   REPORT /folder/ HTTP/1.1\n>   Host: www.webdav.org\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>   Depth: 1\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:labeled-version xmlns:D=\"DAV:\">\n>     <D:label-name>tested</D:label-name>\n>     <D:prop>\n>       <D:version-name/>\n>       <D:version/>\n>     </D:prop>\n>   </D:labeled-version>\n>\n> >>RESPONSE\n>\n>   HTTP/1.1 207 Multi-Status\n>   Content-Type: text/xml; charset=\"utf-8\"\n>   Content-Length: xxxx\n>\n>   <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n>   <D:multistatus xmlns:D=\"DAV:\">\n>     <D:response>\n>       <D:href>http://www.webdav.org/folder/</D:href>\n>       <D:propstat>\n>         <D:prop>\n>           <D:version-name>V5</D:version-name>\n>            <D:version>\n>             <D:href>http://repo.webdav.org/his/23/ver/V5</D:href>\n>           </D:version>\n>         </D:prop>\n>         <D:status>HTTP/1.1 200 OK</D:status>\n>       </D:propstat>\n>     </D:response>\n>     <D:response>\n>       <D:href>http://www.webdav.org/folder/foo.html</D:href>\n>       <D:propstat>\n>         <D:prop>\n>           <D:version-name>V8</D:version-name>\n>           <D:version>\n>             <D:href>http://repo.webdav.org/his/84/ver/V8</D:href>\n>           </D:version>\n>         </D:prop>\n>         <D:status>HTTP/1.1 200 OK</D:status>\n>       </D:propstat>\n>     </D:response>\n>   </D:multistatus>\n>\n> -----------------------------------------\n>\n> -----Original Message-----\n> From: Clemm, Geoff [mailto:gclemm@Rational.Com]\n> Sent: Sunday, April 28, 2002 9:53 AM\n> To: 'Deltav WG'\n> Subject: Replacing the Label header with a DAV:labeled-version report\n>\n>\n> Since this is a fairly significant change, I'd like to\n> hear from a few more folks before adding this to the 3253 Errata.\n>\n> Thanks,\n> Geoff\n>\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Saturday, April 27, 2002 5:09 AM\n> To: Clemm, Geoff; 'Deltav WG'\n> Subject: RE: Label header vs PROPFIND depth 1\n>\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Friday, April 26, 2002 6:06 PM\n> > To: 'Deltav WG'\n> > Subject: RE: Label header vs PROPFIND depth 1\n> >\n> >\n> >    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> >\n> >    - I'd like to see the label *header* deprecated\n> >    - I'm happy with the LABEL method and the label-name-set property\n> >    - I think that PROPFIND/label should be replaced by a specific REPORT\n> >\n> > Is the proposed DAV:labeled-version report OK with you?\n>\n> Yes. But I think it's Tim's turn to say whether this would work for him or\n> not...\n>\n> >    - I'm unsure about other methods that are currently affected by the\n> >    header -- what were the requirements...?\n> >\n> > The other methods are LABEL, CHECKOUT, GET, and COPY.\n> > For Depth:0 variants of these operations, the Label header\n> > just provided an optimization to save one roundtrip\n> > (i.e. first getting the version URL via the DAV:labeled-version report).\n> > I believe we can easily do without that Depth:0 optimization.\n>\n> As stated before, I think that's not the single problem. Having\n> GET return a\n> (representation of a) version rather than (a representation of) the VCR\n> makes the version *by definition* a variant (representation) of the VCR --\n> and it seems that most of us want to avoid that interpretation.\n>\n> > For Depth:infinity (only relevant for LABEL and COPY), the savings\n> > would be more significant, but unfortunately the semantics is broken\n> > (since if the namespace is being versioned, you'll get the wrong\n> > resources if you simply do a Depth operation on the current namespace).\n> >\n> > The Depth:infinity Label header operations are really just a way of\n> > trying to have the client fake workspaces and baselines, instead of\n> > having the server support them directly.  Since it is much more\n> > efficient and reliable to have the server layer these constructs\n> > above a labeling infrastructure, rather than having the client do\n> > so, I believe the cost of maintaining these Depth:infinity Label\n> > header operations in the protocol is not warranted.\n> >\n> > Note though that (depth:0) labeling and baselining go very well\n> > together.  Instead of doing a Depth:infinity LABEL, you can create a\n> > baseline (which under the hood the server may well implement with\n> > reserved labels, but maybe not), and then LABEL that baseline.  Then\n> > when you want to do a Depth:infinity COPY, you retrieve the\n> > DAV:baseline-collection of the labeled baseline (using the\n> > DAV:labeled-version report), and copy that to wherever you want.\n> >\n> > Alternatively, if you want a \"modifiable\" selection, you can create a\n> > workspace (which under the hood the server may well implement with\n> > reserved labels, but maybe not).  When you want to adjust the versions\n> > being selected, you just use UPDATE.  Then when you want to do a\n> > Depth:infinity COPY, you just copy from that workspace to wherever you\n> > want.\n> >\n> >    - Servers that decide to implement LABEL and DAV:label-name-set,\n> >    but no not support the label header should *not* report the LABEL\n> >    feature in OPTIONS.\n> >\n> > That's probably right.  A client can find out if the LABEL operation\n> > is supported by querying the DAV:supported-method-set property values\n> > of a VCR.\n>\n> ...and also use DAV:supported-live-property-set to discover the\n> DAV:label-name-set property.\n>\n>\n\n\n\n", "id": "lists-007-4823519"}, {"subject": "RE: DASL and DELTA-V propertie", "content": "I think we should make SEARCH compatible to RFC3253/ACL -- that is\nDAV:allprop behaves just like for PROPFIND.\n\n> -----Original Message-----\n> From: www-webdav-dasl-request@w3.org\n> [mailto:www-webdav-dasl-request@w3.org]On Behalf Of Wallmer, Martin\n> Sent: Monday, August 12, 2002 9:38 AM\n> To: 'www-webdav-dasl@w3.org'; 'ietf-dav-versioning@w3.org'\n> Cc: Kazeroni, Ladan; Nevermann, Dr., Peter; Pill, Juergen\n> Subject: DASL and DELTA-V properties\n>\n>\n>\n> Hi,\n>\n> should a DAV:allprop SEARCH on a Delta-V enabled resource return\n> all Delta-V\n> properties as well? According to\n>\n> ---\n> RFC 3253\n>\n> 3.11 Additional PROPFIND Semantics\n>\n>    A DAV:allprop PROPFIND request SHOULD NOT return any of the\n>    properties defined by this document.  This allows a versioning server\n>    to perform efficiently when a naive client, which does not understand\n>    the cost of asking a server to compute all possible live properties,\n>    issues a DAV:allprop PROPFIND request.\n> ---\n>\n> PROPFIND should not return them. Is this true for SEARCH as well?\n> Is there a\n> need to define the behaviour for SEARCH as well?\n>\n> Regards,\n>\n> Martin Wallmer\n> Research & Development\n> Software AG ++49 6151 92 1831\n> Uhlandstr. 12\n> D 64297 Darmstadt\n>\n>\n\n\n\n", "id": "lists-007-4847133"}, {"subject": "[ietf-dav-versioning] &lt;none&gt", "content": "On behalf of Martin Wallmer:\n\nHi,\n\nshould a DAV:allprop SEARCH on a Delta-V enabled resource return all Delta-V\nproperties as well? According to \n\n---\nRFC 3253\n\n3.11 Additional PROPFIND Semantics\n\n   A DAV:allprop PROPFIND request SHOULD NOT return any of the\n   properties defined by this document.  This allows a versioning server\n   to perform efficiently when a naive client, which does not understand\n   the cost of asking a server to compute all possible live properties,\n   issues a DAV:allprop PROPFIND request.\n---\n\nPROPFIND should not return them. Is this true for SEARCH as well? Is there a\nneed to define the behaviour for SEARCH as well?\n\nRegards,\n\nMartin Wallmer\nResearch & Development\nSoftware AG\n\n\n\n", "id": "lists-007-4857743"}, {"subject": "DASL and DELTA-V propertie", "content": "Sorry for the missing subject in my previous posting :-)\n\nOn behalf of Martin Wallmer:\n-----\n\nHi,\n\nshould a DAV:allprop SEARCH on a Delta-V enabled resource return all Delta-V\nproperties as well? According to \n\n---\nRFC 3253\n\n3.11 Additional PROPFIND Semantics\n\n   A DAV:allprop PROPFIND request SHOULD NOT return any of the\n   properties defined by this document.  This allows a versioning server\n   to perform efficiently when a naive client, which does not understand\n   the cost of asking a server to compute all possible live properties,\n   issues a DAV:allprop PROPFIND request.\n---\n\nPROPFIND should not return them. Is this true for SEARCH as well? Is there a\nneed to define the behaviour for SEARCH as well?\n\nRegards,\n\nMartin Wallmer\nResearch & Development\nSoftware AG\n\n\n\n", "id": "lists-007-4865456"}, {"subject": "RE: DASL and DELTA-V propertie", "content": "I agree with Julian.  DAV:allprop SEARCH should be defined to\nhave the same behavior as DAV:allprop.  In particular, it\nshould not search RFC-3253 properties.\n\nThe current proposal for the next revision of 2518 is that\nit should only search dead properties and properties \ndefined in RFC-2518.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@gmx.de]\nSent: Monday, August 12, 2002 4:01 AM\nTo: Wallmer, Martin; www-webdav-dasl@w3.org; ietf-dav-versioning@w3.org\nCc: Kazeroni, Ladan; Nevermann, Dr., Peter; Pill, Juergen\nSubject: RE: DASL and DELTA-V properties\n\n\n\nI think we should make SEARCH compatible to RFC3253/ACL -- that is\nDAV:allprop behaves just like for PROPFIND.\n\n> -----Original Message-----\n> From: www-webdav-dasl-request@w3.org\n> [mailto:www-webdav-dasl-request@w3.org]On Behalf Of Wallmer, Martin\n> Sent: Monday, August 12, 2002 9:38 AM\n> To: 'www-webdav-dasl@w3.org'; 'ietf-dav-versioning@w3.org'\n> Cc: Kazeroni, Ladan; Nevermann, Dr., Peter; Pill, Juergen\n> Subject: DASL and DELTA-V properties\n>\n>\n>\n> Hi,\n>\n> should a DAV:allprop SEARCH on a Delta-V enabled resource return\n> all Delta-V\n> properties as well? According to\n>\n> ---\n> RFC 3253\n>\n> 3.11 Additional PROPFIND Semantics\n>\n>    A DAV:allprop PROPFIND request SHOULD NOT return any of the\n>    properties defined by this document.  This allows a versioning server\n>    to perform efficiently when a naive client, which does not understand\n>    the cost of asking a server to compute all possible live properties,\n>    issues a DAV:allprop PROPFIND request.\n> ---\n>\n> PROPFIND should not return them. Is this true for SEARCH as well?\n> Is there a\n> need to define the behaviour for SEARCH as well?\n>\n> Regards,\n>\n> Martin Wallmer\n> Research & Development\n> Software AG ++49 6151 92 1831\n> Uhlandstr. 12\n> D 64297 Darmstadt\n>\n>\n\n\n\n", "id": "lists-007-4873799"}, {"subject": "RE: DASL and DELTA-V propertie", "content": "Wait-a-minute :-)\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Monday, August 12, 2002 2:19 PM\n> To: www-webdav-dasl@w3.org; ietf-dav-versioning@w3.org\n> Cc: Kazeroni, Ladan; Nevermann, Dr., Peter; Wallmer, Martin\n> Subject: RE: DASL and DELTA-V properties\n>\n>\n>\n> I agree with Julian.  DAV:allprop SEARCH should be defined to\n> have the same behavior as DAV:allprop.  In particular, it\n> should not search RFC-3253 properties.\n\nYes, it should SEARCH them (if used in the where clause). No, it shouldn't\nreport them (when select uses allprop).\n\n> The current proposal for the next revision of 2518 is that\n> it should only search dead properties and properties\n> defined in RFC-2518.\n\nsed s/search/report/\n\n\n\n", "id": "lists-007-4886132"}, {"subject": "RE: DASL and DELTA-V propertie", "content": "I was assuming that you were referring to a DAV:allprop in the\n\"WHERE\" clause (i.e. find this string in all properties).\nThus my statement that \"DAV:allprop SEARCH should not search\nRFC-3253 properties\".\n\nIf you were referring to the use of DAV:allprop in the \"SELECT\" clause,\nthen as Julian points out, it should not report RFC-3253 properties\n(but should search whatever is specified in the WHERE clause).\n\nAnd Julian's sed statement is of course correct (thanks, Julian!).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Monday, August 12, 2002 8:28 AM\nTo: Clemm, Geoff; www-webdav-dasl@w3.org; ietf-dav-versioning@w3.org\nCc: Kazeroni, Ladan; Nevermann, Dr., Peter; Wallmer, Martin\nSubject: RE: DASL and DELTA-V properties\n\n\nWait-a-minute :-)\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Monday, August 12, 2002 2:19 PM\n> To: www-webdav-dasl@w3.org; ietf-dav-versioning@w3.org\n> Cc: Kazeroni, Ladan; Nevermann, Dr., Peter; Wallmer, Martin\n> Subject: RE: DASL and DELTA-V properties\n>\n>\n>\n> I agree with Julian.  DAV:allprop SEARCH should be defined to\n> have the same behavior as DAV:allprop.  In particular, it\n> should not search RFC-3253 properties.\n\nYes, it should SEARCH them (if used in the where clause). No, it shouldn't\nreport them (when select uses allprop).\n\n> The current proposal for the next revision of 2518 is that\n> it should only search dead properties and properties\n> defined in RFC-2518.\n\nsed s/search/report/\n\n\n\n", "id": "lists-007-4896832"}, {"subject": "RE: DASL and DELTA-V propertie", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Monday, August 12, 2002 2:42 PM\n> To: www-webdav-dasl@w3.org; ietf-dav-versioning@w3.org\n> Cc: Kazeroni, Ladan; Nevermann, Dr., Peter; Wallmer, Martin\n> Subject: RE: DASL and DELTA-V properties\n> \n> \n> \n> I was assuming that you were referring to a DAV:allprop in the\n> \"WHERE\" clause (i.e. find this string in all properties).\n> Thus my statement that \"DAV:allprop SEARCH should not search\n> RFC-3253 properties\".\n\nGeoff,\n\nyou can't have DAV:allprop in the where clause :-)\n\n\n\n", "id": "lists-007-4908848"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t he Label header with a DAV:labeled-version repor", "content": "Sorry,\n\nproblem doesn't go away :-)\n\n>    Related question of the day: what's the response format for the\n>    version-tree report with depth: 1 applied to a collection that\n>    itself is not versioned but contains one version controlled member?\n>\n>    For depth 0 I'd expect:\n>    409 CONFLICT\n>    with\n>    <error xmlns=\"DAV:\"><supported-report/></error>\n>\n> Sounds right.\n>\n>\n>    So for depth 1 one would get:\n>    207 MULTISTATUS\n>    <multistatus xmlns=\"DAV:\">\n>      <response>\n>        <href>/collection/</href>\n>        <status>HTTP/1.1 409 Conflict</status>\n>        <responsedescription><error><supported-report/>\n>          </error></responsedescription> </response>\n>      <response>\n>        <href>/collection/a</href>\n>        <propstat>\n>  <prop>\n>  ...now what?...\n>  </prop>\n>  <status>HTTP/1.1 200 OK</status>\n>        </propstat>\n>      </response>\n>    </multistatus>\n>\n> Yes.\n\n\nSo,\n\nassume we do a depth: infinity REPORT locate-by-history. This report is\ndefined for collections only, so it must return FORBIDDEN for all\nnon-collection resources it is applied to. This suggests that in the case of\ndepth: infinity, I will get a\n\n<response>\n    <href>...</href>\n    <status>HTTP/1.1 403 Forbidden</status>\n\n<responsedescription><error><supported-report/></error></responsedescription\n> </response>\n<response>\n\nelement for every single non-collection resource in the namespace below the\nrequest URI. Is this really intended???\n\nJulian\n\n\n\n", "id": "lists-007-4919292"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t he Label header with a DAV:labeled-version repor", "content": "A Depth:infinity DAV:locate-by-history request makes no sense,\nso having it return something ugly (i.e. a 403 for every non-collection\nmember) is not a problem.\n\nOn the other hand, a Depth:infinity DAV:labeled-version request does\nmake sense, and it is reasonable for it to return a 403 for every\nnon-version-controlled member of the collection.\n\nIn general, when a request asks you to apply a report to every member\nof a collection, it seems reasonable to indicate the result (possibly,\nan error) for each member of that collection.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, August 15, 2002 8:46 AM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: Marshalling Depth > 0 responses for REPORTs, WAS: Replacing\nt he Label header with a DAV:labeled-version report\n\n\n\nSorry,\n\nproblem doesn't go away :-)\n\n>    Related question of the day: what's the response format for the\n>    version-tree report with depth: 1 applied to a collection that\n>    itself is not versioned but contains one version controlled member?\n>\n>    For depth 0 I'd expect:\n>    409 CONFLICT\n>    with\n>    <error xmlns=\"DAV:\"><supported-report/></error>\n>\n> Sounds right.\n>\n>\n>    So for depth 1 one would get:\n>    207 MULTISTATUS\n>    <multistatus xmlns=\"DAV:\">\n>      <response>\n>        <href>/collection/</href>\n>        <status>HTTP/1.1 409 Conflict</status>\n>        <responsedescription><error><supported-report/>\n>          </error></responsedescription> </response>\n>      <response>\n>        <href>/collection/a</href>\n>        <propstat>\n>  <prop>\n>  ...now what?...\n>  </prop>\n>  <status>HTTP/1.1 200 OK</status>\n>        </propstat>\n>      </response>\n>    </multistatus>\n>\n> Yes.\n\n\nSo,\n\nassume we do a depth: infinity REPORT locate-by-history. This report is\ndefined for collections only, so it must return FORBIDDEN for all\nnon-collection resources it is applied to. This suggests that in the case of\ndepth: infinity, I will get a\n\n<response>\n    <href>...</href>\n    <status>HTTP/1.1 403 Forbidden</status>\n\n<responsedescription><error><supported-report/></error></responsedescription\n> </response>\n<response>\n\nelement for every single non-collection resource in the namespace below the\nrequest URI. Is this really intended???\n\nJulian\n\n\n\n", "id": "lists-007-4929541"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t he Label header with a DAV:labeled-version repor", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Thursday, August 15, 2002 3:20 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: Marshalling Depth > 0 responses for REPORTs, WAS: Replacing\n> t he Label header with a DAV:labeled-version report\n>\n>\n>\n> A Depth:infinity DAV:locate-by-history request makes no sense,\n> so having it return something ugly (i.e. a 403 for every non-collection\n> member) is not a problem.\n\nWell.\n\nIt does make a lot of sense if you don't know which collection the VCR is\nin -- this is why we need it.\n\nSo the use case is:\n\n- I have a VHR\n- I need to lookup VCRs on a server for which the DAV:version-history points\nto my VHR\n\nHow am I supposed to do that if not using depth infinity?\n\n> On the other hand, a Depth:infinity DAV:labeled-version request does\n> make sense, and it is reasonable for it to return a 403 for every\n> non-version-controlled member of the collection.\n>\n> In general, when a request asks you to apply a report to every member\n> of a collection, it seems reasonable to indicate the result (possibly,\n> an error) for each member of that collection.\n\nWhich basically renders all REPORTs that apply to collections (are there\nothers?) useless if you depth = 0 or depth = 1 isn't enough.\n\n\n\n", "id": "lists-007-4941419"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t he Label header with a DAV:labeled-version repor", "content": "The DAV:locate-by-history report finds any collection member\nfor that history, not just internal members.  In particular,\nthe example in 5.4.1 shows a Depth:0 (the default) request which\nfinds the /ws/public/x/test.html member of the /ws/public collection.\n\nSo a DAV:locate-by-history report only makes sense with the \ndefault Depth header value of \"0\".\n\nWhat report are you thinking of that makes sense with a non-zero\ndepth, but which can only be applied to collections?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, August 15, 2002 10:35 AM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: Marshalling Depth > 0 responses for REPORTs, WAS: Replacing\nt he Label header with a DAV:labeled-version report\n\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Thursday, August 15, 2002 3:20 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: Marshalling Depth > 0 responses for REPORTs, WAS: Replacing\n> t he Label header with a DAV:labeled-version report\n>\n>\n>\n> A Depth:infinity DAV:locate-by-history request makes no sense,\n> so having it return something ugly (i.e. a 403 for every non-collection\n> member) is not a problem.\n\nWell.\n\nIt does make a lot of sense if you don't know which collection the VCR is\nin -- this is why we need it.\n\nSo the use case is:\n\n- I have a VHR\n- I need to lookup VCRs on a server for which the DAV:version-history points\nto my VHR\n\nHow am I supposed to do that if not using depth infinity?\n\n> On the other hand, a Depth:infinity DAV:labeled-version request does\n> make sense, and it is reasonable for it to return a 403 for every\n> non-version-controlled member of the collection.\n>\n> In general, when a request asks you to apply a report to every member\n> of a collection, it seems reasonable to indicate the result (possibly,\n> an error) for each member of that collection.\n\nWhich basically renders all REPORTs that apply to collections (are there\nothers?) useless if you depth = 0 or depth = 1 isn't enough.\n\n\n\n", "id": "lists-007-4952597"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t he Label header with a DAV:labeled-version repor", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, August 16, 2002 12:05 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: Marshalling Depth > 0 responses for REPORTs, WAS: Replacing\n> t he Label header with a DAV:labeled-version report\n>\n>\n>\n> The DAV:locate-by-history report finds any collection member\n> for that history, not just internal members.  In particular,\n> the example in 5.4.1 shows a Depth:0 (the default) request which\n> finds the /ws/public/x/test.html member of the /ws/public collection.\n\nOK, agreed.\n\nSomehow, I wasn't paying attention to the distinction between \"collection\nmember\" and \"internal collection member\".\n\n> So a DAV:locate-by-history report only makes sense with the\n> default Depth header value of \"0\".\n\nYes.\n\n> What report are you thinking of that makes sense with a non-zero\n> depth, but which can only be applied to collections?\n\nNone (anymore), currently.\n\n\n\n", "id": "lists-007-4965818"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t he Label header with a DAV:labeled-version repor", "content": "Geoff,\n\nanother (hopefully, last one) question.\n\nAssume that the collection at the root of my WebDAV namespace happens to be\nversioned. How do I use locate-by-history to find it?\n\nShouldn't this\n\n\"The response body for a successful request MUST be a DAV:multistatus XML\nelement containing every version-controlled resource that is a member of the\ncollection identified by the request-URL,...\"\n\nbe\n\n\"The response body for a successful request MUST be a DAV:multistatus XML\nelement containing every version-controlled resource that is  a member of\nthe collection identified by the request-URL or the collection itself,....\"\n\ninstead?\n\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, August 16, 2002 12:05 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: Marshalling Depth > 0 responses for REPORTs, WAS: Replacing\n> t he Label header with a DAV:labeled-version report\n>\n>\n>\n> The DAV:locate-by-history report finds any collection member\n> for that history, not just internal members.  In particular,\n> the example in 5.4.1 shows a Depth:0 (the default) request which\n> finds the /ws/public/x/test.html member of the /ws/public collection.\n>\n> So a DAV:locate-by-history report only makes sense with the\n> default Depth header value of \"0\".\n>\n> What report are you thinking of that makes sense with a non-zero\n> depth, but which can only be applied to collections?\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Thursday, August 15, 2002 10:35 AM\n> To: Clemm, Geoff; ietf-dav-versioning@w3.org\n> Subject: RE: Marshalling Depth > 0 responses for REPORTs, WAS: Replacing\n> t he Label header with a DAV:labeled-version report\n>\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Thursday, August 15, 2002 3:20 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: RE: Marshalling Depth > 0 responses for REPORTs, WAS: Replacing\n> > t he Label header with a DAV:labeled-version report\n> >\n> >\n> >\n> > A Depth:infinity DAV:locate-by-history request makes no sense,\n> > so having it return something ugly (i.e. a 403 for every non-collection\n> > member) is not a problem.\n>\n> Well.\n>\n> It does make a lot of sense if you don't know which collection the VCR is\n> in -- this is why we need it.\n>\n> So the use case is:\n>\n> - I have a VHR\n> - I need to lookup VCRs on a server for which the\n> DAV:version-history points\n> to my VHR\n>\n> How am I supposed to do that if not using depth infinity?\n>\n> > On the other hand, a Depth:infinity DAV:labeled-version request does\n> > make sense, and it is reasonable for it to return a 403 for every\n> > non-version-controlled member of the collection.\n> >\n> > In general, when a request asks you to apply a report to every member\n> > of a collection, it seems reasonable to indicate the result (possibly,\n> > an error) for each member of that collection.\n>\n> Which basically renders all REPORTs that apply to collections (are there\n> others?) useless if you depth = 0 or depth = 1 isn't enough.\n>\n>\n>\n\n\n\n", "id": "lists-007-4977118"}, {"subject": "RE: Marshalling Depth &gt; 0 responses for REPORTs, WAS: Replacing t  he Label header with a DAV:labeled-version repor", "content": "Yes, it should say \"or the collection itself\".  I'll add that to the errata\nsheet.\nThanks for noticing that!\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\nAssume that the collection at the root of my WebDAV namespace happens to be\nversioned. How do I use locate-by-history to find it?\n\nShouldn't this\n\n\"The response body for a successful request MUST be a DAV:multistatus XML\nelement containing every version-controlled resource that is a member of the\ncollection identified by the request-URL,...\"\n\nbe\n\n\"The response body for a successful request MUST be a DAV:multistatus XML\nelement containing every version-controlled resource that is  a member of\nthe collection identified by the request-URL or the collection itself,....\"\n\ninstead?\n\n\n\n", "id": "lists-007-4992385"}, {"subject": "RE: Replacing the Label header with a DAV:labeled-version repor", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > From: Clemm, Geoff [mailto:gclemm@rational.com]\n   > So it looks like the main remaining issue in this thread is\n   > 3.6_CLARIFY_DEPTH_MARSHALLING, i.e. whether to keep the marshalling\n   > defined in 3253 (i.e. in a DAV:prop) or define a new element for it\n   > (i.e. in a DAV:report).  My main concern with making a change is\n   > that until we get RFC 3253 updated, any other spec that wants to\n   > re-use the REPORT method from 3253 would have to know about the\n   > proposed marshalling change, and specify it in their spec (e.g. the\n   > ACL spec).  I'm concerned that this is likely to be a more\n   > significant source of interoperability problems, than is having\n   > DAV:prop be used both for properties and for reports.\n\n   Well, it seems that I'm the only one who feels strongly about this --\n   so probably RFC3253 should stay as it is (with clarifications, not\n   changes).\n\nOK, I'll mark it resolved, with that as the resolution.  The issue\nwill remain in the issues list though, so if anyone would like to\nreopen it, just let me know.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-5001660"}, {"subject": "FW: RFC3253 erratu", "content": "Forwarded to the mailing list, so that it can be referenced in the issues\nlist.\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Monday, March 25, 2002 5:10 AM\nTo: Geoff Clemm\nSubject: RFC3253 erratum\n\n\nProbably caused by the RFC editor:\n\nHTTP/1.1 207 Multi-Status\nContent-Type: text/xml; charset=\"utf-8\"\nContent-Length: xxxx\nCache-Control: no-cache\n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<D:multistatus xmlns:D=\"DAV:\">\n <D:response>\n   <D:href>http://www.webdav.org/foo.html</D:href>\n   <D:status>HTTP/1.1 200 OK</D:status>\n  </D:response>\n\n(note: the last closing tag is missing).\n\n\n[1] <http://greenbytes.de/tech/webdav/rfc3253.html#rfc.section.7.1.1>\n\n\n\n", "id": "lists-007-5010717"}, {"subject": "Typo in RFC3253, Section 4.1.", "content": "It should say \"checkin-fork\", not \"checkout-fork\".\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-5018845"}, {"subject": "VERSION-CONTROL (6.7) vs resurrecting deleted VCR", "content": "Hi.\n\nGiven a VCR a and it's VHR b. The VCR is deleted. The workspace feature\n(section 6) seems to provide a way to create a new VCR whose\nDAV:version-history property points to b.\n\nNow this seems like an extremely important feature in versioning, no matter\nwether the server supports the workspace feature or not. So would it be\npermissible to use VERSION-CONTROL to resurrect the VCR outside a workspace\n(if no other VCR for that VHR exists on the server)?\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5025387"}, {"subject": "RE: VERSION-CONTROL (6.7) vs resurrecting deleted VCR", "content": "It probably would have made sense to make it part of the\nversion-history feature instead of workspace feature, but\nnobody asked for it at the time (probably because most of\nthe people that were planning on supporting the version \nhistory feature were also planning on supporting the workspace\nfeature, so they didn't care).\n\nBut to answer your specific question, it certainly is fine for\na server to support the VERSION-CONTROL extension without\nsupporting the workspace feature, but it isn't something that\nan interoperable client would expect.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Wednesday, August 21, 2002 8:34 AM\nTo: DeltaV (E-mail)\nSubject: VERSION-CONTROL (6.7) vs resurrecting deleted VCRs\n\n\n\nHi.\n\nGiven a VCR a and it's VHR b. The VCR is deleted. The workspace feature\n(section 6) seems to provide a way to create a new VCR whose\nDAV:version-history property points to b.\n\nNow this seems like an extremely important feature in versioning, no matter\nwether the server supports the workspace feature or not. So would it be\npermissible to use VERSION-CONTROL to resurrect the VCR outside a workspace\n(if no other VCR for that VHR exists on the server)?\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5033759"}, {"subject": "RE: VERSION-CONTROL (6.7) vs resurrecting deleted VCR", "content": "Doing this successfully may require an assumption that I only recently\nwas acquainted with: that every regular collection on a server\nsupporting workspaces is a workspace.  Thus, even the main repository or\nmain directory is a workspace that can have an activity, etc. and all\nthe workspace functions work with it, including restoring VCRs to\ndeleted VHRs.\n\nlisa\n\n> -----Original Message-----\n> From: Clemm, Geoff [mailto:gclemm@rational.com]\n> Sent: Wednesday, August 21, 2002 3:50 PM\n> To: DeltaV (E-mail)\n> Subject: RE: VERSION-CONTROL (6.7) vs resurrecting deleted VCRs\n> \n> \n> It probably would have made sense to make it part of the\n> version-history feature instead of workspace feature, but\n> nobody asked for it at the time (probably because most of\n> the people that were planning on supporting the version\n> history feature were also planning on supporting the workspace\n> feature, so they didn't care).\n> \n> But to answer your specific question, it certainly is fine for\n> a server to support the VERSION-CONTROL extension without\n> supporting the workspace feature, but it isn't something that\n> an interoperable client would expect.\n> \n> Cheers,\n> Geoff\n> \n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Wednesday, August 21, 2002 8:34 AM\n> To: DeltaV (E-mail)\n> Subject: VERSION-CONTROL (6.7) vs resurrecting deleted VCRs\n> \n> \n> \n> Hi.\n> \n> Given a VCR a and it's VHR b. The VCR is deleted. The workspace\nfeature\n> (section 6) seems to provide a way to create a new VCR whose\n> DAV:version-history property points to b.\n> \n> Now this seems like an extremely important feature in versioning, no\n> matter\n> wether the server supports the workspace feature or not. So would it\nbe\n> permissible to use VERSION-CONTROL to resurrect the VCR outside a\n> workspace\n> (if no other VCR for that VHR exists on the server)?\n> \n> Julian\n> \n> --\n> <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5042815"}, {"subject": "Delta V client", "content": "Hi all,\nI am implementing a Delta V extension to an existing\nWebdav Server but am surprised I can't yet find a\nDelta V client that I can use to test my Server.\n\nDo Delta V clients exist at the moment?\n\nSalesio\n\n=====\n* Salesio Mbogo Kiura                  \n* Sedanstr. 23 (App. 105)              \n* 20146 Hamburg                        \n* Tel.(Private):0179-123 541 5         \n* email 2: salesio.kiura@tu-harburg.de \n* Domain : http://www.mbogo.org        \n***=========***=========***=========X\n\n__________________________________________________\nDo You Yahoo!?\nEverything you'll ever need on one web page\nfrom News and Sport to Email and Music Charts\nhttp://uk.my.yahoo.com\n\n\n\n", "id": "lists-007-5053131"}, {"subject": "url encoding in XM", "content": "Hi,\nA very basic question.  Should the hrefs that appear within the XML content be encoded? For example, should the hrefs reported in the DAV:successor-set be URL encoded?\n\n<D:successor-set>\n<D:href>http://repo.webdav.org/his/23/ver/V+1</D:href>\n<D:href>http://repo.webdav.org/his/23/ver/V 1</D:href>\n</D:successor-set>\n\nShould the '+' and the blank in the above URLs be encoded?\n\nRgds,\nGirish\n\n\n\n", "id": "lists-007-5060406"}, {"subject": "Re: url encoding in XM", "content": "There are no such things as \"unencoded\" URLs. A URL\ncannot contain a space.\n\n//Stefan\n\nAm Mittwoch den, 28. August 2002, um 12:00, schrieb B H, Girish:\n\n>\n> Hi,\n> A very basic question.  Should the hrefs that appear within the \n> XML content be encoded? For example, should the hrefs reported in \n> the DAV:successor-set be URL encoded?\n>\n> <D:successor-set>\n> <D:href>http://repo.webdav.org/his/23/ver/V+1</D:href>\n> <D:href>http://repo.webdav.org/his/23/ver/V 1</D:href>\n> </D:successor-set>\n>\n> Should the '+' and the blank in the above URLs be encoded?\n>\n> Rgds,\n> Girish\n>\n>\n\n\n\n", "id": "lists-007-5067941"}, {"subject": "RE: url encoding in XM", "content": "Yes.\n\nThere's no such thing as a un-encoded URI. If you un-encode it, it's not\nlonger a URI.\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of B H, Girish\n> Sent: Wednesday, August 28, 2002 12:00 PM\n> To: IETF-DeltaV (E-mail)\n> Subject: url encoding in XML\n>\n>\n>\n> Hi,\n> A very basic question.  Should the hrefs that appear within the\n> XML content be encoded? For example, should the hrefs reported in\n> the DAV:successor-set be URL encoded?\n>\n> <D:successor-set>\n> <D:href>http://repo.webdav.org/his/23/ver/V+1</D:href>\n> <D:href>http://repo.webdav.org/his/23/ver/V 1</D:href>\n> </D:successor-set>\n>\n> Should the '+' and the blank in the above URLs be encoded?\n>\n> Rgds,\n> Girish\n>\n>\n>\n\n\n\n", "id": "lists-007-5075974"}, {"subject": "DAV:workspace property on resources that aren't in workspace", "content": "Hi,\n\nsection 6.2.1 says:\n\n\"The DAV:workspace property of a workspace resource MUST identify itself.\nThe DAV:workspace property of any other type of resource MUST be the same as\nthe DAV:workspace of its parent collection.\"\n\nIt seems to be undefined however what the value is if a resource doesn't\n*have* a (DAV-compliant) parent collection, for instance the root of my DAV\nnamespace.\n\nSo what should it be?\n\na) not present\nb) empty (no href)\n\nJulian (leaning to b)\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5084759"}, {"subject": "UPDATE semantics for checked-out resource", "content": "Hi,\n\nsection 7.1 defines the UPDATE semantics checked-in resources:\n\n\"The UPDATE method modifies the content and dead properties of a checked-in\nversion-controlled resource (the \"update target\") to be those of a specified\nversion (the \"update source\") from the version history of that\nversion-controlled resource.\"\n\nSo is the behaviour for checked-out resources just undefined\n(intentionally)?\n\nI would have expected that DAV:must-be-checked-in is an explicit\nprecondition for this method...\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5092662"}, {"subject": "Required properties with no value [WAS: workspace property on res ources that aren't in workspaces", "content": "This is a good question, and it applies to any \"required\" property that\nsometimes has \"no value\" (e.g. DAV:checked-in and DAV:checked-out).\n\nSo this question probably should be answered in 2518bis (I'll forward\nthis message to the WebDAV list), but we certainly could take a stab\nat it in the DeltaV context first.\n\nLike Julian, I'd probably be inclined to \"b\", but don't feel strongly\neither way.  Anyone prefer \"a\", prefer to decide separately for each\nproperty, or prefer that we leave it up to the server?\n\nCheers,\nGeoff\n\n   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   section 6.2.1 [of rfc 3253] says:\n\n   \"The DAV:workspace property of a workspace resource MUST identify\n   itself.  The DAV:workspace property of any other type of resource\n   MUST be the same as the DAV:workspace of its parent collection.\"\n\n   It seems to be undefined however what the value is if a resource doesn't\n   *have* a (DAV-compliant) parent collection, for instance the root of my\nDAV\n   namespace.\n\n   So what should it be?\n\n   a) not present\n   b) empty (no href)\n\n   Julian (leaning to b)\n\n\n\n", "id": "lists-007-5101547"}, {"subject": "RE: UPDATE semantics for checked-out resource", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   section 7.1 defines the UPDATE semantics checked-in resources:\n\n   \"The UPDATE method modifies the content and dead properties of a\n   checked-in version-controlled resource (the \"update target\") to be\n   those of a specified version (the \"update source\") from the version\n   history of that version-controlled resource.\"\n\n   So is the behaviour for checked-out resources just undefined\n   (intentionally)?\n\n   I would have expected that DAV:must-be-checked-in is an explicit\n   precondition for this method...\n\nI agree that adding the DAV:must-be-checked-in precondition is the\nbetter answer.  I'll add this to the Errata, and resolve it by adding\nthat precondition, unless someone objects.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-5111268"}, {"subject": "RE: Required properties with no value [WAS: workspace property on res ources that aren't in workspaces", "content": "Required properties with no value [WAS: workspace property on resources that\naren't in workspaces]I think this case is a bit different.\n\nFor DAV:checked-in and DAV:checked-out the spec is very clear that they\naren't *present* for resources that don't happen to be checked-out /\nchecked-in.\n\nIn *this* case (DAV:workspace), the spec is just silent about the value for\na resource that happens to be in no workspace.\n\nFurthermore, I don't think a) would work for DAV:checked-in -- clients\nalready check for the *presence* of this property to find out whether a\nresource is checked-in, and RFC3253 explicitly says this is ok...:\n\n\"This property appears on a checked-in version-controlled resource, and\nidentifies a version that has the same content and dead properties as the\nversion-controlled resource. This property is removed when the resource is\nchecked out, and then added back (identifying a new version) when the\nresource is checked back in.\"\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n  Sent: Thursday, September 26, 2002 8:27 PM\n  To: WebDAV (E-mail); ietf-dav-versioning@w3.org\n  Subject: Required properties with no value [WAS: workspace property on res\nources that aren't in workspaces]\n\n\n  This is a good question, and it applies to any \"required\" property that\n  sometimes has \"no value\" (e.g. DAV:checked-in and DAV:checked-out).\n\n  So this question probably should be answered in 2518bis (I'll forward\n  this message to the WebDAV list), but we certainly could take a stab\n  at it in the DeltaV context first.\n\n  Like Julian, I'd probably be inclined to \"b\", but don't feel strongly\n  either way.  Anyone prefer \"a\", prefer to decide separately for each\n  property, or prefer that we leave it up to the server?\n\n  Cheers,\n  Geoff\n\n     From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n     section 6.2.1 [of rfc 3253] says:\n\n     \"The DAV:workspace property of a workspace resource MUST identify\n     itself.  The DAV:workspace property of any other type of resource\n     MUST be the same as the DAV:workspace of its parent collection.\"\n\n     It seems to be undefined however what the value is if a resource\ndoesn't\n     *have* a (DAV-compliant) parent collection, for instance the root of my\nDAV\n     namespace.\n\n     So what should it be?\n\n     a) not present\n     b) empty (no href)\n\n     Julian (leaning to b)\n\n\n\n", "id": "lists-007-5120049"}, {"subject": "again: OPTIONS semantic", "content": "Just taking an example from section 7:\n\n\"Additional OPTIONS Semantics\nIf the server supports the update feature, it MUST include \"update\" as a\nfield in the DAV response header from an OPTIONS request on any resource\nthat supports any versioning properties, reports, or methods.\"\n\n\nSo assuming my DAV namespace is separated into two parts (for instance by\nservlet) \"/a\" and \"/b\". Both parts of the server namespace support\nversioning, but only \"/a\" supports workspaces. Should the \"update\" feature\nbe reported on \"/b\" and it's descendants?\n\nThe spec says \"yes\", but I don't think this is implementable (for instance,\nthe servlet responsible for \"/b\" may not even know about the existence of\n\"/a\").\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5133103"}, {"subject": "RE: Required properties with no value [WAS: workspace property on  resources that aren't in workspaces", "content": "Yes, I came to the same conclusion, so I'm now inclined instead to\n\"a\" (i.e. \"not present\") for compatibility with the defined behavior\nof DAV:checked-in and DAV:checked-out.  For what it's worth, this\nalso makes the structure of the XML somewhat more regular (i.e. a\nDAV:workspace node in a PROPFIND response always has a DAV:href child).\n\nIf nobody objects, I'll just add that to the Errata, and state that\nsection 6.2.1 is updated to define the the DAV:workspace property to\nbe present only if the resource is a workspace or the child of a\nresource that has a DAV:workspace property.\n\nIf you notice any other property definitions that need language of\nthis kind, please let me know.\n\nCheers,\nGeoff\n\n\n   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   I think this case is a bit different.\n\n   For DAV:checked-in and DAV:checked-out the spec is very clear that\n   they aren't *present* for resources that don't happen to be\n   checked-out / checked-in.\n\n   In *this* case (DAV:workspace), the spec is just silent about the\n   value for a resource that happens to be in no workspace.\n\n   Furthermore, I don't think a) would work for DAV:checked-in --\n   clients already check for the *presence* of this property to find\n   out whether a resource is checked-in, and RFC3253 explicitly says\n   this is ok...:\n\n   \"This property appears on a checked-in version-controlled resource,\n   and identifies a version that has the same content and dead\n   properties as the version-controlled resource. This property is\n   removed when the resource is checked out, and then added back\n   (identifying a new version) when the resource is checked back in.\"\n\n   --\n   <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n   -----Original Message-----\n   From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n   Sent: Thursday, September 26, 2002 8:27 PM\n   To: WebDAV (E-mail); ietf-dav-versioning@w3.org\n   Subject: Required properties with no value [WAS: workspace property on\nres ources that aren't in workspaces]\n\n\n   This is a good question, and it applies to any \"required\" property that \n   sometimes has \"no value\" (e.g. DAV:checked-in and DAV:checked-out). \n\n   So this question probably should be answered in 2518bis (I'll forward \n   this message to the WebDAV list), but we certainly could take a stab \n   at it in the DeltaV context first. \n\n   Like Julian, I'd probably be inclined to \"b\", but don't feel strongly \n   either way.  Anyone prefer \"a\", prefer to decide separately for each \n   property, or prefer that we leave it up to the server? \n\n   Cheers, \n   Geoff \n\n      From: Julian Reschke [mailto:julian.reschke@greenbytes.de] \n\n      section 6.2.1 [of rfc 3253] says: \n\n      \"The DAV:workspace property of a workspace resource MUST identify \n      itself.  The DAV:workspace property of any other type of resource \n      MUST be the same as the DAV:workspace of its parent collection.\" \n\n      It seems to be undefined however what the value is if a resource\ndoesn't \n      *have* a (DAV-compliant) parent collection, for instance the root of\nmy DAV \n      namespace. \n\n      So what should it be? \n\n      a) not present \n      b) empty (no href) \n\n      Julian (leaning to b) \n\n\n\n", "id": "lists-007-5141785"}, {"subject": "RE: again: OPTIONS semantic", "content": "I would classify two different servlets as two different\nservers, and so if the servlet handling the OPTIONS request\ndoes not know about the update feature, then it is expected\nto not return \"update\" in the DAV header.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@gmx.de]\nSent: Thursday, September 26, 2002 5:16 PM\nTo: ietf-dav-versioning@w3.org\nSubject: again: OPTIONS semantics\n\n\n\nJust taking an example from section 7:\n\n\"Additional OPTIONS Semantics\nIf the server supports the update feature, it MUST include \"update\" as a\nfield in the DAV response header from an OPTIONS request on any resource\nthat supports any versioning properties, reports, or methods.\"\n\n\nSo assuming my DAV namespace is separated into two parts (for instance by\nservlet) \"/a\" and \"/b\". Both parts of the server namespace support\nversioning, but only \"/a\" supports workspaces. Should the \"update\" feature\nbe reported on \"/b\" and it's descendants?\n\nThe spec says \"yes\", but I don't think this is implementable (for instance,\nthe servlet responsible for \"/b\" may not even know about the existence of\n\"/a\").\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5154158"}, {"subject": "RE: again: OPTIONS semantic", "content": "RE: again: OPTIONS semanticsOK,\n\nlet's take that further -- this is a real implementation issue, not just\nacademic.\n\nI have *one* servlet \"/a\" that controls access to different backends through\ndifferent namespace partitions such as \"/a/filesystem\", \"/a/jdbc\" and so\non... One backend may support workspaces, the other won't.\n\nWould you still consider this \"multiple\" servers?\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n  Sent: Thursday, September 26, 2002 11:22 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: RE: again: OPTIONS semantics\n\n\n  I would classify two different servlets as two different\n  servers, and so if the servlet handling the OPTIONS request\n  does not know about the update feature, then it is expected\n  to not return \"update\" in the DAV header.\n\n  Cheers,\n  Geoff\n\n  -----Original Message-----\n  From: Julian Reschke [mailto:julian.reschke@gmx.de]\n  Sent: Thursday, September 26, 2002 5:16 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: again: OPTIONS semantics\n\n\n\n\n  Just taking an example from section 7:\n\n  \"Additional OPTIONS Semantics\n  If the server supports the update feature, it MUST include \"update\" as a\n  field in the DAV response header from an OPTIONS request on any resource\n  that supports any versioning properties, reports, or methods.\"\n\n\n\n  So assuming my DAV namespace is separated into two parts (for instance by\n  servlet) \"/a\" and \"/b\". Both parts of the server namespace support\n  versioning, but only \"/a\" supports workspaces. Should the \"update\" feature\n  be reported on \"/b\" and it's descendants?\n\n  The spec says \"yes\", but I don't think this is implementable (for\ninstance,\n  the servlet responsible for \"/b\" may not even know about the existence of\n  \"/a\").\n\n  Julian\n\n  --\n  <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5163308"}, {"subject": "RE: again: OPTIONS semantic", "content": "Yes, I think it would be fine to consider different backends to be\ndifferent servers.  The only thing I'd insist on is that the OPTIONS\nrequest return \"update\" in the DAV header if the resource identified\nby the request-URL supports the UPDATE method.  Beyond that, I'd\njust do whatever makes sense for your implementation.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\nlet's take that further -- this is a real implementation issue, not just\nacademic.\n\nI have *one* servlet \"/a\" that controls access to different backends through\ndifferent namespace partitions such as \"/a/filesystem\", \"/a/jdbc\" and so\non... One backend may support workspaces, the other won't.\n\nWould you still consider this \"multiple\" servers?\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n-----Original Message-----\nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\nSent: Thursday, September 26, 2002 11:22 PM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: again: OPTIONS semantics\n\n\nI would classify two different servlets as two different \nservers, and so if the servlet handling the OPTIONS request \ndoes not know about the update feature, then it is expected \nto not return \"update\" in the DAV header. \nCheers, \nGeoff \n-----Original Message----- \nFrom: Julian Reschke [mailto:julian.reschke@gmx.de] \nSent: Thursday, September 26, 2002 5:16 PM \nTo: ietf-dav-versioning@w3.org \nSubject: again: OPTIONS semantics \n\n\n\nJust taking an example from section 7: \n\"Additional OPTIONS Semantics \nIf the server supports the update feature, it MUST include \"update\" as a \nfield in the DAV response header from an OPTIONS request on any resource \nthat supports any versioning properties, reports, or methods.\" \n\n\nSo assuming my DAV namespace is separated into two parts (for instance by \nservlet) \"/a\" and \"/b\". Both parts of the server namespace support \nversioning, but only \"/a\" supports workspaces. Should the \"update\" feature \nbe reported on \"/b\" and it's descendants? \nThe spec says \"yes\", but I don't think this is implementable (for instance, \nthe servlet responsible for \"/b\" may not even know about the existence of \n\"/a\"). \nJulian \n-- \n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n\n\n", "id": "lists-007-5174207"}, {"subject": "Re: UPDATE semantics for checked-out resource", "content": "While we're at this topic: we have a similar issue with auto-update of\nversion controlled collections.\n\n- checkout a versioned collection with apply-to-version\n- remove a member from the working collection\n- checkout in-place the member of the versioned controlled collection\n- checkin the working collection\n\n-> the version controlled collection should be updated an remove\n   the binding to the checked-out resource.\n\nI think the checkin should fail in this case, as the removal of\na checked-out member might cannot be permitted.\n\nDo you agree?\n\n//Stefan\n\nAm Donnerstag, 26.09.02, um 20:33 Uhr (Europe/Berlin) schrieb Clemm, \nGeoff:\n\n> ?? From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n> ?? section 7.1 defines the UPDATE semantics checked-in resources:\n>\n> ?? \"The UPDATE method modifies the content and dead properties of a\n> ?? checked-in version-controlled resource (the \"update target\") to be\n> ?? those of a specified version (the \"update source\") from the version\n> ?? history of that version-controlled resource.\"\n>\n> ?? So is the behaviour for checked-out resources just undefined\n> ?? (intentionally)?\n>\n> ?? I would have expected that DAV:must-be-checked-in is an explicit\n> ?? precondition for this method...\n>\n> I agree that adding the DAV:must-be-checked-in precondition is the\n> better answer.? I'll add this to the Errata, and resolve it by adding\n> that precondition, unless someone objects.\n>\n> Cheers,\n> Geoff\n>\n\n\n\n", "id": "lists-007-5185021"}, {"subject": "RE: UPDATE semantics for checked-out resource", "content": "I agree with your conclusion, but I believe this follows from\nthe DAV:no-overwrite-by-auto-update precondition for CHECKIN, i.e.:\n\n If the DAV:auto-update property for the checked-out resource\n identifies a version-controlled resource, at least one of the\n versions identified by the DAV:predecessor-set property of the\n checked-out resource MUST identify a version that is either the same\n as or a descendant of the version identified by the DAV:checked-in\n property of that version-controlled resource.\n\nIf the VCR is checked-out, there is no DAV:checked-in version,\nwhich means this precondition would not be satisfied.\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\nSent: Friday, September 27, 2002 4:48 AM\nTo: Clemm, Geoff\nCc: ietf-dav-versioning@w3.org\nSubject: Re: UPDATE semantics for checked-out resources\n\n\nWhile we're at this topic: we have a similar issue with auto-update of\nversion controlled collections.\n\n- checkout a versioned collection with apply-to-version\n- remove a member from the working collection\n- checkout in-place the member of the versioned controlled collection\n- checkin the working collection\n\n-> the version controlled collection should be updated an remove\n   the binding to the checked-out resource.\n\nI think the checkin should fail in this case, as the removal of\na checked-out member might cannot be permitted.\n\nDo you agree?\n\n\n\n", "id": "lists-007-5194431"}, {"subject": "AW: UPDATE semantics for checked-out resource", "content": "RE: UPDATE semantics for checked-out resourcesThis is true, but it does not\napply to the more general case of an UPDATE\nof a version.controlled collection containing a checked-out resource which\nis not identified\nby the DAV:version-controlled-binding-set of the update source.\n\nCheers, Manfred\n  -----Urspr?ngliche Nachricht-----\n  Von: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]Im Auftrag von Clemm, Geoff T\n  Gesendet: Freitag, 27. September 2002 14:00\n  An: ietf-dav-versioning@w3.org\n  Betreff: RE: UPDATE semantics for checked-out resources\n\n\n  I agree with your conclusion, but I believe this follows from\n  the DAV:no-overwrite-by-auto-update precondition for CHECKIN, i.e.:\n\n   If the DAV:auto-update property for the checked-out resource\n   identifies a version-controlled resource, at least one of the\n   versions identified by the DAV:predecessor-set property of the\n   checked-out resource MUST identify a version that is either the same\n   as or a descendant of the version identified by the DAV:checked-in\n   property of that version-controlled resource.\n\n  If the VCR is checked-out, there is no DAV:checked-in version,\n  which means this precondition would not be satisfied.\n\n  Cheers,\n  Geoff\n\n\n\n  -----Original Message-----\n  From: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\n  Sent: Friday, September 27, 2002 4:48 AM\n  To: Clemm, Geoff\n  Cc: ietf-dav-versioning@w3.org\n  Subject: Re: UPDATE semantics for checked-out resources\n\n\n\n  While we're at this topic: we have a similar issue with auto-update of\n  version controlled collections.\n\n  - checkout a versioned collection with apply-to-version\n  - remove a member from the working collection\n  - checkout in-place the member of the versioned controlled collection\n  - checkin the working collection\n\n  -> the version controlled collection should be updated an remove\n     the binding to the checked-out resource.\n\n  I think the checkin should fail in this case, as the removal of\n  a checked-out member might cannot be permitted.\n\n  Do you agree?\n\n\n\n", "id": "lists-007-5203888"}, {"subject": "RE: UPDATE semantics for checked-out resource", "content": "Apologies, I misread the original message (i.e. the issue is the\ncheckout of a member of the collection, not a checkout of the\ncollection).\n\nThis is just one way in which you can delete a checked-out VCR, and\ncurrently, deleting a checked-out VCR is allowed by the protocol.\n\nStefan: Were you suggesting that it be disallowed just in this case,\nor disallowed in general (e.g. add it as a precondition to the DELETE\nmethod).\n\nFor now, I'll just add this to the Errata document as an open issue,\nsince disallowing deletion of a checked-out VCR would be a change\nto the protocol semantics.\n\nSo, to get some initial feedback, who thinks we should disallow the\ndeletion of a checked-out VCR?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Manfred Baedke [mailto:manfred.baedke@greenbytes.de]\nSent: Friday, September 27, 2002 9:21 AM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: AW: UPDATE semantics for checked-out resources\n\n\nThis is true, but it does not apply to the more general case of an UPDATE\nof a version.controlled collection containing a checked-out resource which\nis not identified\nby the DAV:version-controlled-binding-set of the update source.\n\nCheers, Manfred\n-----Urspr?ngliche Nachricht-----\nVon: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]Im Auftrag von Clemm, Geoff T \nGesendet: Freitag, 27. September 2002 14:00\nAn: ietf-dav-versioning@w3.org\nBetreff: RE: UPDATE semantics for checked-out resources\n\n\nI agree with your conclusion, but I believe this follows from \nthe DAV:no-overwrite-by-auto-update precondition for CHECKIN, i.e.: \n If the DAV:auto-update property for the checked-out resource \n identifies a version-controlled resource, at least one of the \n versions identified by the DAV:predecessor-set property of the \n checked-out resource MUST identify a version that is either the same \n as or a descendant of the version identified by the DAV:checked-in \n property of that version-controlled resource. \nIf the VCR is checked-out, there is no DAV:checked-in version, \nwhich means this precondition would not be satisfied. \nCheers, \nGeoff \n\n\n-----Original Message----- \nFrom: Stefan Eissing [mailto:stefan.eissing@greenbytes.de] \nSent: Friday, September 27, 2002 4:48 AM \nTo: Clemm, Geoff \nCc: ietf-dav-versioning@w3.org \nSubject: Re: UPDATE semantics for checked-out resources \n\n\nWhile we're at this topic: we have a similar issue with auto-update of \nversion controlled collections. \n- checkout a versioned collection with apply-to-version \n- remove a member from the working collection \n- checkout in-place the member of the versioned controlled collection \n- checkin the working collection \n-> the version controlled collection should be updated an remove \n   the binding to the checked-out resource. \nI think the checkin should fail in this case, as the removal of \na checked-out member might cannot be permitted. \nDo you agree? \n\n\n\n", "id": "lists-007-5215147"}, {"subject": "Re: UPDATE semantics for checked-out resource", "content": "Am Freitag, 27.09.02, um 16:13 Uhr (Europe/Berlin) schrieb Clemm, Geoff:\n\n> Apologies, I misread the original message (i.e. the issue is the\n> checkout of a member of the collection, not a checkout of the\n> collection).\n>\n> This is just one way in which you can delete a checked-out VCR, and\n> currently, deleting a checked-out VCR is allowed by the protocol.\n\nI see where this is going...\n\nI think DELETE on a checked-out VCR must be ok. However if I UPDATE\na collection and someone else checked out the contained VCR and\nthat VCR is silently deleted, all his/her changes are lost.\n\nWhich can happen anyway, unless she/he locks the VCR.\n\nTherefore I change my mind and from now on to forver say that\nexplicit and implicit DELETE on checked-out resources are \"OK\".\n\n//Stefan\n\n> Stefan: Were you suggesting that it be disallowed just in this case,\n> or disallowed in general (e.g. add it as a precondition to the DELETE\n> method).\n>\n> For now, I'll just add this to the Errata document as an open issue,\n> since disallowing deletion of a checked-out VCR would be a change\n> to the protocol semantics.\n>\n> So, to get some initial feedback, who thinks we should disallow the\n> deletion of a checked-out VCR?\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Manfred Baedke [mailto:manfred.baedke@greenbytes.de]\n> Sent: Friday, September 27, 2002 9:21 AM\n> To: Clemm, Geoff; ietf-dav-versioning@w3.org\n> Subject: AW: UPDATE semantics for checked-out resources\n>\n>\n> This is true, but it does not apply to the more general case of an \n> UPDATE\n> of a version.controlled collection containing a checked-out resource \n> which is not identified\n> by the DAV:version-controlled-binding-set of the update source.\n>\n> Cheers, Manfred\n> -----Urspr?ngliche Nachricht-----\n> Von: ietf-dav-versioning-request@w3.org \n> [mailto:ietf-dav-versioning-request@w3.org]Im Auftrag von Clemm, Geoff \n> T\n> Gesendet: Freitag, 27. September 2002 14:00\n> An: ietf-dav-versioning@w3.org\n> Betreff: RE: UPDATE semantics for checked-out resources\n>\n>\n> I agree with your conclusion, but I believe this follows from\n> the DAV:no-overwrite-by-auto-update precondition for CHECKIN, i.e.:\n> ?If the DAV:auto-update property for the checked-out resource\n> ?identifies a version-controlled resource, at least one of the\n> ?versions identified by the DAV:predecessor-set property of the\n> ?checked-out resource MUST identify a version that is either the same\n> ?as or a descendant of the version identified by the DAV:checked-in\n> ?property of that version-controlled resource.\n> If the VCR is checked-out, there is no DAV:checked-in version,\n> which means this precondition would not be satisfied.\n> Cheers,\n> Geoff\n>\n>\n> -----Original Message-----\n> From: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\n> Sent: Friday, September 27, 2002 4:48 AM\n> To: Clemm, Geoff\n> Cc: ietf-dav-versioning@w3.org\n> Subject: Re: UPDATE semantics for checked-out resources\n>\n>\n> While we're at this topic: we have a similar issue with auto-update of\n> version controlled collections.\n> - checkout a versioned collection with apply-to-version\n> - remove a member from the working collection\n> - checkout in-place the member of the versioned controlled collection\n> - checkin the working collection\n> -> the version controlled collection should be updated an remove\n> ?? the binding to the checked-out resource.\n> I think the checkin should fail in this case, as the removal of\n> a checked-out member might cannot be permitted.\n> Do you agree?\n>\n\n\n\n", "id": "lists-007-5227497"}, {"subject": "RE: UPDATE semantics for checked-out resource", "content": "OK, unless anyone wants to suggest otherwise, I'll just\nconsider the issue closed, and not bother adding it to\nthe Errata.\n\nCheers,\nGeoff\n\n(For some reason, I'm getting my posts back as HTML, which\nis really strange since I send them out in plain text ...)\n\n-----Original Message-----\nFrom: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\nSent: Friday, September 27, 2002 10:26 AM\nTo: Clemm, Geoff\nCc: ietf-dav-versioning@w3.org\nSubject: Re: UPDATE semantics for checked-out resources\n\n\n\nAm Freitag, 27.09.02, um 16:13 Uhr (Europe/Berlin) schrieb Clemm, Geoff:\n\n> Apologies, I misread the original message (i.e. the issue is the\n> checkout of a member of the collection, not a checkout of the\n> collection).\n>\n> This is just one way in which you can delete a checked-out VCR, and\n> currently, deleting a checked-out VCR is allowed by the protocol.\n\nI see where this is going...\n\nI think DELETE on a checked-out VCR must be ok. However if I UPDATE\na collection and someone else checked out the contained VCR and\nthat VCR is silently deleted, all his/her changes are lost.\n\nWhich can happen anyway, unless she/he locks the VCR.\n\nTherefore I change my mind and from now on to forver say that\nexplicit and implicit DELETE on checked-out resources are \"OK\".\n\n//Stefan\n\n> Stefan: Were you suggesting that it be disallowed just in this case,\n> or disallowed in general (e.g. add it as a precondition to the DELETE\n> method).\n>\n> For now, I'll just add this to the Errata document as an open issue,\n> since disallowing deletion of a checked-out VCR would be a change\n> to the protocol semantics.\n>\n> So, to get some initial feedback, who thinks we should disallow the\n> deletion of a checked-out VCR?\n>\n> Cheers,\n> Geoff\n>\n> -----Original Message-----\n> From: Manfred Baedke [mailto:manfred.baedke@greenbytes.de]\n> Sent: Friday, September 27, 2002 9:21 AM\n> To: Clemm, Geoff; ietf-dav-versioning@w3.org\n> Subject: AW: UPDATE semantics for checked-out resources\n>\n>\n> This is true, but it does not apply to the more general case of an \n> UPDATE\n> of a version.controlled collection containing a checked-out resource \n> which is not identified\n> by the DAV:version-controlled-binding-set of the update source.\n>\n> Cheers, Manfred\n> -----Urspr?ngliche Nachricht-----\n> Von: ietf-dav-versioning-request@w3.org \n> [mailto:ietf-dav-versioning-request@w3.org]Im Auftrag von Clemm, Geoff \n> T\n> Gesendet: Freitag, 27. September 2002 14:00\n> An: ietf-dav-versioning@w3.org\n> Betreff: RE: UPDATE semantics for checked-out resources\n>\n>\n> I agree with your conclusion, but I believe this follows from\n> the DAV:no-overwrite-by-auto-update precondition for CHECKIN, i.e.:\n> ?If the DAV:auto-update property for the checked-out resource\n> ?identifies a version-controlled resource, at least one of the\n> ?versions identified by the DAV:predecessor-set property of the\n> ?checked-out resource MUST identify a version that is either the same\n> ?as or a descendant of the version identified by the DAV:checked-in\n> ?property of that version-controlled resource.\n> If the VCR is checked-out, there is no DAV:checked-in version,\n> which means this precondition would not be satisfied.\n> Cheers,\n> Geoff\n>\n>\n> -----Original Message-----\n> From: Stefan Eissing [mailto:stefan.eissing@greenbytes.de]\n> Sent: Friday, September 27, 2002 4:48 AM\n> To: Clemm, Geoff\n> Cc: ietf-dav-versioning@w3.org\n> Subject: Re: UPDATE semantics for checked-out resources\n>\n>\n> While we're at this topic: we have a similar issue with auto-update of\n> version controlled collections.\n> - checkout a versioned collection with apply-to-version\n> - remove a member from the working collection\n> - checkout in-place the member of the versioned controlled collection\n> - checkin the working collection\n> -> the version controlled collection should be updated an remove\n> ?? the binding to the checked-out resource.\n> I think the checkin should fail in this case, as the removal of\n> a checked-out member might cannot be permitted.\n> Do you agree?\n>\n\n\n\n", "id": "lists-007-5240812"}, {"subject": "Issues 5.5_USE_PROPERTIES and 5.5_OPTIONS_BOD", "content": "Proposed resolution:\n\n1) Deprecate marshalling through OPTIONS.\n\n2) Add three new live properties:\n\n----------------------\n\n(Version histories)\n\n5.2        Additional Resource Properties\n\nThe version-history feature introduces the following REQUIRED property for\nresources that reside in a part of a server's namespace that supports\nversion histories.\n\n5.1.1           DAV:version-history-collection-set (protected)\n\nThe DAV:version-history-collection-set property identifies collections that\nmay contain version histories.  An identified collection MAY be the root\ncollection of a tree of collections, all of which may contain version\nhistories.  Since different servers can control different parts of the URL\nnamespace, different resources on the same host MAY have different\nDAV:version-history-collection-set values.  The identified collections MAY\nbe located on different hosts from the resource.\n\n<!ELEMENT version-history-collection-set (href+)>\n\n\n----------------------\n\n(Workspaces)\n\n6.2.1           DAV:workspace-collection-set (protected)\n\nThe DAV:workspace-collection-set property  identifies collections that may\ncontain workspaces.  An identified collection MAY be the root collection of\na tree of collections, all of which may contain workspaces.  Since different\nservers can control different parts of the URL namespace, different\nresources on the same host MAY have different DAV:workspace-collection-set\nvalues.  The identified collections MAY be located on different hosts from\nthe resource.\n\n<!ELEMENT workspace-collection-set (href)>\n\n----------------------\n\n(Activities)\n\n\n13.4    Additional Resource Properties\n\nThe activity feature introduces the following REQUIRED property for\nresources that reside in a part of the server's namespace supporting\nactivities.\n\n13.4.1       DAV:activity-collection-set (protected)\n\nThe DAV:activity-collection-set property  identifies collections that may\ncontain activities.  An identified collection MAY be the root collection of\na tree of collections, all of which may contain activities.  Since different\nservers can control different parts of the URL namespace, different\nresources on the same host MAY have different DAV:activity-collection-set\nvalues.  The identified collections MAY be located on different hosts from\nthe resource.\n\n<!ELEMENT activity-collection-set (href*)>\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5255058"}, {"subject": "RE: Issues 5.5_USE_PROPERTIES and 5.5_OPTIONS_BOD", "content": "I agree with the proposed resolution. \nUnless someone disagrees, I will add this to the Errata sheet,\nand mark the issue as closed.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Saturday, September 28, 2002 11:50 AM\nTo: ietf-dav-versioning@w3.org\nSubject: Issues 5.5_USE_PROPERTIES and 5.5_OPTIONS_BODY\n\n\n\nProposed resolution:\n\n1) Deprecate marshalling through OPTIONS.\n\n2) Add three new live properties:\n\n----------------------\n\n(Version histories)\n\n5.2        Additional Resource Properties\n\nThe version-history feature introduces the following REQUIRED property for\nresources that reside in a part of a server's namespace that supports\nversion histories.\n\n5.1.1           DAV:version-history-collection-set (protected)\n\nThe DAV:version-history-collection-set property identifies collections that\nmay contain version histories.  An identified collection MAY be the root\ncollection of a tree of collections, all of which may contain version\nhistories.  Since different servers can control different parts of the URL\nnamespace, different resources on the same host MAY have different\nDAV:version-history-collection-set values.  The identified collections MAY\nbe located on different hosts from the resource.\n\n<!ELEMENT version-history-collection-set (href+)>\n\n\n----------------------\n\n(Workspaces)\n\n6.2.1           DAV:workspace-collection-set (protected)\n\nThe DAV:workspace-collection-set property  identifies collections that may\ncontain workspaces.  An identified collection MAY be the root collection of\na tree of collections, all of which may contain workspaces.  Since different\nservers can control different parts of the URL namespace, different\nresources on the same host MAY have different DAV:workspace-collection-set\nvalues.  The identified collections MAY be located on different hosts from\nthe resource.\n\n<!ELEMENT workspace-collection-set (href)>\n\n----------------------\n\n(Activities)\n\n\n13.4    Additional Resource Properties\n\nThe activity feature introduces the following REQUIRED property for\nresources that reside in a part of the server's namespace supporting\nactivities.\n\n13.4.1       DAV:activity-collection-set (protected)\n\nThe DAV:activity-collection-set property  identifies collections that may\ncontain activities.  An identified collection MAY be the root collection of\na tree of collections, all of which may contain activities.  Since different\nservers can control different parts of the URL namespace, different\nresources on the same host MAY have different DAV:activity-collection-set\nvalues.  The identified collections MAY be located on different hosts from\nthe resource.\n\n<!ELEMENT activity-collection-set (href*)>\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5265143"}, {"subject": "euh... I musta blinke", "content": "Where did the mutable stuff go? Did that get yanked out into a separate I-D\nor something? We (svn) wanted to make a particular resource mutable, but\nthere are no longer guidelines...\n\nthx,\n-g\n\n-- \nGreg Stein, http://www.lyra.org/\n\n\n\n", "id": "lists-007-5275477"}, {"subject": "UPDATE responses for versioned collection", "content": "Hi,\n\nthe spec says about the UPDATE method [1]:\n\n\"The response to an UPDATE request identifies the resources modified by the\nrequest, so that a client can efficiently update any cached state it is\nmaintaining. Extensions to the UPDATE method allow multiple resources to be\nmodified from a single UPDATE request (see Section 12.13). \"\n\nWhen a versioned collection is updated, this may affect the versioned\ncollections and all it's internal members. One possible state transition is\nthat a child is removed.\n\nFor instance, let \"/a\" be a versioned collection with a version controlled\nmember \"/a/b\". I update \"/a\" from a collection version which doesn't have\n\"b\" in it's version-controlled-binding-set. \"/a/b\" gets removed. What\nresponse do we expect?\n\n <D:multistatus xmlns:D=\"DAV:\">\n  <D:response>\n    <D:href>/a/</D:href>\n    <D:status>HTTP/1.1 200 OK</D:status>\n  </D:response>\n  <D:response>\n    <D:href>/a/b</D:href>\n    <D:status>HTTP/1.1 404 Not Found</D:status>\n  </D:response>\n</D:multistatus>\n\nor\n\n <D:multistatus xmlns:D=\"DAV:\">\n  <D:response>\n    <D:href>/a/</D:href>\n    <D:status>HTTP/1.1 200 OK</D:status>\n  </D:response>\n</D:multistatus>\n\n?\n\n\n[1] <http://greenbytes.de/tech/webdav/rfc3253.html#METHOD_UPDATE>\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5375125"}, {"subject": "RE: euh... I musta blinke", "content": "The \"mutable version\" stuff evolved into \"variants\", and\nthen got yanked a few months before we went to final call,\nbecause of lack of interest in supporting it.\n\nThe Variant ID never did get posted (and would have expired\nby now anyway :-), but I still have a copy, and will post it\nto the WebDAV/DeltaV web site, and submit it as an ID.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Greg Stein [mailto:gstein@lyra.org]\nSent: Monday, September 30, 2002 10:36 PM\nTo: ietf-dav-versioning@w3.org\nSubject: euh... I musta blinked\n\n\n\nWhere did the mutable stuff go? Did that get yanked out into a separate I-D\nor something? We (svn) wanted to make a particular resource mutable, but\nthere are no longer guidelines...\n\nthx,\n-g\n\n-- \nGreg Stein, http://www.lyra.org/\n\n\n\n", "id": "lists-007-5384136"}, {"subject": "DAV:workspace propert", "content": "Hi,\n\na very basic question...\n\nThe workspace feature introduces a live (protected) resource property which\nseems to depend on the URI of the resource, not the resource itself:\n\n\" If the request-URL did not identify a workspace, the DAV:workspace of the\ndestination MUST have been updated to have the same value as the\nDAV:workspace of the parent collection of the destination.\"\n\nTo me this seems to indicate that it's not really a property of the resource\nitself, but that it only depends on how you access the resurce.\n\nHow does this property affect bindings to a resource in a workspace?\n\na) there may be no additional bindings\n\nb) there may be additional bindings, but they must all reside in the same\nworkspace's namespace\n\nc) there may be additional bindings, and the reported DAV:workspace property\njust depends on the URI used in the request\n\n(I currently lean towards c)\n\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5391716"}, {"subject": "RE: UPDATE responses for versioned collection", "content": "I would expect the latter, i.e. just the fact that the\nversioned collection had changed.  The client would then\nlook at the DAV:version-controlled-binding-set of the\nDAV:checked-in version of the collection to see how it\nshould update its local state (it needs to do that to\ndifferentiate a delete/add from a move).\n\nOne benefit of this approach is that it doesn't cause \na flood of responses if you move a folder with 1000\nmembers (i.e. it would return just the source and destination\ncollections of the move, rather that 1000 added entries\nand 1000 deleted entries).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@gmx.de]\nSent: Tuesday, October 01, 2002 9:05 AM\nTo: ietf-dav-versioning@w3.org\nSubject: UPDATE responses for versioned collections\n\n\n\nHi,\n\nthe spec says about the UPDATE method [1]:\n\n\"The response to an UPDATE request identifies the resources modified by the\nrequest, so that a client can efficiently update any cached state it is\nmaintaining. Extensions to the UPDATE method allow multiple resources to be\nmodified from a single UPDATE request (see Section 12.13). \"\n\nWhen a versioned collection is updated, this may affect the versioned\ncollections and all it's internal members. One possible state transition is\nthat a child is removed.\n\nFor instance, let \"/a\" be a versioned collection with a version controlled\nmember \"/a/b\". I update \"/a\" from a collection version which doesn't have\n\"b\" in it's version-controlled-binding-set. \"/a/b\" gets removed. What\nresponse do we expect?\n\n <D:multistatus xmlns:D=\"DAV:\">\n  <D:response>\n    <D:href>/a/</D:href>\n    <D:status>HTTP/1.1 200 OK</D:status>\n  </D:response>\n  <D:response>\n    <D:href>/a/b</D:href>\n    <D:status>HTTP/1.1 404 Not Found</D:status>\n  </D:response>\n</D:multistatus>\n\nor\n\n <D:multistatus xmlns:D=\"DAV:\">\n  <D:response>\n    <D:href>/a/</D:href>\n    <D:status>HTTP/1.1 200 OK</D:status>\n  </D:response>\n</D:multistatus>\n\n?\n\n\n[1] <http://greenbytes.de/tech/webdav/rfc3253.html#METHOD_UPDATE>\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5399841"}, {"subject": "RE: workspace propert", "content": "No, the DAV:workspace is not affected by the request-URL that you\nuse to identify the URL (that would be bad for a variety of reasons).\nThe only way you can have two different URLs for the same resource is\nif you have two bindings to either the resource or to a parent of the\nresource.  In this case, some resource has multiple parents, and which\nparent is picked for inheritance of the DAV:workspace property is up to\nthe server (but it has to pick one, and return it consistently).\n\nSo the answer was: (d) None of the above (:-).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Tuesday, October 01, 2002 1:49 PM\nTo: ietf-dav-versioning@w3.org\nSubject: DAV:workspace property\n\n\n\nHi,\n\na very basic question...\n\nThe workspace feature introduces a live (protected) resource property which\nseems to depend on the URI of the resource, not the resource itself:\n\n\" If the request-URL did not identify a workspace, the DAV:workspace of the\ndestination MUST have been updated to have the same value as the\nDAV:workspace of the parent collection of the destination.\"\n\nTo me this seems to indicate that it's not really a property of the resource\nitself, but that it only depends on how you access the resurce.\n\nHow does this property affect bindings to a resource in a workspace?\n\na) there may be no additional bindings\n\nb) there may be additional bindings, but they must all reside in the same\nworkspace's namespace\n\nc) there may be additional bindings, and the reported DAV:workspace property\njust depends on the URI used in the request\n\n(I currently lean towards c)\n\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5410181"}, {"subject": "RE: UPDATE responses for versioned collection", "content": "Well,\n\nin this case we would have an erratum for 7.1:\n\n\"The response for a successful request MUST be a 207 Multi-Status, where the\nDAV:multistatus XML element in the response body identifies all resources\nthat have been modified by the request.\"\n\nI also don't understand the second part of your reply -- we're talking about\nresponse marshalling for UPDATE, not MOVE. What am I missing?\n\nJulian\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n-----Original Message-----\nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\nSent: Tuesday, October 01, 2002 8:25 PM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: UPDATE responses for versioned collections\n\n\nI would expect the latter, i.e. just the fact that the\nversioned collection had changed.  The client would then\nlook at the DAV:version-controlled-binding-set of the\nDAV:checked-in version of the collection to see how it\nshould update its local state (it needs to do that to\ndifferentiate a delete/add from a move).\nOne benefit of this approach is that it doesn't cause\na flood of responses if you move a folder with 1000\nmembers (i.e. it would return just the source and destination\ncollections of the move, rather that 1000 added entries\nand 1000 deleted entries).\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-5419431"}, {"subject": "RE: workspace propert", "content": "RE: workspace propertyNot convinced yet :-)\n\nThe idea of a resource property which changes it's value upon MOVE isn't\nreally appealing -- the properties of a resource should be independant of\nthe access path.\n\nUp to now, I was expecting a MOVE to have the same properties as a BIND\nfollowed by a DELETE on the original URI -- this would be lost with your\ninterpretation.\n\nQuestion: what is the use case for MOVEs between workspaces? Wouldn't it be\nmuch simpler to just forbid that?\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n  Sent: Tuesday, October 01, 2002 8:30 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: RE: workspace property\n\n\n  No, the DAV:workspace is not affected by the request-URL that you\n  use to identify the URL (that would be bad for a variety of reasons).\n  The only way you can have two different URLs for the same resource is\n  if you have two bindings to either the resource or to a parent of the\n  resource.  In this case, some resource has multiple parents, and which\n  parent is picked for inheritance of the DAV:workspace property is up to\n  the server (but it has to pick one, and return it consistently).\n\n  So the answer was: (d) None of the above (:-).\n\n  Cheers,\n  Geoff\n\n  -----Original Message-----\n  From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n  Sent: Tuesday, October 01, 2002 1:49 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: DAV:workspace property\n\n\n\n\n  Hi,\n\n  a very basic question...\n\n  The workspace feature introduces a live (protected) resource property\nwhich\n  seems to depend on the URI of the resource, not the resource itself:\n\n  \" If the request-URL did not identify a workspace, the DAV:workspace of\nthe\n  destination MUST have been updated to have the same value as the\n  DAV:workspace of the parent collection of the destination.\"\n\n  To me this seems to indicate that it's not really a property of the\nresource\n  itself, but that it only depends on how you access the resurce.\n\n  How does this property affect bindings to a resource in a workspace?\n\n  a) there may be no additional bindings\n\n  b) there may be additional bindings, but they must all reside in the same\n  workspace's namespace\n\n  c) there may be additional bindings, and the reported DAV:workspace\nproperty\n  just depends on the URI used in the request\n\n  (I currently lean towards c)\n\n\n\n  Julian\n\n  --\n  <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5429276"}, {"subject": "RE: UPDATE responses for versioned collection", "content": "Why do we need an errata entry?  The question is whether removing a\nbinding to a resource is considered a modification to the\nresource, or a modification to the collection containing the\nbinding.  For the purposes of UPDATE, I believe it should be\nconsidered a modification to the collection containing the\nbinding only.\n\nThe \"move\" (lower case) I was referring to was a multi-resource\nupdate that would result from a labeled update, or a baseline update.\nSuch a multi-resource update could result in a logical move of\na subtree from one URL to another.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Tuesday, October 01, 2002 2:54 PM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: UPDATE responses for versioned collections\n\n\nWell,\n\nin this case we would have an erratum for 7.1:\n\n\"The response for a successful request MUST be a 207 Multi-Status, where the\nDAV:multistatus XML element in the response body identifies all resources\nthat have been modified by the request.\"\n\nI also don't understand the second part of your reply -- we're talking about\nresponse marshalling for UPDATE, not MOVE. What am I missing?\n\nJulian\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n-----Original Message-----\nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\nSent: Tuesday, October 01, 2002 8:25 PM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: UPDATE responses for versioned collections\n\n\nI would expect the latter, i.e. just the fact that the\nversioned collection had changed.  The client would then\nlook at the DAV:version-controlled-binding-set of the\nDAV:checked-in version of the collection to see how it\nshould update its local state (it needs to do that to\ndifferentiate a delete/add from a move).\nOne benefit of this approach is that it doesn't cause\na flood of responses if you move a folder with 1000\nmembers (i.e. it would return just the source and destination\ncollections of the move, rather that 1000 added entries\nand 1000 deleted entries).\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-5440611"}, {"subject": "RE: UPDATE responses for versioned collection", "content": "RE: UPDATE responses for versioned collectionsHmm.\n\nLet's phrase it differently: in the absence of the baseline feature, is\nthere any case where an update for a version controlled collection would\naffect the state of more than one resource (being the collection itself)?\n\nJulian\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n  Sent: Tuesday, October 01, 2002 9:09 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: RE: UPDATE responses for versioned collections\n\n\n  Why do we need an errata entry?  The question is whether removing a\n  binding to a resource is considered a modification to the\n  resource, or a modification to the collection containing the\n  binding.  For the purposes of UPDATE, I believe it should be\n  considered a modification to the collection containing the\n  binding only.\n\n  The \"move\" (lower case) I was referring to was a multi-resource\n  update that would result from a labeled update, or a baseline update.\n  Such a multi-resource update could result in a logical move of\n  a subtree from one URL to another.\n\n  Cheers,\n  Geoff\n\n  -----Original Message-----\n  From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n  Sent: Tuesday, October 01, 2002 2:54 PM\n  To: Clemm, Geoff; ietf-dav-versioning@w3.org\n  Subject: RE: UPDATE responses for versioned collections\n\n\n\n  Well,\n\n  in this case we would have an erratum for 7.1:\n\n  \"The response for a successful request MUST be a 207 Multi-Status, where\nthe\n  DAV:multistatus XML element in the response body identifies all resources\n  that have been modified by the request.\"\n\n  I also don't understand the second part of your reply -- we're talking\nabout\n  response marshalling for UPDATE, not MOVE. What am I missing?\n\n  Julian\n  --\n  <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n  [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n  Sent: Tuesday, October 01, 2002 8:25 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: RE: UPDATE responses for versioned collections\n\n\n\n  I would expect the latter, i.e. just the fact that the\n  versioned collection had changed.  The client would then\n  look at the DAV:version-controlled-binding-set of the\n  DAV:checked-in version of the collection to see how it\n  should update its local state (it needs to do that to\n  differentiate a delete/add from a move).\n  One benefit of this approach is that it doesn't cause\n  a flood of responses if you move a folder with 1000\n  members (i.e. it would return just the source and destination\n  collections of the move, rather that 1000 added entries\n  and 1000 deleted entries).\n  Cheers,\n  Geoff\n\n\n\n", "id": "lists-007-5451605"}, {"subject": "RE: UPDATE responses for versioned collection", "content": "The other case would be with Depth and labels\n(see section 8.5).  So the marshalling for UPDATE\nwas defined with those two cases in mind (i.e. when\nmultiple resources could be affected by an UPDATE).\n\nWe could have defined UPDATE to return DAV:multistatus\nonly if there were multiple resources affected by the\nUPDATE, but it was thought simpler to just always require\nthe multistatus (probably not a big deal either way,\nbut that was where we ended up).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Tuesday, October 01, 2002 3:24 PM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: UPDATE responses for versioned collections\n\n\nHmm.\n\nLet's phrase it differently: in the absence of the baseline feature, is\nthere any case where an update for a version controlled collection would\naffect the state of more than one resource (being the collection itself)?\n\nJulian\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n-----Original Message-----\nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\nSent: Tuesday, October 01, 2002 9:09 PM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: UPDATE responses for versioned collections\n\n\nWhy do we need an errata entry?  The question is whether removing a \nbinding to a resource is considered a modification to the \nresource, or a modification to the collection containing the \nbinding.  For the purposes of UPDATE, I believe it should be \nconsidered a modification to the collection containing the \nbinding only. \nThe \"move\" (lower case) I was referring to was a multi-resource \nupdate that would result from a labeled update, or a baseline update. \nSuch a multi-resource update could result in a logical move of \na subtree from one URL to another. \nCheers, \nGeoff \n-----Original Message----- \nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de] \nSent: Tuesday, October 01, 2002 2:54 PM \nTo: Clemm, Geoff; ietf-dav-versioning@w3.org \nSubject: RE: UPDATE responses for versioned collections \n\n\nWell, \nin this case we would have an erratum for 7.1: \n\"The response for a successful request MUST be a 207 Multi-Status, where the\n\nDAV:multistatus XML element in the response body identifies all resources \nthat have been modified by the request.\" \nI also don't understand the second part of your reply -- we're talking about\n\nresponse marshalling for UPDATE, not MOVE. What am I missing? \nJulian \n-- \n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n-----Original Message----- \nFrom: ietf-dav-versioning-request@w3.org \n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff \nSent: Tuesday, October 01, 2002 8:25 PM \nTo: ietf-dav-versioning@w3.org \nSubject: RE: UPDATE responses for versioned collections \n\n\nI would expect the latter, i.e. just the fact that the \nversioned collection had changed.  The client would then \nlook at the DAV:version-controlled-binding-set of the \nDAV:checked-in version of the collection to see how it \nshould update its local state (it needs to do that to \ndifferentiate a delete/add from a move). \nOne benefit of this approach is that it doesn't cause \na flood of responses if you move a folder with 1000 \nmembers (i.e. it would return just the source and destination \ncollections of the move, rather that 1000 added entries \nand 1000 deleted entries). \nCheers, \nGeoff \n\n\n\n", "id": "lists-007-5464575"}, {"subject": "RE: workspace propert", "content": "Just forbidding the MOVE is certainly reasonable behavior from a server\n(that's what our server will do :-).  There is precedent for having a\nproperty that is modified by a DELETE (e.g. the \"DAV:parent-set\" of a\nresource that supports multiple bindings), but one certainly would\nlike to minimize the number of properties that act this way.\n\nBefore banning a cross-workspace move in the protocol though, I'd probably\nprefer to wait a bit to make sure that this is in fact something that\ndoes not turn out to be generally useful/supported.\n\nCheers,\nGeoff\n\n\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Tuesday, October 01, 2002 3:05 PM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: workspace property\n\n\nNot convinced yet :-)\n\nThe idea of a resource property which changes it's value upon MOVE isn't\nreally appealing -- the properties of a resource should be independant of\nthe access path.\n\nUp to now, I was expecting a MOVE to have the same properties as a BIND\nfollowed by a DELETE on the original URI -- this would be lost with your\ninterpretation.\n\nQuestion: what is the use case for MOVEs between workspaces? Wouldn't it be\nmuch simpler to just forbid that?\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n-----Original Message-----\nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\nSent: Tuesday, October 01, 2002 8:30 PM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: workspace property\n\n\nNo, the DAV:workspace is not affected by the request-URL that you \nuse to identify the URL (that would be bad for a variety of reasons). \nThe only way you can have two different URLs for the same resource is \nif you have two bindings to either the resource or to a parent of the \nresource.  In this case, some resource has multiple parents, and which \nparent is picked for inheritance of the DAV:workspace property is up to \nthe server (but it has to pick one, and return it consistently). \nSo the answer was: (d) None of the above (:-). \nCheers, \nGeoff \n-----Original Message----- \nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de] \nSent: Tuesday, October 01, 2002 1:49 PM \nTo: ietf-dav-versioning@w3.org \nSubject: DAV:workspace property \n\n\n\nHi, \na very basic question... \nThe workspace feature introduces a live (protected) resource property which \nseems to depend on the URI of the resource, not the resource itself: \n\" If the request-URL did not identify a workspace, the DAV:workspace of the \ndestination MUST have been updated to have the same value as the \nDAV:workspace of the parent collection of the destination.\" \nTo me this seems to indicate that it's not really a property of the resource\n\nitself, but that it only depends on how you access the resurce. \nHow does this property affect bindings to a resource in a workspace? \na) there may be no additional bindings \nb) there may be additional bindings, but they must all reside in the same \nworkspace's namespace \nc) there may be additional bindings, and the reported DAV:workspace property\n\njust depends on the URI used in the request \n(I currently lean towards c) \n\n\nJulian \n-- \n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n\n\n", "id": "lists-007-5478305"}, {"subject": "RE: UPDATE responses for versioned collection", "content": "RE: UPDATE responses for versioned collectionsOk,\n\nthat other case didn't occur me because we have deprecated the label header,\nand thus we don't implement it.\n\nI think the multistatus format is fine, it's just not entirely clear what\n\"modified by the request\" means in case of a versioned collection.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n  Sent: Tuesday, October 01, 2002 9:31 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: RE: UPDATE responses for versioned collections\n\n\n  The other case would be with Depth and labels\n  (see section 8.5).  So the marshalling for UPDATE\n  was defined with those two cases in mind (i.e. when\n  multiple resources could be affected by an UPDATE).\n\n  We could have defined UPDATE to return DAV:multistatus\n  only if there were multiple resources affected by the\n  UPDATE, but it was thought simpler to just always require\n  the multistatus (probably not a big deal either way,\n  but that was where we ended up).\n\n  Cheers,\n  Geoff\n\n  -----Original Message-----\n  From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n  Sent: Tuesday, October 01, 2002 3:24 PM\n  To: Clemm, Geoff; ietf-dav-versioning@w3.org\n  Subject: RE: UPDATE responses for versioned collections\n\n\n\n  Hmm.\n\n  Let's phrase it differently: in the absence of the baseline feature, is\nthere any case where an update for a version controlled collection would\naffect the state of more than one resource (being the collection itself)?\n\n  Julian\n  --\n  <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n  Sent: Tuesday, October 01, 2002 9:09 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: RE: UPDATE responses for versioned collections\n\n\n\n  Why do we need an errata entry?  The question is whether removing a\n  binding to a resource is considered a modification to the\n  resource, or a modification to the collection containing the\n  binding.  For the purposes of UPDATE, I believe it should be\n  considered a modification to the collection containing the\n  binding only.\n  The \"move\" (lower case) I was referring to was a multi-resource\n  update that would result from a labeled update, or a baseline update.\n  Such a multi-resource update could result in a logical move of\n  a subtree from one URL to another.\n  Cheers,\n  Geoff\n  -----Original Message-----\n  From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n  Sent: Tuesday, October 01, 2002 2:54 PM\n  To: Clemm, Geoff; ietf-dav-versioning@w3.org\n  Subject: RE: UPDATE responses for versioned collections\n\n\n\n  Well,\n  in this case we would have an erratum for 7.1:\n  \"The response for a successful request MUST be a 207 Multi-Status, where\nthe\n  DAV:multistatus XML element in the response body identifies all resources\n  that have been modified by the request.\"\n  I also don't understand the second part of your reply -- we're talking\nabout\n  response marshalling for UPDATE, not MOVE. What am I missing?\n  Julian\n  --\n  <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n  [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n  Sent: Tuesday, October 01, 2002 8:25 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: RE: UPDATE responses for versioned collections\n\n\n\n  I would expect the latter, i.e. just the fact that the\n  versioned collection had changed.  The client would then\n  look at the DAV:version-controlled-binding-set of the\n  DAV:checked-in version of the collection to see how it\n  should update its local state (it needs to do that to\n  differentiate a delete/add from a move).\n  One benefit of this approach is that it doesn't cause\n  a flood of responses if you move a folder with 1000\n  members (i.e. it would return just the source and destination\n  collections of the move, rather that 1000 added entries\n  and 1000 deleted entries).\n  Cheers,\n  Geoff\n\n\n\n", "id": "lists-007-5490519"}, {"subject": "RE: workspace propert", "content": "RE: workspace propertyGeoff,\n\nthanks for the feedback.\n\nBTW: the last BIND draft doesn't define DAV:parent-set. Maybe this is\nsomething that was removed for the very same reason?\n\nJulian\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n  Sent: Tuesday, October 01, 2002 9:38 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: RE: workspace property\n\n\n  Just forbidding the MOVE is certainly reasonable behavior from a server\n  (that's what our server will do :-).  There is precedent for having a\n  property that is modified by a DELETE (e.g. the \"DAV:parent-set\" of a\n  resource that supports multiple bindings), but one certainly would\n  like to minimize the number of properties that act this way.\n\n  Before banning a cross-workspace move in the protocol though, I'd probably\n  prefer to wait a bit to make sure that this is in fact something that\n  does not turn out to be generally useful/supported.\n\n  Cheers,\n  Geoff\n\n\n\n\n  -----Original Message-----\n  From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n  Sent: Tuesday, October 01, 2002 3:05 PM\n  To: Clemm, Geoff; ietf-dav-versioning@w3.org\n  Subject: RE: workspace property\n\n\n\n  Not convinced yet :-)\n\n  The idea of a resource property which changes it's value upon MOVE isn't\nreally appealing -- the properties of a resource should be independant of\nthe access path.\n\n  Up to now, I was expecting a MOVE to have the same properties as a BIND\nfollowed by a DELETE on the original URI -- this would be lost with your\ninterpretation.\n\n  Question: what is the use case for MOVEs between workspaces? Wouldn't it\nbe much simpler to just forbid that?\n\n  --\n  <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n  Sent: Tuesday, October 01, 2002 8:30 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: RE: workspace property\n\n\n\n  No, the DAV:workspace is not affected by the request-URL that you\n  use to identify the URL (that would be bad for a variety of reasons).\n  The only way you can have two different URLs for the same resource is\n  if you have two bindings to either the resource or to a parent of the\n  resource.  In this case, some resource has multiple parents, and which\n  parent is picked for inheritance of the DAV:workspace property is up to\n  the server (but it has to pick one, and return it consistently).\n  So the answer was: (d) None of the above (:-).\n  Cheers,\n  Geoff\n  -----Original Message-----\n  From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n  Sent: Tuesday, October 01, 2002 1:49 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: DAV:workspace property\n\n\n\n\n  Hi,\n  a very basic question...\n  The workspace feature introduces a live (protected) resource property\nwhich\n  seems to depend on the URI of the resource, not the resource itself:\n  \" If the request-URL did not identify a workspace, the DAV:workspace of\nthe\n  destination MUST have been updated to have the same value as the\n  DAV:workspace of the parent collection of the destination.\"\n  To me this seems to indicate that it's not really a property of the\nresource\n  itself, but that it only depends on how you access the resurce.\n  How does this property affect bindings to a resource in a workspace?\n  a) there may be no additional bindings\n  b) there may be additional bindings, but they must all reside in the same\n  workspace's namespace\n  c) there may be additional bindings, and the reported DAV:workspace\nproperty\n  just depends on the URI used in the request\n  (I currently lean towards c)\n\n\n\n  Julian\n  --\n  <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5506262"}, {"subject": "RE: UPDATE responses for versioned collection", "content": "OK, we could add some words about this in the Errata and the\nrevised draft, if you think that would be good.\n\n(And I agree that the Label case is not very important, since\nwe've deprecated the header, so it really is just the baseline\ncase that matters).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Tuesday, October 01, 2002 3:43 PM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: UPDATE responses for versioned collections\n\n\nOk,\n\nthat other case didn't occur me because we have deprecated the label header,\nand thus we don't implement it.\n\nI think the multistatus format is fine, it's just not entirely clear what\n\"modified by the request\" means in case of a versioned collection.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n-----Original Message-----\nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\nSent: Tuesday, October 01, 2002 9:31 PM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: UPDATE responses for versioned collections\n\n\nThe other case would be with Depth and labels \n(see section 8.5).  So the marshalling for UPDATE \nwas defined with those two cases in mind (i.e. when \nmultiple resources could be affected by an UPDATE). \nWe could have defined UPDATE to return DAV:multistatus \nonly if there were multiple resources affected by the \nUPDATE, but it was thought simpler to just always require \nthe multistatus (probably not a big deal either way, \nbut that was where we ended up). \nCheers, \nGeoff \n-----Original Message----- \nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de] \nSent: Tuesday, October 01, 2002 3:24 PM \nTo: Clemm, Geoff; ietf-dav-versioning@w3.org \nSubject: RE: UPDATE responses for versioned collections \n\n\nHmm. \nLet's phrase it differently: in the absence of the baseline feature, is\nthere any case where an update for a version controlled collection would\naffect the state of more than one resource (being the collection itself)?\nJulian \n-- \n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n-----Original Message----- \nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff \nSent: Tuesday, October 01, 2002 9:09 PM \nTo: ietf-dav-versioning@w3.org \nSubject: RE: UPDATE responses for versioned collections \n\n\nWhy do we need an errata entry?  The question is whether removing a \nbinding to a resource is considered a modification to the \nresource, or a modification to the collection containing the \nbinding.  For the purposes of UPDATE, I believe it should be \nconsidered a modification to the collection containing the \nbinding only. \nThe \"move\" (lower case) I was referring to was a multi-resource \nupdate that would result from a labeled update, or a baseline update. \nSuch a multi-resource update could result in a logical move of \na subtree from one URL to another. \nCheers, \nGeoff \n-----Original Message----- \nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de] \nSent: Tuesday, October 01, 2002 2:54 PM \nTo: Clemm, Geoff; ietf-dav-versioning@w3.org \nSubject: RE: UPDATE responses for versioned collections \n\n\nWell, \nin this case we would have an erratum for 7.1: \n\"The response for a successful request MUST be a 207 Multi-Status, where the\n\nDAV:multistatus XML element in the response body identifies all resources \nthat have been modified by the request.\" \nI also don't understand the second part of your reply -- we're talking about\n\nresponse marshalling for UPDATE, not MOVE. What am I missing? \nJulian \n-- \n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n-----Original Message----- \nFrom: ietf-dav-versioning-request@w3.org \n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff \nSent: Tuesday, October 01, 2002 8:25 PM \nTo: ietf-dav-versioning@w3.org \nSubject: RE: UPDATE responses for versioned collections \n\n\nI would expect the latter, i.e. just the fact that the \nversioned collection had changed.  The client would then \nlook at the DAV:version-controlled-binding-set of the \nDAV:checked-in version of the collection to see how it \nshould update its local state (it needs to do that to \ndifferentiate a delete/add from a move). \nOne benefit of this approach is that it doesn't cause \na flood of responses if you move a folder with 1000 \nmembers (i.e. it would return just the source and destination \ncollections of the move, rather that 1000 added entries \nand 1000 deleted entries). \nCheers, \nGeoff \n\n\n\n", "id": "lists-007-5520000"}, {"subject": "RE: Issues 5.5_USE_PROPERTIES and 5.5_OPTIONS_BOD", "content": "Since there have been no objections, I have taken Julian's\nsuggested text, marked these two issues as closed, and\nposted a revised 3253 draft to the deltav web site.\n\nThese were the last two open issues on the RFC-3253 issues list,\nso all current RFC-3253 issues are now resolved!\nIf any new issues arise, please notify the working group via the mailing\nlist.\n\nI will submit the revised 3253 draft as an internet draft later this week.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Saturday, September 28, 2002 7:22 PM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: Issues 5.5_USE_PROPERTIES and 5.5_OPTIONS_BODY\n\n\nI agree with the proposed resolution. \nUnless someone disagrees, I will add this to the Errata sheet, \nand mark the issue as closed. \nCheers, \nGeoff \n\n-----Original Message----- \nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de] \nSent: Saturday, September 28, 2002 11:50 AM \nTo: ietf-dav-versioning@w3.org \nSubject: Issues 5.5_USE_PROPERTIES and 5.5_OPTIONS_BODY \n\n\n\nProposed resolution: \n1) Deprecate marshalling through OPTIONS. \n2) Add three new live properties: \n---------------------- \n(Version histories) \n5.2        Additional Resource Properties \nThe version-history feature introduces the following REQUIRED property for \nresources that reside in a part of a server's namespace that supports \nversion histories. \n5.1.1           DAV:version-history-collection-set (protected) \nThe DAV:version-history-collection-set property identifies collections that \nmay contain version histories.  An identified collection MAY be the root \ncollection of a tree of collections, all of which may contain version \nhistories.  Since different servers can control different parts of the URL \nnamespace, different resources on the same host MAY have different \nDAV:version-history-collection-set values.  The identified collections MAY \nbe located on different hosts from the resource. \n<!ELEMENT version-history-collection-set (href+)> \n\n\n---------------------- \n(Workspaces) \n6.2.1           DAV:workspace-collection-set (protected) \nThe DAV:workspace-collection-set property  identifies collections that may \ncontain workspaces.  An identified collection MAY be the root collection of \na tree of collections, all of which may contain workspaces.  Since different\n\nservers can control different parts of the URL namespace, different \nresources on the same host MAY have different DAV:workspace-collection-set \nvalues.  The identified collections MAY be located on different hosts from \nthe resource. \n<!ELEMENT workspace-collection-set (href)> \n---------------------- \n(Activities) \n\n\n13.4    Additional Resource Properties \nThe activity feature introduces the following REQUIRED property for \nresources that reside in a part of the server's namespace supporting \nactivities. \n13.4.1       DAV:activity-collection-set (protected) \nThe DAV:activity-collection-set property  identifies collections that may \ncontain activities.  An identified collection MAY be the root collection of \na tree of collections, all of which may contain activities.  Since different\n\nservers can control different parts of the URL namespace, different \nresources on the same host MAY have different DAV:activity-collection-set \nvalues.  The identified collections MAY be located on different hosts from \nthe resource. \n<!ELEMENT activity-collection-set (href*)> \n\n\n-- \n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n\n\n", "id": "lists-007-5535775"}, {"subject": "3.5: VERSION-CONTROL response code", "content": "Hi.\n\nThe VERSION-CONTROL method -- when applied to a versionable but not yet\nversion-controlled resource, creates one or two new resources (being the\nchecked-in version and optionall the version history resource).\n\nI'd like to see the definition in 3.5 extended to\n\n- allow a 201 to be returned when new resources were created (see [1])\n\n- define that in this case, the Location header should point to the version\nbeing created\n\n- define an optional response body (DAV:version-control-response) that\ncontains references to the resources being created, such as:\n\n<version-control-response xmlns=\"DAV:\">\n  <checked-in>...</checked-in>\n  <version-history>...</version-history>\n</version-control-response>\n\n(similar marshalling may also be needed for other methods that create new\nresources)\n\n\n[1] <http://greenbytes.de/tech/webdav/rfc2616.html#rfc.section.10.2.2>\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5547570"}, {"subject": "RE: 3.5: VERSION-CONTROL response code", "content": "Could you motivate why we would want to do this?\n(I'm not saying it's a bad idea, but it is additional\ntext that would need to be added to the protocol definition,\nand we've got a lot of text already :-).\n\nIn particular, this information is easily obtainable\nwith a subsequent PROPFIND (and even a streaming PROPFIND,\ni.e. you can issue the PROPFIND without waiting for\nthe VERSION-CONTROL to succeed).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, October 10, 2002 4:32 AM\nTo: ietf-dav-versioning@w3.org\nSubject: 3.5: VERSION-CONTROL response codes\n\n\n\nHi.\n\nThe VERSION-CONTROL method -- when applied to a versionable but not yet\nversion-controlled resource, creates one or two new resources (being the\nchecked-in version and optionall the version history resource).\n\nI'd like to see the definition in 3.5 extended to\n\n- allow a 201 to be returned when new resources were created (see [1])\n\n- define that in this case, the Location header should point to the version\nbeing created\n\n- define an optional response body (DAV:version-control-response) that\ncontains references to the resources being created, such as:\n\n<version-control-response xmlns=\"DAV:\">\n  <checked-in>...</checked-in>\n  <version-history>...</version-history>\n</version-control-response>\n\n(similar marshalling may also be needed for other methods that create new\nresources)\n\n\n[1] <http://greenbytes.de/tech/webdav/rfc2616.html#rfc.section.10.2.2>\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5556654"}, {"subject": "RE: 3.5: VERSION-CONTROL response code", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Thursday, October 10, 2002 4:18 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: 3.5: VERSION-CONTROL response codes\n>\n>\n> Could you motivate why we would want to do this?\n\nSure.\n\n1) Consistency with HTTP: requests that create new resources should return a\n201.\n\n2) Consistence with deltaV (defining DAV:version-control-response as\noptional response body)\n\n3) Performance: I've seen many cases where after a version-control, a client\nwould like to access either the checked-in version or the VHR -- in which\ncase it currently needs an additional PROPFIND.\n\n> (I'm not saying it's a bad idea, but it is additional\n> text that would need to be added to the protocol definition,\n> and we've got a lot of text already :-).\n> In particular, this information is easily obtainable\n> with a subsequent PROPFIND (and even a streaming PROPFIND,\n> i.e. you can issue the PROPFIND without waiting for\n> the VERSION-CONTROL to succeed).\n\nIt's still an additional request and doesn't come for free. In general, a\nserver will have to do another call to it's backend to get this information.\n\n\n\n", "id": "lists-007-5566256"}, {"subject": "RE: 3.5: VERSION-CONTROL response code", "content": "To date, we've limited 3253 modifications to demonstrable\nsemantic problems with the protocol (e.g. the Label header)\nor interoperability problems (the use of an OPTIONS body).\n\nI personally would not want to modify/extend the protocol\nsimply for \"consistency\".  This makes the protocol too much of a\nmoving target for implementors.\n\nFor the same reason, I would not want to modify/extend the\nprotocol for optimizing certain requests, until it has been demonstrated\nthat these performance issues are common and severe.\n\nBut it certainly would be reasonable to define these extensions in a\nseparate draft, and add that draft to the list of proposed DeltaV \nextensions on the DeltaV web site.  That way implementors who encounter\nthese performance issues can work around them in a common way,\nmaking that extension a likely candidate for inclusion in the next\ndraft.\n\nCheers,\nGeoff \n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, October 10, 2002 4:32 AM\nTo: ietf-dav-versioning@w3.org\nSubject: 3.5: VERSION-CONTROL response codes\n\n\n\nHi.\n\nThe VERSION-CONTROL method -- when applied to a versionable but not yet\nversion-controlled resource, creates one or two new resources (being the\nchecked-in version and optionall the version history resource).\n\nI'd like to see the definition in 3.5 extended to\n\n- allow a 201 to be returned when new resources were created (see [1])\n\n- define that in this case, the Location header should point to the version\nbeing created\n\n- define an optional response body (DAV:version-control-response) that\ncontains references to the resources being created, such as:\n\n<version-control-response xmlns=\"DAV:\">\n  <checked-in>...</checked-in>\n  <version-history>...</version-history>\n</version-control-response>\n\n(similar marshalling may also be needed for other methods that create new\nresources)\n\n\n[1] <http://greenbytes.de/tech/webdav/rfc2616.html#rfc.section.10.2.2>\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5575921"}, {"subject": "RE: 3.5: VERSION-CONTROL response code", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Thursday, October 10, 2002 5:10 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: 3.5: VERSION-CONTROL response codes\n>\n>\n> To date, we've limited 3253 modifications to demonstrable\n> semantic problems with the protocol (e.g. the Label header)\n> or interoperability problems (the use of an OPTIONS body).\n> I personally would not want to modify/extend the protocol\n> simply for \"consistency\".  This makes the protocol too much of a\n> moving target for implementors.\n\nI agree with this. However, I'm not sure about how intrusive this change is.\n\n- Right now the response code for VERSION-CONTROL conflicts with the\nrecommendations from RFC2616. With the current wording, client writers can\nrely on  getting a 200 on success. I think we should relax that so that 201\nis allowed as well (yes, I think this needs to be mentioned as an erratum).\n\n- All the other changes then follow from standard RFC2616 semantics, and or\nsimilar definitions in DeltaV.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5586005"}, {"subject": "RE: 3.5: VERSION-CONTROL response code", "content": "The intrusiveness occurs if we add these extensions as\na MUST.  If it is a MUST, a client should be able to count\non them being there, which is where it is a burden on\nserver writers (they have to go and rev all their servers\nto provide this new required information).\n\nOn the other hand, if we define it in a separate spec,\nit effectively becomes a MAY, which gives clients and servers\na way of starting to use these extensions without forcing\nexisting servers to rev their implementations.\n\nIn a couple of years, it would probably be reasonable to\nabsorb a whole set of extensions that have proven to be useful\nin practice, at which point clients can count on them being\nimplemented as a bundle.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, October 10, 2002 11:30 AM\nTo: Clemm, Geoff; ietf-dav-versioning@w3.org\nSubject: RE: 3.5: VERSION-CONTROL response codes\n\n\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Thursday, October 10, 2002 5:10 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: 3.5: VERSION-CONTROL response codes\n>\n>\n> To date, we've limited 3253 modifications to demonstrable\n> semantic problems with the protocol (e.g. the Label header)\n> or interoperability problems (the use of an OPTIONS body).\n> I personally would not want to modify/extend the protocol\n> simply for \"consistency\".  This makes the protocol too much of a\n> moving target for implementors.\n\nI agree with this. However, I'm not sure about how intrusive this change is.\n\n- Right now the response code for VERSION-CONTROL conflicts with the\nrecommendations from RFC2616. With the current wording, client writers can\nrely on  getting a 200 on success. I think we should relax that so that 201\nis allowed as well (yes, I think this needs to be mentioned as an erratum).\n\n- All the other changes then follow from standard RFC2616 semantics, and or\nsimilar definitions in DeltaV.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5595670"}, {"subject": "RE: 3.5: VERSION-CONTROL response code", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Thursday, October 10, 2002 6:47 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: 3.5: VERSION-CONTROL response codes\n>\n>\n> The intrusiveness occurs if we add these extensions as\n> a MUST.  If it is a MUST, a client should be able to count\n> on them being there, which is where it is a burden on\n> server writers (they have to go and rev all their servers\n> to provide this new required information).\n\nI wasn't saying that it should be a MUST.\n\n> On the other hand, if we define it in a separate spec,\n> it effectively becomes a MAY, which gives clients and servers\n> a way of starting to use these extensions without forcing\n> existing servers to rev their implementations.\n> In a couple of years, it would probably be reasonable to\n> absorb a whole set of extensions that have proven to be useful\n> in practice, at which point clients can count on them being\n> implemented as a bundle.\n\nWell, we can also make it a MAY or a SHOULD and put it into RFC3253bis.\n\nRight now we have:\n\n- the response codes aren't specified, one example (plain V-C) says 200, the\nother (V-C in workspace) says 201.\n\n- the document element for the optional response body in fact *is* defined.\n\nSo what's left?\n\n1) clarifying that the plain V-C *may* return 201 and optionally may provide\nthe location of the checked-in version in the Location header\n\n2) possibly allow marshalling of \"both\" locations (version and VHR) in the\nresponse body.\n\nI think 1) is an erratum, while 2) would be just a useful extension\n(although recommended in HTTP).\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5606545"}, {"subject": "CFP: 11th Int'l Software Configuration Mgmt Worksho", "content": "Members of this list might find the SCM-11 workshop to be of interest.\nExperience papers concerning work with DeltaV would be of interest to\nattendees of this workshop. As well, since the workshop is being held in\nPortland, Oregon, it would be relatively convenient for many on this list to\nattend (it's practically in Merant's back yard :-)\n\nPlease contact me if you have any questions about submitting a paper to this\nworkshop.\n\n- Jim\n\n\n\n***********************************************************************\n*                           Call for Papers                           *\n*                                                                     *\n*  11th INTERNATIONAL WORKSHOP ON SOFTWARE CONFIGURATION MANAGEMENT   *\n*                               SCM-11                                *\n* http://www-i3.informatik.rwth-aachen.de/private/bernhard/scm11.html *\n*                                                                     *\n*   Co-Located Event of ICSE-2003 (http://www.cs.orst.edu/icse2003)   *\n*                   Portland, Oregon, May 9-10, 2003                  *\n***********************************************************************\n\n\nIMPORTANT DATES\n\nTechnical papers due       December 20, 2002\nNotification of acceptance February 7, 2003\nCamera-ready papers due    February 28, 2003\n\n\nGOALS AND SCOPE\n\nThe discipline of software configuration management (SCM) provides one\nof the best success stories in the field of software engineering. With\nthe availability of over a hundred commercial SCM systems that\ntogether form a billion dollar marketplace, and the explicit\nrecognition of SCM by such standards as the CMM and ISO-9000, the\ndiscipline has established itself as one of the essential cornerstones\nof software engineering.\n\nWhile SCM is a well-established discipline, innovative software\nengineering approaches constitute new challenges that require support\nin new and in integrated engineering areas in form of new or improved\ntools, techniques, and processes. These challenges emerge in\ncomponent-based development, distributed systems, dynamically bound\nand reconfigured systems, embedded systems, software architecture,\nweb-based systems, XML, engineering/product data management, system\nengineering, process suppport, concurrent and cooperative engineering,\netc. SCM-11 provides a forum for presenting and discussing innovative\napproaches to SCM. The workshop addresses both researchers and\npractitioners. Moreover, it has a strong interdisciplinary flavor and\nspecifically invites participants from related disciplines.\n\n\nPARTICIPATION\n\nSCM-11 will be open to all participants interested in SCM. The\nworkshop addresses participants from both universities and\nindustry. Registration for the workshop is not restricted, i.e., it\nrequires no invitation by the PC.\n\n\nPAPER SUBMISSIONS\n\nSCM-11 invites two categories of submissions.\n\n1. Long papers (14-16 pages) describe technical contributions to SCM\nin depth. This includes both research papers and experience reports.\n\n2. Short papers (6-8 pages) concisely describe ongoing work, new\nideas, experiences, etc.\n\nAll submitted papers will be reviewed by the program committee. Papers\nmust not have been previously published or submitted elsewhere. The\nproceedings will be published in the LNCS series\n(Springer-Verlag). Submissions must conform to the LNCS style. See\nhttp://www.springer.de/comp/lncs/index.html\n\n\nAll papers are invited which refer to SCM or related\ndisciplines. Papers may address e.g. the following topics (but are not\nlimited to these topics):\n\n* Version and configuration control\n* Process support\n* Distributed and cooperative work\n* Workspace management\n* Software manufacture and software deployment\n* SCM and software architecture (architectures for SCM systems, SCM\n  support for software architecture)\n* SCM for component-based, embedded, dynamically bound and reconfigured\nsystems\n* SCM for web-based systems\n* Industrial experiences gained from introducing and applying SCM systems\n* Process improvement, maturity models, and metrics\n* Related disciplines, e.g., engineering/product data management or\n  document management\n\n\nPROGRAM COMMITTEE\n\nGeoff Clemm, Rational, USA\nReidar Conradi, NTNU Trondheim, Norway\nIvica Crnkovic, Malardalen University, Sweden\nWolfgang Emmerich, University College London, United Kingdom\nAndr? van der Hoek, University of California, Irvine, USA\nAnnita Persson, Ericsson AB, M?lndal, Sweden\nBernhard Westfechtel (program chair), RWTH Aachen, Germany\nJim Whitehead, University of California, Santa Cruz, USA\nAndreas Zeller, University of Saarbr?cken, Germany\n\n\nCONTACT\n\n   Bernhard Westfechtel\n   Computer Science III\n   RWTH Aachen\n   Ahornstra?e 55\n   D-52074 Aachen, Germany\n\n   Phone:   +49 (241) 80-21310\n   Fax:     +49 (241) 80-22218\n   E-Mail:  bernhard@i3.informatik.rwth-aachen.de\n\n\nPREVIOUS WORKSHOPS\n\nSCM-10:http://www.ics.uci.edu/~andre/scm10/\nSCM-9:http://www.cs.colorado.edu/~andre/scm9/\n\n\n\n", "id": "lists-007-5617060"}, {"subject": "Sharing files between project", "content": "This list seems to be addressing issues at a very detailed technical level,\nfar beyond my expertise.\n\nI searched the archive but could not find any reference to file 'shares'.\nWe use this quite a lot in Visual SourceSafe to manage our documentation\nfiles.  Sharing allows a file which participates in several documentation\ndeliverables to be added to different projects.  Whenever it is checked out\nin one project it is automatically locked against checking out in any of\nthe other projects in which it participates.\n\nA trivial example might be a copyright  and licence notice which is\nidentical for all publications but need to be changed to reflect changing\nlegislation.  The legal notices file participates in all user guide,\ninstallation guide, etc. deliverables projects, can be checked out in any\none for modification, and ensures that legal notices continue to reflect\nchanges in all projects.\n\nCan file sharing be implemented in WebDAV, please?\n\nRegards,\nHedley\n\n--\nHedley Finger\nTechnical Communications/Technical communicator and FrameMaker mentor\nMYOB Australia <http://www.myob.com.au/>\nP.O. box 371   Blackburn VIC 3130   Australia\n12 Wesley Court   Tally Ho Business Park   East Burwood VIC 3151\nAustralia\n<mailto:hedley_finger@myob.com.au>\nTel. +61 3 9222 9992 x 7421,   Mob. (cell) +61 412 461 558\n\n(C) MYOB Limited 2002\n\n\n\n", "id": "lists-007-5629189"}, {"subject": "RE: Sharing files between project", "content": "There are two ways to \"share\" files in different \"projects\".\n\nOne way is to have the server have a separate workspace for\neach project.  You use the VERSION-CONTROL method on an existing\nversion of a file to make that file appear in a new workspace.\nIf you set DAV:checkout-fork to be DAV:forbidden, then only\none workspace can have a given file checked out at a given time.\n\nThe other way is to use working resources, and have the state\nof the \"project\" stored on the client.  In this case, again, you\nwould set DAV:checkout-fork to be DAV:forbidden to ensure that\na file is checked out by only one client at a time.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: hedley_finger@myob.com.au [mailto:hedley_finger@myob.com.au]\nSent: Friday, October 18, 2002 12:48 AM\nTo: ietf-dav-versioning@w3.org\nSubject: Sharing files between projects\n\n\n\nThis list seems to be addressing issues at a very detailed technical level,\nfar beyond my expertise.\n\nI searched the archive but could not find any reference to file 'shares'.\nWe use this quite a lot in Visual SourceSafe to manage our documentation\nfiles.  Sharing allows a file which participates in several documentation\ndeliverables to be added to different projects.  Whenever it is checked out\nin one project it is automatically locked against checking out in any of\nthe other projects in which it participates.\n\nA trivial example might be a copyright  and licence notice which is\nidentical for all publications but need to be changed to reflect changing\nlegislation.  The legal notices file participates in all user guide,\ninstallation guide, etc. deliverables projects, can be checked out in any\none for modification, and ensures that legal notices continue to reflect\nchanges in all projects.\n\nCan file sharing be implemented in WebDAV, please?\n\nRegards,\nHedley\n\n--\nHedley Finger\nTechnical Communications/Technical communicator and FrameMaker mentor\nMYOB Australia <http://www.myob.com.au/>\nP.O. box 371   Blackburn VIC 3130   Australia\n12 Wesley Court   Tally Ho Business Park   East Burwood VIC 3151\nAustralia\n<mailto:hedley_finger@myob.com.au>\nTel. +61 3 9222 9992 x 7421,   Mob. (cell) +61 412 461 558\n\n(C) MYOB Limited 2002\n\n\n\n", "id": "lists-007-5637841"}, {"subject": "RE: BIND vs. non-movable resources in RFC325", "content": "It looks like we have finally narrowed down this thread to\none issue for 3253, which I've added as 14.4_CLARIFY_VH_DELETE_2\n(i.e. can you delete the stable binding to a version history\nor version, if there are other bindings).  Any discussion of\n14.4_CLARIFY_VH_DELETE_2 should be mailed to the deltav mailing\nlist, not to the general webdav mailing list.\n\nFor the binding spec, Julian asks for two new preconditions\nfor BIND, which I will go ahead and add, unless someone objects\n(they both seem reasonable to me).  Any discussion of these two\nnew preconditions for BIND should be mailed to the general\nwebdav mailing list.\n\nCheers,\nGeoff \n \n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@gmx.de]\n\n...\nThe issue here is that if we allow a DELETE to fail because other bindings\nexist, a client may never be able to delete a binding (because due to race\nconditions, there will always be additional bindings left). I'm not saying\nthat this can be avoided, however it *really* sounds ugly. As I said, I\nhaven't seen a convincing argument why we need this restriction in RFC3253\n(and yes, this discussion should be moved to the other mailing list).\n\n> Can we agree that servers can reject DELETE/MOVE requests and move the\n> versioning specific discussion to the versioning mailing list?\n\nYes. Still, we may have to define additional precondition values for\n\n- resource does not support additional bindings\n- new member name can't be used (in deltav: because it was already used for\na stable URI)\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5647843"}, {"subject": "RE: BIND vs. non-movable resources in RFC325", "content": "RE: BIND vs. non-movable resources in RFC3253Geoff,\n\nthanks. I think I've got at least one other precondition:\n\nDAV:bind-loops-allowed\n\n(explanation: we don't want the server to produce a 5xx error code for this\ncase)\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n  -----Original Message-----\n  From: w3c-dist-auth-request@w3.org [mailto:w3c-dist-auth-request@w3.org]On\nBehalf Of Clemm, Geoff\n  Sent: Friday, October 25, 2002 10:46 PM\n  To: DeltaV (E-mail); w3c-dist-auth@w3c.org\n  Subject: RE: BIND vs. non-movable resources in RFC3253\n\n\n  It looks like we have finally narrowed down this thread to\n  one issue for 3253, which I've added as 14.4_CLARIFY_VH_DELETE_2\n  (i.e. can you delete the stable binding to a version history\n  or version, if there are other bindings).  Any discussion of\n  14.4_CLARIFY_VH_DELETE_2 should be mailed to the deltav mailing\n  list, not to the general webdav mailing list.\n\n  For the binding spec, Julian asks for two new preconditions\n  for BIND, which I will go ahead and add, unless someone objects\n  (they both seem reasonable to me).  Any discussion of these two\n  new preconditions for BIND should be mailed to the general\n  webdav mailing list.\n\n  Cheers,\n  Geoff\n\n\n  -----Original Message-----\n  From: Julian Reschke [mailto:julian.reschke@gmx.de]\n\n  ...\n  The issue here is that if we allow a DELETE to fail because other bindings\n  exist, a client may never be able to delete a binding (because due to race\n  conditions, there will always be additional bindings left). I'm not saying\n  that this can be avoided, however it *really* sounds ugly. As I said, I\n  haven't seen a convincing argument why we need this restriction in RFC3253\n  (and yes, this discussion should be moved to the other mailing list).\n\n  > Can we agree that servers can reject DELETE/MOVE requests and move the\n  > versioning specific discussion to the versioning mailing list?\n\n  Yes. Still, we may have to define additional precondition values for\n\n  - resource does not support additional bindings\n  - new member name can't be used (in deltav: because it was already used\nfor\n  a stable URI)\n\n  Julian\n\n  --\n  <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5657322"}, {"subject": "14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable resources in RFC325", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, October 25, 2002 10:46 PM\n> To: DeltaV (E-mail); w3c-dist-auth@w3c.org\n> Subject: RE: BIND vs. non-movable resources in RFC3253\n>\n>\n> It looks like we have finally narrowed down this thread to\n> one issue for 3253, which I've added as 14.4_CLARIFY_VH_DELETE_2\n> (i.e. can you delete the stable binding to a version history\n> or version, if there are other bindings).  Any discussion of\n> 14.4_CLARIFY_VH_DELETE_2 should be mailed to the deltav mailing\n> list, not to the general webdav mailing list.\n> ...\n\nActually, I think there are *two* issues, one of which is the one above\n(where I clearly disagree with the current resolution), and...\n\nFor all live properties that refer to version resources or version history\nresources, which one of possibly multiple bindings should be reported? (I\nthink we all agree that the stable binding should be reported).\n\nAs we also have agreed (months ago) that the fact that the a deltaV live\nproperty points to a specific URL does *not* guarantee that the reported URL\nis still mapped (so a client can get a 404...), I hereby ask again to\nconsider the following alternate resolution to 14.4_CLARIFY_VH_DELETE_2:\n\nBindings to version resources or version history resources may be deleted in\nany order. Removing the stable binding does not affect which URL will be\nreported in the live properties -- the resource just itself isn't accessible\nthrough the stable URL anymore. This relaxes the \"stable URL\" requirement\nsuch that clients still can rely on the stable URL when being mapped to be\nmapped to the initially created resource (it won't be reused). Upon\nencountering a 404, they would however not be able to conclude that the\nresource itself is gone (I'd still like to hear why that would be a\nproblem).\n\nThis model is completely deterministic and avoids special-casing DELETE and\nBIND for these resources, therefore it would be a protocol simplification (a\nhopefully shared goal of the WG :-).\n\nJulian\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5668758"}, {"subject": "RE: 3.5: VERSION-CONTROL response code", "content": "(I'd like to see this issue added to the issues list)\n\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Friday, October 11, 2002 4:06 PM\n> To: Clemm, Geoff; ietf-dav-versioning@w3.org\n> Subject: RE: 3.5: VERSION-CONTROL response codes\n> \n> \n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Thursday, October 10, 2002 6:47 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: RE: 3.5: VERSION-CONTROL response codes\n> > \n> > \n> > The intrusiveness occurs if we add these extensions as\n> > a MUST.  If it is a MUST, a client should be able to count\n> > on them being there, which is where it is a burden on\n> > server writers (they have to go and rev all their servers\n> > to provide this new required information).\n> \n> I wasn't saying that it should be a MUST.\n> \n> > On the other hand, if we define it in a separate spec,\n> > it effectively becomes a MAY, which gives clients and servers\n> > a way of starting to use these extensions without forcing\n> > existing servers to rev their implementations.\n> > In a couple of years, it would probably be reasonable to\n> > absorb a whole set of extensions that have proven to be useful\n> > in practice, at which point clients can count on them being\n> > implemented as a bundle.\n> \n> Well, we can also make it a MAY or a SHOULD and put it into RFC3253bis.\n> \n> Right now we have:\n> \n> - the response codes aren't specified, one example (plain V-C) \n> says 200, the other (V-C in workspace) says 201.\n> \n> - the document element for the optional response body in fact \n> *is* defined.\n> \n> So what's left?\n> \n> 1) clarifying that the plain V-C *may* return 201 and optionally \n> may provide the location of the checked-in version in the Location header\n> \n> 2) possibly allow marshalling of \"both\" locations (version and \n> VHR) in the response body.\n> \n> I think 1) is an erratum, while 2) would be just a useful \n> extension (although recommended in HTTP).\n> \n> Julian\n> \n> --\n> <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n> \n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n\n\n", "id": "lists-007-5679318"}, {"subject": "RE: 3.5: VERSION-CONTROL response code", "content": "I'll add the issues identified in (1) to the issues/errata list.\n\nI think clarifying that VERSION-CONTROL can return 201 is\nuncontroversial, so I'll just make that as an editorial change.\n\nDoes anyone object to having VERSION-CONTROL be required to\nreturn a Location header with the newly created version, just\nas CHECKIN does?  This does seem like a reasonable thing to require,\nto make sure that the client can get a reliable handle to the\nversion it just created.\n\nAs for the extension (marshalling the version and vhr info in\nthe response body), since this is just an optimization of information\nthat can currently be obtained via PROPFIND or the DAV:version-tree\nreport, I'd prefer to see that written up in a draft\nthat is referenced in the \"proposed extensions\" section of the\ndeltav page, to keep the \"issues and errata\" document for errors and\nambiguities in 3253.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Sunday, October 27, 2002 2:15 PM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: 3.5: VERSION-CONTROL response codes\n\n\n\n(I'd like to see this issue added to the issues list)\n\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Friday, October 11, 2002 4:06 PM\n> To: Clemm, Geoff; ietf-dav-versioning@w3.org\n> Subject: RE: 3.5: VERSION-CONTROL response codes\n> \n> \n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Thursday, October 10, 2002 6:47 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: RE: 3.5: VERSION-CONTROL response codes\n> > \n> > \n> > The intrusiveness occurs if we add these extensions as\n> > a MUST.  If it is a MUST, a client should be able to count\n> > on them being there, which is where it is a burden on\n> > server writers (they have to go and rev all their servers\n> > to provide this new required information).\n> \n> I wasn't saying that it should be a MUST.\n> \n> > On the other hand, if we define it in a separate spec,\n> > it effectively becomes a MAY, which gives clients and servers\n> > a way of starting to use these extensions without forcing\n> > existing servers to rev their implementations.\n> > In a couple of years, it would probably be reasonable to\n> > absorb a whole set of extensions that have proven to be useful\n> > in practice, at which point clients can count on them being\n> > implemented as a bundle.\n> \n> Well, we can also make it a MAY or a SHOULD and put it into RFC3253bis.\n> \n> Right now we have:\n> \n> - the response codes aren't specified, one example (plain V-C) \n> says 200, the other (V-C in workspace) says 201.\n> \n> - the document element for the optional response body in fact \n> *is* defined.\n> \n> So what's left?\n> \n> 1) clarifying that the plain V-C *may* return 201 and optionally \n> may provide the location of the checked-in version in the Location header\n> \n> 2) possibly allow marshalling of \"both\" locations (version and \n> VHR) in the response body.\n> \n> I think 1) is an erratum, while 2) would be just a useful \n> extension (although recommended in HTTP).\n> \n\n\n\n", "id": "lists-007-5690545"}, {"subject": "deltaV write-locks and GET request", "content": "Hi, I'm Ben, one of the main developers for the Subversion project.\n(http://subversion.tigris.org) You're probably aware that our 'server'\nis mod_dav_svn, a provider to mod_dav which implements a subset of\nDeltaV.\n\nI'm investigating what it would take to implement auto-versioning, so\nthat programs like MS Office could operate directly against a\nSubversion repository, using vanilla RFC 2518 requests:\n\n   LOCK, GET, PUT, PUT, PUT, UNLOCK.\n\nAt the moment, mod_dav_svn doesn't support any locking at all.  But I\nhope to change that.  :-)\n\nAnyway, here's my question: if the holder of an exclusive write-lock\nexecutes a PUT on a write-locked item, does the change become\nimmediately visible to the world?  Will subsequent GETs from\nnon-lock-holders see the latest version?  Or should they see the 'old'\nversion (as it looked before the write-lock), until the the resource\nis unlocked?\n\nI've scoured both rfc 2518 and 3253, and this question doesn't seem to\nbe answered explicitly.  My intuition is that every single PUT should\nbe publically visible, whether a resource is write-locked or not.  On\nthe other hand, it would be a lot easier to implement the latter\nbehavior in Subversion.\n\nThe only section I could find that *might* be relevant is this.  It\ndoesn't say much:\n\nRFC 2518, 7.1:\n\n     A write lock MUST prevent a principal without the lock from\n     successfully executing a PUT, POST, PROPPATCH, LOCK, UNLOCK,\n     MOVE, DELETE, or MKCOL on the locked resource. All other current\n     methods, GET in particular, function independently of the lock.\n\nAnyway, I thought I'd turn to this discussion group for feedback.\nThanks in advance for your help.\n\n\n\n", "id": "lists-007-5703110"}, {"subject": "RE: deltaV write-locks and GET request", "content": "Yes, a PUT to a write-locked item should be immediately visible to\na subsequent GET on that write-locked item.  Any other behavior is\nrelatively certain to confuse existing clients.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Ben Collins-Sussman [mailto:sussman@collab.net]\nSent: Monday, November 04, 2002 1:16 PM\nTo: ietf-dav-versioning@w3.org\nSubject: deltaV write-locks and GET requests\n\n\n\n\nHi, I'm Ben, one of the main developers for the Subversion project.\n(http://subversion.tigris.org) You're probably aware that our 'server'\nis mod_dav_svn, a provider to mod_dav which implements a subset of\nDeltaV.\n\nI'm investigating what it would take to implement auto-versioning, so\nthat programs like MS Office could operate directly against a\nSubversion repository, using vanilla RFC 2518 requests:\n\n   LOCK, GET, PUT, PUT, PUT, UNLOCK.\n\nAt the moment, mod_dav_svn doesn't support any locking at all.  But I\nhope to change that.  :-)\n\nAnyway, here's my question: if the holder of an exclusive write-lock\nexecutes a PUT on a write-locked item, does the change become\nimmediately visible to the world?  Will subsequent GETs from\nnon-lock-holders see the latest version?  Or should they see the 'old'\nversion (as it looked before the write-lock), until the the resource\nis unlocked?\n\nI've scoured both rfc 2518 and 3253, and this question doesn't seem to\nbe answered explicitly.  My intuition is that every single PUT should\nbe publically visible, whether a resource is write-locked or not.  On\nthe other hand, it would be a lot easier to implement the latter\nbehavior in Subversion.\n\nThe only section I could find that *might* be relevant is this.  It\ndoesn't say much:\n\nRFC 2518, 7.1:\n\n     A write lock MUST prevent a principal without the lock from\n     successfully executing a PUT, POST, PROPPATCH, LOCK, UNLOCK,\n     MOVE, DELETE, or MKCOL on the locked resource. All other current\n     methods, GET in particular, function independently of the lock.\n\nAnyway, I thought I'd turn to this discussion group for feedback.\nThanks in advance for your help.\n\n\n\n", "id": "lists-007-5711821"}, {"subject": "Re: deltaV write-locks and GET request", "content": "\"Clemm, Geoff\" <gclemm@rational.com> writes:\n\n> Yes, a PUT to a write-locked item should be immediately visible to\n> a subsequent GET on that write-locked item.  Any other behavior is\n> relatively certain to confuse existing clients.\n\nI don't understand:  are you saying that the PUT should be immediately\nvisible to the person with the lock, or to *all* users who do a GET?\n\n\n\n", "id": "lists-007-5721732"}, {"subject": "RE: deltaV write-locks and GET request", "content": "To all users.  The lock only controls who can write to the resource,\nnot who can read it, and not what they read from it.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Ben Collins-Sussman [mailto:sussman@collab.net]\nSent: Monday, November 04, 2002 2:53 PM\nTo: Clemm, Geoff\nCc: ietf-dav-versioning@w3.org\nSubject: Re: deltaV write-locks and GET requests\n\n\n\"Clemm, Geoff\" <gclemm@rational.com> writes:\n\n> Yes, a PUT to a write-locked item should be immediately visible to\n> a subsequent GET on that write-locked item.  Any other behavior is\n> relatively certain to confuse existing clients.\n\nI don't understand:  are you saying that the PUT should be immediately\nvisible to the person with the lock, or to *all* users who do a GET?\n\n\n\n", "id": "lists-007-5729672"}, {"subject": "RE: 3.5: VERSION-CONTROL response code", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Monday, October 28, 2002 11:38 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: 3.5: VERSION-CONTROL response codes\n>\n>\n> I'll add the issues identified in (1) to the issues/errata list.\n> I think clarifying that VERSION-CONTROL can return 201 is\n> uncontroversial, so I'll just make that as an editorial change.\n> Does anyone object to having VERSION-CONTROL be required to\n> return a Location header with the newly created version, just\n> as CHECKIN does?  This does seem like a reasonable thing to require,\n\nNote that this would only apply to VERSION-CONTROL when applied to a version\ncontrolled resource. When creating a working resource, it would return 201\nbut no Location header (because the resource at the request URI was\ncreated).\n\n> to make sure that the client can get a reliable handle to the\n> version it just created.\n> As for the extension (marshalling the version and vhr info in\n> the response body), since this is just an optimization of information\n> that can currently be obtained via PROPFIND or the DAV:version-tree\n> report, I'd prefer to see that written up in a draft\n> that is referenced in the \"proposed extensions\" section of the\n> deltav page, to keep the \"issues and errata\" document for errors and\n> ambiguities in 3253.\n\nOK.\n\nWould it make sense to start a draft that contains *all* proposed extensions\nthe working group agrees on?\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5737973"}, {"subject": "RE: 14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable resources  in RFC325", "content": "Currently, we have 3 votes (Stefan, Geoff, Jim) in favor of Stefan's\nresolution (i.e. disallow a delete on the stable URL of a resource if\nthere are any other bindings to that resource), and 1 vote (Julian) in\nfavor of Julian's resolution (have DELETE handle the stable URL the\nsame as any other URL).  Since there appear to be no compatibility or\nimplementability issues here (just \"usability\" ones), unless we get\nsome more feedback, it looks like Stefan's proposal is the winner.\n\nAs for the other topic, i.e. which URL appears in property values,\nI'm inclined to leave that up to the server for now, until we get\nmore experience with these alternative URLs.\n\nCheers,\nGeoff\n\n\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Sunday, October 27, 2002 2:00 PM\nTo: DeltaV (E-mail)\nSubject: 14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable resources\nin RFC3253\n\n\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, October 25, 2002 10:46 PM\n> To: DeltaV (E-mail); w3c-dist-auth@w3c.org\n> Subject: RE: BIND vs. non-movable resources in RFC3253\n>\n>\n> It looks like we have finally narrowed down this thread to\n> one issue for 3253, which I've added as 14.4_CLARIFY_VH_DELETE_2\n> (i.e. can you delete the stable binding to a version history\n> or version, if there are other bindings).  Any discussion of\n> 14.4_CLARIFY_VH_DELETE_2 should be mailed to the deltav mailing\n> list, not to the general webdav mailing list.\n> ...\n\nActually, I think there are *two* issues, one of which is the one above\n(where I clearly disagree with the current resolution), and...\n\nFor all live properties that refer to version resources or version history\nresources, which one of possibly multiple bindings should be reported? (I\nthink we all agree that the stable binding should be reported).\n\nAs we also have agreed (months ago) that the fact that the a deltaV live\nproperty points to a specific URL does *not* guarantee that the reported URL\nis still mapped (so a client can get a 404...), I hereby ask again to\nconsider the following alternate resolution to 14.4_CLARIFY_VH_DELETE_2:\n\nBindings to version resources or version history resources may be deleted in\nany order. Removing the stable binding does not affect which URL will be\nreported in the live properties -- the resource just itself isn't accessible\nthrough the stable URL anymore. This relaxes the \"stable URL\" requirement\nsuch that clients still can rely on the stable URL when being mapped to be\nmapped to the initially created resource (it won't be reused). Upon\nencountering a 404, they would however not be able to conclude that the\nresource itself is gone (I'd still like to hear why that would be a\nproblem).\n\nThis model is completely deterministic and avoids special-casing DELETE and\nBIND for these resources, therefore it would be a protocol simplification (a\nhopefully shared goal of the WG :-).\n\nJulian\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5747889"}, {"subject": "RE: 14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable resources in RFC325", "content": "Geoff,\n\nI have to say that I completely disagree, and I would have really hoped that\nthe arguments in my previous mail would actually be considered (I've seen no\nreply -- does this mean nobody had anything to say about it???).\n\nIn particular:\n\n> As for the other topic, i.e. which URL appears in property values,\n> I'm inclined to leave that up to the server for now, until we get\n> more experience with these alternative URLs.\n\nNo way! DeltaV has the concept of stable bindings, but if there's no\ninteroperable way to discover them, the whole concept is *completely*\nuseless. So if we wan't agree that live properties such as \"DAV:checked-in\"\n*always* identify the stable binding, it makes no sense whatsoever to keep\nthis concept. So we *really* need to write that down. Does anybody have a\nproblem with this (just in case: silence means \"no\"!)?\n\nAnd if we get *that* issue resolved, I'd really like to see a *discussion*\nof the argument I made:\n\n>> is still mapped (so a client can get a 404...), I hereby ask again to\n>> consider the following alternate resolution to 14.4_CLARIFY_VH_DELETE_2:\n>> Bindings to version resources or version history resources may be deleted\nin\n>> any order. Removing the stable binding does not affect which URL will be\n>> reported in the live properties -- the resource just itself isn't\naccessible\n>> through the stable URL anymore. This relaxes the \"stable URL\" requirement\n>> such that clients still can rely on the stable URL when being mapped to\nbe\n>> mapped to the initially created resource (it won't be reused). Upon\n>> encountering a 404, they would however not be able to conclude that the\n>> resource itself is gone (I'd still like to hear why that would be a\n>> problem).\n>> This model is completely deterministic and avoids special-casing DELETE\nand\n>> BIND for these resources, therefore it would be a protocol\nsimplification (a\n>> hopefully shared goal of the WG :-).\n\nRegards, Julian\n\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Tuesday, November 12, 2002 7:13 PM\n> To: Julian Reschke\n> Subject: FW: 14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable\n> resources in RFC3253\n>\n>\n>\n>\n> --\n> <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Monday, November 11, 2002 6:46 PM\n> To: DeltaV (E-mail)\n> Subject: RE: 14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable resources\n> in RFC3253\n>\n>\n> Currently, we have 3 votes (Stefan, Geoff, Jim) in favor of Stefan's\n> resolution (i.e. disallow a delete on the stable URL of a resource if\n> there are any other bindings to that resource), and 1 vote (Julian) in\n> favor of Julian's resolution (have DELETE handle the stable URL the\n> same as any other URL).  Since there appear to be no compatibility or\n> implementability issues here (just \"usability\" ones), unless we get\n> some more feedback, it looks like Stefan's proposal is the winner.\n> As for the other topic, i.e. which URL appears in property values,\n> I'm inclined to leave that up to the server for now, until we get\n> more experience with these alternative URLs.\n> Cheers,\n> Geoff\n>\n>\n>\n> -----Original Message-----\n> From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n> Sent: Sunday, October 27, 2002 2:00 PM\n> To: DeltaV (E-mail)\n> Subject: 14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable resources\n> in RFC3253\n>\n>\n>\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> > Sent: Friday, October 25, 2002 10:46 PM\n> > To: DeltaV (E-mail); w3c-dist-auth@w3c.org\n> > Subject: RE: BIND vs. non-movable resources in RFC3253\n> >\n> >\n> > It looks like we have finally narrowed down this thread to\n> > one issue for 3253, which I've added as 14.4_CLARIFY_VH_DELETE_2\n> > (i.e. can you delete the stable binding to a version history\n> > or version, if there are other bindings).  Any discussion of\n> > 14.4_CLARIFY_VH_DELETE_2 should be mailed to the deltav mailing\n> > list, not to the general webdav mailing list.\n> > ...\n> Actually, I think there are *two* issues, one of which is the one above\n> (where I clearly disagree with the current resolution), and...\n> For all live properties that refer to version resources or version history\n> resources, which one of possibly multiple bindings should be reported? (I\n> think we all agree that the stable binding should be reported).\n> As we also have agreed (months ago) that the fact that the a deltaV live\n> property points to a specific URL does *not* guarantee that the\n> reported URL\n> is still mapped (so a client can get a 404...), I hereby ask again to\n> consider the following alternate resolution to 14.4_CLARIFY_VH_DELETE_2:\n> Bindings to version resources or version history resources may be\n> deleted in\n> any order. Removing the stable binding does not affect which URL will be\n> reported in the live properties -- the resource just itself isn't\n> accessible\n> through the stable URL anymore. This relaxes the \"stable URL\" requirement\n> such that clients still can rely on the stable URL when being mapped to be\n> mapped to the initially created resource (it won't be reused). Upon\n> encountering a 404, they would however not be able to conclude that the\n> resource itself is gone (I'd still like to hear why that would be a\n> problem).\n> This model is completely deterministic and avoids special-casing\n> DELETE and\n> BIND for these resources, therefore it would be a protocol\n> simplification (a\n> hopefully shared goal of the WG :-).\n> Julian\n>\n>\n> --\n> <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n>\n>\n\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5760197"}, {"subject": "RE: 14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable resources  in RFC325", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   I have to say that I completely disagree, and I would have really\n   hoped that the arguments in my previous mail would actually be\n   considered (I've seen no reply -- does this mean nobody had\n   anything to say about it???).\n\nI didn't see any new arguments in your previous mail, just a\nrestatement of your orginal argument.  I thought that Jim and Stefan\nboth gave good reasons for why they prefer requiring the stable URL to\nbe mapped to a resource as long as there are any bindings to the\nresource.  I will summarize those reasons below.\n\n   DeltaV has the concept of stable bindings, but if there's no\n   interoperable way to discover them, the whole concept is\n   *completely* useless. So if we wan't agree that live properties\n   such as \"DAV:checked-in\" *always* identify the stable binding, it\n   makes no sense whatsoever to keep this concept. So we *really* need\n   to write that down. Does anybody have a problem with this?\n\nThat's fine with me.  I'm guessing most folks are not especially\nconcerned because they are not planning on implementing multiple\nbindings to either version histories or versions (but for the same\nreason, would have no problem if this is made explicit).\n\n   And if we get *that* issue resolved, I'd really like to see a\n   *discussion* of the argument I made:\n\n   >> I hereby ask again to consider the following alternate\n   >> resolution to 14.4_CLARIFY_VH_DELETE_2: Bindings to version\n   >> resources or version history resources may be deleted in any\n   >> order. Removing the stable binding does not affect which URL\n   >> will be reported in the live properties -- the resource just\n   >> itself isn't accessible through the stable URL anymore. This\n   >> relaxes the \"stable URL\" requirement such that clients still can\n   >> rely on the stable URL when being mapped to be mapped to the\n   >> initially created resource (it won't be reused). Upon\n   >> encountering a 404, they would however not be able to conclude\n   >> that the resource itself is gone (I'd still like to hear why\n   >> that would be a problem).  This model is completely\n   >> deterministic and avoids special-casing DELETE and BIND for\n   >> these resources, therefore it would be a protocol simplification\n   >> (a hopefully shared goal of the WG :-).\n\nThe only argument I see here for this alternative resolution is that\navoids special-casing DELETE (there is no special casing needed for\nBIND).  The reason given in favor of special-casing DELETE is that it\nguarantees that a client can store away a stable URL with confidence\nthat it will be usable for operating on the resource as long as that\nresource is accessible by any other URL.  Jim, Stefan, and I believe\nthat this behavior is more important than avoiding the special-casing\nfor DELETE. You believe the opposite.  It seems appropriate to mark\nthis issue as resolved until you can provide an argument that at least\none other person finds compelling.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-5777315"}, {"subject": "RE: 14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable resources  in RFC325", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Tuesday, November 12, 2002 9:40 PM\n> To: DeltaV (E-mail)\n> Subject: RE: 14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable resources\n> in RFC3253\n>\n>\n> ...\n>\n>    DeltaV has the concept of stable bindings, but if there's no\n>    interoperable way to discover them, the whole concept is\n>    *completely* useless. So if we wan't agree that live properties\n>    such as \"DAV:checked-in\" *always* identify the stable binding, it\n>    makes no sense whatsoever to keep this concept. So we *really* need\n>    to write that down. Does anybody have a problem with this?\n> That's fine with me.  I'm guessing most folks are not especially\n> concerned because they are not planning on implementing multiple\n> bindings to either version histories or versions (but for the same\n> reason, would have no problem if this is made explicit).\n\nHow can you not implement multiple bindings, if they appear as port of\nworking collections?\n\nAnyway, I think this should be marked as resolved (the spec should state\nthat all version and VHR URIs that are reported in live properties must be\nthe stable URIs).\n\nI'll answer the \"other\" issue in a separate mail (which will take time).\n\nJulian\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5788876"}, {"subject": "RE: 14.4_CLARIFY_VH_DELETE_2, was: BIND vs. non-movable resources   in RFC325", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > From: Clemm, Geoff\n   > ....  I'm guessing most folks are not especially concerned\n   > because they are not planning on implementing multiple bindings\n   > to either version histories or versions (but for the same reason,\n   > would have no problem if this is made explicit).\n\n   How can you not implement multiple bindings, if they appear as port\n   of working collections?\n\nYou would only implement multiple bindings if you are supporting the\nadvanced client workspace package (i.e. supporting both working\nresources and version-controlled collections).\n\n   Anyway, I think this should be marked as resolved (the spec should state\n   that all version and VHR URIs that are reported in live properties must\nbe\n   the stable URIs).\n\nDone.\n\n   I'll answer the \"other\" issue in a separate mail (which will take time).\n\nFor now, I'll mark the other issue closed as well, but will be happy\nto reopen it if Julian can muster at least one other working group member\nwho is unhappy with the current resolution.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-5799458"}, {"subject": "Resume computer information systems CA CO http://hometown.aol.com/gmasle", "content": "\"computer,consultant,resume,IT,IS,MIS,CNE,CNA,MCSE,network,PC,California,com\nputer repair,computer guy,Los Angeles,Orange County, Network\nsupport,Network Repair,Computer Consulting,PC Repair,PC Support,network\nengineer,network administrator,California,Los Angeles,Orange County,Costa\nMesa,California,Greg Masley,Masley And Associates,resumes,computer\nhardware,computer software,microsoft,novell\"\n\nGREGORY J. MASLEY, Network Engineer ? CNA, CNE, MCSE \n10 years experience in computer support for Fortune 500 companies\n2339 East Santa Clara #D Santa Ana CA 92705 \nphone (714)541 - 0585 cell (714) 928 - 3566\nRoxyMuzick@yahoo.com\nhttp://hometown.aol.com/gmasley\n\n\nOpen to contract, consulting, temporary and full-time computer and network\nsupport opportunities in Orange County, California and Colorado Springs,\nColorado. Please call or e-mail for availability and rates.\n\n\nNETWORK ADMINISTRATOR\nDedicated hard working individual with strong technical abilities and\npeople skills.  Ten years experience in Southern California.  Proven\nsuccess coordinating previously acquired management, operations and people\nskills with technical knowledge to benefit the company.\n\n\nTECHNICAL SKILLS\nSystems: IBM, Compaq, Toshiba and compatible PC?s and servers\nLanguages: Visual BASIC, BASIC, COBOL, FORTRAN, SQL, Oracle  and DBASE\nOperating Systems:  DOS, Windows NT 4.0, Windows 95, Windows 3.11, Novell\nand UNIX, Windows  2000\nCommunications/Networks: Ethernet, Token Ring, ATM, Frame Relay, TCP/IP,\nAPPN, APPC, SDLC and ISDN\nHardware: IBM PC?s, PS/2 and compatibles, networks (servers, workstations,\nbridges, gateways, routers, switches, hubs, printservers, faxservers),\nCAD/CAM Systems, printers, multimedia components and peripherals\nApplications: MS Office, MS Mail, Word Perfect Lotus (CCMail, Notes,\n1-2-3), ACT, Q & A, MS Exchange, Intralink, Pro Engineer, AutoCAD, MAPICS,\nRhumba, Reflections\n\n\nPROFESSIONAL EXPERIENCE\nMASLEY AND ASSOCIATES, Newport Beach, CA    1987-Present\nComputer Consultant\n?    Installed, repaired, trained, upgraded and maintained PC?s and\nnetworks for major Southern California companies including: Capitol\nRecords, Unihealth Insurance, Fuji Bank, UNOCAL 76 Products, Price\nCompany, Mellon Financial, Mallinckrodt Medical, Shiley Medical, AJS\nAccounting Service, Online Connecting Point, Sandpiper Computer, Nadek,\nARC and Manpower Technical.  Installed, repaired systems and networks for\nARC and Manpower Technical\n?    Responsible for system configuration, communications, installation\nand configuration of software applications, operating system upgrades and\nhardware. Computer hardware troubleshooting, repair, configuration and\ninstallation of IBM PC?s, PS/2 and compatibles, Novell and Microsoft\nNetworks (gateways, bridges, routers, cabling and network interface\ncards), CAD/CAM Systems, tape backup systems, monitors, controller and\nadapter cards, printers, multimedia components and peripherals.\nTroubleshooting\nproblems with Virtual Private Networks(VPN's). - Experience with Routers. -\nExperience troubleshooting TCP/IP related issues. - 10 years experience\nwith Microsoft NT. - Experience with large scale LAN/WAN & Host\nenvironments. - Experience troubleshooting Satellites, LAN/WAN, modems\nissues. - Escalate and handle data communication failures or degradation.\n\n\nMALLINCKRODT MEDICAL, Irvine, CA    1994-1999\nNetwork Administrator\n?    Projects included the development, implementation, training and sole\ndaily support for a 200-user network. The replacement of Novell based\nMicrosoft and CCMail servers with Windows NT based Exchange servers. \nDevelopment of a Windows NT RAS server for remote access to e-mail and the\nAS400?s and a Windows NT SQL server for access to databases.\n?    Responsible for complete support, repair, upgrades, installation,\nmaintenance and training on all hardware and software applications for 200\nnetwork end users.  Sole technical support, training and administration of\nWindows NT, Back Office, Exchange and RAS, as well as Client Access issues\nto the AS400?s in MAPICS, JD Edwards, Rumba and Reflections.\n\n\nCOMPUTER SUPPORT NETWORK, Huntington Beach, CA    1993-1994\nGeneral Manager\nResponsible for hardware and software system configuration, installation,\nrepair and maintenance on Microsoft and Novell networks, PC?s and printers. \n?    Supervised a staff of seven computer and network technicians, managed\ndaily company operations and client accounts. Designed, configured, quoted\nand installed Novell networks and PC systems.  Sourced vendors and\nprovided on-site and telephone technical support on PC and network\nhardware and software.\n\n\nEDUCATION\nCalifornia State University, Fullerton College of Higher Education,\nAnaheim, CA\nNovell Certified Network Administrator, Novell Certified Network Engineer,\n Microsoft Certified Systems Engineer\n(Graduated in the top 20 out of 369 students)\n \n\n\n\n", "id": "lists-007-5808040"}, {"subject": "Typo in RFC3253, 14.1.", "content": "In\n\n   !ELEMENT eclipsed-set (binding-name*)>\n   <!ELEMENT binding-name (#PCDATA)>\n   PCDATA value: URL segment\n\nthe leading \"<\" is missing.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n\n\n", "id": "lists-007-5820364"}, {"subject": "DeltaV servers and client", "content": "I am looking for a list of the available\nimplementations of the DeltaV servers and clients?   \nMoreover, are there any fully implementation now or in\nthe near features? \n\nThanks.\nHussam A.\n\n__________________________________________________\nDo you Yahoo!?\nYahoo! Mail Plus - Powerful. Affordable. Sign up now.\nhttp://mailplus.yahoo.com\n\n\n\n", "id": "lists-007-5828129"}, {"subject": "RE: DeltaV servers and client", "content": "From the DAV interop mailing list:\n\nServer product name: SAP Portals Enterprise Portal Server 5.0\n\nContact: julian.reschke@greenbytes.de, stefan.eissing@greenbytes.de\n\nContact method/times: Email or tel:++492512807760 (UTC+0100).\n\nOperating from behind a proxy/firewall: yes\n\nSSL support: no\n\nAuthentication methods supported: Basic\n\nDeltaV, ACL, DASL? All of them, plus ordering and redirect references\n\nProcedure for obtaining a test account: Email \njulian.reschke@greenbytes.de\n\nAdditional notes: -\n\n==========\n\nServer product name: Xythos WebFile Server\n\nContact: Lisa Dusseault\n\nContact method/times:\n   Email: lisa@xythos.com\n   AOL IM: LisaDusseault\n\nOperating from behind a proxy/firewall: no\n\nSSL support: yes\n\nAuthentication methods supported: Basic or Digest Access\n\nDeltaV, ACL, DASL?\n   DeltaV: Yes (some packages)\n   ACL: Yes\n   DASL: Yes (somewhat outdated syntax)\n\nProcedure for obtaining a test account:\n   www.sharemation.com: register for new account at the login page\n   https://files.xythos.com/: contact Lisa if SSL needed.\n\nAdditional notes: Once an account on Sharemation is created, the home \ndirectory name is the same as the username. So if a user 'testuser' \nwere created, then the client could PROPFIND \nhttp://www.sharemation.com/testuser/.\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of well xml\n> Sent: Friday, November 29, 2002 3:05 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: DeltaV servers and clients\n> \n> \n> \n> I am looking for a list of the available\n> implementations of the DeltaV servers and clients?   \n> Moreover, are there any fully implementation now or in\n> the near features? \n> \n> Thanks.\n> Hussam A.\n> \n> __________________________________________________\n> Do you Yahoo!?\n> Yahoo! Mail Plus - Powerful. Affordable. Sign up now.\n> http://mailplus.yahoo.com\n> \n> \n> \n\n\n\n", "id": "lists-007-5835487"}, {"subject": "RE: DeltaV servers and client", "content": "Just added following entry:\n\n\nWebDAV Server Form\n------------------\n\nServer product name: Tamino WebDAV Server\nContact:\nhttp://tamino.demozone.softwareag.com/demoWebDAV/AlwaysOnline/feedbackform.j\nsp  or email: tamino.demozone@softwareag.com\nContact method/times: find details here:\nhttp://tamino.demozone.softwareag.com/demoWebDAV/index.html or\nhttp://tamino.demozone.softwareag.com/demoWebDAV/AlwaysOnline/index.jsp \nOperating from behind a proxy/firewall: Yes, please use standard http port\n80\nSSL support: no\nAuthentication methods supported: Basic\nDeltaV, ACL, DASL? All of them.\nProcedure for obtaining a test account: find details here:\nhttp://tamino.demozone.softwareag.com/demoWebDAV/index.html or\nhttp://tamino.demozone.softwareag.com/demoWebDAV/AlwaysOnline/index.jsp\nAdditional notes: \nMethods supported: > COPY, DELETE, GET, HEAD, LOCK, MKCOL, MOVE,\nOPTIONS\n> POST, PROPFIND, PROPPATCH, PUT, UNLOCK, VERSION-CONTROL\n> REPORT, CHECKIN, CHECKOUT, UNCHECKOUT, MKWORKSPACE\n> UPDATE, LABEL, ACL, SEARCH\n\nTest account: Every registered user receives a WebDAV URL and a\nseries of user and password combination valid for 2 weeks. Users may\nre-register again to extend the testing time frame.\n\n\n\n -----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de] \nSent:Friday, November 29, 2002 10.01 AM\nTo:well xml; ietf-dav-versioning@w3.org\nSubject:RE: DeltaV servers and clients\n\n\nFrom the DAV interop mailing list:\n\nServer product name: SAP Portals Enterprise Portal Server 5.0\n\nContact: julian.reschke@greenbytes.de, stefan.eissing@greenbytes.de\n\nContact method/times: Email or tel:++492512807760 (UTC+0100).\n\nOperating from behind a proxy/firewall: yes\n\nSSL support: no\n\nAuthentication methods supported: Basic\n\nDeltaV, ACL, DASL? All of them, plus ordering and redirect references\n\nProcedure for obtaining a test account: Email \njulian.reschke@greenbytes.de\n\nAdditional notes: -\n\n==========\n\nServer product name: Xythos WebFile Server\n\nContact: Lisa Dusseault\n\nContact method/times:\n   Email: lisa@xythos.com\n   AOL IM: LisaDusseault\n\nOperating from behind a proxy/firewall: no\n\nSSL support: yes\n\nAuthentication methods supported: Basic or Digest Access\n\nDeltaV, ACL, DASL?\n   DeltaV: Yes (some packages)\n   ACL: Yes\n   DASL: Yes (somewhat outdated syntax)\n\nProcedure for obtaining a test account:\n   www.sharemation.com: register for new account at the login page\n   https://files.xythos.com/: contact Lisa if SSL needed.\n\nAdditional notes: Once an account on Sharemation is created, the home \ndirectory name is the same as the username. So if a user 'testuser' \nwere created, then the client could PROPFIND \nhttp://www.sharemation.com/testuser/.\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of well xml\n> Sent: Friday, November 29, 2002 3:05 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: DeltaV servers and clients\n> \n> \n> \n> I am looking for a list of the available\n> implementations of the DeltaV servers and clients?   \n> Moreover, are there any fully implementation now or in\n> the near features? \n> \n> Thanks.\n> Hussam A.\n> \n> __________________________________________________\n> Do you Yahoo!?\n> Yahoo! Mail Plus - Powerful. Affordable. Sign up now.\n> http://mailplus.yahoo.com\n> \n> \n> \n\n\n\n", "id": "lists-007-5846986"}, {"subject": "expand-property and namespace prefi", "content": "Hi,\nIs there a possibility to provide a prefix for the namespace of those properties which I want to expand? The \"namespace\" attribute of the \"property\" element requires that I provide a valid XML namespace. Can this be a prefix too?  \nWithout the prefix, the XML payload would unnecessarily increase if I a reasonable number of properties to expand.\n\nRgds,\nGirish\n\n\n\n", "id": "lists-007-5861474"}, {"subject": "RE: expand-property and namespace prefi", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Hiranniah,\n> Girish Betadpur\n> Sent: Monday, December 16, 2002 5:24 PM\n> To: IETF-DeltaV (E-mail)\n> Subject: expand-property and namespace prefix\n> \n> \n> \n> Hi,\n> Is there a possibility to provide a prefix for the namespace of \n> those properties which I want to expand? The \"namespace\" \n> attribute of the \"property\" element requires that I provide a \n> valid XML namespace. Can this be a prefix too?  \n\nNo.\n\n> Without the prefix, the XML payload would unnecessarily increase \n> if I a reasonable number of properties to expand.\n\nYou'll have to live with that.\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n\n\n", "id": "lists-007-5868987"}, {"subject": "RE: Typo in RFC3253, 14.1.", "content": "It turns out this typo was already fixed in the current\nrevised draft, but the issue does not appear in the issues list.\nSo the revised draft is unchanged, but I updated the issues list.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Thursday, November 28, 2002 8:52 AM\nTo: DeltaV (E-mail)\nSubject: Typo in RFC3253, 14.1.1\n\n\n\nIn\n\n   !ELEMENT eclipsed-set (binding-name*)>\n   <!ELEMENT binding-name (#PCDATA)>\n   PCDATA value: URL segment\n\nthe leading \"<\" is missing.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n\n\n", "id": "lists-007-5877803"}, {"subject": "New client supporting DeltaV..", "content": "Stumbled across this recent press release:\n\n\"To meet the needs of enterprise developers, XMLSPY 5 builds on the\nsuccess of previous award winning versions through the addition of\nseveral key new features: \n\nEnhanced WebDAV Support -- Web-based Distributed Authoring and\nVersioning (WebDAV) is a standardized set of extensions to the HTTP\n(web) protocol, which allows users to collaboratively edit and manage\nXML files located on remote web-servers. XMLSPY 5 and AUTHENTIC 5 now\nsupport Delta-V (http://www.webdav.org/deltav/), an extension to the\nWebDAV protocol which enables check-in/check-out functionality when used\nin conjunction with a WebDAV server, thus supporting XML content editing\nin a truly collaborative, distributed environment, such as the Web.\"\n\n\nhttp://biz.yahoo.com/prnews/030407/nem030_1.html\n\n\n\n", "id": "lists-007-5932945"}, {"subject": "New client supporting DeltaV..", "content": "Stumbled across this recent press release:\n\n\"To meet the needs of enterprise developers, XMLSPY 5 builds on the\nsuccess of previous award winning versions through the addition of\nseveral key new features: \n\nEnhanced WebDAV Support -- Web-based Distributed Authoring and\nVersioning (WebDAV) is a standardized set of extensions to the HTTP\n(web) protocol, which allows users to collaboratively edit and manage\nXML files located on remote web-servers. XMLSPY 5 and AUTHENTIC 5 now\nsupport Delta-V (http://www.webdav.org/deltav/), an extension to the\nWebDAV protocol which enables check-in/check-out functionality when used\nin conjunction with a WebDAV server, thus supporting XML content editing\nin a truly collaborative, distributed environment, such as the Web.\"\n\n\nhttp://biz.yahoo.com/prnews/030407/nem030_1.html\n\n\n\n", "id": "lists-007-5940136"}, {"subject": "RE: New client supporting DeltaV..", "content": "> From: w3c-dist-auth-request@w3.org\n> [mailto:w3c-dist-auth-request@w3.org]On Behalf Of Lisa Dusseault\n> Sent: Wednesday, April 09, 2003 7:09 PM\n> To: Webdav WG; DeltaV\n> Subject: New client supporting DeltaV...\n> Importance: Low\n>\n>\n>\n>\n> Stumbled across this recent press release:\n>\n> \"To meet the needs of enterprise developers, XMLSPY 5 builds on the\n> success of previous award winning versions through the addition of\n> several key new features:\n>\n> Enhanced WebDAV Support -- Web-based Distributed Authoring and\n> Versioning (WebDAV) is a standardized set of extensions to the HTTP\n> (web) protocol, which allows users to collaboratively edit and manage\n> XML files located on remote web-servers. XMLSPY 5 and AUTHENTIC 5 now\n> support Delta-V (http://www.webdav.org/deltav/), an extension to the\n> WebDAV protocol which enables check-in/check-out functionality when used\n> in conjunction with a WebDAV server, thus supporting XML content editing\n> in a truly collaborative, distributed environment, such as the Web.\"\n>\n>\n> http://biz.yahoo.com/prnews/030407/nem030_1.html\n\nInteresting.\n\nA trace reveals that it does indeed PROPFIND some DeltaV properties, but\nit's unclear what it does with them.\n\nAfter switching off autoversioning on our server, I wasn't able to PUT\nresources anymore. No Checkin/Checkout menu item in sight.\n\nDid anybody else have more success?\n\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5948319"}, {"subject": "search featur", "content": "Hi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n", "id": "lists-007-5958165"}, {"subject": "RE: search featur", "content": "What \"search feature\" were you referring to?\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Fabian Weber [mailto:lematin@gmx.net]\nSent: Wednesday, April 09, 2003 6:51 PM\nTo: ietf-dav-versioning@w3.org\nSubject: search feature\n\n\n\nHi,\nSorry for this stupid question, but I have a complicated query to do and I\nwanted to know how can I use the search feature most efficiently.\n\nThanks a lot.\n\nFabian\nhttp://www.ariane.net\n\n\n\n", "id": "lists-007-5964938"}, {"subject": "Free DeltaV Client wanted", "content": "Hi,\ndoes anybody know a free DeltaV Client (Baselines would be nice).\nI would like to see how my simple server copes with a foreign client.\n\nCheers, Edgar\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-5972291"}, {"subject": "RE: New client supporting DeltaV..", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Lisa Dusseault\n> Sent: Wednesday, April 09, 2003 7:09 PM\n> To: Webdav WG; DeltaV\n> Subject: New client supporting DeltaV...\n> Importance: Low\n>\n>\n>\n>\n> Stumbled across this recent press release:\n>\n> \"To meet the needs of enterprise developers, XMLSPY 5 builds on the\n> success of previous award winning versions through the addition of\n> several key new features:\n>\n> Enhanced WebDAV Support -- Web-based Distributed Authoring and\n> Versioning (WebDAV) is a standardized set of extensions to the HTTP\n> (web) protocol, which allows users to collaboratively edit and manage\n> XML files located on remote web-servers. XMLSPY 5 and AUTHENTIC 5 now\n> support Delta-V (http://www.webdav.org/deltav/), an extension to the\n> WebDAV protocol which enables check-in/check-out functionality when used\n> in conjunction with a WebDAV server, thus supporting XML content editing\n> in a truly collaborative, distributed environment, such as the Web.\"\n>\n>\n> http://biz.yahoo.com/prnews/030407/nem030_1.html\n\nOK,\n\nI finally got feedback from Altova. The Home Edition doesn't seem to do\nDeltaV, but the Enterprise Edition does. Once an external web folder is\nadded to a project, version-controlled resources can be checked-in and\nchecked-out. Checkin even prompts for DAV:comment (I think this is the first\nclient doing this :-). I haven't managed to enable version-control using\nXML-Spy, though.\n\nSome more info is at:\n\nhttp://www.altova.com/manual/sourcecontrol.htm\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-5979776"}, {"subject": "RE: Free DeltaV Client wanted", "content": "Hi Edgar,\n\n> does anybody know a free DeltaV Client (Baselines would be nice).\n> I would like to see how my simple server copes with a foreign client.\n\nThe Cadaver client, as of version 0.21.0, supports simple versioning\ncommands ('version', 'checkin', 'checkout', 'uncheckout', 'label',\n'history'), but not baseline. Still should be a useful interop check for\nyour server.\n\nhttp://www.webdav.org/cadaver/\n\n- Jim\n\n\n\n", "id": "lists-007-5989790"}, {"subject": "MERGE and newly created VCR", "content": "As\nhttp://www.webdav.org/deltav/protocol/draft-ietf-webdav-versioning-xx.7.htm\nis currently not available, I refer to version xx.6.\n\n11.2 MERGE Method states:\n\n\"The request-URL identifies the set of possible merge targets.  If the\nrequest-URL identifies a collection, any member of the configuration rooted\nat the request-URL is a possible merge target.  The merge target of a\nparticular merge source is the version-controlled or checked-out resource\nwhose DAV:checked-in or DAV:checked-out version is from the same version\nhistory as the merge source.  If a merge source has no merge target, that\nmerge source is ignored.\"\n\nSo, as the example at 11.2.1 shows, the changes of a workspace /ws/dev/sally\ncan be merged into a workspace /ws/public. The last sentence of the above\nquotation states, that VCRs newly created in Sally's workspace are ignored\nby the MERGE operation. So, I suppose that a VERSION-CONTROL applied to\nexisting versions is required for each newly created VCR to be taken over to\nthe public workspace.\n\nIs there a more efficient way to \"merge\" the newly created resources by\nSally into the public workspace? Wouldn't it be a good idea to let the MERGE\noperation automatically doing the VERSION-CONTROL's on request?\n\nRegards,\nPeter\n\n\n\n", "id": "lists-007-5997196"}, {"subject": "Distributing versions across server", "content": "Hi,\n\nIs it possible in WebDAV versioning that the version resources of a version\nhistory are distributed across mutliple servers? I guess this may sound a\nlittle bit strange, though a server somehow implies among others autonomy\nand responsibility for hosted resources, thus it seems that it might be\nfeasible (e.g., when multiple organizations are manipulating documents in\ncooperation) to allocate version resources on the different servers.\n\nFor example, is it possible to allocate three versions V1, V2 (succeeding\nV1), and V3 (succeeding V2) on servers S1, S2, and S3 respectively? Is this\nachieveable with server workspaces (sort of workaround)? Or do server\nworkspaces only work on the same physical machine (server)?\n\nKind regards,\nMartin\n\n\n\n", "id": "lists-007-6005496"}, {"subject": "Re: Distributing versions across server", "content": "Hi Martin,\n\nThis is my definitely-non-expert opinion..\n\nI've been looking at a similar scenario and realised that a solution\nmight be possible combining versioning and a build tool such as Ant\n(ant.apache.org), which can query a repository for a particular version\nand upload it via FTP.  The Ant project doesn't yet include WebDAV\nsupport, but I'm sure it won't be far off.\n\nWould take a wee bit of work, but there could be an exciting open\nsource project in it that I'm willing to give a go.\n\nSo, in summary, I (personally) think what you're asking steps into the\nrealm of other technologies assisting a WebDAV repository, but it wounds\nlike a project worth doing! I'd like to know if I'm wrong in this - it\nmay well be an area supported by WebDAV/Delta-V.\n\nregards,\nShanan Holm\n\n>>> \"Martin Bernauer\" <bernauer@big.tuwien.ac.at> 05/28/03 11:02pm >>>\n\nHi,\n\nIs it possible in WebDAV versioning that the version resources of a\nversion\nhistory are distributed across mutliple servers? I guess this may sound\na\nlittle bit strange, though a server somehow implies among others\nautonomy\nand responsibility for hosted resources, thus it seems that it might\nbe\nfeasible (e.g., when multiple organizations are manipulating documents\nin\ncooperation) to allocate version resources on the different servers.\n\nFor example, is it possible to allocate three versions V1, V2\n(succeeding\nV1), and V3 (succeeding V2) on servers S1, S2, and S3 respectively? Is\nthis\nachieveable with server workspaces (sort of workaround)? Or do server\nworkspaces only work on the same physical machine (server)?\n\nKind regards,\nMartin\n\n\n\n", "id": "lists-007-6013461"}, {"subject": "Re: Distributing versions across server", "content": "Hallo Martin,\n\nI'm not sure I completely understand what you want to achieve but will give it a try.\n\n> Is it possible in WebDAV versioning that the version resources of a version\n> history are distributed across mutliple servers?\nThe version resource is defined as the distinct URL of a version. So if you do a\ncheckin on a server I guess it makes sense for the server to create an URL for\nitself because it can't guarantee for any URL on another server to be available.\nPlease give more details if this isn't what you wanted to know.\n\n> For example, is it possible to allocate three versions V1, V2 (succeeding\n> V1), and V3 (succeeding V2) on servers S1, S2, and S3 respectively?\nWhat do you mean by 'allocate three versions' ?\nIs 'version' a 'version resource' or a 'version-controlled resource' ?\n\nMfG, Edgar\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6022623"}, {"subject": "Re: Distributing versions across server", "content": "There is nothing in the protocol that prevents a server from storing\nversions from a given version history on different servers.  What\nmade you think that this was not allowed?\n\nCheers,\nGeoff\n\nietf-dav-versioning-request@w3.org wrote on 05/28/2003 09:02:54 AM:\n\n> \n> Hi,\n> \n> Is it possible in WebDAV versioning that the version resources of a \nversion\n> history are distributed across mutliple servers? I guess this may sound \na\n> little bit strange, though a server somehow implies among others \nautonomy\n> and responsibility for hosted resources, thus it seems that it might be\n> feasible (e.g., when multiple organizations are manipulating documents \nin\n> cooperation) to allocate version resources on the different servers.\n> \n> For example, is it possible to allocate three versions V1, V2 \n(succeeding\n> V1), and V3 (succeeding V2) on servers S1, S2, and S3 respectively? Is \nthis\n> achieveable with server workspaces (sort of workaround)? Or do server\n> workspaces only work on the same physical machine (server)?\n> \n> Kind regards,\n> Martin\n> \n\n\n\n", "id": "lists-007-6031319"}, {"subject": "Re: Distributing versions across server", "content": "Hi Edgar,\n\nthanks for answering. I will try to describe my problem from another\ndirection.\n\nWhat I was interested in was whether WebDAV supports a version history that\ncomprises version resources stored on different servers.\n\nI will try to explain it with a scenario, however, I will not use WebDAV\nterms, because when I do, I am somehow constrained to the WebDAV model and\nnot able to say what I want to say. An abstract version (different from a\nVR!) is for me a persistent snapshot of a document at a point in time.\nScenario: I create a document with some content and store it on server S1,\nresulting in version V1. This version is then copied to server S2,\nmanipulated there by someone else, resulting in version V2, however, stored\nat server S2. V1 and V2 constitute the document's version history.\n\nPossible implementation with WebDAV (from my novice point of view): put\ndocument (resource) under version control at S1, resulting in VCR1, VH1, and\nVR1. Then copy VCR1 to S2 and put it under version control resulting in\nVCR2, VH2, and VR2. Reading Section 3.14 from the spec, VH2 is empty.\n\nNow, there is no metadata structure that describes the connection between\nVCR1 and VCR2 (or VR1 and VR2, or VH1 and VH2), though from an application\npoint of view they constitute a single version history. Thus I would have to\nimplement a layer above WebDAV myself providing for the unified version\nhistory. At least that is how I interpreted the spec... Is this true? Or is\nthere an alternative implementation with WebDAV that would preserve the\nconnection of (abstract) versions V1 and V2?\n\nRegards, Martin\n\n\n|-----Urspr?ngliche Nachricht-----\n|Von: ietf-dav-versioning-request@w3.org\n|[mailto:ietf-dav-versioning-request@w3.org] Im Auftrag von \n|Edgar@EdgarSchwarz.de\n|Gesendet: Freitag, 30. Mai 2003 12:23\n|An: ietf-dav-versioning@w3.org\n|Cc: Edgar@EdgarSchwarz.de\n|Betreff: Re: Distributing versions across servers\n|\n|\n|\n|Hallo Martin,\n|\n|I'm not sure I completely understand what you want to achieve\n|but will give it a try.\n|\n|> Is it possible in WebDAV versioning that the version resources of a\n|> version history are distributed across mutliple servers?\n|The version resource is defined as the distinct URL of a\n|version. So if you do a checkin on a server I guess it makes \n|sense for the server to create an URL for itself because it \n|can't guarantee for any URL on another server to be available. \n|Please give more details if this isn't what you wanted to know.\n|\n|> For example, is it possible to allocate three versions V1, V2\n|> (succeeding V1), and V3 (succeeding V2) on servers S1, S2, and S3 \n|> respectively?\n|What do you mean by 'allocate three versions' ?\n|Is 'version' a 'version resource' or a 'version-controlled resource' ?\n|\n|MfG, Edgar\n|\n|\n|-- \n|edgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n|\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\n|Make it as simple as possible, but not simpler.     Albert Einstein\n|\n|\n\n\n\n", "id": "lists-007-6041057"}, {"subject": "How to get the baselines for a given version", "content": "Given a VR, how can the client efficiently determine the set of baselines\ncontaining the version?\n\nRegards,\nPeter\n\n\n\n", "id": "lists-007-6053041"}, {"subject": "Re: Distributing versions across server", "content": "As far as I understood it, a VR is created automatically upon checkin. And\nby Section 3.15 of the spec, I cannot move the VR by a move method.  So how\ncan it be possible then to store a VR of a VH on a different (WebDAV)\nserver?\n\nRegards, Martin\n\n-----Urspr?ngliche Nachricht-----\nVon: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org] Im Auftrag von Geoffrey M Clemm\nGesendet: Freitag, 30. Mai 2003 13:50\nAn: Martin Bernauer\nCc: ietf-dav-versioning@w3.org; ietf-dav-versioning-request@w3.org\nBetreff: Re: Distributing versions across servers\n\n\n\nThere is nothing in the protocol that prevents a server from storing \nversions from a given version history on different servers.  What \nmade you think that this was not allowed? \n\nCheers, \nGeoff \n\nietf-dav-versioning-request@w3.org wrote on 05/28/2003 09:02:54 AM:\n\n> \n> Hi,\n> \n> Is it possible in WebDAV versioning that the version resources of a\nversion\n> history are distributed across mutliple servers? I guess this may sound a\n> little bit strange, though a server somehow implies among others autonomy\n> and responsibility for hosted resources, thus it seems that it might be\n> feasible (e.g., when multiple organizations are manipulating documents in\n> cooperation) to allocate version resources on the different servers.\n> \n> For example, is it possible to allocate three versions V1, V2 (succeeding\n> V1), and V3 (succeeding V2) on servers S1, S2, and S3 respectively? Is\nthis\n> achieveable with server workspaces (sort of workaround)? Or do server\n> workspaces only work on the same physical machine (server)?\n> \n> Kind regards,\n> Martin\n> \n\n\n\n", "id": "lists-007-6060869"}, {"subject": "Re: Distributing versions across server", "content": "There are two several questions here.\n\nOne is: Can the server store different versions on different servers?\nThe answer to this is: yes.\nA server can do whatever it wants in this regard.\n\nAnother is: Does the protocol provide a way for a client to force the \nserver to put a version on a particular server?\nThe answer to this is: no.\nDifferent server implementations will have very different policies and \ncapabilities wrt where and how versions are stored, and any attempt by a \nclient to \"control\" this will inevitably result in poor interoperability.\n\nAnother is: Can a client hint at what server it would want a new version \nto be stored on?\nThe answer to this is: yes.\nIn particular, a client explicitly creates a version-controlled resource \nat a particular location.  A client can create (or at least try to create \n... depends on what the server supports) different version-controlled \nresources for a given version history on different servers.  When a user \nchecks in a given version-controlled resource (or checks in a working \nresource checked-out from a given version-controlled resource), a server \ncan take this as a hint that it would be reasonable to store the new \nversion on the same server that stores that version-controlled resource.\n\nCheers,\nGeoff\n\nietf-dav-versioning-request@w3.org wrote on 05/30/2003 09:18:02 AM:\n\n> \n> As far as I understood it, a VR is created automatically upon checkin. \nAnd\n> by Section 3.15 of the spec, I cannot move the VR by a move method.  So \nhow\n> can it be possible then to store a VR of a VH on a different (WebDAV)\n> server?\n> \n> Regards, Martin\n> \n> -----Urspr?ngliche Nachricht-----\n> Von: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org] Im Auftrag von Geoffrey M \nClemm\n> Gesendet: Freitag, 30. Mai 2003 13:50\n> An: Martin Bernauer\n> Cc: ietf-dav-versioning@w3.org; ietf-dav-versioning-request@w3.org\n> Betreff: Re: Distributing versions across servers\n> \n> \n> \n> There is nothing in the protocol that prevents a server from storing \n> versions from a given version history on different servers.  What \n> made you think that this was not allowed? \n> \n> Cheers, \n> Geoff \n> \n> ietf-dav-versioning-request@w3.org wrote on 05/28/2003 09:02:54 AM:\n> \n> > \n> > Hi,\n> > \n> > Is it possible in WebDAV versioning that the version resources of a\n> version\n> > history are distributed across mutliple servers? I guess this may \nsound a\n> > little bit strange, though a server somehow implies among others \nautonomy\n> > and responsibility for hosted resources, thus it seems that it might \nbe\n> > feasible (e.g., when multiple organizations are manipulating documents \nin\n> > cooperation) to allocate version resources on the different servers.\n> > \n> > For example, is it possible to allocate three versions V1, V2 \n(succeeding\n> > V1), and V3 (succeeding V2) on servers S1, S2, and S3 respectively? Is\n> this\n> > achieveable with server workspaces (sort of workaround)? Or do server\n> > workspaces only work on the same physical machine (server)?\n> > \n> > Kind regards,\n> > Martin\n> > \n> \n> \n\n\n\n", "id": "lists-007-6071498"}, {"subject": "Re: Distributing versions across server", "content": "ietf-dav-versioning-request@w3.org wrote on 05/30/2003 09:10:44 AM:\n\n> \n> Hi Edgar,\n> \n> thanks for answering. I will try to describe my problem from another\n> direction.\n> \n> What I was interested in was whether WebDAV supports a version history \nthat\n> comprises version resources stored on different servers.\n> \n> I will try to explain it with a scenario, however, I will not use WebDAV\n> terms, because when I do, I am somehow constrained to the WebDAV model \nand\n> not able to say what I want to say.\n\nI don't seen anything in your scenario below that you couldn't describe\nusing the WebDAV model.\n\n> An abstract version (different from a\n> VR!) is for me a persistent snapshot of a document at a point in time.\n\nHow is an \"abstract version\" any different from a VR?  A VR is a \npersistent\nsnapshot of a document at a point in time.\n\n> Scenario: I create a document with some content and store it on server \nS1,\n> resulting in version V1. This version is then copied to server S2,\n\nWhether or not your server chose to make a copy of a version on another\nserver should be an implementation detail invisible to your client. \nOtherwise, your clients are unlikely to interoperate well with other \nservers\nthat make different choices about when or whether to make these copies.\n\nNote that only the server can control this does not mean you\ncannot describe it using the WebDAV model.\n\n> manipulated there by someone else, resulting in version V2, however, \nstored\n> at server S2. \n\nThat's fine, but again, should not be something the client should try to\ncontrol (if you care whether that client interoperates with other \nservers).\n\n> V1 and V2 constitute the document's version history.\n\nThat's correct.\n\n\n> \n> Possible implementation with WebDAV (from my novice point of view): put\n> document (resource) under version control at S1, resulting in VCR1, VH1, \nand\n> VR1. Then copy VCR1 to S2 and put it under version control resulting in\n> VCR2, VH2, and VR2. Reading Section 3.14 from the spec, VH2 is empty.\n\nCOPY creates a new resource ... that's not what you want.  What you do \nwant\nis to use the VERSION-CONTROL request to create VCR2 on S2, specifying VR1\nas the version to initialize the new version-controlled resource.\n\n> Now, there is no metadata structure that describes the connection \nbetween\n> VCR1 and VCR2 (or VR1 and VR2, or VH1 and VH2), though from an \napplication\n> point of view they constitute a single version history. Thus I would \nhave to\n> implement a layer above WebDAV myself providing for the unified version\n> history. At least that is how I interpreted the spec... Is this true? Or \nis\n> there an alternative implementation with WebDAV that would preserve the\n> connection of (abstract) versions V1 and V2?\n\nIf you use VERSION-CONTROL with VR1 as the argument to create VCR2, any \nnew\nversion resources created by checking in VCR2 will be added as versions to\nVH1.  Whether those versions are stored on S1 or S2 is up to your \nimplementation,\nbut your implementation is certainly free to store the new versions on S2.\n\nCheers,\nGeoff\n \n> Regards, Martin\n> \n> \n> |-----Urspr?ngliche Nachricht-----\n> |Von: ietf-dav-versioning-request@w3.org\n> |[mailto:ietf-dav-versioning-request@w3.org] Im Auftrag von \n> |Edgar@EdgarSchwarz.de\n> |Gesendet: Freitag, 30. Mai 2003 12:23\n> |An: ietf-dav-versioning@w3.org\n> |Cc: Edgar@EdgarSchwarz.de\n> |Betreff: Re: Distributing versions across servers\n> |\n> |\n> |\n> |Hallo Martin,\n> |\n> |I'm not sure I completely understand what you want to achieve\n> |but will give it a try.\n> |\n> |> Is it possible in WebDAV versioning that the version resources of a\n> |> version history are distributed across mutliple servers?\n> |The version resource is defined as the distinct URL of a\n> |version. So if you do a checkin on a server I guess it makes \n> |sense for the server to create an URL for itself because it \n> |can't guarantee for any URL on another server to be available. \n> |Please give more details if this isn't what you wanted to know.\n> |\n> |> For example, is it possible to allocate three versions V1, V2\n> |> (succeeding V1), and V3 (succeeding V2) on servers S1, S2, and S3 \n> |> respectively?\n> |What do you mean by 'allocate three versions' ?\n> |Is 'version' a 'version resource' or a 'version-controlled resource' ?\n> |\n> |MfG, Edgar\n> |\n> |\n> |-- \n> |edgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n> |\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\n> |Make it as simple as possible, but not simpler.     Albert Einstein\n> |\n> |\n> \n> \n\n\n\n", "id": "lists-007-6084965"}, {"subject": "Re: How to get the baselines for a given version", "content": "They can't.  Requiring that there be such a mechanism would severely \nconstrain distributed\nimplementations, which want to allow you to create baselines without write \naccess to the versions\nor version histories being added to that baseline.  Without write access \nto the version or \nversion history, there's no good way to answer this query.  A particular \nimplementation could\nadd a custom report/property for such a purpose, but the use of that \nreport/property would not\nbe interoperable.\n\nCheers,\nGeoff\n\nietf-dav-versioning-request@w3.org wrote on 05/30/2003 09:14:10 AM:\n\n> \n> Given a VR, how can the client efficiently determine the set of \nbaselines\n> containing the version?\n> \n> Regards,\n> Peter\n> \n\n\n\n", "id": "lists-007-6099074"}, {"subject": "DeltaV and AC", "content": "On behalf of Eckehard Hermann:\n\nHi all,\n\nwe implemented the DeltaV and ACL extensions in our WebDAV server and now\nclients are having problems in defining access rights on versioning\nresources, i.e. VHR and VR resources (im particular, in view of\nauto-versioning).\nFor example:\n- how to protect /history/* without hindering auto-versioning?\n- shouldn't access rights on a VCR imply access right on the associated\nVR/VHR?\n\nThe DeltaV spec just touches the theme in section 16 and the ACL spec does\nnot mention versioning resources at all.\n\nAs VHRs and VRs are usually implicitly created while operating on VCRs\n(VERSION-CONTROL, CHECKOUT, CHECKIN, auto-versioning) it should be specified\nhow access rights are initialized on these resources (e.g. is the DAV:acl\nproperty to be copied to the newly created VR on CHECKIN?). \n\nIn view of ACL inheritance over the namespace hierarchy, we believe that\nintegrating DeltaV and ACL is not a trivial theme and should be addressed in\neither the ACL or the DeltaV spec.\n\nRegards\nEckehard Hermann\n\n\n\n", "id": "lists-007-6108477"}, {"subject": "DeltaV scenario", "content": "Hi,\nI'm looking for some DeltaV scenarios. Meaning I'm interested in logs\nof request/response between a server and a client.\nDoes anybody have such information ?\nThe main problem isn't DeltaV itself. In RFC3253 there are many examples.\nBut what about the basics like an OPTIONS reply ?\nRFC2518 and RFC2616 aren't that verbose.\nWhen I e.g. tried to connect as a Windows Webfolder my server got an OPTIONS\nrequest.\nBut what should I give as a reply ?\n\nI tried to compile cadaver on my Mandrake 8.1 Linux but got an error :-(\n\nCheers, Edgar\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6116713"}, {"subject": "Re: Distributing versions across server", "content": "With my e-Mail client HTML emails are hard to answer (quite weird), thus my\nanswer are marked by \">\" (so, the inverse from usual), sorry for that.\n\n-----Original Message-----\nFrom: Geoffrey M Clemm [mailto:geoffrey.clemm@us.ibm.com] \nSent: Friday, May 30, 2003 4:32 PM\nTo: Martin Bernauer\nCc: ietf-dav-versioning@w3.org; ietf-dav-versioning-request@w3.org\nSubject: Re: Distributing versions across servers\n\nThere are two several questions here. \n\nOne is: Can the server store different versions on different servers? \nThe answer to this is: yes. \nA server can do whatever it wants in this regard. \n  \n> I wouldn't be so sure about that ;)\n\nAnother is: Does the protocol provide a way for a client to force the server\nto put a version on a particular server? \nThe answer to this is: no. \nDifferent server implementations will have very different policies and\ncapabilities wrt where and how versions are stored, and any attempt by a\nclient to \"control\" this will inevitably result in poor interoperability. \n\n> That was what I wanted to know. Though I would say this *might*\n> result in poor interoperability, depending on facts that are \n> outside the scope of WebDAV. I can think of two interoperability \n> issues:\n> (a) the client uses an URI scheme (or URN namespace) the server or \n> other clients can't resolve (b) the client forces the server to store \n> the version on a computer that other clients do not have access to. \n> Sure there are more issues, however, does e.g. a programming language \n> prevent you from writing non-interoperable applications? So it comes \n> down to the question whether it is it the responsibility of WebDAV \n> (and if yes, how far) to enforce interoperability of WebDAV \n> applications. It seems that HTTP wasn't concerned about that so far, \n> it relies on a common adressing scheme (URI) and that's it.\n\nAnother is: Can a client hint at what server it would want a new version to\nbe stored on? \nThe answer to this is: yes. \nIn particular, a client explicitly creates a version-controlled resource at\na particular location.  A client can create (or at least try to create ...\ndepends on what the server supports) different version-controlled resources\nfor a given version history on different servers.  When a user checks in a\ngiven version-controlled resource (or checks in a working resource\nchecked-out from a given version-controlled resource), a server can take\nthis as a hint that it would be reasonable to store the new version on the\nsame server that stores that version-controlled resource. \n\n> Yes, but  that is not Standard WebDAV...\n>\n> Thanks for clarification,\n> Martin\n\nCheers, \nGeoff \n\n\n\n", "id": "lists-007-6124011"}, {"subject": "HTTP 404 Not Foun", "content": "The link following link on webdav.org/deltav is broken:\n \n http://www.webdav.org/deltav/protocol/draft-ietf-webdav-versioning-xx.7.htm\n\n\n\n", "id": "lists-007-6134514"}, {"subject": "Re: HTTP 404 Not Foun", "content": "Not sure what happened there ... the latest version is xx.6.\nI fixed the link to correctly point to xx.6.\n\nCheers,\nGeoff\n\nietf-dav-versioning-request@w3.org wrote on 06/05/2003 02:09:42 AM:\n\n> \n> The link following link on webdav.org/deltav is broken:\n> \n> \nhttp://www.webdav.org/deltav/protocol/draft-ietf-webdav-versioning-xx.7.htm\n> \n\n\n\n", "id": "lists-007-6142049"}, {"subject": "Property name for version creation tim", "content": "Hi,\nmy repository naturally is giving me a time when a version of a resource\nwas created.\nDid we define a name for this property ? I didn't find anything in 3253.\nOr should DAV:creationdate of a checked-in VCR be set to the\ncreation time of the version ?\nIs this be possible for all operating systems ?\n\nCheers, Edgar\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6149993"}, {"subject": "DAV:merge-preview repor", "content": "A colleague & I have a question about the DAV:merge-preview report for a\nserver capable of auto-merging version-controlled collections.\n\nThe MERGE method itself can include a DAV:no-auto-merge element, which\nwould prohibit the server from auto-merging a collection. As we\nunderstand it, the response to the MERGE method can change dependent on\nwhether or not the server is permitted to auto-merge collections.\n\nThe DAV:merge-preview report has no similar directive to allow /\ndisallow auto-merging consequences. Given this, how should the report be\nevaluated?\n\nFor example, is the intention that the report describe the changes that\nwould be the result from a MERGE request which excludes a\nDAV:no-auto-merge (and a DAV:no-checkout) element?\n\nThe following example illustrates how we understand merge to work for a\nserver that supports:\n\n1. Server workspaces.\n2. Version-controlled collections\n3. Auto-merging of version-controlled collections.\n\nAssume the following resources:\n\nVersion Control Resources:\n----------------------------\nserver/ws/fred/top  where DAV:checked-in is server/v/1/ver/2\nserver/ws/fred/top/foo.c where DAV:checked-in is server/v/2/ver/1\nserver/ws/fred/top/bar.c where DAV:checked-in is server/v/3/ver/2\n\nVersion Histories:\n------------------\nserver/vh/1   this is a for a collection resource\nserver/vh/2   this is for a non-collection resource\nserver/vh/3   this is for a non-collection resource\n\nVersion resources:\n-------------------\nThe DAV:version-set of history server/vh/1 includes:\nserver/v/1/ver/1 - has no bindings\nserver/v/1/ver/2 - has bindings for server/vh/2 and server/vh/3\nserver/v/1/ver/3 - has bindings for server/vh/2 only.\n(server/v/1/ver/2 is not a predecessor of server/v/1/ver/3)\n\nThe DAV:version-set of history server/vh/2 includes:\nserver/v/2/ver/1\n\nThe DAV:version-set of history server/vh/3 includes:\nserver/v/3/ver/1\nserver/v/3/ver/2\nserver/v/3/ver/3\n(server/v/3/ver/2 is not a predecessor of server/v/3/ver/3)\n\nActivity;\n--------\nserver/act/fix1 where DAV:activity-version-set includes server/v/1/ver/3\nand server/v/3/ver/3.\n\nThen issuing the following MERGE request:\n\nMERGE /ws/fred HTTP/1.1\nHost: server\nContent-type: text/xml; charset=\"utf-8\"\nContent-Length: xxxx\n\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<D:merge xmlns:D=\"DAV:\">\n  <D:source>\n    <D:href>http://server/act/fix1</D:href>\n  </D:source>\n</D:merge>\n\nand assuming that the server automatically merges the version-controlled\ncollection  such that the checked-out resource, server/ws/fred/top, has\nonly a version-controlled binding for server/vh/2, then we'd expect the\nMERGE response to include only the single DAV:response element:\n\n<D:response>\n  <D:href>http://server/ws/fred/top</D:href>\n  <D:status>HTTP/1.1 200 OK</D:status>\n</D:response>\n\nResource server/ws/fred/top/bar.c is not in the response because the\nauto-merge of the parent collection  removed the binding to the\ncorresponding version-history.\n(Resource server/ws/fred/top/foo.c is not in the response because the\nactivity does not identify it as a target)\n\nAnd likewise for server/ws/fred to contain the following resources:\n  server/ws/fred/top with DAV:checked-out of server/v/1/ver/2\n  server/ws/fred/top/foo.c with DAV:checked-in of server/v/2/ver/1\n\nHowever, if the DAV:no-auto-merge element was sent in the MERGE request\nthen no merge of the collection would have been performed.\nThe resource server/ws/fred/top/bar.c would have been recognized as a\ntarget, and the MERGE response would include DAV:response elements:\n\n<D:response>\n  <D:href>http://server/ws/fred/top</D:href>\n  <D:status>HTTP/1.1 200 OK</D:status>\n</D:response>\n<D:response>\n  <D:href>http://server/ws/fred/top/bar.c</D:href>\n  <D:status>HTTP/1.1 200 OK</D:status>\n</D:response>\n\nAnd likewise server/ws/fred would contain the following resources:\n  server/ws/fred/top with DAV:checked-out of server/v/1/ver/2\n  server/ws/fred/top/foo.c with DAV:checked-in of server/v/2/ver/1\n  server/ws/fred/top/bar.c with DAV:checked-out of server/v/3/ver/2\n\nGiven this variation in the MERGE response, what should the response to\na DAV:merge-preview report for the same merge request be?\n\n-- Alison.\n\n\n\n", "id": "lists-007-6157824"}, {"subject": "Binding an DAV:workspace propert", "content": "I followed the thread \"workspace property\" in this list ... but there are\nstill open questions. \n\nGeoff wrote:\n\"No, the DAV:workspace is not affected by the request-URL that you use to\nidentify the URL (that would be bad for a variety of reasons). The only way\nyou can have two different URLs for the same resource is \nif you have two bindings to either the resource or to a parent of the\nresource.  In this case, some resource has multiple parents, and which\nparent is picked for inheritance of the DAV:workspace property is up to the\nserver (but it has to pick one, and return it consistently).\".\n\nWhat does \"consistently\" exactly means? That the value shouldn't change if\nthe resource is accessed by an alternate URI?\n\nSo, let's have the following: 2 workspaces W1 accessed by /ws1 and W2\naccessed by /ws2 and a resource R in W1 accessed by /w1/r. Now, I do some\noperations and check the value of DAV:workspace of R:\n\n- PROPFIND /ws1/r (workspace)   ==> worspace=/ws1\n- BIND /ws2 (r -> /ws1/r)\n- PROPFIND /ws2/r (workspace)   ==> worspace=/ws1 [it's in both but show W1\nfor consistency]\n- UNBIND /ws1 (r)               \n- PROPFIND /ws2/r (workspace)   ==> worspace=/ws2 [it's not anymore in W1]\n- BIND /ws1 (r -> /ws2/r)               \n- PROPFIND /ws1/r (workspace)   ==> worspace=/ws1 [it's in both but show W2\nfor consistency]\n\nCorrect?\n\nApparently, in view of Binding, DAV:worspace becomes a computed property?\n\nRegards,\nPeter\n\n\n\n", "id": "lists-007-6169046"}, {"subject": "Re: Binding an DAV:workspace propert", "content": "Peter wrote on 06/20/2003 11:03:54 AM:\n\n> I followed the thread \"workspace property\" in this list ... but there \nare\n> still open questions. \n> \n> Geoff wrote:\n> \"No, the DAV:workspace is not affected by the request-URL that you use \nto\n> identify the URL (that would be bad for a variety of reasons). The only \nway\n> you can have two different URLs for the same resource is \n> if you have two bindings to either the resource or to a parent of the\n> resource.  In this case, some resource has multiple parents, and which\n> parent is picked for inheritance of the DAV:workspace property is up to \nthe\n> server (but it has to pick one, and return it consistently).\".\n> \n> What does \"consistently\" exactly means? That the value shouldn't change \nif\n> the resource is accessed by an alternate URI?\n\nYes.\n\n> So, let's have the following: 2 workspaces W1 accessed by /ws1 and W2\n> accessed by /ws2 and a resource R in W1 accessed by /w1/r. Now, I do \nsome\n> operations and check the value of DAV:workspace of R:\n> \n> - PROPFIND /ws1/r (workspace)   ==> worspace=/ws1\n> - BIND /ws2 (r -> /ws1/r)\n> - PROPFIND /ws2/r (workspace)   ==> worspace=/ws1 [it's in both but show \nW1\n> for consistency]\n\nYes.\n\n> - UNBIND /ws1 (r) \n> - PROPFIND /ws2/r (workspace)   ==> worspace=/ws2 [it's not anymore in \nW1]\n\nYes.\n\n> - BIND /ws1 (r -> /ws2/r) \n> - PROPFIND /ws1/r (workspace)   ==> worspace=/ws1 [it's in both but show \nW2\n> for consistency]\n\nThat's up to the server.  Once it has two parents, the server can pick \nwhich\none is its workspace.  A side effect of the BIND could be to reset the \nworkspace\nproperty back to be W1.\n\n> Apparently, in view of Binding, DAV:worspace becomes a computed \nproperty?\n\nIt is a property that can be modified as a side-effect of a request (e.g.\nBIND or UNBIND), but I'm not sure I'd call it a \"computed\" property.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6178014"}, {"subject": "Re: Property name for version creation tim", "content": "Edgar wrote on 06/20/2003 09:40:25 AM:\n\n> my repository naturally is giving me a time when a version of a resource\n> was created.\n> Did we define a name for this property ? I didn't find anything in 3253.\n\nThat would be the DAV:creationdate of the version.\n\n> Or should DAV:creationdate of a checked-in VCR be set to the\n> creation time of the version ?\n\nNo, the DAV:creationdate of the VCR is the date that the VCR was created\n(which is usually a different date from when a particular version was\ncreated).\n\n> Is this be possible for all operating systems ?\n\nDo you mean adjusting the creation date?  In many OS, this is not \npossible.\nHappily, the protocol does not make you do this (:-).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6187408"}, {"subject": "Re: DAV:merge-preview repor", "content": "This was deliberately left up to the server.  Since the results\nof the auto-merge is up to the server, the exact result will be\nserver-dependent anyway.  Since commonly a client will want auto-merge\nto be performed for collections, it didn't seem worth including a\nparameter that most clients wouldn't use.\n\nCheers,\nGeoff\n\n\n\nAlison wrote on 06/20/2003 10:36:04 AM:\n\n> \n> A colleague & I have a question about the DAV:merge-preview report for a\n> server capable of auto-merging version-controlled collections.\n> \n> The MERGE method itself can include a DAV:no-auto-merge element, which\n> would prohibit the server from auto-merging a collection. As we\n> understand it, the response to the MERGE method can change dependent on\n> whether or not the server is permitted to auto-merge collections.\n> \n> The DAV:merge-preview report has no similar directive to allow /\n> disallow auto-merging consequences. Given this, how should the report be\n> evaluated?\n> \n> For example, is the intention that the report describe the changes that\n> would be the result from a MERGE request which excludes a\n> DAV:no-auto-merge (and a DAV:no-checkout) element?\n> \n> The following example illustrates how we understand merge to work for a\n> server that supports:\n> \n> 1. Server workspaces.\n> 2. Version-controlled collections\n> 3. Auto-merging of version-controlled collections.\n> \n> Assume the following resources:\n> \n> Version Control Resources:\n> ----------------------------\n> server/ws/fred/top  where DAV:checked-in is server/v/1/ver/2\n> server/ws/fred/top/foo.c where DAV:checked-in is server/v/2/ver/1\n> server/ws/fred/top/bar.c where DAV:checked-in is server/v/3/ver/2\n> \n> Version Histories:\n> ------------------\n> server/vh/1   this is a for a collection resource\n> server/vh/2   this is for a non-collection resource\n> server/vh/3   this is for a non-collection resource\n> \n> Version resources:\n> -------------------\n> The DAV:version-set of history server/vh/1 includes:\n> server/v/1/ver/1 - has no bindings\n> server/v/1/ver/2 - has bindings for server/vh/2 and server/vh/3\n> server/v/1/ver/3 - has bindings for server/vh/2 only.\n> (server/v/1/ver/2 is not a predecessor of server/v/1/ver/3)\n> \n> The DAV:version-set of history server/vh/2 includes:\n> server/v/2/ver/1\n> \n> The DAV:version-set of history server/vh/3 includes:\n> server/v/3/ver/1\n> server/v/3/ver/2\n> server/v/3/ver/3\n> (server/v/3/ver/2 is not a predecessor of server/v/3/ver/3)\n> \n> Activity;\n> --------\n> server/act/fix1 where DAV:activity-version-set includes server/v/1/ver/3\n> and server/v/3/ver/3.\n> \n> Then issuing the following MERGE request:\n> \n> MERGE /ws/fred HTTP/1.1\n> Host: server\n> Content-type: text/xml; charset=\"utf-8\"\n> Content-Length: xxxx\n> \n> <?xml version=\"1.0\" encoding=\"utf-8\"?>\n> <D:merge xmlns:D=\"DAV:\">\n>   <D:source>\n>     <D:href>http://server/act/fix1</D:href>\n>   </D:source>\n> </D:merge>\n> \n> and assuming that the server automatically merges the version-controlled\n> collection  such that the checked-out resource, server/ws/fred/top, has\n> only a version-controlled binding for server/vh/2, then we'd expect the\n> MERGE response to include only the single DAV:response element:\n> \n> <D:response>\n>   <D:href>http://server/ws/fred/top</D:href>\n>   <D:status>HTTP/1.1 200 OK</D:status>\n> </D:response>\n> \n> Resource server/ws/fred/top/bar.c is not in the response because the\n> auto-merge of the parent collection  removed the binding to the\n> corresponding version-history.\n> (Resource server/ws/fred/top/foo.c is not in the response because the\n> activity does not identify it as a target)\n> \n> And likewise for server/ws/fred to contain the following resources:\n>   server/ws/fred/top with DAV:checked-out of server/v/1/ver/2\n>   server/ws/fred/top/foo.c with DAV:checked-in of server/v/2/ver/1\n> \n> However, if the DAV:no-auto-merge element was sent in the MERGE request\n> then no merge of the collection would have been performed.\n> The resource server/ws/fred/top/bar.c would have been recognized as a\n> target, and the MERGE response would include DAV:response elements:\n> \n> <D:response>\n>   <D:href>http://server/ws/fred/top</D:href>\n>   <D:status>HTTP/1.1 200 OK</D:status>\n> </D:response>\n> <D:response>\n>   <D:href>http://server/ws/fred/top/bar.c</D:href>\n>   <D:status>HTTP/1.1 200 OK</D:status>\n> </D:response>\n> \n> And likewise server/ws/fred would contain the following resources:\n>   server/ws/fred/top with DAV:checked-out of server/v/1/ver/2\n>   server/ws/fred/top/foo.c with DAV:checked-in of server/v/2/ver/1\n>   server/ws/fred/top/bar.c with DAV:checked-out of server/v/3/ver/2\n> \n> Given this variation in the MERGE response, what should the response to\n> a DAV:merge-preview report for the same merge request be?\n> \n> -- Alison.\n> \n> \n\n\n\n", "id": "lists-007-6195213"}, {"subject": "Response to an unimplemented report request", "content": "Geoffrey M Clemm <geoffrey.clemm@us.ibm.com> wrote:\n> To get the creation date of the checked-in version of a VCR,\n> you can either use the DAV:expand-property REPORT (to get\n> the DAV:creation-date of the DAV:checked-in version of the VCR),\n> or use two PROPFIND's to achieve the same result.\nNow suppose a client wants a DAV:expand-property REPORT report but\nmy server doesn't implement it (yet).\nShould I return:\n- A plain 501 ?\n- A 501 and some explanation in a body. How could this body look like ?\n- Other response ?\n\nI know that a client can find the supported-report-set. But perhaps not\nall are doing it.\n\nRegards, Edgar\n\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6207649"}, {"subject": "RE: Response to an unimplemented report request", "content": "HTTP/1.1 403 Forbidden\nContent-Type: text/xml; charset=\"utf-8\"\nContent-Length: xxxx\n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<D:error xmlns:D=\"DAV:\">\n <D:supported-report/>\n</D:error>\n\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> Edgar@edgarschwarz.de\n> Sent: Tuesday, June 24, 2003 8:18 AM\n> To: ietf-dav-versioning@w3.org\n> Cc: Edgar@edgarschwarz.de\n> Subject: Response to an unimplemented report request.\n> \n> \n> \n> Geoffrey M Clemm <geoffrey.clemm@us.ibm.com> wrote:\n> > To get the creation date of the checked-in version of a VCR,\n> > you can either use the DAV:expand-property REPORT (to get\n> > the DAV:creation-date of the DAV:checked-in version of the VCR),\n> > or use two PROPFIND's to achieve the same result.\n> Now suppose a client wants a DAV:expand-property REPORT report but\n> my server doesn't implement it (yet).\n> Should I return:\n> - A plain 501 ?\n> - A 501 and some explanation in a body. How could this body look like ?\n> - Other response ?\n> \n> I know that a client can find the supported-report-set. But perhaps not\n> all are doing it.\n> \n> Regards, Edgar\n> \n> \n> \n> -- \n> edgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n> \"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\n> Make it as simple as possible, but not simpler.     Albert Einstein\n> \n> \n\n\n\n", "id": "lists-007-6216189"}, {"subject": "Visibility of a Workspac", "content": "Hi,\n     In the RFC , workspace is defined to be a collection , but isn't it actually a \"scratch\" pad on which first all changes are done and then later merged with the \"main\" branch/stream ? My question is , would this workspace be visible through a PROPFIND request or a \nnormal directory listing ?\n\nwarm regards,\nVikram\n\n\n\n", "id": "lists-007-6264808"}, {"subject": "RE: Visibility of a Workspac", "content": "When the workspace feature is supported, a workspace\nis the primary way that the contents of the repository\nis accessed, so there will be a workspace for viewing\nthe \"main branch\", as well as \"scratch\" workspaces for\nanyone that wants a separate stable environment.\n\nWrt to your particular question, yes, since\na workspace is a collection, it is visible through\na PROPFIND request (I'm not sure what you mean by a \n\"normal directory listing\", but the answer is probably\n\"yes\" for that as well:-).\nIf it weren't, how would your client access the information \nin it?\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Vikram_Roopchand [mailto:Vikram_Roopchand@infosys.com]\n\n     In the RFC , workspace is defined to be a collection , but isn't it\nactually a \"scratch\" pad on which first all changes are done and then later\nmerged with the \"main\" branch/stream ? My question is , would this workspace\nbe visible through a PROPFIND request or a \nnormal directory listing ?\n\nwarm regards,\nVikram\n\n\n\n", "id": "lists-007-6272219"}, {"subject": "RE: Visibility of a Workspac", "content": "Hi,\n   When it is said that a vcr is created in a workspace by VERSION-CONTROL request and initialized with another version from some other version history , does that mean that \nthis vcr also \"point's\" to the same version (and thus is part of the same tree ) or is altogether\nnew with it's own vr and history (of that vr). \n\ne.g:\n\nVERSION-CONTROL /foo.html HTTP/1.1\nHost: ...\n.\n.\n.\n\n<?xml .....>\n<D:version-control ...>\n<D:version>\n<D:href> http://server/someotherhistory/12/ver/3 </D:href>\n</D:version>\n</D:version-control>\n\nso is foo.html pointing to ver/3 or is totally new with it's vr having history as v1 ?\n\nI believe it is the latter , but I am quite confused at this moment to reason.\n\nThanks a lot,\nVikram\n \n\n\n\n", "id": "lists-007-6280492"}, {"subject": "Multiple VCR'", "content": "Hi ,\n    A VCR is created (when a resourceis put under version control) along with a VR and a VHistory. VR and VH cannot be created independently (checkout and checkin only). Also a VCR will point to atmost one VR using DAV:checked-in property.\nNow there would be seperate VH and VR for two seperate VCR's . \n\nCould there be anyway in which two vcr's point to the same VR in a given VH ? If so , how ?\n\neg:\n\n VH1VH2\n  |                      |\n----                    ----\nVCR1 -->   | V1 |                  | V1 | <-- VCR2\n----                    ----\n\n\n                       VH3 (VCR3's VR history)\n                        |\n                       ----\n                      | V1 |   <-- VCR3\n                       ----\n                        |\n                       ----\n            VCR1 -->  | V2 |   <--- VCR2\n                       ----\n\n\nwarm regards,\nVikram\n\n\n\n", "id": "lists-007-6288424"}, {"subject": "Re: Multiple VCR'", "content": "Hi,\nI think the solution is what you wrote in you other post.\n \n\"Vikram_Roopchand\" <Vikram_Roopchand@infosys.com>:\n> When it is said that a vcr is created in a workspace by VERSION-CONTROL request\n> and initialized with another version from some other version history , does that\n> mean that this vcr also \"point's\" to the same version\nAs it interpret \"point's\" the answer is yes.\n> or is altogether new with it's own vr and history (of that vr).\nNo new history created.\n\nEditing your example by adding \"/workspace..\"\n> VERSION-CONTROL /workspace1/foo.html HTTP/1.1\n> Host: ...\n> \n> <?xml .....>\n> <D:version-control ...>\n> <D:version>\n> <D:href> http://server/someotherhistory/12/ver/3 </D:href>\n> </D:version>\n> </D:version-control>\n> \n> so is /workspace1/foo.html pointing to ver/3\nYes. \n\n> Could there be anyway in which two vcr's point to the same VR in a given VH ?\n> If so , how ?\nUse e.g.\n> VERSION-CONTROL /workspace2/foo.html HTTP/1.1\n> Host: ...\n> \n> <?xml .....>\n> <D:version-control ...>\n> <D:version>\n> <D:href> http://server/someotherhistory/12/ver/2 </D:href>\n> </D:version>\n> </D:version-control>\nIIRC there is a restriction that you can't have multiple VCRs with the same VR\nin a workspace to avoid merging problems (Which I still don't think necessary BTW,\nbut that's another matter not for today to discuss)\n\nCheers, Edgar\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6296514"}, {"subject": "RE: Multiple VCR'", "content": "Hi ,\n    so what you mean is that when I will create a collection and baseline it , all the member\nvcr's in it will point to vr's (existing history lines) of there corresponding \"source\" lines (from the baselines) , instead of creating new ones ?\n\n\nwamr regards,\nVikram\n\n-----Original Message-----\nFrom: Edgar@EdgarSchwarz.de [mailto:Edgar@EdgarSchwarz.de]\nSent: Sunday, January 19, 2003 4:32 PM\nTo: ietf-dav-versioning@w3.org\nCc: Edgar@EdgarSchwarz.de\nSubject: Re: Multiple VCR's\n\n\n\nHi,\nI think the solution is what you wrote in you other post.\n \n\"Vikram_Roopchand\" <Vikram_Roopchand@infosys.com>:\n> When it is said that a vcr is created in a workspace by VERSION-CONTROL request\n> and initialized with another version from some other version history , does that\n> mean that this vcr also \"point's\" to the same version\nAs it interpret \"point's\" the answer is yes.\n> or is altogether new with it's own vr and history (of that vr).\nNo new history created.\n\nEditing your example by adding \"/workspace..\"\n> VERSION-CONTROL /workspace1/foo.html HTTP/1.1\n> Host: ...\n> \n> <?xml .....>\n> <D:version-control ...>\n> <D:version>\n> <D:href> http://server/someotherhistory/12/ver/3 </D:href>\n> </D:version>\n> </D:version-control>\n> \n> so is /workspace1/foo.html pointing to ver/3\nYes. \n\n> Could there be anyway in which two vcr's point to the same VR in a given VH ?\n> If so , how ?\nUse e.g.\n> VERSION-CONTROL /workspace2/foo.html HTTP/1.1\n> Host: ...\n> \n> <?xml .....>\n> <D:version-control ...>\n> <D:version>\n> <D:href> http://server/someotherhistory/12/ver/2 </D:href>\n> </D:version>\n> </D:version-control>\nIIRC there is a restriction that you can't have multiple VCRs with the same VR\nin a workspace to avoid merging problems (Which I still don't think necessary BTW,\nbut that's another matter not for today to discuss)\n\nCheers, Edgar\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6305568"}, {"subject": "RE: Visibility of a Workspac", "content": "VERSION-CONTROL with a specific version argument creates\na VCR that refers to the existing version and its version\nhistory.  This is what lets multiple workspaces work on the\nsame version history concurrently.  See postcondition\nDAV:new-version-controlled-resource:\n\"a new version-controlled resource exists at the request-URL whose\nDAV:checked-in property identifies that version\"\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Vikram_Roopchand [mailto:Vikram_Roopchand@infosys.com]\nSent: Sunday, January 19, 2003 3:30 AM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: Visibility of a Workspace\n\n\n\nHi,\n   When it is said that a vcr is created in a workspace by VERSION-CONTROL\nrequest and initialized with another version from some other version history\n, does that mean that \nthis vcr also \"point's\" to the same version (and thus is part of the same\ntree ) or is altogether\nnew with it's own vr and history (of that vr). \n\ne.g:\n\nVERSION-CONTROL /foo.html HTTP/1.1\nHost: ...\n.\n.\n.\n\n<?xml .....>\n<D:version-control ...>\n<D:version>\n<D:href> http://server/someotherhistory/12/ver/3 </D:href>\n</D:version>\n</D:version-control>\n\nso is foo.html pointing to ver/3 or is totally new with it's vr having\nhistory as v1 ?\n\nI believe it is the latter , but I am quite confused at this moment to\nreason.\n\nThanks a lot,\nVikram\n \n\n\n\n", "id": "lists-007-6316346"}, {"subject": "RE: Multiple VCR'", "content": "Baselining a collection never changes what versions are\nselected by the members of that collection ... it just\nrecords what versions are currently selected.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Vikram_Roopchand [mailto:Vikram_Roopchand@infosys.com]\nSent: Sunday, January 19, 2003 7:03 AM\nTo: ietf-dav-versioning@w3.org\nSubject: RE: Multiple VCR's\n\n\n\nHi ,\n    so what you mean is that when I will create a collection and baseline it\n, all the member\nvcr's in it will point to vr's (existing history lines) of there\ncorresponding \"source\" lines (from the baselines) , instead of creating new\nones ?\n\n\nwamr regards,\nVikram\n\n-----Original Message-----\nFrom: Edgar@EdgarSchwarz.de [mailto:Edgar@EdgarSchwarz.de]\nSent: Sunday, January 19, 2003 4:32 PM\nTo: ietf-dav-versioning@w3.org\nCc: Edgar@EdgarSchwarz.de\nSubject: Re: Multiple VCR's\n\n\n\nHi,\nI think the solution is what you wrote in you other post.\n \n\"Vikram_Roopchand\" <Vikram_Roopchand@infosys.com>:\n> When it is said that a vcr is created in a workspace by VERSION-CONTROL\nrequest\n> and initialized with another version from some other version history ,\ndoes that\n> mean that this vcr also \"point's\" to the same version\nAs it interpret \"point's\" the answer is yes.\n> or is altogether new with it's own vr and history (of that vr).\nNo new history created.\n\nEditing your example by adding \"/workspace..\"\n> VERSION-CONTROL /workspace1/foo.html HTTP/1.1\n> Host: ...\n> \n> <?xml .....>\n> <D:version-control ...>\n> <D:version>\n> <D:href> http://server/someotherhistory/12/ver/3 </D:href>\n> </D:version>\n> </D:version-control>\n> \n> so is /workspace1/foo.html pointing to ver/3\nYes. \n\n> Could there be anyway in which two vcr's point to the same VR in a given\nVH ?\n> If so , how ?\nUse e.g.\n> VERSION-CONTROL /workspace2/foo.html HTTP/1.1\n> Host: ...\n> \n> <?xml .....>\n> <D:version-control ...>\n> <D:version>\n> <D:href> http://server/someotherhistory/12/ver/2 </D:href>\n> </D:version>\n> </D:version-control>\nIIRC there is a restriction that you can't have multiple VCRs with the same\nVR\nin a workspace to avoid merging problems (Which I still don't think\nnecessary BTW,\nbut that's another matter not for today to discuss)\n\nCheers, Edgar\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6324953"}, {"subject": "Version Controlled Collection , PostCondition", "content": "Hi All,\n\nThe Postconditions in case of Version Controlled Collection\n\n\"14.11 Additional UPDATE and MERGE Semantics\n\n   Additional Postconditions:\n\n      (DAV:update-version-controlled-collection-members): If the request\n      modified the DAV:checked-in version of a version-controlled\n      collection, then the version-controlled members of that version-\n      controlled collection MUST have been updated.  In particular:\n\n      -  A version-controlled internal member MUST have been deleted if\n         its version history is not identified by the DAV:version-\n         controlled-binding-set of the new DAV:checked-in version.\n      -  A version-controlled internal member for a given version\n         history MUST have been renamed if its binding name differs from\n         the DAV:binding-name for that version history in the\n         DAV:version-controlled-binding-set of the new DAV:checked-in\n         version.\n      -  A new version-controlled internal member MUST have been created\n         when a version history is identified by the DAV:version-\n         controlled-binding-set of the DAV:checked-in version, but there\n         was no member of the version-controlled collection for that\n         version history.  If a new version-controlled member is in a\n         workspace that already has a version-controlled resource for\n         that version history, then the new version-controlled member\n         MUST be just a binding (i.e., another name for) that existing\n         version-controlled resource.  Otherwise, the content and dead\n         properties of the new version-controlled member MUST have been\n         initialized to be those of the version specified for that\n         version history by the request.  If no version is specified for\n         that version history by the request, the version selected is\n         server defined.\"\n\nIn the last point, it is written \"...then the new version-controlled member\nMUST be just a binding\".\n\nI am unclear about this \"binding\" , since the term \"version-controlled member\" has been used alongwith it,  does it mean that another VCR having DAV:checked-in the same as that of already existing VCR should be created (which violates workspace semantics ?) or will there be a non versioned member created (having the content and dead properties of the already existing VCR )?\n\nIf it is the first case , then how will checkouts/checkins/merge be handled on both VCR's ?\n\nwarm regards,\nVikram\n\n\n\n", "id": "lists-007-6336091"}, {"subject": "RE: Version Controlled Collection , PostCondition", "content": "   From: Vikram_Roopchand [mailto:Vikram_Roopchand@infosys.com]\n\n   The Postconditions in case of Version Controlled Collection\n\n   \"14.11 Additional UPDATE and MERGE Semantics\n\n      Additional Postconditions:\n\n (DAV:update-version-controlled-collection-members): If the request\n modified the DAV:checked-in version of a version-controlled\n collection, then the version-controlled members of that version-\n controlled collection MUST have been updated.  In particular:\n         - ...\n -  A new version-controlled internal member MUST have been created\n    when a version history is identified by the DAV:version-\n    controlled-binding-set of the DAV:checked-in version, but there\n    was no member of the version-controlled collection for that\n    version history.  If a new version-controlled member is in a\n    workspace that already has a version-controlled resource for\n    that version history, then the new version-controlled member\n    MUST be just a binding (i.e., another name for) that existing\n    version-controlled resource.  Otherwise, the content and dead\n    properties of the new version-controlled member MUST have been\n    initialized to be those of the version specified for that\n    version history by the request.  If no version is specified for\n    that version history by the request, the version selected is\n    server defined.\"\n\n   In the last point, it is written \"...then the new\n   version-controlled member MUST be just a binding\".\n   I am unclear about this \"binding\" , since the term\n   \"version-controlled member\" has been used alongwith it,\n\nThe term \"binding\" is defined in Section 10.2 as part of the\n\"Collection\" definition.\n\n   does it mean that another VCR having DAV:checked-in the same as\n   that of already existing VCR should be created (which violates\n   workspace semantics ?) or will there be a non versioned member\n   created (having the content and dead properties of the already\n   existing VCR )?\n\nNeither.  It is like a Unix hard link, i.e. two names in two different\ncollections identify exactly the same resource.  \n\n   If it is the first case , then how will checkouts/checkins/merge be\n   handled on both VCR's ?\n\nIf you make a change to the resource at one of its names, that change\nis visible at its other name (since both names identify the same\nresource).  Two names ... one resource.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6345869"}, {"subject": "request for un-version-control featur", "content": "Hi.\n\nAs far as I know, there has been a long discussion about whether this\nfeature is required or not. Fact is, it's missing from RFC3253, yet several\nsystems need a way to implement it.\n\nSeveral workaround have been discussed, but IMHO all of them have some\ndisadvantages, and furthermore there's no interoperability here:\n\n1) COPY to new resource / DELETE old / MOVE back\n\nDisadvantage: creates new resource (ACLs are lost, DAV:resource-id changes),\nrequires multiple steps\n\n\n2) DELETE on version history resource\n\nDisadvantage: actually requires that VHRs are supported, also it's quit\npossible that the version history should be preserved\n\n\n3) PROPPATCH/remove on live properties such as DAV:checked-in,\nDAV:checked-out or DAV:version-history\n\nDisadvantage: messy and breaks RFC3253 (because the properties are\nprotected).\n\n\nTherefore I think that an (optional) new method \"UNVERSION-CONTROL\" makes\nmost sense. Servers won't need to support it, and it's presence can easily\nbe detected using OPTIONS and PROPFIND/supported-method-set.\n\nI can think of one optional parameter that would be marshalled in the\nrequest body: whether the version history should be deleted as well or not.\n\nFeedback appreciated,\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6355560"}, {"subject": "RE: request for un-version-control featur", "content": "Could you motivate the need to unversion-control a resource\nbut not delete it?  In particular, should a server that automatically\nputs all resources under version control fail such a request,\nor just ignore it?\n\nCheers,\nGeoff\n\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\nSent: Friday, February 07, 2003 12:27 PM\nTo: ietf-dav-versioning@w3.org\nSubject: request for un-version-control feature\n\n\n\nHi.\n\nAs far as I know, there has been a long discussion about whether this\nfeature is required or not. Fact is, it's missing from RFC3253, yet several\nsystems need a way to implement it.\n\nSeveral workaround have been discussed, but IMHO all of them have some\ndisadvantages, and furthermore there's no interoperability here:\n\n1) COPY to new resource / DELETE old / MOVE back\n\nDisadvantage: creates new resource (ACLs are lost, DAV:resource-id changes),\nrequires multiple steps\n\n\n2) DELETE on version history resource\n\nDisadvantage: actually requires that VHRs are supported, also it's quit\npossible that the version history should be preserved\n\n\n3) PROPPATCH/remove on live properties such as DAV:checked-in,\nDAV:checked-out or DAV:version-history\n\nDisadvantage: messy and breaks RFC3253 (because the properties are\nprotected).\n\n\nTherefore I think that an (optional) new method \"UNVERSION-CONTROL\" makes\nmost sense. Servers won't need to support it, and it's presence can easily\nbe detected using OPTIONS and PROPFIND/supported-method-set.\n\nI can think of one optional parameter that would be marshalled in the\nrequest body: whether the version history should be deleted as well or not.\n\nFeedback appreciated,\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6364545"}, {"subject": "RE: request for un-version-control featur", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, February 07, 2003 7:38 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: request for un-version-control feature\n>\n>\n>\n> Could you motivate the need to unversion-control a resource\n> but not delete it?  In particular, should a server that automatically\n\nI don't see why this needs to be coupled. I do understand that there are\ncases where servers do not support the concept of un-vcr-ing a resource, but\nwe have provably two independant implementations that both want/need to\nsupport this feature and are looking for a interoperable way to do it\neasily.\n\n> puts all resources under version control fail such a request,\n> or just ignore it?\n\nI think in this case it's best to just return 405 (not allowed), just as a\nRFC3253-conforming server would do it anyway.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6374275"}, {"subject": "RE: request for un-version-control featur", "content": "The main part of the question was:\n\n\"Could you motivate the need to unversion-control a resource.\"\n\nThe fact that \"two implementations want to do it\" is not the\nmost compelling answer (there are lots of things that you could\nget two implementations to agree on that would not merit\nadding to a standard protocol).\n\nNote: I'm not saying there are no compelling use cases ...\njust that I haven't heard any yet.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, February 07, 2003 7:38 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: request for un-version-control feature\n>\n>\n>\n> Could you motivate the need to unversion-control a resource\n> but not delete it?  In particular, should a server that automatically\n\nI don't see why this needs to be coupled. I do understand that there are\ncases where servers do not support the concept of un-vcr-ing a resource, but\nwe have provably two independant implementations that both want/need to\nsupport this feature and are looking for a interoperable way to do it\neasily.\n\n> puts all resources under version control fail such a request,\n> or just ignore it?\n\nI think in this case it's best to just return 405 (not allowed), just as a\nRFC3253-conforming server would do it anyway.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6383798"}, {"subject": "RE: request for un-version-control featur", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Saturday, February 08, 2003 2:25 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: request for un-version-control feature\n>\n>\n>\n> The main part of the question was:\n>\n> \"Could you motivate the need to unversion-control a resource.\"\n>\n> The fact that \"two implementations want to do it\" is not the\n> most compelling answer (there are lots of things that you could\n> get two implementations to agree on that would not merit\n> adding to a standard protocol).\n\nWell, if there are multiple implementations that want it, it's certainly\nnice if you can marshall it. That was the point of the proposal. Right now,\nI really don't care which kind of activity this leads to (deltaV addendum,\nprivate informational RFC, ...).\n\nRegarding the what-is-the-need-question: it makes a difference whether you\nare building a new system that accurately reflects the deltaV model, or if\nyou are busing deltaV to HTTP-marshall requests between systems that exist\nindependantly of WebDAV. In the latter case, you really can't choose --\nyou'll have to come up with a way to marshall that type of request (or\nyou'll have to live with an unhappy customer).\n\nIn general, I understand why a system would version everything, or a system\nwhere the decision about what is version-controlled is made by the server.\nWhat I don't really see is the use case for a system that has an explicit\n\"enable\" but no \"disable\" call.\n\n> Note: I'm not saying there are no compelling use cases ...\n> just that I haven't heard any yet.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6393899"}, {"subject": "un-version-control, unbaseline-contro", "content": "\"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:> \n> Regarding the what-is-the-need-question: it makes a difference whether you\n> are building a new system that accurately reflects the deltaV model, or if\n> you are busing deltaV to HTTP-marshall requests between systems that exist\n> independantly of WebDAV. In the latter case, you really can't choose --\n> you'll have to come up with a way to marshall that type of request (or\n> you'll have to live with an unhappy customer).\nUntil today I thought UNVERSION-CONTROL (like UNCHECKOUT) would be nice to\nhave. Just do a COPY, DELETE, MOVE dance and all is well. Perhaps some information\nis lost but who cares :-)\nNow I was writing a test scenario to test some baseline stuff.\nAt first I wanted to have a clean slate which would mean that the baseline I want\nto create doesn't exist. There I realized that UNVERSION-CONTROL has a bigger\nbrother named UNBASELINE-CONTROL.\nThe collection I want to unbaseline can have other configurations hidden in it.\nSo are these configurations preserved if I do a deep copy of the collection,\nDELETE and MOVE it back ? Also this can be expensive.\nIf the subordinate configurations are preserved I could accept doing this also\nfor configurations. If not please read on.\nThe concept of unversion and unbaseline is easy to understand and at the moment\nI think it would be cheap to realize it in my implementation.\nUnbaseline also would make sense in some cases. Sometimes you want to restructure\nyour configurations. E.g. at my current work with Visual Studio .NET we have\na solution and many projects (Configurations and subconfigurations in DeltaV I guess).\nSome people now want to repackage the projects because they think there are too many.\nSo perhaps UNBASELINE-CONTROL (and in it's wake UNVERSION-CONTROL) would be cheap but\nclean concepts for big projects.\n\nCheers, Edgar\n\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6404209"}, {"subject": "RE: request for un-version-control featur", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > From: Clemm, Geoff\n   >\n   > The main part of the question was:\n   > \"Could you motivate the need to unversion-control a resource.\"\n   > The fact that \"two implementations want to do it\" is not the\n   > most compelling answer (there are lots of things that you could\n   > get two implementations to agree on that would not merit\n   > adding to a standard protocol).\n\n   Well, if there are multiple implementations that want it, it's\n   certainly nice if you can marshall it.\n\nNew standard protocol features do not come for free ... they introduce\nadditional complexity into the protocol, especially for client and\nserver implementations that try to fully implement the protocol (to\nmaximize interoperability).  So I believe it is reasonable to at least\nrequire a compelling use case (and even that is not sufficient, when\nthere is not agreement on how to handle that use case, e.g. the\nrejection of the Translate header).\n\n   Regarding the what-is-the-need-question: it makes a difference\n   whether you are building a new system that accurately reflects the\n   deltaV model, or if you are using deltaV to HTTP-marshall requests\n   between systems that exist independantly of WebDAV. In the latter\n   case, you really can't choose -- you'll have to come up with a way\n   to marshall that type of request (or you'll have to live with an\n   unhappy customer).\n\nIf you included in the standard every feature provided by any system, \nthe protocol would be unusably complex, and would provide no basis\nfor effective inter-operation.  So every system will have a set of\nnon-standard features and extensions that it supports.  Only ones that\nare considered widely needed will end up in the standard protocol.\n\n   In general, I understand why a system would version everything, or\n   a system where the decision about what is version-controlled is\n   made by the server.  What I don't really see is the use case for a\n   system that has an explicit \"enable\" but no \"disable\" call.\n\nThe burden of proof is on the proponent of a new feature.  A new\nfeature is accepted because you have convinced people that it is\nuseful/necessary, not just because nobody demonstrated it was not\nuseful.\n\nNote that there are use cases for deleting the history of a resource\n(which is marshalled by issuing a DELETE request against the\nversion-history resource).  What has not been demonstrated is the need\nto \"disconnect\" a resource from its history without deleting the\nhistory.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6413298"}, {"subject": "RE: request for un-version-control featur", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Friday, February 14, 2003 9:17 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: request for un-version-control feature\n>\n>\n>\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>\n>    > From: Clemm, Geoff\n>    >\n>    > The main part of the question was:\n>    > \"Could you motivate the need to unversion-control a resource.\"\n>    > The fact that \"two implementations want to do it\" is not the\n>    > most compelling answer (there are lots of things that you could\n>    > get two implementations to agree on that would not merit\n>    > adding to a standard protocol).\n>\n>    Well, if there are multiple implementations that want it, it's\n>    certainly nice if you can marshall it.\n>\n> New standard protocol features do not come for free ... they introduce\n> additional complexity into the protocol, especially for client and\n> server implementations that try to fully implement the protocol (to\n> maximize interoperability).  So I believe it is reasonable to at least\n\nI wasn't actually asking for a \"standard protocol feature\". I was looking\nfor an agreement between those that *do* want that feature, so that *their*\nservers can interoperate.\n\nNote that under that proposal, any existing RFC3253 server would be\ncompliant, because it specifically allows servers not to implement it (just\nlike RFC3253 is silent about whether new resources are automatically\nversion-controlled or not).\n\n> require a compelling use case (and even that is not sufficient, when\n> there is not agreement on how to handle that use case, e.g. the\n> rejection of the Translate header).\n\nThat's correct, but I don't think the comparison makes sense here. The\nreason for the rejection of the \"translate\" header is that it's in direct\nviolation of the base spec (RFC2616). I don't see any problem like that with\na potential UNVERSION-CONTROL feature.\n\n> ...\n> If you included in the standard every feature provided by any system,\n> the protocol would be unusably complex, and would provide no basis\n> for effective inter-operation.  So every system will have a set of\n> non-standard features and extensions that it supports.  Only ones that\n> are considered widely needed will end up in the standard protocol.\n\nYes. That's why this feature hasn't made it into RFC3253. But that doesn't\nmean that it can't make it into a different specification, possibly just an\ninformational RFC.\n\nGiven the choice of several people coming up with proprietary and\nundocumented solutions, or having them agree on a common protocol and have\nthat published as RFC, I definitively prefer the latter. Don't you?\n\n>    In general, I understand why a system would version everything, or\n>    a system where the decision about what is version-controlled is\n>    made by the server.  What I don't really see is the use case for a\n>    system that has an explicit \"enable\" but no \"disable\" call.\n>\n> The burden of proof is on the proponent of a new feature.  A new\n> feature is accepted because you have convinced people that it is\n> useful/necessary, not just because nobody demonstrated it was not\n> useful.\n>\n> Note that there are use cases for deleting the history of a resource\n> (which is marshalled by issuing a DELETE request against the\n> version-history resource).  What has not been demonstrated is the need\n> to \"disconnect\" a resource from its history without deleting the\n> history.\n\nAs far as I understand, RFC3253 makes no promise at all about what happens\nwith a VCR when it's version history is deleted. Will it end up unversioned,\nor will it's version properties be left dangling (pointing to resources that\nhave been removed)? I think that if RFC3253 would mandate the former, less\npeople would be asking for this feature.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6423758"}, {"subject": "RE: request for un-version-control featur", "content": "I agree that DeltaV needs a real and standardized way to make a resource\nunversioned. Work-around proposals so far have not met the requirements\nfor the feature.\n\n> Note that there are use cases for deleting the history of a resource\n> (which is marshalled by issuing a DELETE request against the\n> version-history resource).  What has not been demonstrated is the need\n> to \"disconnect\" a resource from its history without deleting the\n> history.\n\nHere's the use case that demonstrates the need.\n\nFirst, a resource exists -- foo.doc. It is version-controlled.  I \ndecide to make foo.doc a regular resource. Why? Could be any of a \nnumber of reasons:\n - It was a mistake to make it versioned in the first place\n - My quota isn't big enough for all the old versions.\n - The resource is now published (publicly readable), not being \n   authored, so it's no longer appropriate to show or track \n   changes via versioning\n\nSo far, this motivates the basic need to have the content at URL \n\"foo.doc\" not be versioned... Now some side requirements:\nAlthough I want \"foo.doc\" to be unversioned, other things should \nstay the same.  Among these things:\n - The creationdate should not change\n - The user who created it should not change, nor should the owner\n - Permissions should not be re-initialized or changed\n - If there's a file access history, that should still be there\n - If foo.doc is locked, the lock should stay.\n - Other characteristics like tickets should not change.\n\nThe unversion use case may need to be supported in any repository \nwhere both versioned and unversioned resources exist. Users make \nmistakes, and they like to undo mistakes without making themselves \neven worse off.\n\nThe unversion problem, if not dealt with via a standard and well-behaved\nmechanism, could become the same as the \"safe-save\" problem which \nJulian has documented on the WebDAV.  When a client does a safe save to \na resource like \"foo.doc\", the client often does something like this:\n 1. PUT foo.doc~\n 2. HEAD foo.doc~\n 3. DELETE foo.doc\n 4. MOVE foo.doc~ to foo.doc\n\nWhen a user's client \"safe saves\" their document, the user is surprised\nif \nthe file's permissions change. Yet it's very common for the server to \napply a set of default permissions to \"foo.doc~\" when it's created, \nand then the custom permissions on \"foo.doc\" are lost when that one\nis deleted.\n\nIf clients start to do (1) COPY foo.doc to foo.doc~, (2) DELETE foo.doc,\n\n(3) MOVE foo.doc~ to foo.doc in order to accomplish unversioning, then\nwe'll just see more safe-save type garbage.\n\nLisa\n\n\n\n", "id": "lists-007-6436716"}, {"subject": "Configuratio", "content": "Hi ,\n    I could not understand the following part of defination of Configuration\n\n\" A configuration is a set of resources that consists of a root collection and all members (not just internal members) of that root collection that are not members of another configuration. \"\n\nWhy should the member's not be part of another configuration ? Could anyone please give a relevant use case also ?\n\nThanksa a ton,\nbest regards,\nVikram\n\n\n\n", "id": "lists-007-6446666"}, {"subject": "Re: Configuratio", "content": "\"Vikram_Roopchand\" <Vikram_Roopchand@infosys.com>\n>     I could not understand the following part of defination of Configuration\n> \n> \" A configuration is a set of resources that consists of a root collection and all\n> members (not just internal members) of that root collection that are not members\n> of another configuration. \"\nThis allows to have a second configurations root collection to be in the namespace\nof a first configuration. So you can put e.g. some subconfigurations \"below\" a\nmaster configuration.\n\nCheers, Edgar\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6454024"}, {"subject": "Allowing DAV:error in any 4xx or 5xx respons", "content": "In a recent thread on the ordering protocol, Julian suggested that a\n500 response code is more appropriate than either a 403 or a 409 for a\npostcondition failure.  I agree, and furthermore believe that RFC3253\nshould be updated to allow a DAV:error node to appear in the body of\nany 4xx or 5xx response.  This allows the server to use the most\nmeaningful response code for clients that do not understand DAV:error\nnodes.\n\nDoes anyone object to this extension?\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6461767"}, {"subject": "RE: Allowing DAV:error in any 4xx or 5xx respons", "content": "No (I don't object).\n\nActually, this (raising this issue here) was on my list of things to do\nanyway :-)\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Monday, February 24, 2003 3:38 PM\n> To: DeltaV (E-mail)\n> Subject: Allowing DAV:error in any 4xx or 5xx response\n>\n>\n>\n> In a recent thread on the ordering protocol, Julian suggested that a\n> 500 response code is more appropriate than either a 403 or a 409 for a\n> postcondition failure.  I agree, and furthermore believe that RFC3253\n> should be updated to allow a DAV:error node to appear in the body of\n> any 4xx or 5xx response.  This allows the server to use the most\n> meaningful response code for clients that do not understand DAV:error\n> nodes.\n>\n> Does anyone object to this extension?\n>\n> Cheers,\n> Geoff\n>\n>\n\n\n\n", "id": "lists-007-6469413"}, {"subject": "RE: request for un-version-control featur", "content": "   From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n\n   > From: Clemm, Geoff\n   >\n   > The main part of the question was: \"Could you motivate the need\n   > to unversion-control a resource.\"  New standard protocol features\n   > do not come for free ... they introduce additional complexity\n   > into the protocol, especially for client and server\n   > implementations that try to fully implement the protocol (to\n   > maximize interoperability).\n\n   I wasn't actually asking for a \"standard protocol feature\". I was\n   looking for an agreement between those that *do* want that feature,\n   so that *their* servers can interoperate.\n\nOK, that wasn't clear before (there was a request earlier to get\nan UNVERSION-CONTROL method into the standard protocol).\n\n   > Note that there are use cases for deleting the history of a\n   > resource (which is marshalled by issuing a DELETE request against\n   > the version-history resource).  What has not been demonstrated is\n   > the need to \"disconnect\" a resource from its history without\n   > deleting the history.\n\n   As far as I understand, RFC3253 makes no promise at all about what\n   happens with a VCR when it's version history is deleted. Will it\n   end up unversioned, or will it's version properties be left\n   dangling (pointing to resources that have been removed)? I think\n   that if RFC3253 would mandate the former, less people would be\n   asking for this feature.\n\nYes, that was my impression as well.  In particular, this is the use\ncase that Lisa identified in her email on this thread.\n\nI personally would be willing to require that deleting a version\nhistory converts all version-controlled resources for that\nversion-history into non-version-controlled resources, if that\naddresses the primary use case that is motivating the request for an\nUNVERSION-CONTROL method.  (And if it doesn't, please motivate\nthe use case where you want to keep the version history, and you\nwant to keep a version-controlled resource, but you no longer want\nthat version-controlled resource to be associated with that version\nhistory.)\n\nEdgar: Does this also address your request for an UNBASELINE-CONTROL\noperation (i.e. if we defined that deleting the\nversion-controlled-configuration causes the associated\nbaseline-controlled collection to no longer be baseline controlled)?\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6478562"}, {"subject": "Re (2): request for un-version-control featur", "content": "\"Clemm, Geoff\" <gclemm@rational.com> wrote:\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>    > From: Clemm, Geoff\n>    > The main part of the question was: \"Could you motivate the need\n>    > to unversion-control a resource.\"  New standard protocol features\n>    > do not come for free ... they introduce additional complexity\n>    > into the protocol, especially for client and server\n>    > implementations that try to fully implement the protocol (to\n>    > maximize interoperability).\n>    I wasn't actually asking for a \"standard protocol feature\". I was\n>    looking for an agreement between those that *do* want that feature,\n>    so that *their* servers can interoperate.\n> OK, that wasn't clear before (there was a request earlier to get\n> an UNVERSION-CONTROL method into the standard protocol).\nI somehow like complete concepts. So I see:\nUN-PUT = DELETE\nUN-CHECKOUT = UNCHECKOUT\nUN-CHECKIN = we don't want that in the protocol. Normally available at\n the repository level I suppose.\nUN-UPDATE = UPDATE\nUN-MOVE = MOVE\nSo for most operations sort of a rollback is possible. Therefore I also would\nlike to have it for VERSION-CONTROL. BTW my emphasis is more on UNBASELINE-CONTROL.\nSee below.\nSo we have basic and advanced versioning. Could we add an \"optional\" part including\nUNVERSION-CONTROL and UNBASELINE-CONTROL for these systems who think they need it ?\nIt needs to be written down somewhere to be agreed on.\nWhen I have a look at my implementation it would be easy to implement. But perhaps\nI don't see the problems yet :-)\nNo request body necessary. No depth problems. Perhaps a precondition\nversion-controlled-configuration-must-be-checked-out if baselines are also\nimplemented.\n\n> I personally would be willing to require that deleting a version\n> history converts all version-controlled resources for that\n> version-history into non-version-controlled resources,\nIs that realistic ? Does the keeper of the version history know about all\nthe VCRs and version urls that exist perhaps on other servers ?\n\n> Edgar: Does this also address your request for an UNBASELINE-CONTROL\n> operation (i.e. if we defined that deleting the\n> version-controlled-configuration causes the associated\n> baseline-controlled collection to no longer be baseline controlled)?\nNo it doesn't. My interest is mainly in UNBASELINE-CONTROL (UNVERSION-CONTROL is\njust it's little brother). It doesn't happen every day but once in a while I found\nthat software projects with hundreds or thousands of files need some redesign.\nSo you want to rearrange your subconfiguration hierarchy. In this case I don't want\nto delete the baseline history. An UNBASELINE-CONTROL would be an easy to understand\nconcept (At least to me :-)\nAlso I can imagine to restore a baseline which I would like to publish on\nCD with versioning info removed. \nAnd because (As I already mentioned before) I still think that it would be easy to\ndo in my implementation I would like to have the option to do it.\nTo be able to be interoperable with other implementations it needs to be\ndefined somwhere. Because it's such simple stuff it would be overkill to\nhave another RFC. So I would prefer it to be described in a \"optional\" section\nof 3253.\nBTW, I'm writing DeltaV stuff for an exotic language called Oberon at the moment.\nSo it's not so important what I do :-)\n\nCheers, Edgar\n\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6488169"}, {"subject": "RE: Re (2): request for un-version-control featur", "content": "OK, since there are three folks asking for UN-XXX-CONTROL,\nI'm willing to withdraw my objection since I'm the only one\nobjecting.\n\nSo now the main question is: should this go in the\nnext revision of 3253, or should it be a separate draft?\n(Either one is OK with me).\n\nCheers,\nGeoff \n\n\n-----Original Message-----\nFrom: Edgar@EdgarSchwarz.de [mailto:Edgar@EdgarSchwarz.de]\n\n\"Clemm, Geoff\" <gclemm@rational.com> wrote:\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>    > From: Clemm, Geoff\n>    > The main part of the question was: \"Could you motivate the need\n>    > to unversion-control a resource.\"  New standard protocol features\n>    > do not come for free ... they introduce additional complexity\n>    > into the protocol, especially for client and server\n>    > implementations that try to fully implement the protocol (to\n>    > maximize interoperability).\n>    I wasn't actually asking for a \"standard protocol feature\". I was\n>    looking for an agreement between those that *do* want that feature,\n>    so that *their* servers can interoperate.\n> OK, that wasn't clear before (there was a request earlier to get\n> an UNVERSION-CONTROL method into the standard protocol).\nI somehow like complete concepts. So I see:\nUN-PUT = DELETE\nUN-CHECKOUT = UNCHECKOUT\nUN-CHECKIN = we don't want that in the protocol. Normally available at\n the repository level I suppose.\nUN-UPDATE = UPDATE\nUN-MOVE = MOVE\nSo for most operations sort of a rollback is possible. Therefore I also\nwould\nlike to have it for VERSION-CONTROL. BTW my emphasis is more on\nUNBASELINE-CONTROL.\nSee below.\nSo we have basic and advanced versioning. Could we add an \"optional\" part\nincluding\nUNVERSION-CONTROL and UNBASELINE-CONTROL for these systems who think they\nneed it ?\nIt needs to be written down somewhere to be agreed on.\nWhen I have a look at my implementation it would be easy to implement. But\nperhaps\nI don't see the problems yet :-)\nNo request body necessary. No depth problems. Perhaps a precondition\nversion-controlled-configuration-must-be-checked-out if baselines are also\nimplemented.\n\n> I personally would be willing to require that deleting a version\n> history converts all version-controlled resources for that\n> version-history into non-version-controlled resources,\nIs that realistic ? Does the keeper of the version history know about all\nthe VCRs and version urls that exist perhaps on other servers ?\n\n> Edgar: Does this also address your request for an UNBASELINE-CONTROL\n> operation (i.e. if we defined that deleting the\n> version-controlled-configuration causes the associated\n> baseline-controlled collection to no longer be baseline controlled)?\nNo it doesn't. My interest is mainly in UNBASELINE-CONTROL\n(UNVERSION-CONTROL is\njust it's little brother). It doesn't happen every day but once in a while I\nfound\nthat software projects with hundreds or thousands of files need some\nredesign.\nSo you want to rearrange your subconfiguration hierarchy. In this case I\ndon't want\nto delete the baseline history. An UNBASELINE-CONTROL would be an easy to\nunderstand\nconcept (At least to me :-)\nAlso I can imagine to restore a baseline which I would like to publish on\nCD with versioning info removed. \nAnd because (As I already mentioned before) I still think that it would be\neasy to\ndo in my implementation I would like to have the option to do it.\nTo be able to be interoperable with other implementations it needs to be\ndefined somwhere. Because it's such simple stuff it would be overkill to\nhave another RFC. So I would prefer it to be described in a \"optional\"\nsection\nof 3253.\nBTW, I'm writing DeltaV stuff for an exotic language called Oberon at the\nmoment.\nSo it's not so important what I do :-)\n\nCheers, Edgar\n\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6499954"}, {"subject": "RE: Re (2): request for un-version-control featur", "content": "Hi,\n\nI think these new methods should be added to the next revision of 3253\nas a new optional feature.\n\nregards\nMatthias\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Montag, 3. M?rz 2003 23:55\nTo: ietf-dav-versioning@w3.org\nSubject: RE: Re (2): request for un-version-control feature\n\n\n\nOK, since there are three folks asking for UN-XXX-CONTROL,\nI'm willing to withdraw my objection since I'm the only one\nobjecting.\n\nSo now the main question is: should this go in the\nnext revision of 3253, or should it be a separate draft?\n(Either one is OK with me).\n\nCheers,\nGeoff \n\n\n-----Original Message-----\nFrom: Edgar@EdgarSchwarz.de [mailto:Edgar@EdgarSchwarz.de]\n\n\"Clemm, Geoff\" <gclemm@rational.com> wrote:\n>    From: Julian Reschke [mailto:julian.reschke@greenbytes.de]\n>    > From: Clemm, Geoff\n>    > The main part of the question was: \"Could you motivate the need\n>    > to unversion-control a resource.\"  New standard protocol features\n>    > do not come for free ... they introduce additional complexity\n>    > into the protocol, especially for client and server\n>    > implementations that try to fully implement the protocol (to\n>    > maximize interoperability).\n>    I wasn't actually asking for a \"standard protocol feature\". I was\n>    looking for an agreement between those that *do* want that feature,\n>    so that *their* servers can interoperate.\n> OK, that wasn't clear before (there was a request earlier to get\n> an UNVERSION-CONTROL method into the standard protocol).\nI somehow like complete concepts. So I see:\nUN-PUT = DELETE\nUN-CHECKOUT = UNCHECKOUT\nUN-CHECKIN = we don't want that in the protocol. Normally available at\n the repository level I suppose.\nUN-UPDATE = UPDATE\nUN-MOVE = MOVE\nSo for most operations sort of a rollback is possible. Therefore I also\nwould\nlike to have it for VERSION-CONTROL. BTW my emphasis is more on\nUNBASELINE-CONTROL.\nSee below.\nSo we have basic and advanced versioning. Could we add an \"optional\" part\nincluding\nUNVERSION-CONTROL and UNBASELINE-CONTROL for these systems who think they\nneed it ?\nIt needs to be written down somewhere to be agreed on.\nWhen I have a look at my implementation it would be easy to implement. But\nperhaps\nI don't see the problems yet :-)\nNo request body necessary. No depth problems. Perhaps a precondition\nversion-controlled-configuration-must-be-checked-out if baselines are also\nimplemented.\n\n> I personally would be willing to require that deleting a version\n> history converts all version-controlled resources for that\n> version-history into non-version-controlled resources,\nIs that realistic ? Does the keeper of the version history know about all\nthe VCRs and version urls that exist perhaps on other servers ?\n\n> Edgar: Does this also address your request for an UNBASELINE-CONTROL\n> operation (i.e. if we defined that deleting the\n> version-controlled-configuration causes the associated\n> baseline-controlled collection to no longer be baseline controlled)?\nNo it doesn't. My interest is mainly in UNBASELINE-CONTROL\n(UNVERSION-CONTROL is\njust it's little brother). It doesn't happen every day but once in a while I\nfound\nthat software projects with hundreds or thousands of files need some\nredesign.\nSo you want to rearrange your subconfiguration hierarchy. In this case I\ndon't want\nto delete the baseline history. An UNBASELINE-CONTROL would be an easy to\nunderstand\nconcept (At least to me :-)\nAlso I can imagine to restore a baseline which I would like to publish on\nCD with versioning info removed. \nAnd because (As I already mentioned before) I still think that it would be\neasy to\ndo in my implementation I would like to have the option to do it.\nTo be able to be interoperable with other implementations it needs to be\ndefined somwhere. Because it's such simple stuff it would be overkill to\nhave another RFC. So I would prefer it to be described in a \"optional\"\nsection\nof 3253.\nBTW, I'm writing DeltaV stuff for an exotic language called Oberon at the\nmoment.\nSo it's not so important what I do :-)\n\nCheers, Edgar\n\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6512720"}, {"subject": "RE: Re (2): request for un-version-control featur", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Clemm, Geoff\n> Sent: Monday, March 03, 2003 11:55 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: Re (2): request for un-version-control feature\n>\n>\n>\n> OK, since there are three folks asking for UN-XXX-CONTROL,\n> I'm willing to withdraw my objection since I'm the only one\n> objecting.\n>\n> So now the main question is: should this go in the\n> next revision of 3253, or should it be a separate draft?\n> (Either one is OK with me).\n\nI think it would be best to collect all \"common\" extensions to DeltaV into a\nseparate draft. Once it's stable and depending on the timeline for\nRFC3253bis,  we can decide either to move contents into RFC3253bis or to\npublish it separately.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6526554"}, {"subject": "Re (3): request for un-version-control featur", "content": "\"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n> \"Clemm, Geoff\" <gclemm@rational.com>\n> > OK, since there are three folks asking for UN-XXX-CONTROL,\n> > I'm willing to withdraw my objection since I'm the only one\n> > objecting.\n> >\n> > So now the main question is: should this go in the\n> > next revision of 3253, or should it be a separate draft?\n> > (Either one is OK with me).\n> \n> I think it would be best to collect all \"common\" extensions to DeltaV into a\n> separate draft. Once it's stable and depending on the timeline for\n> RFC3253bis,  we can decide either to move contents into RFC3253bis or to\n> publish it separately.\nSounds fine to me. BTW, is there already an \"common\" extensions draft ?\nThen there would be a search for volunteers to do a draft for UNVERSION-CONTROL\nand UNBASELINE-CONTROL.\nLisa, Julian, others or should I give it a try ? I couldn't promise to do it the next\ncouple of days but it's not that urgent I guess.\n\nCheers, Edgar \n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6536186"}, {"subject": "RE: Re (3): request for un-version-control featur", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of\n> Edgar@edgarschwarz.de\n> Sent: Tuesday, March 04, 2003 9:45 PM\n> To: ietf-dav-versioning@w3.org\n> Cc: Edgar@edgarschwarz.de\n> Subject: Re (3): request for un-version-control feature\n>\n>\n>\n> \"Julian Reschke\" <julian.reschke@greenbytes.de> wrote:\n> > \"Clemm, Geoff\" <gclemm@rational.com>\n> > > OK, since there are three folks asking for UN-XXX-CONTROL,\n> > > I'm willing to withdraw my objection since I'm the only one\n> > > objecting.\n> > >\n> > > So now the main question is: should this go in the\n> > > next revision of 3253, or should it be a separate draft?\n> > > (Either one is OK with me).\n> >\n> > I think it would be best to collect all \"common\" extensions to\n> DeltaV into a\n> > separate draft. Once it's stable and depending on the timeline for\n> > RFC3253bis,  we can decide either to move contents into RFC3253bis or to\n> > publish it separately.\n> Sounds fine to me. BTW, is there already an \"common\" extensions draft ?\n\nNo, not yet.\n\n> Then there would be a search for volunteers to do a draft for\nUNVERSION-CONTROL\n> and UNBASELINE-CONTROL.\n> Lisa, Julian, others or should I give it a try ? I couldn't\n> promise to do it the next\n> couple of days but it's not that urgent I guess.\n\nThat would be great. Let me know if I can assist with rfc RFC2629 machinery\n(RFC in XML), if you happen to prefer that to Word or plain text.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6545401"}, {"subject": "ANN: ObeDAV 0.", "content": "Hi,\nI just uploaded a new release of my DeltaV server and client for Active Oberon.\nIt already can do simple baselines.\nI would like the following text to be added to the list of WebDAV Open Source\nprojects:\n\n<A href=\"http://www.edgarschwarz.de/oberon/\">ObeDAV</A>\nis a DeltaV server and client for \n<A href=\"http://bluebottle.ethz.ch/\">Bluebottle</A>\nwritten in Oberon supporting BASELINE-CONTROL.\n\nCheers, Edgar\n\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6556623"}, {"subject": "exclusive checkout of VC", "content": "Hi,\n\nI am wondering how an exclusive checkout with apply-to-version of a \nVCR could be requested using DeltaV protocol. We want to be able\nto prevent concurrent checkouts of the same VCR in the same workspace.\n\nregards\nMatthias\n\n\n\n", "id": "lists-007-6564216"}, {"subject": "RE: exclusive checkout of VC", "content": "Just set the DAV:checkout-fork property of the VCR to be DAV:forbidden.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Sohn, Matthias [mailto:matthias.sohn@sap.com]\nSent: Monday, March 10, 2003 8:44 AM\nTo: ietf-dav-versioning@w3.org\nSubject: exclusive checkout of VCR\n\n\n\nHi,\n\nI am wondering how an exclusive checkout with apply-to-version of a \nVCR could be requested using DeltaV protocol. We want to be able\nto prevent concurrent checkouts of the same VCR in the same workspace.\n\nregards\nMatthias\n\n\n\n", "id": "lists-007-6572290"}, {"subject": "URGENT: Please Help ...... DeltaV and WebDAV Relationshi", "content": "Hi ,\n\n       We are implementing a server for DeltaV , there are conflicts among couple of groups here about the design of the Server. \n\nOne Group believes that since DeltaV is a versioning extension of WebDAV the relationship in terms of OOAD is \"is Kind Of\" (Inheritance) , hence the Implementation of DeltaV should extend from already implemented WebDAV server.\n\nWhile the other group believes that the DeltaV is a \"Component\" (not to be taken literally) of WebDAV  i.e WebDAV can be made \"versionable\" using DeltaV or by simply \"activating\" DeltaV Implementation Code .... and hence DeltaV should be treated seperately.\n\nI would like to know the relationship between DeltaV and WebDAV in terms of OOP/OOAD.\n\nI would be highly grateful , if anyone could get back to me with his/her views as soon as possible.\n\nBest Regards,         \n\nVikram\n\n\n\n---------------------------------\nDo you Yahoo!?\nYahoo! Web Hosting - establish your business online\n\n\n\n", "id": "lists-007-6580529"}, {"subject": "RE: exclusive checkout of VC", "content": "Hi,\n\n4.3 CHECKOUT Method (applied to a version-controlled resource)\ndefines the precondition :\n\n(DAV:checkout-of-version-with-descendant-is-forbidden): If the\n      DAV:checkout-fork property of the version being checked out is\n      DAV:forbidden, the request MUST fail if a version identifies that\n      version in its DAV:predecessor-set.\n\nThis means if I set checkout-fork to forbidden on the VCR this would\nprohibit concurrent checkouts across all workspaces having a VCR for \nthis version history. \n\nThis is not exactly what we want to provide.\nWe want to prohibit concurrent checkouts in the same workspace only,\ni.e. if a user exclusively checks out a VCR pointing to Version V7 in \nworkspace A we want to prevent concurrent checkouts in the same workspace\nonly, but checkout of a VCR of a different workspace B currently \npointing to the same version V7 shall be allowed.\n\nIs there a way to specify this in DeltaV ?\n\nregards\nMatthias\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Montag, 10. M?rz 2003 15:15\nTo: ietf-dav-versioning@w3.org\nSubject: RE: exclusive checkout of VCR\n\n\n\nJust set the DAV:checkout-fork property of the VCR to be DAV:forbidden.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Sohn, Matthias [mailto:matthias.sohn@sap.com]\nSent: Monday, March 10, 2003 8:44 AM\nTo: ietf-dav-versioning@w3.org\nSubject: exclusive checkout of VCR\n\n\n\nHi,\n\nI am wondering how an exclusive checkout with apply-to-version of a \nVCR could be requested using DeltaV protocol. We want to be able\nto prevent concurrent checkouts of the same VCR in the same workspace.\n\nregards\nMatthias\n\n\n\n", "id": "lists-007-6588926"}, {"subject": "Re: exclusive checkout of VC", "content": "Hi,\n\nin my opinion, the following precondition solves your problem\n\n(DAV:one-version-controlled-resource-per-history-per-workspace): If the \nDAV:version-control request body specifies a version, and if the \nrequest-URL is a member of a workspace, then there MUST NOT already be a \nversion-controlled member of that workspace whose DAV:checked-in or \nDAV:checked-out property identifies any version from the version history \nof the version specified in the request body.\n\nregards, Manfred\n\n>Hi,\n>\n>4.3 CHECKOUT Method (applied to a version-controlled resource)\n>defines the precondition :\n>\n>(DAV:checkout-of-version-with-descendant-is-forbidden): If the\n>      DAV:checkout-fork property of the version being checked out is\n>      DAV:forbidden, the request MUST fail if a version identifies that\n>      version in its DAV:predecessor-set.\n>\n>This means if I set checkout-fork to forbidden on the VCR this would\n>prohibit concurrent checkouts across all workspaces having a VCR for \n>this version history. \n>\n>This is not exactly what we want to provide.\n>We want to prohibit concurrent checkouts in the same workspace only,\n>i.e. if a user exclusively checks out a VCR pointing to Version V7 in \n>workspace A we want to prevent concurrent checkouts in the same workspace\n>only, but checkout of a VCR of a different workspace B currently \n>pointing to the same version V7 shall be allowed.\n>\n>Is there a way to specify this in DeltaV ?\n>\n>regards\n>Matthias\n>\n>-----Original Message-----\n>From: Clemm, Geoff [mailto:gclemm@rational.com]\n>Sent: Montag, 10. M?rz 2003 15:15\n>To: ietf-dav-versioning@w3.org\n>Subject: RE: exclusive checkout of VCR\n>\n>\n>\n>Just set the DAV:checkout-fork property of the VCR to be DAV:forbidden.\n>\n>Cheers,\n>Geoff\n>\n>-----Original Message-----\n>From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n>Sent: Monday, March 10, 2003 8:44 AM\n>To: ietf-dav-versioning@w3.org\n>Subject: exclusive checkout of VCR\n>\n>\n>\n>Hi,\n>\n>I am wondering how an exclusive checkout with apply-to-version of a \n>VCR could be requested using DeltaV protocol. We want to be able\n>to prevent concurrent checkouts of the same VCR in the same workspace.\n>\n>regards\n>Matthias\n>\n>  \n>\n\n\n\n", "id": "lists-007-6599377"}, {"subject": "RE: exclusive checkout of VC", "content": "Having multiple version-controlled resources in a workspace\nwas not Matthias' issue.  He wanted to prevent multiple\nconcurrent DAV:apply-to-version CHECKOUT's on the same\nversion-controlled resource.  \n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Manfred Baedke [mailto:manfred.baedke@greenbytes.de]\nSent: Tuesday, March 11, 2003 6:52 AM\nTo: Sohn, Matthias\nCc: 'ietf-dav-versioning@w3.org'; 'Clemm, Geoff'\nSubject: Re: exclusive checkout of VCR\n\n\nHi,\n\nin my opinion, the following precondition solves your problem\n\n(DAV:one-version-controlled-resource-per-history-per-workspace): If the \nDAV:version-control request body specifies a version, and if the \nrequest-URL is a member of a workspace, then there MUST NOT already be a \nversion-controlled member of that workspace whose DAV:checked-in or \nDAV:checked-out property identifies any version from the version history \nof the version specified in the request body.\n\nregards, Manfred\n\n>Hi,\n>\n>4.3 CHECKOUT Method (applied to a version-controlled resource)\n>defines the precondition :\n>\n>(DAV:checkout-of-version-with-descendant-is-forbidden): If the\n>      DAV:checkout-fork property of the version being checked out is\n>      DAV:forbidden, the request MUST fail if a version identifies that\n>      version in its DAV:predecessor-set.\n>\n>This means if I set checkout-fork to forbidden on the VCR this would\n>prohibit concurrent checkouts across all workspaces having a VCR for \n>this version history. \n>\n>This is not exactly what we want to provide.\n>We want to prohibit concurrent checkouts in the same workspace only,\n>i.e. if a user exclusively checks out a VCR pointing to Version V7 in \n>workspace A we want to prevent concurrent checkouts in the same workspace\n>only, but checkout of a VCR of a different workspace B currently \n>pointing to the same version V7 shall be allowed.\n>\n>Is there a way to specify this in DeltaV ?\n>\n>regards\n>Matthias\n>\n>-----Original Message-----\n>From: Clemm, Geoff [mailto:gclemm@rational.com]\n>Sent: Montag, 10. M?rz 2003 15:15\n>To: ietf-dav-versioning@w3.org\n>Subject: RE: exclusive checkout of VCR\n>\n>\n>\n>Just set the DAV:checkout-fork property of the VCR to be DAV:forbidden.\n>\n>Cheers,\n>Geoff\n>\n>-----Original Message-----\n>From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n>Sent: Monday, March 10, 2003 8:44 AM\n>To: ietf-dav-versioning@w3.org\n>Subject: exclusive checkout of VCR\n>\n>\n>\n>Hi,\n>\n>I am wondering how an exclusive checkout with apply-to-version of a \n>VCR could be requested using DeltaV protocol. We want to be able\n>to prevent concurrent checkouts of the same VCR in the same workspace.\n>\n>regards\n>Matthias\n>\n>  \n>\n\n\n\n", "id": "lists-007-6610213"}, {"subject": "RE: exclusive checkout of VC", "content": "   From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n\n   We want to prohibit concurrent checkouts in the same workspace\n   only, i.e. if a user exclusively checks out a VCR pointing to\n   Version V7 in workspace A we want to prevent concurrent checkouts\n   in the same workspace only, but checkout of a VCR of a different\n   workspace B currently pointing to the same version V7 shall be\n   allowed.\n\n   Is there a way to specify this in DeltaV ?\n\nThere's no standard way for you to expose that restriction, so I'd\nsuggest just returning DAV:checkin-fork-forbidden with some custom\nerror string indicating that it is a checkout in this workspace\nthat is blocking the CHECKOUT.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6621819"}, {"subject": "RE: exclusive checkout of VC", "content": "Hi,\n\nok, understand how to reject a concurrent checkout if an exclusive\ncheckout is already present. \n\nMy question was how to request the exclusive checkout through\nthe protocol. We don't want to do exclusive checkouts implicitly\non all checkouts but we want to allow the client to specify if\nthe checkout is to be done exclusively or not in the sense\ndescribed below.\n\nregards\nMatthias\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Dienstag, 11. M?rz 2003 15:14\nTo: 'ietf-dav-versioning@w3.org'\nSubject: RE: exclusive checkout of VCR\n\n\n\n   From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n\n   We want to prohibit concurrent checkouts in the same workspace\n   only, i.e. if a user exclusively checks out a VCR pointing to\n   Version V7 in workspace A we want to prevent concurrent checkouts\n   in the same workspace only, but checkout of a VCR of a different\n   workspace B currently pointing to the same version V7 shall be\n   allowed.\n\n   Is there a way to specify this in DeltaV ?\n\nThere's no standard way for you to expose that restriction, so I'd\nsuggest just returning DAV:checkin-fork-forbidden with some custom\nerror string indicating that it is a checkout in this workspace\nthat is blocking the CHECKOUT.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6630028"}, {"subject": "RE: exclusive checkout of VC", "content": "   From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n\n   My question was how to request the exclusive checkout through\n   the protocol. We don't want to do exclusive checkouts implicitly\n   on all checkouts but we want to allow the client to specify if\n   the checkout is to be done exclusively or not in the sense\n   described below.\n\nWith RFC-3253, the mechanism to allow you to constrain a checkout\nin this fashion is an activity.  In particular, the\nactivity is used to specify the \"line of descent\" that you are\nchecking out against, and the system ensures that no more than\none checkout can occur on a given line of descent.\n\nSo if you are already exposing activities to your users,\nautomatically create a \"workspace activity\", and automatically\nmake every activity that a user wants to work on in the workspace\na subactivity of that workspace activity.  The\nDAV:one-checkout-per-activity-per-history precondition will\nensure there is at most one checkout per VCR in your workspace.\n\nIf you are not exposing activities to your users,\nyou still automatically create a \"workspace activity\", and\nset the DAV:current-activity property of the workspace to\nbe that activity.  This will ensure there is at most one\ncheckout per VCR in the workspace.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6639581"}, {"subject": "RE: exclusive checkout of VC", "content": "Hi,\n\nbut this would mean that all checkouts are automatically excluding \nconcurrent checkout with respect to a workspace. But we want that \nthe client can decide if it wants an exclusive or non-exclusive checkout.\n\nregards\nMatthias\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Dienstag, 11. M?rz 2003 15:50\nTo: 'ietf-dav-versioning@w3.org'\nSubject: RE: exclusive checkout of VCR\n\n\n\n   From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n\n   My question was how to request the exclusive checkout through\n   the protocol. We don't want to do exclusive checkouts implicitly\n   on all checkouts but we want to allow the client to specify if\n   the checkout is to be done exclusively or not in the sense\n   described below.\n\nWith RFC-3253, the mechanism to allow you to constrain a checkout\nin this fashion is an activity.  In particular, the\nactivity is used to specify the \"line of descent\" that you are\nchecking out against, and the system ensures that no more than\none checkout can occur on a given line of descent.\n\nSo if you are already exposing activities to your users,\nautomatically create a \"workspace activity\", and automatically\nmake every activity that a user wants to work on in the workspace\na subactivity of that workspace activity.  The\nDAV:one-checkout-per-activity-per-history precondition will\nensure there is at most one checkout per VCR in your workspace.\n\nIf you are not exposing activities to your users,\nyou still automatically create a \"workspace activity\", and\nset the DAV:current-activity property of the workspace to\nbe that activity.  This will ensure there is at most one\ncheckout per VCR in the workspace.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6648396"}, {"subject": "RE: exclusive checkout of VC", "content": "With activities, you can specify DAV:unreserved\nin the CHECKOUT if you want non-exclusive checkouts.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Sohn, Matthias [mailto:matthias.sohn@sap.com]\nSent: Tuesday, March 11, 2003 9:57 AM\nTo: 'ietf-dav-versioning@w3.org'; 'Clemm, Geoff'\nSubject: RE: exclusive checkout of VCR\n\n\nHi,\n\nbut this would mean that all checkouts are automatically excluding \nconcurrent checkout with respect to a workspace. But we want that \nthe client can decide if it wants an exclusive or non-exclusive checkout.\n\nregards\nMatthias\n\n-----Original Message-----\nFrom: Clemm, Geoff [mailto:gclemm@rational.com]\nSent: Dienstag, 11. M?rz 2003 15:50\nTo: 'ietf-dav-versioning@w3.org'\nSubject: RE: exclusive checkout of VCR\n\n\n\n   From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n\n   My question was how to request the exclusive checkout through\n   the protocol. We don't want to do exclusive checkouts implicitly\n   on all checkouts but we want to allow the client to specify if\n   the checkout is to be done exclusively or not in the sense\n   described below.\n\nWith RFC-3253, the mechanism to allow you to constrain a checkout\nin this fashion is an activity.  In particular, the\nactivity is used to specify the \"line of descent\" that you are\nchecking out against, and the system ensures that no more than\none checkout can occur on a given line of descent.\n\nSo if you are already exposing activities to your users,\nautomatically create a \"workspace activity\", and automatically\nmake every activity that a user wants to work on in the workspace\na subactivity of that workspace activity.  The\nDAV:one-checkout-per-activity-per-history precondition will\nensure there is at most one checkout per VCR in your workspace.\n\nIf you are not exposing activities to your users,\nyou still automatically create a \"workspace activity\", and\nset the DAV:current-activity property of the workspace to\nbe that activity.  This will ensure there is at most one\ncheckout per VCR in the workspace.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6658354"}, {"subject": "RE: exclusive checkout of VC", "content": "Wouldn't the DAV: checkout-fork property of all the versions have to be\nforbidden as well? Otherwise, the other user could just issue a CHECKOUT\nrequest directly to the latest version, and get a working resource, thus\na non-exclusive checkout.\n\nLisa\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org \n> [mailto:ietf-dav-versioning-request@w3.org] On Behalf Of Clemm, Geoff\n> Sent: Monday, March 10, 2003 6:15 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: exclusive checkout of VCR\n> \n> \n> \n> Just set the DAV:checkout-fork property of the VCR to be \n> DAV:forbidden.\n> \n> Cheers,\n> Geoff\n> \n> -----Original Message-----\n> From: Sohn, Matthias [mailto:matthias.sohn@sap.com]\n> Sent: Monday, March 10, 2003 8:44 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: exclusive checkout of VCR\n> \n> \n> \n> Hi,\n> \n> I am wondering how an exclusive checkout with apply-to-version of a \n> VCR could be requested using DeltaV protocol. We want to be able\n> to prevent concurrent checkouts of the same VCR in the same workspace.\n> \n> regards\n> Matthias\n> \n> \n\n\n\n", "id": "lists-007-6668673"}, {"subject": "RE: URGENT: Please Help ...... DeltaV and WebDAV Relationshi", "content": "Vikram,\n \nIn protocol design, generally we attempt to avoid specific OOP or OOAD\nmodels.  It's up to the server implementor to decide how to implement a\nprotocol, and they may not even be using an object-oriented programming\nlanguage.\n \nGood luck resolving your conflicts!\n \nLisa\n\n-----Original Message-----\nFrom: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org] On Behalf Of Vikram\nRoopchand\nSent: Monday, March 10, 2003 8:53 PM\nTo: ietf-dav-versioning@w3.org\nSubject: URGENT: Please Help ...... DeltaV and WebDAV Relationship\n\n\n\nHi ,\n\n       We are implementing a server for DeltaV , there are conflicts\namong couple of groups here about the design of the Server. \n\nOne Group believes that since DeltaV is a versioning extension of WebDAV\nthe relationship in terms of OOAD is \"is Kind Of\" (Inheritance) , hence\nthe Implementation of DeltaV should extend from already implemented\nWebDAV server.\n\nWhile the other group believes that the DeltaV is a \"Component\" (not to\nbe taken literally) of WebDAV  i.e WebDAV can be made \"versionable\"\nusing DeltaV or by simply \"activating\" DeltaV Implementation Code ....\nand hence DeltaV should be treated seperately.\n\nI would like to know the relationship between DeltaV and WebDAV in terms\nof OOP/OOAD.\n\nI would be highly grateful , if anyone could get back to me with his/her\nviews as soon as possible.\n\nBest Regards,         \n\nVikram\n\n\n\n\n  _____  \n\nDo you Yahoo!?\nYahoo!  <http://webhosting.yahoo.com/ps/wh3/prod/> Web Hosting -\nestablish your business online\n\n\n\n", "id": "lists-007-6678227"}, {"subject": "RE: URGENT: Please Help ...... DeltaV and WebDAV Relationshi", "content": "In OO terms, DeltaV and WebDAV are interface definitions, not\nimplementations.  DeltaV extends WebDAV both by introducing some new\nsub-interfaces of Resource (e.g. Activity and Version-History), but to make\nthings interesting, for interoperability with existing clients, DeltaV also\nintroduces some new *super-interfaces* that extend existing WebDAV classes\n(e.g. Resource and Collection) with new versioning methods.\n\nBut you asked how an existing WebDAV server implementation should be\nextended to provide DeltaV support.  That depends totally on how your\nexisting WebDAV server is implemented, and to some extent, on what the\nimplementation language is for your WebDAV server.  So that leaves you with\nthe very unsatisfying answer: \"It depends\" (:-).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Vikram Roopchand [mailto:vikramrc@yahoo.com]\nSent: Monday, March 10, 2003 11:53 PM\nTo: ietf-dav-versioning@w3.org\nSubject: URGENT: Please Help ...... DeltaV and WebDAV Relationship\n\n\nHi ,\n       We are implementing a server for DeltaV , there are conflicts among\ncouple of groups here about the design of the Server. \nOne Group believes that since DeltaV is a versioning extension of WebDAV the\nrelationship in terms of OOAD is \"is Kind Of\" (Inheritance) , hence the\nImplementation of DeltaV should extend from already implemented WebDAV\nserver.\nWhile the other group believes that the DeltaV is a \"Component\" (not to be\ntaken literally) of WebDAV  i.e WebDAV can be made \"versionable\" using\nDeltaV or by simply \"activating\" DeltaV Implementation Code .... and hence\nDeltaV should be treated seperately.\nI would like to know the relationship between DeltaV and WebDAV in terms of\nOOP/OOAD.\nI would be highly grateful , if anyone could get back to me with his/her\nviews as soon as possible.\nBest Regards,         \nVikram\n\n\n\n\nDo you Yahoo!?\nYahoo! Web Hosting - establish your business online\n\n\n\n", "id": "lists-007-6688350"}, {"subject": "Tamino WebDAV Server's PUT implementatio", "content": "I have a question regarding the Tamino WebDAV Server's\nimplementation of the PUT method.\n\nIt appears that when PUTing an XML document, Tamino stores it \npreserving the XML infoset but not the actual byte-for-byte \nlayout of the document, so for example, PUTing:\n\n  <hello></hello> \n\nwill be retrieved using GET as:\n\n  <hello/>\n\nI've seen some discussion stating that the server must \nmaintain octet-for-octet fidelity of the entity enclosed \nin the PUT request.\n\nIs Tamino's implementation wrong or is my description of \nPUT too strict?  \n\nThanks.\n\n\n\n", "id": "lists-007-6697921"}, {"subject": "RE: Tamino WebDAV Server's PUT implementatio", "content": "Hi.\n\nFirst of all, this isn't really about WebDAV or DeltaV -- it's a generic\nHTTP question.\n\nI'd say that yes, a server may use \"lossy\" ways to persist entities. After\nall, all HTTP is giving you are methods that get/set certain\n*representations* of resources.\n\nNow of course this will fail if your client assumes that it can round-trip\noctet-by-octet. In which case I'd recommend just to use a different server\n(or backend within that server). It's a backend optimized for a specific use\ncase (storing XML infosets). If this doesn't fit into your requirements, use\nsomething else.\n\nJulian\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n  -----Original Message-----\n  From: ietf-dav-versioning-request@w3.org\n[mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Jeffrey Winter\n  Sent: Thursday, March 13, 2003 5:21 PM\n  To: ietf-dav-versioning@w3.org\n  Subject: Tamino WebDAV Server's PUT implementation\n\n\n  I have a question regarding the Tamino WebDAV Server's\n  implementation of the PUT method.\n\n  It appears that when PUTing an XML document, Tamino stores it\n  preserving the XML infoset but not the actual byte-for-byte\n  layout of the document, so for example, PUTing:\n\n    <hello></hello>\n\n  will be retrieved using GET as:\n\n    <hello/>\n\n  I've seen some discussion stating that the server must\n  maintain octet-for-octet fidelity of the entity enclosed\n  in the PUT request.\n\n  Is Tamino's implementation wrong or is my description of\n  PUT too strict?\n\n  Thanks.\n\n\n\n", "id": "lists-007-6705826"}, {"subject": "RE: Tamino WebDAV Server's PUT implementatio", "content": "Hello Jeffrey,\n\n \n\nTamino XML Server (as the back end store of Tamino WebDAV Server)\n\"optimizes\" the XML representation. From an XML perspective both\nrepresentations are identical. From a binary perspective, they are obviously\ndifferent.\n\nIf you want to get back the original input document (also on a binary\nlevel), Tamino WebDAV Server offers some configuration parameters, which\nwill allow doing so.\n\nPlease have a look at the community of Tamino WebDAV Sever for more details\n(http://developer.softwareag.com/tamino/webdav/default.htm\n<http://developer.softwareag.com/tamino/webdav/default.htm> , \"http put\nstorage\").\n\n \n\nBest regards\n\n \n\nJuergen Pill\n\n \n\n \n\n \n\n-----Original Message-----\nFrom: Jeffrey Winter [mailto:jeffreywinter@crd.com] \nSent: Donnerstag, 13. M?rz 2003 17:21\nTo: ietf-dav-versioning@w3.org\nSubject: Tamino WebDAV Server's PUT implementation\n\n \n\nI have a question regarding the Tamino WebDAV Server's\n\nimplementation of the PUT method.\n\n \n\nIt appears that when PUTing an XML document, Tamino stores it \n\npreserving the XML infoset but not the actual byte-for-byte \n\nlayout of the document, so for example, PUTing:\n\n \n\n  <hello></hello> \n\n \n\nwill be retrieved using GET as:\n\n \n\n  <hello/>\n\n \n\nI've seen some discussion stating that the server must \n\nmaintain octet-for-octet fidelity of the entity enclosed \n\nin the PUT request.\n\n \n\nIs Tamino's implementation wrong or is my description of \n\nPUT too strict?  \n\n \n\nThanks.\n\n\n\n", "id": "lists-007-6715940"}, {"subject": "RE: Tamino WebDAV Server's PUT implementatio", "content": "Juergen, Julian,\n\nThanks for your responses.\n\nI agree that this was perhaps more of an HTTP-specific question,\nbut my sense was that in the DAV world, the document fidelity \nof PUT would be even more important.\n\nI actually prefer a looser, context-specific interpretation of\nthe PUT semantics as it allows PUT to be more data-centric as\nopposed to purely document-centric.\n\nIt's never been clear to me where the strict, byte-for-byte \nentity preservation interpretation came from.  It seems folkloric.\n\n- Jeff\n\n\n\n", "id": "lists-007-6725917"}, {"subject": "Checkout-In-Plac", "content": "Hi all,\n\nI've just been studying the proposed standard for DAV versioning and \njust joined the email list. There is something in the spec that's \nconfusing me. After poring through the spec several times, I've about \ndecided it's an editing problem. Especially after I searched the email \nlist archives and found another message that seems to be related.\n\nSection 4 of the spec refers to the \"Checkout-in-place Feature\". \nHowever, this feature is rather disconnected from the rest of the \ndocument. Section 2.1 talks of three separate basic versioning packages. \nCheckout-in-place is not listed as belonging to any of these. While it's \nin the set of sections about basic versioning (2-9), the first mention \nof it occurs in the Section 4 heading.\n\nHowever, the Basic-Server-Workspace Package (Section 2.1) includes a \nfeature \"checkout\", which doesn't seem to be described anywhere in the spec.\n\nSearching the email list archive, I discovered message \nhttp://lists.w3.org/Archives/Public/ietf-dav-versioning/2001JulSep/0111.html \n.  This seems to suggest that the confusion may be due to an incomplete \nsearch and replace. Apparently, \"checkout_in_place\" was formerly called \n\"checkout\" and the reference in Section 2.1 may simply be on that wasn't \ncorrected.\n\nHowever, that same email message serves to further muddy the waters. It \nmentions the \"checkout\" method. That's probably not what Section 2.1 \nrefers to, but the names do match.\n\nJeff Thompson\n\n\n\n", "id": "lists-007-6733984"}, {"subject": "RE: Checkout-In-Plac", "content": "Good catch, Jeff!\n\nYou are correct on both counts, i.e. section 2.1 should refer to\nthe \"checkout-in-place\" feature, not the \"checkout\" feature, and\nthe reason was as you surmised, that it originally was called the\n\"checkout\" feature, and the occurrence in section 2.1 was missed\nby the query/replace.\n\nI'll fix it in the next draft.\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Jeff Thompson [mailto:Jeff_Thompson@CoCreate.com]\nSent: Friday, March 21, 2003 6:00 PM\nTo: ietf-dav-versioning@w3.org\nSubject: Checkout-In-Place\n\n\n\nHi all,\n\nI've just been studying the proposed standard for DAV versioning and \njust joined the email list. There is something in the spec that's \nconfusing me. After poring through the spec several times, I've about \ndecided it's an editing problem. Especially after I searched the email \nlist archives and found another message that seems to be related.\n\nSection 4 of the spec refers to the \"Checkout-in-place Feature\". \nHowever, this feature is rather disconnected from the rest of the \ndocument. Section 2.1 talks of three separate basic versioning packages. \nCheckout-in-place is not listed as belonging to any of these. While it's \nin the set of sections about basic versioning (2-9), the first mention \nof it occurs in the Section 4 heading.\n\nHowever, the Basic-Server-Workspace Package (Section 2.1) includes a \nfeature \"checkout\", which doesn't seem to be described anywhere in the spec.\n\nSearching the email list archive, I discovered message \nhttp://lists.w3.org/Archives/Public/ietf-dav-versioning/2001JulSep/0111.html\n\n.  This seems to suggest that the confusion may be due to an incomplete \nsearch and replace. Apparently, \"checkout_in_place\" was formerly called \n\"checkout\" and the reference in Section 2.1 may simply be on that wasn't \ncorrected.\n\nHowever, that same email message serves to further muddy the waters. It \nmentions the \"checkout\" method. That's probably not what Section 2.1 \nrefers to, but the names do match.\n\nJeff Thompson\n\n\n\n", "id": "lists-007-6742127"}, {"subject": "Basic Versioning Package", "content": "  Another question regarding basic versioning packages.\n\nSection 2.1 of the spec states:\n\n> Although a server MAY support any combination of versioning features, \n> in order to minimize the complexity of a WebDAV basic versioning \n> client, a WebDAV basic versioning server SHOULD support one of the \n> following three \"packages\" (feature sets):\n>\n> - Core-Versioning Package: version-control\n>\n> - Basic-Server-Workspace Package: version-control, workspace, \n> version-history, checkout\n>\n> - Basic-Client-Workspace Package: version-control, working-resource, \n> update, label\n>\n\nIn reviewing the features, it seems to me that a combination of \nversion-control and checkout-in-place would meet our needs very well and \nprovide a minimalist yet complete package. Yet, the spec states that we \nSHOULD not provide this combination. I'm trying to get a feeling for \nthis statement from the spec.\n\nWhat is the rationale behind this restriction?\n\nThe referred spec, RFC 2119, defines SHOULD as,\n\n>This word, or the adjective \"RECOMMENDED\", mean that there\n>   may exist valid reasons in particular circumstances to ignore a\n>   particular item, but the full implications must be understood and\n>   carefully weighed before choosing a different course.\n>\nThe full implications of ignoring this SHOULD are not at all clear to \nme. My proposed combination seems reasonable. Can someone please \nenlighten me?\n\nJeff Thompson\n\n\n\n", "id": "lists-007-6751212"}, {"subject": "RE: Basic Versioning Package", "content": "The purpose of the SHOULD is to make live easier for an interoperable\nclient writer.  In particular, the presence or absence of a particular\ncombination of features can significantly affect what kind of model\nshould be presented to a user in order to give them simple, intuitive\naccess to supported functionality.  For an interoperable client\nwriter to optimize that model for all possible\nfeature combinations would be prohibitively complex, so after much\ndebate, we settled on 5 packages that seemed to best balance what\nexisting versioning systems actually supported and what the\nknown DeltaV server writers were planning on implementing.\n\nSo in this case, the \"known implications\" of supporting a set of\nfeatures that does not exactly correspond to one of the recommended\nsets is that interoperable clients are likely to just take advantage\nof the subset of the features that do correspond to a recommended set,\nand only clients specifically written for your server will use the\nextended features.\n\nSo the valid reasons include:\n- these are important features for clients written specifically for your\nserver\n- this set of features is one that you hope to be considered as a \"standard\nset\" in the next draft of the specification\n- there are interoperable clients that have been written to take advantage\nof feature combinations other than those defined as a standard package (and\nthat therefore will expose all the features your server is providing).\n\nCheers,\nGeoff\n\n-----Original Message-----\nFrom: Jeff Thompson [mailto:Jeff_Thompson@CoCreate.com]\nSent: Monday, March 24, 2003 1:37 PM\nTo: ietf-dav-versioning\nSubject: Basic Versioning Packages\n\n\n\n  Another question regarding basic versioning packages.\n\nSection 2.1 of the spec states:\n\n> Although a server MAY support any combination of versioning features, \n> in order to minimize the complexity of a WebDAV basic versioning \n> client, a WebDAV basic versioning server SHOULD support one of the \n> following three \"packages\" (feature sets):\n>\n> - Core-Versioning Package: version-control\n>\n> - Basic-Server-Workspace Package: version-control, workspace, \n> version-history, checkout\n>\n> - Basic-Client-Workspace Package: version-control, working-resource, \n> update, label\n>\n\nIn reviewing the features, it seems to me that a combination of \nversion-control and checkout-in-place would meet our needs very well and \nprovide a minimalist yet complete package. Yet, the spec states that we \nSHOULD not provide this combination. I'm trying to get a feeling for \nthis statement from the spec.\n\nWhat is the rationale behind this restriction?\n\nThe referred spec, RFC 2119, defines SHOULD as,\n\n>This word, or the adjective \"RECOMMENDED\", mean that there\n>   may exist valid reasons in particular circumstances to ignore a\n>   particular item, but the full implications must be understood and\n>   carefully weighed before choosing a different course.\n>\nThe full implications of ignoring this SHOULD are not at all clear to \nme. My proposed combination seems reasonable. Can someone please \nenlighten me?\n\nJeff Thompson\n\n\n\n", "id": "lists-007-6759322"}, {"subject": "Namespace of attributes in DAV:property elemen", "content": "In RFC 3253, the DTD for the DAV:property element in the \nDAV:expand-property report is\n\n<!ELEMENT property (property*)>\n<!ATTLIST property name NMTOKEN #REQUIRED>\nname value: a property element type\n<!ATTLIST property namespace NMTOKEN \"DAV:\">\nnamespace value: an XML namespace\n\nSince all element names defined by the protocol are understood to be in \nthe DAV: namespace, I would assume that attributes would be too, except \nthat the example in section 3.8.1 uses the \"name\" attribute without a \nnamespace. Was that really the intent, and if so, wouldn't it be better, \nor at least a little more consistent, to put the attributes in the DAV: \nnamespace?\n\nIn any case, I think this needs to be clarified, since the DTDs do not \nexplicitly define namespaces.\n\nJohn Vasta\n\n\n\n", "id": "lists-007-6818022"}, {"subject": "RE: Namespace of attributes in DAV:property elemen", "content": "I agree that this should be added to the issues list (basically, RFC3253bis\nshould clarify the role of the DTD segments, just like what we're doing with\nthe other news specs right now).\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of John R Vasta\n> Sent: Wednesday, July 09, 2003 9:42 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: Namespace of attributes in DAV:property element\n>\n>\n>\n> In RFC 3253, the DTD for the DAV:property element in the\n> DAV:expand-property report is\n>\n> <!ELEMENT property (property*)>\n> <!ATTLIST property name NMTOKEN #REQUIRED>\n> name value: a property element type\n> <!ATTLIST property namespace NMTOKEN \"DAV:\">\n> namespace value: an XML namespace\n>\n> Since all element names defined by the protocol are understood to be in\n> the DAV: namespace, I would assume that attributes would be too, except\n> that the example in section 3.8.1 uses the \"name\" attribute without a\n> namespace. Was that really the intent, and if so, wouldn't it be better,\n> or at least a little more consistent, to put the attributes in the DAV:\n> namespace?\n>\n> In any case, I think this needs to be clarified, since the DTDs do not\n> explicitly define namespaces.\n>\n> John Vasta\n>\n>\n\n\n\n", "id": "lists-007-6825873"}, {"subject": "RE: Namespace of attributes in DAV:property elemen", "content": "What about John's particular question ... should we modify 3253 in\nthe next revision to state that the \"name\" and \"namespace\" attributes\nare in the DAV: namespace, and then modify the example in 3.8.1\nto reflect this?  If there aren't many implementations yet of the\nDAV:expand-property report, we could get this change publicized now,\nto minimize interoperability issues in the future.\n\nI could go either way on this, but just to get the voting started,\nI'll vote, yes, we should make this change.\n\nCheers,\nGeoff \n\nietf-dav-versioning-request@w3.org wrote on 07/09/2003 04:01:18 PM:\n\n> \n> I agree that this should be added to the issues list (basically, \nRFC3253bis\n> should clarify the role of the DTD segments, just like what we're doing \nwith\n> the other news specs right now).\n> \n> --\n> <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n> \n> > -----Original Message-----\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of John R Vasta\n> > Sent: Wednesday, July 09, 2003 9:42 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: Namespace of attributes in DAV:property element\n> >\n> >\n> >\n> > In RFC 3253, the DTD for the DAV:property element in the\n> > DAV:expand-property report is\n> >\n> > <!ELEMENT property (property*)>\n> > <!ATTLIST property name NMTOKEN #REQUIRED>\n> > name value: a property element type\n> > <!ATTLIST property namespace NMTOKEN \"DAV:\">\n> > namespace value: an XML namespace\n> >\n> > Since all element names defined by the protocol are understood to be \nin\n> > the DAV: namespace, I would assume that attributes would be too, \nexcept\n> > that the example in section 3.8.1 uses the \"name\" attribute without a\n> > namespace. Was that really the intent, and if so, wouldn't it be \nbetter,\n> > or at least a little more consistent, to put the attributes in the \nDAV:\n> > namespace?\n> >\n> > In any case, I think this needs to be clarified, since the DTDs do not\n> > explicitly define namespaces.\n> >\n> > John Vasta\n> >\n> >\n> \n\n\n\n", "id": "lists-007-6836322"}, {"subject": "RE: Namespace of attributes in DAV:property elemen", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Geoffrey M Clemm\n> Sent: Friday, July 11, 2003 11:39 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: Namespace of attributes in DAV:property element\n>\n>\n>\n> What about John's particular question ... should we modify 3253 in\n> the next revision to state that the \"name\" and \"namespace\" attributes\n> are in the DAV: namespace, and then modify the example in 3.8.1\n> to reflect this?  If there aren't many implementations yet of the\n\nFor heaven's sake, no!!!!! That would be an incompatible change.\n\nWe should clarify that the attributes are in no namespace.\n\n> DAV:expand-property report, we could get this change publicized now,\n> to minimize interoperability issues in the future.\n\nThere are. Speaking of which -- I think several server implementors claim to\nsupport RFC3253 (basic versioning). I'd certainly hope that they all support\nDAV:expand-property, as it's a required report.\n\n> I could go either way on this, but just to get the voting started,\n> I'll vote, yes, we should make this change.\n\nNo. Not only because it is a incompatible change (that breaks our server),\nit's also a very unusual usage of namespaces in XML. For instance, check\nXSLT: XSLT attributes are in no namespace, unless they appear on an element\nwhich itself is not in the XSLT namespace.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6847736"}, {"subject": "REPORT/PROPFIND of baseline member", "content": "Hi,\nI would like to get a list of the versions contained in a baseline.\nHow could a request and response look like ?\n\nCheers, Edgar\n\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6857704"}, {"subject": "CHECKOUT/UNCHECKOUT of configuration", "content": "Hi,\nI need some clarifications.\nIs it necessary to CHECKOUT a configuration to be allowed to CHECKOUT one\nof it's members ?\nAnd if that applies suppose I modify or delete a member.\nThen I UNCHECKOUT the configuration. Is it necessary to undo the changes ?\n\nCheers, Edgar\n\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-6865378"}, {"subject": "Re: REPORT/PROPFIND of baseline member", "content": "Edgar wrote on 07/13/2003 04:27:52 PM:\n\n> I would like to get a list of the versions contained in a baseline.\n> How could a request and response look like ?\n> \n\nDo a Depth:Infinity PROPFIND on the URL in the DAV:baseline-collection\nof the baseline, asking for the DAV:checked-in property.  Standard\nPROPFIND request and response format.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6873184"}, {"subject": "Re: CHECKOUT/UNCHECKOUT of configuration", "content": "Edgar wrote on 07/13/2003 04:28:02 PM:\n\n> Is it necessary to CHECKOUT a configuration to be allowed to CHECKOUT \none\n> of it's members ?\n\nNo, only to CHECKIN one of its members.  One certainly could \nreasonably argue that the spec should have required this\n(but currently, it doesn't).\n\n> And if that applies suppose I modify or delete a member.\n\nNo, only to CHECKIN the version-controlled collection from which\nyou deleted the member.  Although as above, one certainly could\nreasonably argue that the spec should have required this.\n\n> Then I UNCHECKOUT the configuration. Is it necessary to undo the changes \n?\n\nNo, there is no such requirement for UNCHECKOUT.  And here again,\nonce certainly could reasonably argue that the spec should have\nrequired this (but currently it doesn't).\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-6880613"}, {"subject": "VERSION-CONTROL erro", "content": "What should the DeltaV error code (in the XML body) be if a client sends VERSION-CONTROL request to a collection, and the server does not support versioned collections?\n\nLisa\n\n\n\n", "id": "lists-007-6888456"}, {"subject": "RE: VERSION-CONTROL erro", "content": "I don't think we have a precondition for that, as it would simply be a 405 (Method Not Allowed).\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760 \n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Lisa Dusseault\n> Sent: Thursday, August 07, 2003 9:10 PM\n> To: DeltaV\n> Subject: VERSION-CONTROL error\n> \n> \n> \n> \n> What should the DeltaV error code (in the XML body) be if a \n> client sends VERSION-CONTROL request to a collection, and the \n> server does not support versioned collections?\n> \n> Lisa\n> \n> \n> \n> \n\n\n\n", "id": "lists-007-6895490"}, {"subject": "Typo in RFC3253, section 14.1.", "content": "'... the new versioned-controlled internal member'. [1]\n\n\n[1] <http://greenbytes.de/tech/webdav/rfc3253.html#PROPERTY_eclipsed-set>\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6904089"}, {"subject": "Re: Typo in RFC3253, section 14.1.", "content": "Will fix.  Thanks!\n\nCheers,\nGeoff\n\nJulian wrote on 08/10/2003 04:40:23 AM:\n\n> \n> '... the new versioned-controlled internal member'. [1]\n> \n> \n> [1] \n<http://greenbytes.de/tech/webdav/rfc3253.html#PROPERTY_eclipsed-set>\n> \n> --\n> <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n> \n> \n\n\n\n", "id": "lists-007-6911816"}, {"subject": "DAV:displayname with version", "content": "Just a simple question, is the DAV:displayname of a resource \"global\" ?\nOr is it possible to have different DAV:displayname(s) for different\nversions of the same resource.\n\nI found nothing in the mailing lists or in the RFC.\n\nBest regards\n\n Horst Liermann\n\n\n\n", "id": "lists-007-6919334"}, {"subject": "RE: displayname with version", "content": "Different versions of a version controlled resource *are* different\nresource, thus they usually don't share properties.\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Horst Liermann\n> Sent: Monday, August 11, 2003 5:48 PM\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: DAV:displayname with versions\n>\n>\n>\n> Just a simple question, is the DAV:displayname of a resource \"global\" ?\n> Or is it possible to have different DAV:displayname(s) for different\n> versions of the same resource.\n>\n> I found nothing in the mailing lists or in the RFC.\n>\n> Best regards\n>\n>  Horst Liermann\n>\n>\n\n\n\n", "id": "lists-007-6927239"}, {"subject": "Re: DAV:displayname with version", "content": "There is no concept of a \"global\" property of a version.\nEach version is a separate resource, with its own properties.\nSo each version has its own DAV:displayname property.\n\nBut there is a natural place to put a \"global\" property of a\nversion, namely, as a property on the VersionHistory of that\nversion.\n\nCheers,\nGeoff\n\nietf-dav-versioning-request@w3.org wrote on 08/11/2003 11:47:38 AM:\n\n> \n> Just a simple question, is the DAV:displayname of a resource \"global\" ?\n> Or is it possible to have different DAV:displayname(s) for different\n> versions of the same resource.\n> \n> I found nothing in the mailing lists or in the RFC.\n> \n> Best regards\n> \n>  Horst Liermann\n> \n\n\n\n", "id": "lists-007-6936378"}, {"subject": "RE: DAV:displayname with version", "content": "Sure, every version must have the displayname property so you can get it\nwith PROPFIND.  However, no specification requires that to be either\nwritable or protected on a version, so on some servers it won't be writable.\nAlso no specification requires it to be either static or dynamic, so it's\npossible on some servers that the property would be protected, and it would\nchange whenever the value on the VCR changed.\n\nI believe on Xythos WFS the displayname property is protected and static on\nversions.  It will always have the same value as the displayname property of\nthe VCR.\n\nLisa\n\n> -----Original Message-----\n> From: ietf-dav-versioning-request@w3.org \n> [mailto:ietf-dav-versioning-request@w3.org] On Behalf Of \n> Geoffrey M Clemm\n> Sent: Monday, August 11, 2003 9:03 AM\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: Re: DAV:displayname with versions\n> \n> \n> \n> There is no concept of a \"global\" property of a version.\n> Each version is a separate resource, with its own properties. \n> So each version has its own DAV:displayname property.\n> \n> But there is a natural place to put a \"global\" property of a \n> version, namely, as a property on the VersionHistory of that version.\n> \n> Cheers,\n> Geoff\n> \n> ietf-dav-versioning-request@w3.org wrote on 08/11/2003 11:47:38 AM:\n> \n> > \n> > Just a simple question, is the DAV:displayname of a \n> resource \"global\" \n> > ? Or is it possible to have different DAV:displayname(s) \n> for different \n> > versions of the same resource.\n> > \n> > I found nothing in the mailing lists or in the RFC.\n> > \n> > Best regards\n> > \n> >  Horst Liermann\n> > \n> \n> \n\n\n\n", "id": "lists-007-6945240"}, {"subject": "RE: DAV:displayname with version", "content": "Yes, 3253 leaves the definition of versioning behavior for live properties\nup to the standard that defines those live properties.\n\n\nSo we should probably try to define the versioning behavior for 2518 \nproperties\nin 2518bis.  In general, the simplest default versioning behavior for a\nproperty such as DAV:displayname is to treat it the same as a dead \nproperty,\ni.e. it is an immutable copy of the value of that property on the VCR at\nCHECKIN time.  Does this work for folks currently doing versioning?\n(I couldn't quite tell from Lisa's description whether this is\nthe Xythos behavior or not).\n\nCheers,\nGeoff\n\nLisa wrote on 08/11/2003 01:09:58 PM:\n> \n> Sure, every version must have the displayname property so you can get it\n> with PROPFIND.  However, no specification requires that to be either\n> writable or protected on a version, so on some servers it won't be \nwritable.\n> Also no specification requires it to be either static or dynamic, so \nit's\n> possible on some servers that the property would be protected, and it \nwould\n> change whenever the value on the VCR changed.\n> \n> I believe on Xythos WFS the displayname property is protected and static \non\n> versions.  It will always have the same value as the displayname \nproperty of\n> the VCR.\n\n> > -----Original Message-----\n> > From: Geoffrey M Clemm\n> > \n> > There is no concept of a \"global\" property of a version.\n> > Each version is a separate resource, with its own properties. \n> > So each version has its own DAV:displayname property.\n> > \n> > But there is a natural place to put a \"global\" property of a \n> > version, namely, as a property on the VersionHistory of that version.\n\n> > Horst wrote on 08/11/2003 11:47:38 AM:\n> > > \n> > > Just a simple question, is the DAV:displayname of a \n> > resource \"global\" \n> > > ? Or is it possible to have different DAV:displayname(s) \n> > for different \n> > > versions of the same resource.\n\n\n\n", "id": "lists-007-6955604"}, {"subject": "RE: DAV:displayname with version", "content": "That isn't quite the Xythos WFS behavior.  If you MOVE a VCR, its\ndisplayname changes to the current name.  Thus the displayname changes for\nall the versions as well. They aren't entirely immutable, in other words. \n\n I wouldn't put the versioning behavior of properties in RFC2518bis,\nhowever, we need to keep changes there down so we get finished in finite\ntime and get draft standard status with tested interoperable features.  If\nwe think we can specify property behavior for versioning it could just as\neasily be done in a separate short draft.\n\nSpeaking of this, what are the issues for the binding draft and the behavior\nof live properties?  Does the binding draft sufficiently cover what happens\nwith versioning in the mix?\n\nLisa\n\n> -----Original Message-----\n> From: w3c-dist-auth-request@w3.org \n> [mailto:w3c-dist-auth-request@w3.org] On Behalf Of Geoffrey M Clemm\n> Sent: Monday, August 11, 2003 10:46 AM\n> To: ietf-dav-versioning@w3.org; webdav\n> Subject: RE: DAV:displayname with versions\n> \n> \n> \n> Yes, 3253 leaves the definition of versioning behavior for \n> live properties up to the standard that defines those live properties.\n> \n> \n> So we should probably try to define the versioning behavior for 2518 \n> properties\n> in 2518bis.  In general, the simplest default versioning \n> behavior for a property such as DAV:displayname is to treat \n> it the same as a dead \n> property,\n> i.e. it is an immutable copy of the value of that property on \n> the VCR at CHECKIN time.  Does this work for folks currently \n> doing versioning? (I couldn't quite tell from Lisa's \n> description whether this is the Xythos behavior or not).\n> \n> Cheers,\n> Geoff\n> \n> Lisa wrote on 08/11/2003 01:09:58 PM:\n> > \n> > Sure, every version must have the displayname property so \n> you can get \n> > it with PROPFIND.  However, no specification requires that to be \n> > either writable or protected on a version, so on some \n> servers it won't \n> > be\n> writable.\n> > Also no specification requires it to be either static or dynamic, so\n> it's\n> > possible on some servers that the property would be \n> protected, and it\n> would\n> > change whenever the value on the VCR changed.\n> > \n> > I believe on Xythos WFS the displayname property is protected and \n> > static\n> on\n> > versions.  It will always have the same value as the displayname\n> property of\n> > the VCR.\n> \n> > > -----Original Message-----\n> > > From: Geoffrey M Clemm\n> > > \n> > > There is no concept of a \"global\" property of a version. Each \n> > > version is a separate resource, with its own properties. So each \n> > > version has its own DAV:displayname property.\n> > > \n> > > But there is a natural place to put a \"global\" property of a\n> > > version, namely, as a property on the VersionHistory of \n> that version.\n> \n> > > Horst wrote on 08/11/2003 11:47:38 AM:\n> > > > \n> > > > Just a simple question, is the DAV:displayname of a\n> > > resource \"global\"\n> > > > ? Or is it possible to have different DAV:displayname(s)\n> > > for different\n> > > > versions of the same resource.\n> \n> \n\n\n\n", "id": "lists-007-6965650"}, {"subject": "RE: DAV:displayname with version", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Lisa Dusseault\n> Sent: Monday, August 11, 2003 8:04 PM\n> To: 'Geoffrey M Clemm'; ietf-dav-versioning@w3.org; 'webdav'\n> Subject: RE: DAV:displayname with versions\n>\n>\n>\n> That isn't quite the Xythos WFS behavior.  If you MOVE a VCR, its\n> displayname changes to the current name.  Thus the displayname changes for\n> all the versions as well. They aren't entirely immutable, in other words.\n\nMay I ask what this is good for? If the DAV:displayname always equals the\nlast path component, it's much simpler not to have it at all. [WYes, I know\nthat IIS behaves the same -- however this doesn't make it right]\n\n>  I wouldn't put the versioning behavior of properties in RFC2518bis,\n> however, we need to keep changes there down so we get finished in finite\n> time and get draft standard status with tested interoperable features.  If\n> we think we can specify property behavior for versioning it could just as\n> easily be done in a separate short draft.\n>\n> Speaking of this, what are the issues for the binding draft and  the\nbehavior\n> of live properties?  Does the binding draft sufficiently cover  what\nhappens\n> with versioning in the mix?\n\nWhich reminds me that having the DAV:displayname change with MOVE is deeply\nincompatible with bindings. In particular, consider one resource A with\nbindings a' and a''. How does the DAV:displayname obtained from a' change if\nyou rename a''? Don't tell me that the property value will vary depending on\nthe URL you use.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6977700"}, {"subject": "RE: DAV:displayname with version", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Lisa Dusseault\n> Sent: Monday, August 11, 2003 7:10 PM\n> To: 'Geoffrey M Clemm'; ietf-dav-versioning@w3.org\n> Subject: RE: DAV:displayname with versions\n>\n>\n>\n> Sure, every version must have the displayname property so you can get it\n> with PROPFIND.  However, no specification requires that to be either\n\nNope. DAV:displayname is an *optional* property:\n\n\"If present, the property contains a description of the resource that is\nsuitable for presentation to a user.\"\n\nIt's perfectly OK not to have it when it was never explicitly set.\n\n> writable or protected on a version, so on some servers it won't\n> be writable.\n\nYes, but the specification still says \"...contains a description of the\nresource that is suitable for presentation to a user...\". So no matter how a\nserver implements it's protected DAV:displayname property, it still must\nsuit this purpose. Just copying the last path component of the request URL\n(that's what IIS does) doesn't satisfy this requirement.\n\n> Also no specification requires it to be either static or dynamic, so it's\n> possible on some servers that the property would be protected, and it\nwould\n> change whenever the value on the VCR changed.\n\nYes (unfortunately).\n\n> ...\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6988410"}, {"subject": "RE: DAV:displayname with version", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Geoffrey M Clemm\n> Sent: Monday, August 11, 2003 7:46 PM\n> To: ietf-dav-versioning@w3.org; webdav\n> Subject: RE: DAV:displayname with versions\n>\n>\n>\n> Yes, 3253 leaves the definition of versioning behavior for live properties\n> up to the standard that defines those live properties.\n>\n>\n> So we should probably try to define the versioning behavior for 2518\n> properties\n> in 2518bis.  In general, the simplest default versioning behavior for a\n> property such as DAV:displayname is to treat it the same as a dead\n> property,\n> i.e. it is an immutable copy of the value of that property on the VCR at\n> CHECKIN time.  Does this work for folks currently doing versioning?\n\nYes.\n\n> (I couldn't quite tell from Lisa's description whether this is\n> the Xythos behavior or not).\n\nI'd really like to see a use case that conflicts with Geoff's definition.\n\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-6998548"}, {"subject": "RE: DAV:displayname with version", "content": "I agree that we want to finish RFC2518bis in a finite amount of time,\nbut I disagree that versioning behavior of RFC2518 properties should be\ndefined in a separate draft.  Any new WebDAV draft should fully define\nthe behavior of any live property it defines, and versioning is \na standard part of the WebDAV family (after all, it is \"WebDAV\", not\n\"WebDA\" :-).\n\nCheers,\nGeoff\n\n\"Lisa Dusseault\" <lisa@xythos.com> wrote on 08/11/2003 02:04:24 PM:\n\n> That isn't quite the Xythos WFS behavior.  If you MOVE a VCR, its\n> displayname changes to the current name.  Thus the displayname changes \nfor\n> all the versions as well. They aren't entirely immutable, in other \nwords. \n> \n>  I wouldn't put the versioning behavior of properties in RFC2518bis,\n> however, we need to keep changes there down so we get finished in finite\n> time and get draft standard status with tested interoperable features. \nIf\n> we think we can specify property behavior for versioning it could just \nas\n> easily be done in a separate short draft.\n> \n> Speaking of this, what are the issues for the binding draft and the \nbehavior\n> of live properties?  Does the binding draft sufficiently cover what \nhappens\n> with versioning in the mix?\n> \n> Lisa\n> \n> > -----Original Message-----\n> > From: w3c-dist-auth-request@w3.org \n> > [mailto:w3c-dist-auth-request@w3.org] On Behalf Of Geoffrey M Clemm\n> > Sent: Monday, August 11, 2003 10:46 AM\n> > To: ietf-dav-versioning@w3.org; webdav\n> > Subject: RE: DAV:displayname with versions\n> > \n> > \n> > \n> > Yes, 3253 leaves the definition of versioning behavior for \n> > live properties up to the standard that defines those live properties.\n> > \n> > \n> > So we should probably try to define the versioning behavior for 2518 \n> > properties\n> > in 2518bis.  In general, the simplest default versioning \n> > behavior for a property such as DAV:displayname is to treat \n> > it the same as a dead \n> > property,\n> > i.e. it is an immutable copy of the value of that property on \n> > the VCR at CHECKIN time.  Does this work for folks currently \n> > doing versioning? (I couldn't quite tell from Lisa's \n> > description whether this is the Xythos behavior or not).\n> > \n> > Cheers,\n> > Geoff\n> > \n> > Lisa wrote on 08/11/2003 01:09:58 PM:\n> > > \n> > > Sure, every version must have the displayname property so \n> > you can get \n> > > it with PROPFIND.  However, no specification requires that to be \n> > > either writable or protected on a version, so on some \n> > servers it won't \n> > > be\n> > writable.\n> > > Also no specification requires it to be either static or dynamic, so\n> > it's\n> > > possible on some servers that the property would be \n> > protected, and it\n> > would\n> > > change whenever the value on the VCR changed.\n> > > \n> > > I believe on Xythos WFS the displayname property is protected and \n> > > static\n> > on\n> > > versions.  It will always have the same value as the displayname\n> > property of\n> > > the VCR.\n> > \n> > > > -----Original Message-----\n> > > > From: Geoffrey M Clemm\n> > > > \n> > > > There is no concept of a \"global\" property of a version. Each \n> > > > version is a separate resource, with its own properties. So each \n> > > > version has its own DAV:displayname property.\n> > > > \n> > > > But there is a natural place to put a \"global\" property of a\n> > > > version, namely, as a property on the VersionHistory of \n> > that version.\n> > \n> > > > Horst wrote on 08/11/2003 11:47:38 AM:\n> > > > > \n> > > > > Just a simple question, is the DAV:displayname of a\n> > > > resource \"global\"\n> > > > > ? Or is it possible to have different DAV:displayname(s)\n> > > > for different\n> > > > > versions of the same resource.\n> > \n> > \n> \n> \n\n\n\n", "id": "lists-007-7008369"}, {"subject": "RE: DAV:displayname with version", "content": "Yes, but support for RFC3253 is not required for support of RFC2518.  The\ncore or base specification is responsible for core functionality.  I think\nit encourages implementation of RFC2518 to keep it as simple as it can be,\nand keeping description of optional functionality (other than locking)\noutside of RFC2518 is one way to continue to keep it simple.\n\nAnother reason is that versioning functionality is newer and has seen much\nless interoperability testing.  One of the considerations for RFC2518bis is\nwhether each feature specified meets the interoperability bar for IETF draft\nstandard publication.  \n\nFor drafts like binding and ordering, I agree that new properties should\nhave their versioning behavior specified as well as their non-versioning\nbehavior if necessary.  And for drafts after that, new properties may have\nto be defined with their binding behavior as well as versioning.\n\nLisa\n\n> -----Original Message-----\n> From: Geoffrey M Clemm [mailto:geoffrey.clemm@us.ibm.com] \n> Sent: Monday, August 11, 2003 12:52 PM\n> To: Lisa Dusseault\n> Cc: ietf-dav-versioning@w3.org; 'webdav'\n> Subject: RE: DAV:displayname with versions\n> \n> \n> I agree that we want to finish RFC2518bis in a finite amount \n> of time, but I disagree that versioning behavior of RFC2518 \n> properties should be defined in a separate draft.  Any new \n> WebDAV draft should fully define the behavior of any live \n> property it defines, and versioning is \n> a standard part of the WebDAV family (after all, it is \n> \"WebDAV\", not \"WebDA\" :-).\n> \n> Cheers,\n> Geoff\n> \n> \"Lisa Dusseault\" <lisa@xythos.com> wrote on 08/11/2003 02:04:24 PM:\n> \n> > That isn't quite the Xythos WFS behavior.  If you MOVE a VCR, its \n> > displayname changes to the current name.  Thus the \n> displayname changes\n> for\n> > all the versions as well. They aren't entirely immutable, in other\n> words. \n> > \n> >  I wouldn't put the versioning behavior of properties in \n> RFC2518bis, \n> > however, we need to keep changes there down so we get finished in \n> > finite time and get draft standard status with tested interoperable \n> > features.\n> If\n> > we think we can specify property behavior for versioning it \n> could just\n> as\n> > easily be done in a separate short draft.\n> > \n> > Speaking of this, what are the issues for the binding draft and the\n> behavior\n> > of live properties?  Does the binding draft sufficiently cover what\n> happens\n> > with versioning in the mix?\n> > \n> > Lisa\n> > \n> > > -----Original Message-----\n> > > From: w3c-dist-auth-request@w3.org\n> > > [mailto:w3c-dist-auth-request@w3.org] On Behalf Of \n> Geoffrey M Clemm\n> > > Sent: Monday, August 11, 2003 10:46 AM\n> > > To: ietf-dav-versioning@w3.org; webdav\n> > > Subject: RE: DAV:displayname with versions\n> > > \n> > > \n> > > \n> > > Yes, 3253 leaves the definition of versioning behavior for\n> > > live properties up to the standard that defines those \n> live properties.\n> > > \n> > > \n> > > So we should probably try to define the versioning \n> behavior for 2518\n> > > properties\n> > > in 2518bis.  In general, the simplest default versioning \n> > > behavior for a property such as DAV:displayname is to treat \n> > > it the same as a dead \n> > > property,\n> > > i.e. it is an immutable copy of the value of that property on \n> > > the VCR at CHECKIN time.  Does this work for folks currently \n> > > doing versioning? (I couldn't quite tell from Lisa's \n> > > description whether this is the Xythos behavior or not).\n> > > \n> > > Cheers,\n> > > Geoff\n> > > \n> > > Lisa wrote on 08/11/2003 01:09:58 PM:\n> > > > \n> > > > Sure, every version must have the displayname property so\n> > > you can get\n> > > > it with PROPFIND.  However, no specification requires that to be\n> > > > either writable or protected on a version, so on some \n> > > servers it won't\n> > > > be\n> > > writable.\n> > > > Also no specification requires it to be either static \n> or dynamic, \n> > > > so\n> > > it's\n> > > > possible on some servers that the property would be\n> > > protected, and it\n> > > would\n> > > > change whenever the value on the VCR changed.\n> > > > \n> > > > I believe on Xythos WFS the displayname property is \n> protected and\n> > > > static\n> > > on\n> > > > versions.  It will always have the same value as the displayname\n> > > property of\n> > > > the VCR.\n> > > \n> > > > > -----Original Message-----\n> > > > > From: Geoffrey M Clemm\n> > > > > \n> > > > > There is no concept of a \"global\" property of a version. Each\n> > > > > version is a separate resource, with its own \n> properties. So each \n> > > > > version has its own DAV:displayname property.\n> > > > > \n> > > > > But there is a natural place to put a \"global\" property of a \n> > > > > version, namely, as a property on the VersionHistory of\n> > > that version.\n> > > \n> > > > > Horst wrote on 08/11/2003 11:47:38 AM:\n> > > > > > \n> > > > > > Just a simple question, is the DAV:displayname of a\n> > > > > resource \"global\"\n> > > > > > ? Or is it possible to have different DAV:displayname(s)\n> > > > > for different\n> > > > > > versions of the same resource.\n> > > \n> > > \n> > \n> > \n> \n> \n\n\n\n", "id": "lists-007-7022097"}, {"subject": "RE: DAV:displayname with version", "content": "> -----Original Message-----\n> From: Geoffrey M Clemm [mailto:geoffrey.clemm@us.ibm.com]\n> Sent: Montag, 11. August 2003 19:46\n> To: ietf-dav-versioning@w3.org; webdav\n> Subject: RE: DAV:displayname with versions\n> \n> \n> \n> Yes, 3253 leaves the definition of versioning behavior for \n> live properties\n> up to the standard that defines those live properties.\n> \n> \n> So we should probably try to define the versioning behavior for 2518 \n> properties\n> in 2518bis.  In general, the simplest default versioning \n> behavior for a\n> property such as DAV:displayname is to treat it the same as a dead \n> property,\n> i.e. it is an immutable copy of the value of that property on \n> the VCR at\n> CHECKIN time.  Does this work for folks currently doing versioning?\n> (I couldn't quite tell from Lisa's description whether this is\n> the Xythos behavior or not).\n\nYes this is exactly the behavior of our server implementation\n\n> \n> Cheers,\n> Geoff\n> \n> Lisa wrote on 08/11/2003 01:09:58 PM:\n> > \n> > Sure, every version must have the displayname property so \n> you can get it\n> > with PROPFIND.  However, no specification requires that to be either\n> > writable or protected on a version, so on some servers it won't be \n> writable.\n> > Also no specification requires it to be either static or \n> dynamic, so \n> it's\n> > possible on some servers that the property would be \n> protected, and it \n> would\n> > change whenever the value on the VCR changed.\n> > \n> > I believe on Xythos WFS the displayname property is \n> protected and static \n> on\n> > versions.  It will always have the same value as the displayname \n> property of\n> > the VCR.\n> \n> > > -----Original Message-----\n> > > From: Geoffrey M Clemm\n> > > \n> > > There is no concept of a \"global\" property of a version.\n> > > Each version is a separate resource, with its own properties. \n> > > So each version has its own DAV:displayname property.\n> > > \n> > > But there is a natural place to put a \"global\" property of a \n> > > version, namely, as a property on the VersionHistory of \n> that version.\n> \n> > > Horst wrote on 08/11/2003 11:47:38 AM:\n> > > > \n> > > > Just a simple question, is the DAV:displayname of a \n> > > resource \"global\" \n> > > > ? Or is it possible to have different DAV:displayname(s) \n> > > for different \n> > > > versions of the same resource.\n> \n\n\n\n", "id": "lists-007-7037230"}, {"subject": "Is creator-displayname protected ", "content": "Hi,\nI'm testing my client with Tamino. Before checking in I proppatched\ncreator-displayname. 3253 doesn't say it's protected.\nBut after checkin Tamino used my username as creator-displayname.\nThat ok ? 3253 doesn't say much on this topic.\n\nCheers, Edgar\n\n\n-- \nedgar@edgarschwarz.de                  \"http://www.edgarschwarz.de\"\n\"http://www.edgar-schwarz.de/forum/oberon\"    Running Active Oberon\nMake it as simple as possible, but not simpler.     Albert Einstein\n\n\n\n", "id": "lists-007-7048050"}, {"subject": "Re: Is creator-displayname protected ", "content": "The Tamino behavior is a bit surprising (i.e. one would expect that\nthe version would just have a copy of the DAV:creator-displayname\nof the VCR at checkin time), but 3253 does give implementers a lot\nof latitude wrt how they handle this property, so this doesn't\nviolate any MUST requirements.\n\nCheers,\nGeoff\n\nEdgar on 08/12/2003 03:30:53 PM:\n\n> \n> Hi,\n> I'm testing my client with Tamino. Before checking in I proppatched\n> creator-displayname. 3253 doesn't say it's protected.\n> But after checkin Tamino used my username as creator-displayname.\n> That ok ? 3253 doesn't say much on this topic.\n\n\n\n", "id": "lists-007-7055837"}, {"subject": "BIND and DAV:checkout-set propert", "content": "Does a checked-out resource appear in the DAV:checkout-set property of the\nversion only *once* or with all its mappings?\n\nI.E.: If the checked-out resource is mapped to URI-1 and URI-2, what's true,\na) or b) ?\n\na) both URIs appear in the DAV:checked-out property value of the version\nb) only one URI appears (server-defined)\n\nSame question for other <href> valued properties, e.g.\nDAV:workspace-checkout-set.\n\nOur server forbids multiple mappings for history and version resources, so\nproperties like DAV:checked-out or DAV:version-history are not a problem in\nour case.  \n\nRegards,\nPeter\n\n\n\n", "id": "lists-007-7063544"}, {"subject": "Re: BIND and DAV:checkout-set propert", "content": "RFC-3253 leaves this up to the server implementation.\nSo you can do whatever is easier for your server. \nIf either one is equally easy, I'd suggest (a),\nand in particular, store the URI that the CHECKOUT\nrequest was applied to.  This is likely to be the\nbehavior that is most expected by clients that are\nnot written with multiple bindings in mind.\n\nCheers,\nGeoff\n\nPeter wrote on 08/30/2003 12:14:01 PM:\n\n> Does a checked-out resource appear in the DAV:checkout-set property \n> of the version only *once* or with all its mappings?\n> I.E.: If the checked-out resource is mapped to URI-1 and URI-2, \n> what's true, a) or b) ? \n> a) both URIs appear in the DAV:checked-out property value of the version \n\n> b) only one URI appears (server-defined) \n> Same question for other <href> valued properties, e.g. DAV:\n> workspace-checkout-set. \n> Our server forbids multiple mappings for history and version \n> resources, so properties like DAV:checked-out or DAV:version-history\n> are not a problem in our case. \n> Regards, \n> Peter \n\n\n\n", "id": "lists-007-7072211"}, {"subject": "RE: BIND and DAV:checkout-set propert", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Geoffrey M Clemm\n> Sent: Sunday, August 31, 2003 3:57 AM\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: Re: BIND and DAV:checkout-set property\n>\n>\n>\n> RFC-3253 leaves this up to the server implementation.\n> So you can do whatever is easier for your server.\n> ...\n\nI think this is wrong, and as far as I remember, we already discussed this\nquestion some time ago and came to a different conclusion.\n\nIn this particular case, the spec says:\n\n\"This property identifies each checked-out resource whose DAV:checked-out\nproperty identifies this version.\"\n\nThat is, if there's only one checked-out resource and two bindings, there\nshould be only one href element, giving one of the bindings.\n\nIf a server would report all bindings, a non-binding-aware client might\nconclude that there are in fact multiple checked-out resources which is not\nthe case.\n\nAnyway: we clearly should work on a clarification of RFC3253 regarding\nbindings.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-7081019"}, {"subject": "RE: BIND and DAV:checkout-set propert", "content": "> ... store the URI that the CHECKOUT \n> request was applied to.  This is likely to be the \n> behavior that is most expected by clients that are \n> not written with multiple bindings in mind.\n\nWhat happens, if the URI that the CHECKOUT request was applied to becomes\nunvalid - e.g. because of some UNBIND happened somewhere above in the\nhierarchy.\n\nShould UNCHECKOUT or CHECKIN work with alternate paths, i.e. not the URI the\nCHECKOUT request was applied to? Yes, I suppose.\n\nThanks,\nPeter\n \n\n> -----Original Message-----\n> From: Geoffrey M Clemm [mailto:geoffrey.clemm@us.ibm.com]\n> Sent: Sunday, August 31, 2003 03:57\n> To: 'ietf-dav-versioning@w3.org'\n> Subject: Re: BIND and DAV:checkout-set property\n> \n> \n> \n> RFC-3253 leaves this up to the server implementation. \n> So you can do whatever is easier for your server.   \n> If either one is equally easy, I'd suggest (a), \n> and in particular, store the URI that the CHECKOUT \n> request was applied to.  This is likely to be the \n> behavior that is most expected by clients that are \n> not written with multiple bindings in mind. \n> \n> Cheers, \n> Geoff \n> \n> Peter wrote on 08/30/2003 12:14:01 PM:\n> \n> > Does a checked-out resource appear in the DAV:checkout-set property \n> > of the version only *once* or with all its mappings? \n> > I.E.: If the checked-out resource is mapped to URI-1 and URI-2, \n> > what's true, a) or b) ? \n> > a) both URIs appear in the DAV:checked-out property value \n> of the version \n> > b) only one URI appears (server-defined) \n> > Same question for other <href> valued properties, e.g. DAV:\n> > workspace-checkout-set. \n> > Our server forbids multiple mappings for history and version \n> > resources, so properties like DAV:checked-out or DAV:version-history\n> > are not a problem in our case.   \n> > Regards, \n> > Peter \n> \n\n\n\n", "id": "lists-007-7090917"}, {"subject": "RE: BIND and DAV:checkout-set propert", "content": "One could equally well make the argument that a binding-unaware\nclient would be even more surprised when it encounters a checked-out\nresource whose URL does not appear in the DAV:checkout-set of\nits DAV:checked-out version. \n\nI do not see anything in the current specification language that\nrequires a server to do it one way or the other, so until we \nget a compelling reason to do it one way or the other, I'd probably\nleave the language as it is.\n\nCheers,\nGeoff\n\n\"Julian Reschke\" <julian.reschke@greenbytes.de> wrote on 09/01/2003 \n05:42:56 AM:\n\n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Geoffrey M \nClemm\n> > Sent: Sunday, August 31, 2003 3:57 AM\n> > To: 'ietf-dav-versioning@w3.org'\n> > Subject: Re: BIND and DAV:checkout-set property\n> >\n> >\n> >\n> > RFC-3253 leaves this up to the server implementation.\n> > So you can do whatever is easier for your server.\n> > ...\n> \n> I think this is wrong, and as far as I remember, we already discussed \nthis\n> question some time ago and came to a different conclusion.\n> \n> In this particular case, the spec says:\n> \n> \"This property identifies each checked-out resource whose \nDAV:checked-out\n> property identifies this version.\"\n> \n> That is, if there's only one checked-out resource and two bindings, \nthere\n> should be only one href element, giving one of the bindings.\n> \n> If a server would report all bindings, a non-binding-aware client might\n> conclude that there are in fact multiple checked-out resources which is \nnot\n> the case.\n> \n> Anyway: we clearly should work on a clarification of RFC3253 regarding\n> bindings.\n> \n> Julian\n> \n> --\n> <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n> \n\n\n\n", "id": "lists-007-7101191"}, {"subject": "RE: BIND and DAV:checkout-set propert", "content": "\"Nevermann, Dr., Peter\" <Peter.Nevermann@softwareag.com> wrote on \n09/01/2003 07:00:39 AM:\n\n> > (I suggest to) store the URI that the CHECKOUT \n> > request was applied to.  This is likely to be the \n> > behavior that is most expected by clients that are \n> > not written with multiple bindings in mind.\n \n> What happens, if the URI that the CHECKOUT request was applied to \n> becomes unvalid - e.g. because of UNBIND somewhere above in the \n> hierarchy.\n\nBy the definition of the DAV:checkout-set property, in case of an\nREBIND/MOVE or a UNBIND/DELETE, the server would\nhave to update the DAV:checkout-set to ensure that it correctly\nidentifies (i.e. has valid URLs for) the current set of checked-out\nresources.\n\n> If I still have a path to the resource, should UNCHECKOUT\n> or CHECKIN still work with the alternate path?\n\nYes.\n\nCheers,\nGeoff\n\n\n\n", "id": "lists-007-7111964"}, {"subject": "RE: BIND and DAV:checkout-set propert", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Geoffrey M Clemm\n> Sent: Tuesday, September 02, 2003 4:28 AM\n> To: ietf-dav-versioning@w3.org\n> Subject: RE: BIND and DAV:checkout-set property\n>\n>\n>\n> One could equally well make the argument that a binding-unaware\n> client would be even more surprised when it encounters a checked-out\n> resource whose URL does not appear in the DAV:checkout-set of\n> its DAV:checked-out version.\n\nI think this is less likely, but of course I can't speak of all clients.\n\nAnyway, the spec says that the property identifies *resources*, not URLs or\nbindings. Finally, I think we should try to decide what to do and *not*\nleave that up to the server. If we do that, reporting all bindings obviously\nwould be a bad choice because there's always the potential for bind loops\ncausing the set of URLs for that resource to be ... big.\n\n> I do not see anything in the current specification language that\n> requires a server to do it one way or the other, so until we\n> get a compelling reason to do it one way or the other, I'd probably\n> leave the language as it is.\n\nI think the spec (revision) really needs to clarify a few things regarding\nbinding behaviour, and this is one of those things.\n\nJulian\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-7120282"}, {"subject": "Good news from interop even", "content": "I'm happy to report that at the WebDAV Interoperability Testing Event held\nthe past two days (Sept. 15-16, 2003) we saw some nice interoperability of\nmultiple DeltaV clients and servers. Specifically, Xythos Client and Cadaver\nboth interoperated against Xythos Server, Catacomb, and Tamino (these were\nthe only DeltaV implementations present). Interoperability occurred out of\nthe box (no additional code modification needed).\n\nMethods tested were VERSION-CONTROL, CHECKOUT, CHECKIN, REPORT (version\nhistory). Only linear versioning, and comments were not supported by these\nclients.\n\nSo, while the capabilities demonstrated were limited, it was *very*\nencouraging to see this interoperability, especially since this was the\nfirst time the DeltaV capabilities of these client/server pairs were\nexercised.\n\nThis provides a nice base from which to grow.\n\n- Jim\n\n\n\n", "id": "lists-007-7130204"}, {"subject": "Re: Good news from interop even", "content": "That is a very encouraging result, and I'd like to thank Jim and\ncompany for hosting the event, and the Xythos, Cadaver, Catacomb,\nand Tamino implementors for doing such a good job with their\nimplementations!\n\nAnd I like to especially thank all the members of this working group\nwho stuck with the process over the years it took to produce RFC3253.\nIt is thanks to your efforts that the spec was written in a way that\nallowed initial subset implementations that interoperate, one of the\nmost hotly debated and challenging aspects of the spec.\n\nCheers,\nGeoff \n\nJim wrote on 09/16/2003 08:48:58 PM:\n\n> \n> I'm happy to report that at the WebDAV Interoperability Testing Event \nheld\n> the past two days (Sept. 15-16, 2003) we saw some nice interoperability \nof\n> multiple DeltaV clients and servers. Specifically, Xythos Client and \nCadaver\n> both interoperated against Xythos Server, Catacomb, and Tamino (these \nwere\n> the only DeltaV implementations present). Interoperability occurred out \nof\n> the box (no additional code modification needed).\n> \n> Methods tested were VERSION-CONTROL, CHECKOUT, CHECKIN, REPORT (version\n> history). Only linear versioning, and comments were not supported by \nthese\n> clients.\n> \n> So, while the capabilities demonstrated were limited, it was *very*\n> encouraging to see this interoperability, especially since this was the\n> first time the DeltaV capabilities of these client/server pairs were\n> exercised.\n> \n> This provides a nice base from which to grow.\n> \n> - Jim\n> \n\n\n\n", "id": "lists-007-7137925"}, {"subject": "DAV:resourcetype for an activit", "content": "Section 13.1 of the spec says that the DAV:resourcetype of an activity\nmust be DAV:activity. This would seem to disallow an implementation\nwhere the resourcetype was, say:\n\n<resourcetype xmlns=\"DAV:\">\n  <activity/>\n  <collection/>\n</resourcetype>\n\nIs there a reason for saying that an activity's resourcetype must be\n(rather than include) DAV:activity?\n\n-- Alison.\n\n\n\n", "id": "lists-007-7185724"}, {"subject": "RE: resourcetype for an activit", "content": "> From: ietf-dav-versioning-request@w3.org\n> [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Alison Macmillan\n> Sent: Monday, October 13, 2003 7:48 PM\n> To: ietf-dav-versioning@w3.org\n> Subject: DAV:resourcetype for an activity\n>\n>\n>\n> Section 13.1 of the spec says that the DAV:resourcetype of an activity\n> must be DAV:activity. This would seem to disallow an implementation\n> where the resourcetype was, say:\n>\n> <resourcetype xmlns=\"DAV:\">\n>   <activity/>\n>   <collection/>\n> </resourcetype>\n>\n> Is there a reason for saying that an activity's resourcetype must be\n> (rather than include) DAV:activity?\n\nNo. In fact, I think this is what RFC3253 *should* be saying (similar\nconsiderations apply to version history resources).\n\nGeoff, I think this should be on the errata list.\n\nJulian\n\n\n--\n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-7192591"}, {"subject": "RE: resourcetype for an activit", "content": "That change is fine with me.  If there are no objections, I'll add\nthis as a closed issue to RFC-3253.\n\nCheers,\nGeoff\n\nJulian wrote on 10/13/2003 02:08:11 PM:\n\n> \n> > From: ietf-dav-versioning-request@w3.org\n> > [mailto:ietf-dav-versioning-request@w3.org]On Behalf Of Alison \nMacmillan\n> > Sent: Monday, October 13, 2003 7:48 PM\n> > To: ietf-dav-versioning@w3.org\n> > Subject: DAV:resourcetype for an activity\n> >\n> >\n> >\n> > Section 13.1 of the spec says that the DAV:resourcetype of an activity\n> > must be DAV:activity. This would seem to disallow an implementation\n> > where the resourcetype was, say:\n> >\n> > <resourcetype xmlns=\"DAV:\">\n> >   <activity/>\n> >   <collection/>\n> > </resourcetype>\n> >\n> > Is there a reason for saying that an activity's resourcetype must be\n> > (rather than include) DAV:activity?\n> \n> No. In fact, I think this is what RFC3253 *should* be saying (similar\n> considerations apply to version history resources).\n> \n> Geoff, I think this should be on the errata list.\n> \n> Julian\n> \n> \n> --\n> <green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n> \n\n\n\n", "id": "lists-007-7202113"}, {"subject": "CFP: IEEE/WIC/ACM Web Intelligence 200", "content": "[Apologies if you receive this more than once]\n\n#####################################################################\n\n                IEEE/WIC/ACM  WEB INTELLIGENCE 2004\n                -----------------------------------\n                   C A L L   F O R   P A P E R S\n\n#####################################################################\n\n2004 IEEE/WIC/ACM International Conference on Web Intelligence (WI'04)\n\n                      September 20-24, 2004\n            King Wing Hot Spring Hotel, Beijing, China\n\n            Homepage: http://www.maebashi-it.org/WI04\n\n                           Sponsored By \n                      IEEE Computer Society\n                 Web Intelligence Consortium (WIC)\n             Association for Computing Machinery (ACM)\n\n                Co-Organized and In Cooperation With  \n                  Beijing University of Technology\n                  China Computer Federation (CCF) \n                  Hong Kong Baptist University (HKBU)\n                  Maebashi Institute of Technology\n                  Tsinghua University\n\n                        Corporate Sponsors  \n                  Beijing University of Technology\n           National Natural Science Foundation of China (NSFC) \n\n**********************************************************************\n - Paper submission due: April 4, 2004\n - Submission websites: http://www.maebashi-it.org/WI04\n                        http://www.comp.hkbu.edu.hk/WI04\n - Electronic submissions are required in the form of PDF or PS files\n**********************************************************************\n\nWeb Intelligence (WI) has been recognized as a new direction for\nscientific research and development to explore the fundamental roles\nas well as practical impacts of Artificial Intelligence (AI) (e.g.,\nknowledge representation, planning, knowledge discovery and data\nmining, intelligent agents, and social network intelligence) and\nadvanced Information Technology (IT) (e.g., wireless networks,\nubiquitous devices, social networks, and data/knowledge grids) on the\nnext generation of Web-empowered products, systems, services, and\nactivities. It is one of the most important as well as promising IT\nresearch fields in the era of Web and agent intelligence.\n\nThe 2004 IEEE/WIC/ACM International Conference on Web Intelligence\n(WI'04) will be jointly held with the 2004 IEEE/WIC/ACM International\nConference on Intelligent Agent Technology (IAT'04\nhttp://www.maebashi-it.org/IAT04).  The IEEE/WIC/ACM 2004 joint\nconferences are sponsored and organized by IEEE Computer Society\nTechnical Committee on Computational Intelligence (TCCI)\n(http://www.cs.uvm.edu/~xwu/tcci/index.shtml), Web Intelligence\nConsortium (WIC) (http://wi-consortium.org), and ACM-SIGART\n(http://www.acm.org/sigart/).\n\n++++++++\nTopics\n++++++++\n\nThe topics and areas include, but not limited to:\n\nWI Topics\n\n* World Wide Wisdom Web (W4) \n\n  Distributed Resources Optimization\n  Goal-Directed Services Support \n  Information and Knowledge Markets \n  Knowledge Community Formation and Support\n  Meta-Knowledge Discovery and Representation\n  New Social Interaction Paradigms\n  Problem Solver Markup Language (PSML)\n  Regularities and Laws of W4\n  Search of Best Means and Ends\n  Service Self-Aggregation\n  Social and Psychological Contexts\n  Web Inference Engine \n\n* Social Networks and Social Intelligence\n\n  Entertainment\n  Knowledge Community Formation and Support\n  Link Topology and Site Hierarchy\n  Intelligent Wireless Web\n  Social Networks Mining\n  Theories of Small-World Web\n  Ubiquitous Computing \n  Ubiquitous Learning Systems\n  Virtual and Web Communities\n  Web-Based Cooperative Work\n  Web Site Clustering\n\n* Knowledge Grids and Grid Intelligence\n\n  Brokering and Scheduling\n  Knowledge Resources and Services Discovery\n  Middleware Architectures and Tools\n  On-Demand Planning and Routing\n  Semantic Grids\n\n* Web Mining and Farming\n\n  Context Sensitive Web Mining\n  E-Mail Classification\n  Data Warehousing \n  Learning User Profiles\n  Multimedia Data Mining \n  Mining Data Streams\n  Text Mining \n  Web Farming and Warehousing\n  Web Content Mining \n  Web Information Clustering\n  Web Information Indexing\n  Web Log and Usage Mining\n  Web Page Clustering and Mining\n  Web Site Classification\n\n* Semantics and Ontology Engineering\n\n  Ontology-Based Information Extraction and Retrieval\n  Ontology-Based Web Mining\n  Web-Based Ontology Learning \n  Semantic Web\n\n* Web Agents\n\n  Agent Networks and Topologies\n  Coordination\n  Distributed Problem Solving\n  Global Information Foraging\n  Macroscopic Behavior Modeling\n  Mobile Agents\n  Remembrance Agents \n  Resource Intermediary and Coordination Mechanisms \n  Self-Organization and Reproduction\n  Trust Models for Web Agents \n\n* Web Services\n\n  Matchmaking\n  Middleware-Based Ubiquitous Services\n  Web Service Reconfiguration\n  Web Service Workflow Composition\n  Grid Services\n\n* Web Information Filtering and Retrieval\n\n  Automatic Cataloging and Indexing \n  Clustering-Based Recommender Systems\n  Collaborative Filtering\n  Digital Library\n  Distributed Web Search\n  Hybrid Recommendation\n  Information Retrieval Criteria and Evaluations\n  Proxy and Cache Techniques\n  Search Engines and Meta-search Engines\n  Specifications for Web Information Extraction Process\n  Web Crawling Systems\n  Web Information Categorization and Ranking\n  Web Prediction and Prefetching\n\n* Intelligent Human-Web Interaction\n\n  Adaptive Web Interfaces\n  Context-Aware Computing\n  Learning User Profiles \n  Multimedia Representation\n  Personalized Interfaces\n  Personalized Web Sites\n  Social and Psychological Issues \n  Visualization of Information and Knowledge\n\n* Web Support Systems \n\n  Information Retrieval Support Systems\n  Web Site Navigation Support Systems\n  Recommender Support Systems\n  Soft Computing (including neural networks, fuzzy logic, \n       evolutionary computation, rough sets, and granular\n       computing) and Uncertainty Management for WI \n  Web-Based Decision Support Systems \n\n* Intelligent E-Technology\n  Collaborative Filtering and Recommendation\n  Business Intelligence \n  Decentralized Community Communication Techniques\n  E-Business and E-Commerce \n  E-Community \n  E-Finance\n  E-Government \n  E-Learning\n  E-Publishing \n  E-Science \n  Intelligent Enterprise Portals\n  Web-Based Direct Marketing and CRM\n  Web-Based EDI \n  Web Security, Integrity, Privacy and Trust\n\n+++++++++++++++++\nImportant Dates\n+++++++++++++++++\n\n      Electronic submission of full papers:  April 4, 2004\n          Notification of paper acceptance:  June 10, 2004\n Workshop and tutorial proposal submission:  June 10, 2004\n           Camera-ready of accepted papers:  July  5, 2004\n                       Workshops/Tutorials:  September 20, 2004\n                                Conference:  September 21-24, 2004\n\n+++++++++++++++++++++++++++++++++++++\nOn-Line Submissions and Publication\n+++++++++++++++++++++++++++++++++++++\n\nHigh-quality papers in all WI related areas are solicited. Papers\nexploring new directions or areas will receive a careful and\nsupportive review.  All submitted papers will be reviewed on the basis\nof technical quality, relevance, significance, and clarity.  Note that\nWI'04 will accept ONLY on-line submissions, containing PDF (PostScript\nor MS-Word) versions.\n\nThe conference proceedings will be published by the IEEE Computer\nSociety Press.\n\nWI'04 also welcomes Industry/Demo-Track submissions, Workshop and\nTutorial proposals.\n\nMore detailed instructions and the On-Line Submission Form can be\nfound from the WI'04 homepage: http://www.maebashi-it.org/WI04.\n\nA selected number of WI'04 accepted papers will be expanded and\nrevised for inclusion in Web Intelligence and Agent Systems:\nAn International Journal (http://wi-consortium.org/journal.html)\nand in Annual Review of Intelligent Informatics\n(http://www.wi-consortium.org/annual.html)\n\nThe best paper awards will be conferred on the authors of\nthe best papers at the conference.\n\n+++++++++++++++++++++++++\nConference Organization\n+++++++++++++++++++++++++\n\n***** Conference Committee *****\n\nConference Chairs:\n  Jiming Liu, Hong Kong Baptist University, HK \n  Nick Cercone, University of Dalhousie, Canada\n\nProgram Chair:\n  Ning Zhong, Maebashi Institute of Technology, Japan\n\nProgram Co-chairs:\n\nWI-Track:\n  Henry Tirri, University of Helsinki, Finland \n  Yiyu Yao, University of Regina, Canada\n  Lizhu Zhou, Tsinghua University, China\n \nIAT-Track:\n  Jeffrey Bradshaw, UWF/Institute for Human and Machine Cognition, USA\n  Sankar K. Pal, Indian Statistical Institute, Inida\n  Domenico Talia, University of Calabria, Italy\n\nIndustry/Demo-Track Chairs:\n  Qiang Yang, Hong Kong University of Science and Technology, HK\n  Wei-Ying Ma, Microsoft Research Asia, China\n \nWorkshop Chair: \n  Pawan Lingras, Saint Mary's University, Canada\n\nTutorial Chair: \n  Gerd Wagner, Eindhoven University of Technology, The Netherlands\n\nPublicity Chair:\n  Yuefeng Li, Queensland University of Technology, Australia\n\nOrganizing Chairs:\n  Tieyoung Zuo, Beijing University of Technology, China\n  Chunnian Liu, Beijing University of Technology, China\n\nLocal Arrangement Chair:\n  Baocai Yin, Beijing University of Technology, China\n\n\nIEEE-CS-TCCI Chair\n  Xindong Wu                      USA\n\nWIC Co-Chairs/Directors\n  Ning Zhong                    Japan\n  Jiming Liu                       HK\n\nACM-SIGART Chair \n  Maria Gini                      USA\n\nWIC Advisory Board\n  Edward A. Feigenbaum            USA\n  Setsuo Ohsuga                 Japan\n  Benjamin Wah                    USA\n  Philip Yu                       USA\n  L.A. Zadeh                      USA\n\nWIC Technical Committee & WI/IAT Steering Committee\n  Nick Cercone                 Canada\n  Dieter Fensel               Austria\n  Georg Gottlob               Austria\n  Lakhmi Jain               Australia\n  W. Lewis Johnson                USA\n  Jianchang Mao                   USA\n  Hiroshi Motoda                Japan\n  Toyoaki Nishida               Japan\n  Xindong Wu                      USA\n  Yiyu Yao                     Canada\n\n***** WI'04 Program Committee *****\n\n(to be announced)\n\n*** Contact Information ***\n\nWI'04 and IAT'04 Conference Secretariat\nwi-iat@maebashi-it.org \n\n\n\n", "id": "lists-007-7211333"}, {"subject": "CFP: IEEE/WIC/ACM Web Intelligence 200", "content": "[Apologies if you receive this more than once]\n\n#####################################################################\n\n                IEEE/WIC/ACM  WEB INTELLIGENCE 2004\n                -----------------------------------\n                   C A L L   F O R   P A P E R S\n\n#####################################################################\n\n2004 IEEE/WIC/ACM International Conference on Web Intelligence (WI'04)\n\n                      September 20-24, 2004\n            King Wing Hot Spring Hotel, Beijing, China\n\n            Homepages: http://www.maebashi-it.org/WI04\n                       http://www.comp.hkbu.edu.hk/WI04\n\n                           Sponsored By \n                      IEEE Computer Society\n                 Web Intelligence Consortium (WIC)\n             Association for Computing Machinery (ACM)\n\n                Co-Organized and In Cooperation With  \n                  Beijing University of Technology\n                  China Computer Federation (CCF) \n                  Hong Kong Baptist University (HKBU)\n                  Maebashi Institute of Technology\n                  Tsinghua University\n\n                        Corporate Sponsors  \n                  Beijing University of Technology\n  Microsoft Research Asia\n                  National Natural Science Foundation of China (NSFC) \n\n**********************************************************************\n - Paper submission due: April 4, 2004\n - Submission websites: http://www.maebashi-it.org/WI04\n                        http://www.comp.hkbu.edu.hk/WI04\n - Electronic submissions are required in the form of PDF or PS files\n**********************************************************************\n\nWeb Intelligence (WI) has been recognized as a new direction for\nscientific research and development to explore the fundamental roles\nas well as practical impacts of Artificial Intelligence (AI) (e.g.,\nknowledge representation, planning, knowledge discovery and data\nmining, intelligent agents, and social network intelligence) and\nadvanced Information Technology (IT) (e.g., wireless networks,\nubiquitous devices, social networks, wisdom Web, and data/knowledge\ngrids) on the next generation of Web-empowered products, systems,\nservices, and activities. It is one of the most important as well as\npromising IT research fields in the era of Web and agent intelligence.\n\nThe 2004 IEEE/WIC/ACM International Conference on Web Intelligence\n(WI'04) will be jointly held with the 2004 IEEE/WIC/ACM International\nConference on Intelligent Agent Technology (IAT'04\nhttp://www.maebashi-it.org/IAT04).  The IEEE/WIC/ACM 2004 joint\nconferences are sponsored and organized by IEEE Computer Society\nTechnical Committee on Computational Intelligence (TCCI)\n(http://www.cs.uvm.edu/~xwu/tcci/index.shtml), Web Intelligence\nConsortium (WIC) (http://wi-consortium.org), and ACM-SIGART\n(http://www.acm.org/sigart/).\n\nFollowing the great successes of WI'01 held in Maebashi City, Japan\nand WI'03 held in Halifax, Canada, WI 2004 provides a leading\ninternational forum for researchers and practitioners (1) to present\nthe state-of-the-art of WI technologies; (2) to examine performance\ncharacteristics of various approaches in Web-based intelligent\ninformation technology; and (3) to cross-fertilize ideas on the\ndevelopment of Web-based intelligent information systems among\ndifferent domains.  By idea-sharing and discussions on the underlying\nfoundations and the enabling technologies of Web intelligence, WI 2004\nwill capture current important developments of new models, new\nmethodologies and new tools for building a variety of embodiments of\nWeb-based intelligent information systems.\n\n++++++++\nTopics\n++++++++\n\nThe topics and areas include, but not limited to:\n\n* World Wide Wisdom Web (W4) \n\n  Distributed Resources Optimization\n  Goal-Directed Services Support \n  Information and Knowledge Markets \n  Knowledge Community Formation and Support\n  Meta-Knowledge Discovery and Representation\n  New Social Interaction Paradigms\n  Problem Solver Markup Language (PSML)\n  Regularities and Laws of W4\n  Search of Best Means and Ends\n  Service Self-Aggregation\n  Social and Psychological Contexts\n  Web Inference Engine \n\n* Social Networks and Social Intelligence\n\n  Entertainment\n  Knowledge Community Formation and Support\n  Link Topology and Site Hierarchy\n  Intelligent Wireless Web\n  Social Networks Mining\n  Theories of Small-World Web\n  Ubiquitous Computing \n  Ubiquitous Learning Systems\n  Virtual and Web Communities\n  Web-Based Cooperative Work\n  Web Site Clustering\n\n* Knowledge Grids and Grid Intelligence\n\n  Brokering and Scheduling\n  Knowledge Resources and Services Discovery\n  Middleware Architectures and Tools\n  On-Demand Planning and Routing\n  Semantic Grids\n\n* Web Mining and Farming\n\n  Context Sensitive Web Mining\n  E-Mail Classification\n  Data Warehousing \n  Learning User Profiles\n  Multimedia Data Mining \n  Mining Data Streams\n  Text Mining \n  Web Farming and Warehousing\n  Web Content Mining \n  Web Information Clustering\n  Web Information Indexing\n  Web Log and Usage Mining\n  Web Page Clustering and Mining\n  Web Site Classification\n\n* Semantics and Ontology Engineering\n\n  Ontology-Based Information Extraction and Retrieval\n  Ontology-Based Web Mining\n  Web-Based Ontology Learning \n  Semantic Web\n\n* Web Agents\n\n  Agent Networks and Topologies\n  Coordination\n  Distributed Problem Solving\n  Global Information Foraging\n  Macroscopic Behavior Modeling\n  Mobile Agents\n  Remembrance Agents \n  Resource Intermediary and Coordination Mechanisms \n  Self-Organization and Reproduction\n  Trust Models for Web Agents \n\n* Web Services\n\n  Matchmaking\n  Middleware-Based Ubiquitous Services\n  Service-Oriented Computing\n  Web Service Reconfiguration\n  Web Service Workflow Composition\n  Grid Services\n\n* Web Information Filtering and Retrieval\n\n  Automatic Cataloging and Indexing \n  Clustering-Based Recommender Systems\n  Collaborative Filtering\n  Digital Library\n  Distributed Web Search\n  Hybrid Recommendation\n  Information Retrieval Criteria and Evaluations\n  Proxy and Cache Techniques\n  Search Engines and Meta-search Engines\n  Specifications for Web Information Extraction Process\n  Web Crawling Systems\n  Web Information Categorization and Ranking\n  Web Prediction and Prefetching\n\n* Intelligent Human-Web Interaction\n\n  Adaptive Web Interfaces\n  Context-Aware Computing\n  Learning User Profiles \n  Multimedia Representation\n  Personalized Interfaces\n  Personalized Web Sites\n  Social and Psychological Issues \n  Visualization of Information and Knowledge\n\n* Web Support Systems \n\n  Information Retrieval Support Systems\n  Web Site Navigation Support Systems\n  Recommender Support Systems\n  Soft Computing (including neural networks, fuzzy logic, \n       evolutionary computation, rough sets, and granular\n       computing) and Uncertainty Management for WI \n  Web-Based Decision Support Systems \n\n* Intelligent E-Technology\n  Collaborative Filtering and Recommendation\n  Business Intelligence \n  Decentralized Community Communication Techniques\n  E-Business and E-Commerce \n  E-Community \n  E-Finance\n  E-Government \n  E-Learning\n  E-Publishing \n  E-Science \n  Intelligent Enterprise Portals\n  Web-Based Direct Marketing and CRM\n  Web-Based EDI \n  Web Security, Integrity, Privacy and Trust\n\n+++++++++++++++++\nImportant Dates\n+++++++++++++++++\n\n      Electronic submission of full papers:  April 4, 2004\n          Notification of paper acceptance:  June 10, 2004\n Workshop and tutorial proposal submission:  June 10, 2004\n           Camera-ready of accepted papers:  July  5, 2004\n                       Workshops/Tutorials:  September 20, 2004\n                                Conference:  September 21-24, 2004\n\n+++++++++++++++++++++++++++++++++++++\nOn-Line Submissions and Publication\n+++++++++++++++++++++++++++++++++++++\n\nHigh-quality papers in all WI related areas are solicited. Papers\nexploring new directions or areas will receive a careful and\nsupportive review.  All submitted papers will be reviewed on the basis\nof technical quality, relevance, significance, and clarity.  Note that\nWI'04 will accept ONLY on-line submissions, containing PDF (PostScript\nor MS-Word) versions.\n\nThe conference proceedings will be published by the IEEE Computer\nSociety Press.\n\nWI'04 also welcomes Industry/Demo-Track submissions, Workshop and\nTutorial proposals.\n\nAll paper submissions will be handled electronically.  More detailed\ninstructions and the On-Line Submission Form can be found from the\nWI'04 homepages: http://www.maebashi-it.org/WI04 and\nhttp://www.comp.hkbu.edu.hk/WI04.\n\nA selected number of WI'04 accepted papers will be expanded and\nrevised for inclusion in Web Intelligence and Agent Systems:\nAn International Journal (http://wi-consortium.org/journal.html)\nand in Annual Review of Intelligent Informatics\n(http://www.wi-consortium.org/annual.html)\n\nThe best paper award and the best demo award will be conferred on the\nauthors of the best papers and the best demos at the conference.\n\n+++++++++++++++++++++++++\nConference Organization\n+++++++++++++++++++++++++\n\n***** Conference Committee *****\n\nConference Chairs:\n  Jiming Liu, Hong Kong Baptist University, HK \n  Nick Cercone, University of Dalhousie, Canada\n\nProgram Chair:\n  Ning Zhong, Maebashi Institute of Technology, Japan\n\nProgram Co-Chairs:\n\nWI-Track:\n  Henry Tirri, University of Helsinki, Finland \n  Yiyu Yao, University of Regina, Canada\n  Lizhu Zhou, Tsinghua University, China\n \nIAT-Track:\n  Jeffrey Bradshaw, UWF/Institute for Human and Machine Cognition, USA\n  Sankar K. Pal, Indian Statistical Institute, Inida\n  Domenico Talia, University of Calabria, Italy\n\nIndustry/Demo-Track Chairs:\n  Qiang Yang, Hong Kong University of Science and Technology, HK\n  Wei-Ying Ma, Microsoft Research Asia, China\n \nWorkshop Chair: \n  Pawan Lingras, Saint Mary's University, Canada\n\nTutorial Chair: \n  Gerd Wagner, Eindhoven University of Technology, The Netherlands\n\nPublicity Chair:\n  Yuefeng Li, Queensland University of Technology, Australia\n\nOrganizing Chairs:\n  Tieyong Zuo, Beijing University of Technology, China\n  Chunnian Liu, Beijing University of Technology, China\n\nLocal Arrangement Chair:\n  Baocai Yin, Beijing University of Technology, China\n\n\nIEEE-CS-TCCI Chair\n  Xindong Wu                      USA\n\nWIC Co-Chairs/Directors\n  Ning Zhong                    Japan\n  Jiming Liu                       HK\n\nACM-SIGART Chair \n  Maria Gini                      USA\n\nWIC Advisory Board\n  Edward A. Feigenbaum            USA\n  Setsuo Ohsuga                 Japan\n  Benjamin Wah                    USA\n  Philip Yu                       USA\n  L.A. Zadeh                      USA\n\nWIC Technical Committee & WI/IAT Steering Committee\n  Nick Cercone                 Canada\n  Dieter Fensel               Austria\n  Georg Gottlob               Austria\n  Lakhmi Jain               Australia\n  W. Lewis Johnson                USA\n  Jianchang Mao                   USA\n  Hiroshi Motoda                Japan\n  Toyoaki Nishida               Japan\n  Xindong Wu                      USA\n  Yiyu Yao                     Canada\n\n***** WI'04 Program Committee *****\n\n(to be announced)\n\n*** Contact Information ***\n\nWI'04 and IAT'04 Conference Secretariat\nwi-iat@maebashi-it.org \n\n\n*******************************************************\nWI/IAT Conference Secretariat\nwi-iat@maebashi-it.org\n\nWI'04:  http://www.maebashi-it.org/WI04/\nIAT'04: http://www.maebashi-it.org/IAT04/\n??????????????????????????\n2003-12-26 17:59:49\n********************************************************\n\n\n\n", "id": "lists-007-7228448"}, {"subject": "DELTAV (RFC 3253) States &amp; State chart", "content": "Hi,\n\nI am learning the HTTP protocol and one of the things I noticed is that it \nis stateless.  When I was reading the 3253, it mentions that there are \nstates.  So far I have identified these groupings on states:\n\nchecked in vs checked out\n\nlocked vs unlocked\n\nIs there a state chart diagram anywhere that explains all of the states and \ntransitions for this protocol?\n\n--------\nAdditionally is RFC 3648's ORDERPATCH method generally supported by HTTP \nservers yet?\n\n\nThanks,\n\nDavid Bearh\n\n_________________________________________________________________\nLimited-time offer: Fast, reliable MSN 9 Dial-up Internet access FREE for 2 \nmonths! \nhttp://join.msn.com/?page=dept/dialup&pgmarket=en-us&ST=1/go/onm00200361ave/direct/01/\n\n\n\n", "id": "lists-007-7271814"}, {"subject": "Re: DELTAV (RFC 3253) States &amp; State chart", "content": "David Bearh wrote:\n> \n> Hi,\n> \n> I am learning the HTTP protocol and one of the things I noticed is that \n> it is stateless.  When I was reading the 3253, it mentions that there \n\nThe *protocol* is stateless. The resources you communicat with have state.\n\n\n> are states.  So far I have identified these groupings on states:\n> \n> checked in vs checked out\n> \n> locked vs unlocked\n> \n> Is there a state chart diagram anywhere that explains all of the states \n> and transitions for this protocol?\n\nI don't think so.\n\n> Additionally is RFC 3648's ORDERPATCH method generally supported by HTTP \n> servers yet?\n\nAs far as I know, only by one (SAP's Enterprise Portal server).\n\nRegards, Julian\n\n\n-- \n<green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n\n\n\n", "id": "lists-007-7279442"}, {"subject": "Re: DELTAV (RFC 3253) States &amp; State chart", "content": "Thank you very much for the infos.\n<eom>\nDavid Bearh\n\n>From: Julian Reschke <julian.reschke@gmx.de>\n>To: David Bearh <winexpert@hotmail.com>\n>CC: ietf-dav-versioning@w3.org\n>Subject: Re: DELTAV (RFC 3253) States & State charts\n>Date: Fri, 02 Apr 2004 22:02:20 +0200\n>\n>\n>David Bearh wrote:\n>>\n>>Hi,\n>>\n>>I am learning the HTTP protocol and one of the things I noticed is that it \n>>is stateless.  When I was reading the 3253, it mentions that there\n>\n>The *protocol* is stateless. The resources you communicat with have state.\n>\n>\n>>are states.  So far I have identified these groupings on states:\n>>\n>>checked in vs checked out\n>>\n>>locked vs unlocked\n>>\n>>Is there a state chart diagram anywhere that explains all of the states \n>>and transitions for this protocol?\n>\n>I don't think so.\n>\n>>Additionally is RFC 3648's ORDERPATCH method generally supported by HTTP \n>>servers yet?\n>\n>As far as I know, only by one (SAP's Enterprise Portal server).\n>\n>Regards, Julian\n>\n>\n>--\n><green/>bytes GmbH -- http://www.greenbytes.de -- tel:+492512807760\n>\n\n_________________________________________________________________\nTax headache? MSN Money provides relief with tax tips, tools, IRS forms and \nmore! http://moneycentral.msn.com/tax/workshop/welcome.asp\n\n\n\n", "id": "lists-007-7287562"}, {"subject": "tes", "content": "W??Az???\n???K\\R?.i???5??e?6??{?4???'??p-x???Vc???$????)I?K?{??N-???5?K???T;?m66?(%???8????&q?????U?a?M_?,???7Q?%?r\n?v?N??l???d?o?$e\\??{5?{\n????[:????YP/c}a2?1???h?a?.8]*??c;???pgo'<{????JkFW???x}??\"?e?????`T???????\"? tF??Wj;???w????k(???{??8I1??????\"\\???Nv\"???O?\n?c??????S?????h?i?o'?n?????,??Z??X???????~????f?M????A??>????\nB?$?cg?I?????2l?9??o???&?^?G?k}??K???>?\\z[7???.?o?????D??Y)Wf?n?R???????S?\\D9W???Le\n?S_??????(?????YVX?CJR3D???n?????<??5??????<??\"(A3nC?i???[7????M??$F36????3j???A???Z????WT??84???l???J|;.9G`?M??\\?C?Ms??????V~?s??D>?P??2IPu* ????NA??CS?a3?x??S?xY??\"9??)?v?GX%?O???t??[?{?????k???I;?\n?????I???????d\n??c??1?????\n??qh????JS>J??R?ux???????N??d?K??V????H1H\n??i?\n???g;???I?R?f?3<??.1& ?:\n:??D?jM??q??)?s1????c\nT?4?\n?L?0??*].??????#zF?O??r;o?c????/8??F?m??-?T?d$???/|??(0???C????r?xF7h?1?????????.?C??$??,?hh?Q2?F\"YzU??~?W0o?,.E??z?3??????XE?>\n?m???v?rR?}????????S?\\5e?fz??????K[????N:?7\"?X???&?(??_??????_1?H?z*???Y??ui?c??-?V,?`?g?S?;?a??RF?.-\"Gor??cKG??3W??z?r\n???j??_?'??<6?6??M???`?[???8?????b???,??????q????X????QF{???Y3?N?????Q?]y??%? }?P???? W???&\nf|?9??]???a??k?n???T?L*}V?i?,??kT?L?TE??t??\\??w;g\\7[R/??g??4?v??m??:V&QR,0??U&o????????L/:???CL_?[?????K;|Z?P??7???d??Fd?}????wJ???t?<4?t?9x?<??H??O??????5Y&M?/?W? ?g?FS????{?x???Y0?p???}^?d?????\n? 9?E?~?_????sT?2?'??Apx9?????P?????T?W???????U???Y?n?|?????K?}?c\n?h88I??^F????g??{p?yK$??JC?C?R?-\nV??h]5?RJ4??J??H?S?5\n???4c??7Nd??^??x?X?H??a&?kOE????\\?a??T?1v\ns??????4????{??????H,?O?????!$???????<?$v??0?/???x?v???G? ?N?r???Z??WD??,?Cj?xU1????[???o??V??b?^?&?aM4??????[\n?_???v?????d?????U?p?5hSy^???O?t???F?~?RP?x?\n??Df?Q?3??p?uG?D??u?YR????G???:#Hzh$?#?hc??w?u??????d???cr???V????j??G??w???2??q?ZP&]??RM\n???????o?????1???'??\n\\??#?mu?vb??VY?K/??????m5<o7?c????`|?:??\n\",v??N?:/???|???c??????e:p?$?W???h1???r?????bU?\\*<??}??L??\n?????XPe~\n1?M??}VO??-j????_???6b????nz????]\n??u?0????\n8?n??%?^?bc?]W???)p???L?hGd???EJt??^?/ia[#?????????LEy%M??U7U??2??ey5???c??|?5??%Sm?\n0}A??u???Q??l?0?F]?<????dz?????s|)?e??9>??,E??s?[???9y??????$R????%?z:??]??\nq?v???u?x?ZZ??0w???Q?y*?M?5?Z?c???9??]??Z?3,z(i?????$?n??y,YL.?????1Z??|???K_C???)?Y?Gd3?`???G??G??L???C??e#?#Q??,;b?x*?h? :?Dw?????8?8?c<?R\n\n\n\n\n\n\napplication/octet-stream attachment: text.zip\n\n\n\n\n", "id": "lists-007-7318632"}, {"subject": "WI/IAT'04 On-Line Submission is ope", "content": "The On-Line Submission of \n2004 IEEE/WIC/ACM International Joint Conference on \n                  Web Intelligence (WI'04) and\n           Intelligent Agent Technology (IAT'04)\nis open.\n\nSubmissions for Web Intelligence 2004, please visit:\nhttp://www.maebashi-it.org/WI04/onlinesub.php\n\nSubmissions for Intelligent Agent Technology 2004, please visit:\nhttp://www.maebashi-it.org/IAT04/onlinesub.php\n\nIf you have any further questions or problems, please do\nnot hesitate to contact me.\n\n\nThank you for your support!\n\n\n***************************************************************\nThe 2004 IEEE/WIC/ACM WI/IAT Conference Secretariat         \nwi-iat@maebashi-it.org                                                 \n                                                             \nThe 2004 IEEE/WIC/ACM Web Intelligence (WI'04)              \nhttp://www.maebashi-it.org/WI04/                          \nhttp://www.comp.hkbu.edu.hk/WI04/                         \n                                                             \nThe 2004 IEEE/WIC/ACM Intelligent Agent Technology (IAT'04) \nhttp://www.maebashi-it.org/IAT04/                         \nhttp://www.comp.hkbu.edu.hk/IAT04/                                                                                                                                \n***************************************************************\n\n\n.\n\n\n.\n\n\n.\n\n\n\n", "id": "lists-007-7326915"}, {"subject": "DAV:unreserved - missing precondition", "content": "Section 13.3.1 of the spec says:\n\n> 13.3.1 DAV:unreserved\n> This property of a checked-out resource indicates whether the \n> DAV:activity-set of another checked-out resource associated with the \n> version history of this version-controlled resource can have an \n> activity that is in the DAV:activity-set property of this checked-out \n> resource.\n\nThe activity feature adds a checkout precondition:\n\n> (DAV:one-checkout-per-activity-per-history): If there is a request \n> activity set, unless DAV:unreserved is specified, another checkout \n> from a version of that version history MUST NOT select an activity in \n> that activity set.\n\nShould this precondition also cover the case where the checkout request \nincludes an activity and specifies DAV:unreserved, but the checkout \nshould fail because a checked-out resource already exists, with \nDAV:unreserved false, and a DAV:activity-set value that contains the \ncheckout request activity?\n\nThanks,\nAlison.\n\n\n\n", "id": "lists-007-7335524"}, {"subject": "Re: DAV:unreserved - missing precondition", "content": "Either interpretation is OK with me.  Do you (or anyone else) want\nthis to be added?\n\nCheers,\nGeoff\n\nAlison wrote on 03/12/2004 01:04:43 PM:\n\n> Section 13.3.1 of the spec says:\n> \n> > 13.3.1 DAV:unreserved\n> > This property of a checked-out resource indicates whether the \n> > DAV:activity-set of another checked-out resource associated with the \n> > version history of this version-controlled resource can have an \n> > activity that is in the DAV:activity-set property of this checked-out \n> > resource.\n> \n> The activity feature adds a checkout precondition:\n> \n> > (DAV:one-checkout-per-activity-per-history): If there is a request \n> > activity set, unless DAV:unreserved is specified, another checkout \n> > from a version of that version history MUST NOT select an activity in \n> > that activity set.\n> \n> Should this precondition also cover the case where the checkout request \n> includes an activity and specifies DAV:unreserved, but the checkout \n> should fail because a checked-out resource already exists, with \n> DAV:unreserved false, and a DAV:activity-set value that contains the \n> checkout request activity?\n\n\n\n", "id": "lists-007-7343355"}, {"subject": "Re: DAV:unreserved - missing precondition", "content": "The 13.3.1 description of DAV:unreserved is more restrictive  than  \nDAV:one-checkout-per-activity-per-history enforces. The description only \nallows for one checked-out resource for the activity, if that \nchecked-out resource has DAV:unreserved false. The precondition however \nallows for multiple checked-out resources for the activity,  where at \nmost one of these has a DAV:unreserved property of false. \n\nGiven existing implementations of 3253 which may only enforce the \nprecondition rather than the description, I would suggest that the \ndescription of DAV:unreserved is lined up with the precondition. That \nis, at most one reserved (DAV:unreserved false) checked out resource for \nan activity, but any number of unreserved (DAV:unreserved true) checked \nout resources for the same activity.\n\nAlison.\n\nGeoffrey M Clemm wrote:\n\n>Either interpretation is OK with me.  Do you (or anyone else) want\n>this to be added?\n>\n>Cheers,\n>Geoff\n>\n>Alison wrote on 03/12/2004 01:04:43 PM:\n>\n>  \n>\n>>Section 13.3.1 of the spec says:\n>>\n>>    \n>>\n>>>13.3.1 DAV:unreserved\n>>>This property of a checked-out resource indicates whether the \n>>>DAV:activity-set of another checked-out resource associated with the \n>>>version history of this version-controlled resource can have an \n>>>activity that is in the DAV:activity-set property of this checked-out \n>>>resource.\n>>>      \n>>>\n>>The activity feature adds a checkout precondition:\n>>\n>>    \n>>\n>>>(DAV:one-checkout-per-activity-per-history): If there is a request \n>>>activity set, unless DAV:unreserved is specified, another checkout \n>>>from a version of that version history MUST NOT select an activity in \n>>>that activity set.\n>>>      \n>>>\n>>Should this precondition also cover the case where the checkout request \n>>includes an activity and specifies DAV:unreserved, but the checkout \n>>should fail because a checked-out resource already exists, with \n>>DAV:unreserved false, and a DAV:activity-set value that contains the \n>>checkout request activity?\n>>    \n>>\n>\n>  \n>\n\n\n\n", "id": "lists-007-7352156"}, {"subject": "Re: DAV:unreserved - missing precondition", "content": "I believe the point of a reserved checkout was to ensure that the\ncheckin would succeed.  But if we allow a reserved checkout to succeed\nwhen there are currently unreserved checkouts against that activity,\nif any of the unreserved checkouts are checked in, the subsequent\ncheckin of the reserved checkout will fail.\n\nSo doesn't that imply we should either:\n- disallow a reserved checkout if there is already an unreserved checkout\nor\n- disallow the checkin of an unreserved checkout if there is a reserved \ncheckout\n?\n\nCheers,\nGeoff\n\nAlison wrote on 03/18/2004 08:08:27 AM:\n\n> The 13.3.1 description of DAV:unreserved is more restrictive  than \n> DAV:one-checkout-per-activity-per-history enforces. The description \n> only allows for one checked-out resource for the activity, if that \n> checked-out resource has DAV:unreserved false. The precondition \n> however allows for multiple checked-out resources for the activity, \n> where at most one of these has a DAV:unreserved property of false. \n> \n> Given existing implementations of 3253 which may only enforce the \n> precondition rather than the description, I would suggest that the \n> description of DAV:unreserved is lined up with the precondition. \n> That is, at most one reserved (DAV:unreserved false) checked out \n> resource for an activity, but any number of unreserved (DAV:\n> unreserved true) checked out resources for the same activity.\n> \n> Geoffrey M Clemm wrote:\n> Either interpretation is OK with me.  Do you (or anyone else) want\n> this to be added?\n> \n> Alison wrote on 03/12/2004 01:04:43 PM:\n> \n> Section 13.3.1 of the spec says:\n> \n> \n> 13.3.1 DAV:unreserved\n> This property of a checked-out resource indicates whether the \n> DAV:activity-set of another checked-out resource associated with the \n> version history of this version-controlled resource can have an \n> activity that is in the DAV:activity-set property of this checked-out \n> resource.\n> \n> The activity feature adds a checkout precondition:\n> \n> \n> (DAV:one-checkout-per-activity-per-history): If there is a request \n> activity set, unless DAV:unreserved is specified, another checkout \n> from a version of that version history MUST NOT select an activity in \n> that activity set.\n> \n> Should this precondition also cover the case where the checkout request \n> includes an activity and specifies DAV:unreserved, but the checkout \n> should fail because a checked-out resource already exists, with \n> DAV:unreserved false, and a DAV:activity-set value that contains the \n> checkout request activity?\n> \n> \n> \n\n\n\n", "id": "lists-007-7361988"}, {"subject": "Re: DAV:unreserved - missing precondition", "content": "The second option looks better to me, i.e.\n\n- disallow the checkin of an unreserved checkout if there is a reserved checkout\n\nas I think the first condition would need to be:\n\n- disallow a reserved checkout if there is already an unreserved checkout, and disallow an unreserved checkout if there is already a reserved checkout.\n\nwhich restricts parallel development.\n\nAlison.\n\nGeoffrey M Clemm wrote:\n\n>I believe the point of a reserved checkout was to ensure that the\n>checkin would succeed.  But if we allow a reserved checkout to succeed\n>when there are currently unreserved checkouts against that activity,\n>if any of the unreserved checkouts are checked in, the subsequent\n>checkin of the reserved checkout will fail.\n>\n>So doesn't that imply we should either:\n>- disallow a reserved checkout if there is already an unreserved checkout\n>or\n>- disallow the checkin of an unreserved checkout if there is a reserved \n>checkout\n>?\n>\n>Cheers,\n>Geoff\n>\n>Alison wrote on 03/18/2004 08:08:27 AM:\n>\n>  \n>\n>>The 13.3.1 description of DAV:unreserved is more restrictive  than \n>>DAV:one-checkout-per-activity-per-history enforces. The description \n>>only allows for one checked-out resource for the activity, if that \n>>checked-out resource has DAV:unreserved false. The precondition \n>>however allows for multiple checked-out resources for the activity, \n>>where at most one of these has a DAV:unreserved property of false. \n>>\n>>Given existing implementations of 3253 which may only enforce the \n>>precondition rather than the description, I would suggest that the \n>>description of DAV:unreserved is lined up with the precondition. \n>>That is, at most one reserved (DAV:unreserved false) checked out \n>>resource for an activity, but any number of unreserved (DAV:\n>>unreserved true) checked out resources for the same activity.\n>>\n>>Geoffrey M Clemm wrote:\n>>Either interpretation is OK with me.  Do you (or anyone else) want\n>>this to be added?\n>>\n>>Alison wrote on 03/12/2004 01:04:43 PM:\n>>\n>>Section 13.3.1 of the spec says:\n>>\n>>\n>>13.3.1 DAV:unreserved\n>>This property of a checked-out resource indicates whether the \n>>DAV:activity-set of another checked-out resource associated with the \n>>version history of this version-controlled resource can have an \n>>activity that is in the DAV:activity-set property of this checked-out \n>>resource.\n>>\n>>The activity feature adds a checkout precondition:\n>>\n>>\n>>(DAV:one-checkout-per-activity-per-history): If there is a request \n>>activity set, unless DAV:unreserved is specified, another checkout \n>>from a version of that version history MUST NOT select an activity in \n>>that activity set.\n>>\n>>Should this precondition also cover the case where the checkout request \n>>includes an activity and specifies DAV:unreserved, but the checkout \n>>should fail because a checked-out resource already exists, with \n>>DAV:unreserved false, and a DAV:activity-set value that contains the \n>>checkout request activity?\n>>\n>>\n>>\n>>    \n>>\n>\n>  \n>\n\n\n\n", "id": "lists-007-7372265"}, {"subject": "Re: DAV:unreserved - missing precondition", "content": "OK, that makes sense to me.\n\nI'll make this update to both RFC-3253bis as well as JSR-147,\nif there are no objections.\n\nCheers,\nGeoff\n\nAlison wrote on 03/22/2004 06:46:49 AM:\n\n> The second option looks better to me, i.e.\n> - disallow the checkin of an unreserved checkout if there is a \n> reserved checkout\n> \n> as I think the first condition would need to be:\n> \n> - disallow a reserved checkout if there is already an unreserved \n> checkout, and disallow an unreserved checkout if there is already a \n> reserved checkout.\n> \n> which restricts parallel development.\n> \n> Alison.\n\n> Geoffrey M Clemm wrote:\n> I believe the point of a reserved checkout was to ensure that the\n> checkin would succeed.  But if we allow a reserved checkout to succeed\n> when there are currently unreserved checkouts against that activity,\n> if any of the unreserved checkouts are checked in, the subsequent\n> checkin of the reserved checkout will fail.\n> \n> So doesn't that imply we should either:\n> - disallow a reserved checkout if there is already an unreserved \ncheckout\n> or\n> - disallow the checkin of an unreserved checkout if there is a reserved \n> checkout\n> ?\n> \n> Cheers,\n> Geoff\n> \n> Alison wrote on 03/18/2004 08:08:27 AM:\n> \n> \n> The 13.3.1 description of DAV:unreserved is more restrictive  than \n> DAV:one-checkout-per-activity-per-history enforces. The description \n> only allows for one checked-out resource for the activity, if that \n> checked-out resource has DAV:unreserved false. The precondition \n> however allows for multiple checked-out resources for the activity, \n> where at most one of these has a DAV:unreserved property of false. \n> \n> Given existing implementations of 3253 which may only enforce the \n> precondition rather than the description, I would suggest that the \n> description of DAV:unreserved is lined up with the precondition. \n> That is, at most one reserved (DAV:unreserved false) checked out \n> resource for an activity, but any number of unreserved (DAV:\n> unreserved true) checked out resources for the same activity.\n> \n> Geoffrey M Clemm wrote:\n> Either interpretation is OK with me.  Do you (or anyone else) want\n> this to be added?\n> \n> Alison wrote on 03/12/2004 01:04:43 PM:\n> \n> Section 13.3.1 of the spec says:\n> \n> \n> 13.3.1 DAV:unreserved\n> This property of a checked-out resource indicates whether the \n> DAV:activity-set of another checked-out resource associated with the \n> version history of this version-controlled resource can have an \n> activity that is in the DAV:activity-set property of this checked-out \n> resource.\n> \n> The activity feature adds a checkout precondition:\n> \n> \n> (DAV:one-checkout-per-activity-per-history): If there is a request \n> activity set, unless DAV:unreserved is specified, another checkout \n> from a version of that version history MUST NOT select an activity in \n> that activity set.\n> \n> Should this precondition also cover the case where the checkout request \n> includes an activity and specifies DAV:unreserved, but the checkout \n> should fail because a checked-out resource already exists, with \n> DAV:unreserved false, and a DAV:activity-set value that contains the \n> checkout request activity?\n> \n> \n> \n> \n> \n> \n\n\n\n", "id": "lists-007-7383160"}, {"subject": "Re: DAV:unreserved - missing precondition", "content": "Would it also be clearer if the precondition:\n\n  DAV:one-checkout-per-activity-per-history\n\nwas renamed to\n\n  DAV:one-reserved-checkout-per-activity-per-history?\n\nAlison.\n\nGeoffrey M Clemm wrote:\n\n>OK, that makes sense to me.\n>\n>I'll make this update to both RFC-3253bis as well as JSR-147,\n>if there are no objections.\n>\n>Cheers,\n>Geoff\n>\n>Alison wrote on 03/22/2004 06:46:49 AM:\n>\n>  \n>\n>>The second option looks better to me, i.e.\n>>- disallow the checkin of an unreserved checkout if there is a \n>>reserved checkout\n>>\n>>as I think the first condition would need to be:\n>>\n>>- disallow a reserved checkout if there is already an unreserved \n>>checkout, and disallow an unreserved checkout if there is already a \n>>reserved checkout.\n>>\n>>which restricts parallel development.\n>>\n>>Alison.\n>>    \n>>\n>\n>  \n>\n>>Geoffrey M Clemm wrote:\n>>I believe the point of a reserved checkout was to ensure that the\n>>checkin would succeed.  But if we allow a reserved checkout to succeed\n>>when there are currently unreserved checkouts against that activity,\n>>if any of the unreserved checkouts are checked in, the subsequent\n>>checkin of the reserved checkout will fail.\n>>\n>>So doesn't that imply we should either:\n>>- disallow a reserved checkout if there is already an unreserved \n>>    \n>>\n>checkout\n>  \n>\n>>or\n>>- disallow the checkin of an unreserved checkout if there is a reserved \n>>checkout\n>>?\n>>\n>>Cheers,\n>>Geoff\n>>\n>>Alison wrote on 03/18/2004 08:08:27 AM:\n>>\n>>\n>>The 13.3.1 description of DAV:unreserved is more restrictive  than \n>>DAV:one-checkout-per-activity-per-history enforces. The description \n>>only allows for one checked-out resource for the activity, if that \n>>checked-out resource has DAV:unreserved false. The precondition \n>>however allows for multiple checked-out resources for the activity, \n>>where at most one of these has a DAV:unreserved property of false. \n>>\n>>Given existing implementations of 3253 which may only enforce the \n>>precondition rather than the description, I would suggest that the \n>>description of DAV:unreserved is lined up with the precondition. \n>>That is, at most one reserved (DAV:unreserved false) checked out \n>>resource for an activity, but any number of unreserved (DAV:\n>>unreserved true) checked out resources for the same activity.\n>>\n>>Geoffrey M Clemm wrote:\n>>Either interpretation is OK with me.  Do you (or anyone else) want\n>>this to be added?\n>>\n>>Alison wrote on 03/12/2004 01:04:43 PM:\n>>\n>>Section 13.3.1 of the spec says:\n>>\n>>\n>>13.3.1 DAV:unreserved\n>>This property of a checked-out resource indicates whether the \n>>DAV:activity-set of another checked-out resource associated with the \n>>version history of this version-controlled resource can have an \n>>activity that is in the DAV:activity-set property of this checked-out \n>>resource.\n>>\n>>The activity feature adds a checkout precondition:\n>>\n>>\n>>(DAV:one-checkout-per-activity-per-history): If there is a request \n>>activity set, unless DAV:unreserved is specified, another checkout \n>>from a version of that version history MUST NOT select an activity in \n>>that activity set.\n>>\n>>Should this precondition also cover the case where the checkout request \n>>includes an activity and specifies DAV:unreserved, but the checkout \n>>should fail because a checked-out resource already exists, with \n>>DAV:unreserved false, and a DAV:activity-set value that contains the \n>>checkout request activity?\n>>\n>>\n>>\n>>\n>>\n>>\n>>    \n>>\n>\n>  \n>\n\n\n\n", "id": "lists-007-7394560"}, {"subject": "Re (2): DAV:unreserved - missing precondition", "content": "Alison Macmillan <alison.macmillan@oracle.com> wrote:\n> The second option looks better to me, i.e.\n> - disallow the checkin of an unreserved checkout if there is a reserved checkout\n> as I think the first condition would need to be:\n> - disallow a reserved checkout if there is already an unreserved checkout,\n>   and disallow an unreserved checkout if there is already a reserved checkout.\n> which restricts parallel development.\nAgreed.\n\n> Section 13.3.1 of the spec says:\n> 13.3.1 DAV:unreserved\n> This property of a checked-out resource indicates whether the \n> DAV:activity-set of another checked-out resource associated with the \n> version history of this version-controlled resource can have an \n> activity that is in the DAV:activity-set property of this checked-out \n> resource.\nFirst I wonder why we think negative. I think it would be more natural\nto make an editorial change to DAV:reserved and depreceate DAV:unreserved.\nAlso here DAV:unreserved is tied to the activity feature. I feel it already\nmakes sense without activities (Which for me implies that there is a single\nimplicit default activity).\n\nCheers, Edgar\n\n\n\n", "id": "lists-007-7406418"}, {"subject": "Re: DAV:unreserved - missing precondition", "content": "We could make this change for JSR-147 (and I will do so),\nbut for backward compatibility, we should leave the name\nof this precondition alone for RFC-3253.\n\nCheers,\nGeoff\n\nAlison wrote on 03/22/2004 09:12:25 AM:\n> Would it also be clearer if the precondition:\n> \n>   DAV:one-checkout-per-activity-per-history\n> \n> was renamed to \n> \n>   DAV:one-reserved-checkout-per-activity-per-history?\n> \n> Geoffrey M Clemm wrote:\n> OK, that makes sense to me.\n> \n> I'll make this update to both RFC-3253bis as well as JSR-147,\n> if there are no objections.\n> \n> Alison wrote on 03/22/2004 06:46:49 AM:\n> \n> \n> The second option looks better to me, i.e.\n> - disallow the checkin of an unreserved checkout if there is a \n> reserved checkout\n> \n> as I think the first condition would need to be:\n> \n> - disallow a reserved checkout if there is already an unreserved \n> checkout, and disallow an unreserved checkout if there is already a \n> reserved checkout.\n> \n> which restricts parallel development.\n> \n> Alison.\n> \n> \n> \n> Geoffrey M Clemm wrote:\n> I believe the point of a reserved checkout was to ensure that the\n> checkin would succeed.  But if we allow a reserved checkout to succeed\n> when there are currently unreserved checkouts against that activity,\n> if any of the unreserved checkouts are checked in, the subsequent\n> checkin of the reserved checkout will fail.\n> \n> So doesn't that imply we should either:\n> - disallow a reserved checkout if there is already an unreserved \n> \n> checkout\n> \n> or\n> - disallow the checkin of an unreserved checkout if there is a reserved \n> checkout\n> ?\n> \n> Cheers,\n> Geoff\n> \n> Alison wrote on 03/18/2004 08:08:27 AM:\n> \n> \n> The 13.3.1 description of DAV:unreserved is more restrictive  than \n> DAV:one-checkout-per-activity-per-history enforces. The description \n> only allows for one checked-out resource for the activity, if that \n> checked-out resource has DAV:unreserved false. The precondition \n> however allows for multiple checked-out resources for the activity, \n> where at most one of these has a DAV:unreserved property of false. \n> \n> Given existing implementations of 3253 which may only enforce the \n> precondition rather than the description, I would suggest that the \n> description of DAV:unreserved is lined up with the precondition. \n> That is, at most one reserved (DAV:unreserved false) checked out \n> resource for an activity, but any number of unreserved (DAV:\n> unreserved true) checked out resources for the same activity.\n> \n> Geoffrey M Clemm wrote:\n> Either interpretation is OK with me.  Do you (or anyone else) want\n> this to be added?\n> \n> Alison wrote on 03/12/2004 01:04:43 PM:\n> \n> Section 13.3.1 of the spec says:\n> \n> \n> 13.3.1 DAV:unreserved\n> This property of a checked-out resource indicates whether the \n> DAV:activity-set of another checked-out resource associated with the \n> version history of this version-controlled resource can have an \n> activity that is in the DAV:activity-set property of this checked-out \n> resource.\n> \n> The activity feature adds a checkout precondition:\n> \n> \n> (DAV:one-checkout-per-activity-per-history): If there is a request \n> activity set, unless DAV:unreserved is specified, another checkout \n> from a version of that version history MUST NOT select an activity in \n> that activity set.\n> \n> Should this precondition also cover the case where the checkout request \n> includes an activity and specifies DAV:unreserved, but the checkout \n> should fail because a checked-out resource already exists, with \n> DAV:unreserved false, and a DAV:activity-set value that contains the \n> checkout request activity?\n> \n> \n> \n> \n> \n> \n> \n> \n> \n\n\n\n", "id": "lists-007-7415211"}, {"subject": "Re: Re (2): DAV:unreserved - missing precondition", "content": "Renaming a feature only introduces complexity, because for \ninteroperability,\nnew clients and servers would have to support both the old and the new\nnames.  So I would suggest we not do that.  (The reason it was defined\nin the negative is that the default behavior should be \"reserved\", since\nmaking the checkout unreserved introduces the possibility that you will\nnot be able to checkin if another checkin for that version for that\nactivity is done before you.\n\nIf a server/client wants non-branching behavior, they would use the\nDAV:checkout-fork and DAV:checkin-fork mechanisms, not DAV:unreserved.\nDAV:unreserved is only needed to \"reserve\" a particular activity\n(aka branch).\n\nCheers,\nGeoff\n\nEdgar wrote on 03/23/2004 03:24:56 PM:\n> Alison Macmillan <alison.macmillan@oracle.com> wrote:\n> > Section 13.3.1 of the spec says:\n> > 13.3.1 DAV:unreserved\n> > This property of a checked-out resource indicates whether the \n> > DAV:activity-set of another checked-out resource associated with the \n> > version history of this version-controlled resource can have an \n> > activity that is in the DAV:activity-set property of this checked-out \n> > resource.\n> First I wonder why we think negative. I think it would be more natural\n> to make an editorial change to DAV:reserved and depreceate \nDAV:unreserved.\n> Also here DAV:unreserved is tied to the activity feature. I feel it \nalready\n> makes sense without activities (Which for me implies that there is a \nsingle\n> implicit default activity).\n\n\n\n", "id": "lists-007-7426606"}, {"subject": "Re: new applications-area mailing list", "content": "Keith,\n\nI will be happy to review drafts for you that are related to\ndirectory, policy, and schema of any type. If I can ever free up more\ntime, then perhaps I can review some others as well.\n\nregards,\nJohn\n\n-----Original Message-----\nFrom: Keith Moore <moore@cs.utk.edu>\nTo: discuss@apps.ietf.org <discuss@apps.ietf.org>\nCc: moore@cs.utk.edu <moore@cs.utk.edu>\nDate: Tuesday, December 01, 1998 6:32 PM\nSubject: new applications-area mailing lists\n\n\n>At the last IETF meeting several people offered to offload some of\nthe\n>ADs' workload by reviewing draft specifications.  I've recently\ncreated\n>some mailing lists for use by people who volunteer to review drafts\nin\n>the following categories:\n>\n>messaging[-request]@apps.ietf.org\n> for people willing to review messaging-related draft specifications\n> (including email, netnews, fax, voice mail, mobile messaging)\n>\n>web[-request]@apps.ietf.org\n> for people willing to review web-related draft specifications\n>\n>directory[-request]@apps.ietf.org\n> for people willing to review directory-related draft specifications\n>\n>Here's how I forsee these lists being used:\n>\n>When the Apps ADs need review of a draft specification in one of the\nabove\n>categories, one of the ADs will post a message to the appropriate\nlist\n>asking for volunteers to review that specification.  Those willing to\n>review the spec should reply to the list.  The AD will then note who\nhas\n>agreed to review the draft.  The reviews, when complete, can then be\n>posted to the list (or if the reviewer prefers, sent directly to the\nADs)\n>Some reviews might prompt other people to look at those documents,\n>so with luck documents that deserve additional review will get it.\n>\n>Offhand, I don't think these lists should be used for random\ndiscussion\n>of these topics.  Many people are too busy to read high-volume lists.\n>I hope that by keeping the lists narrowly focused on document\nreviews,\n>we can keep some of those busy (but valuable) people subscribed.\n>\n>General apps-area discussion should stay on discuss@apps.ietf.org.\n>\n>Thanks for your patience while I got this set up.\n>I'm looking forward to having more reviewers.\n>\n>Keith\n>\n\n\n\n", "id": "lists-007-7474050"}, {"subject": "Extending IETF meetings to two weeks", "content": "The IETF meetings tend to become too large, creating\nlogistics and planning problems. I suggest that future\nmeetings are held for two weeks, with applications and user\nservices issues the first week, and all other issues the\nsecond week. Those who so wish could attend both weeks, and\nother people could attend only one week. Those who choose\nto attend both weeks would be able to cover more groups and\ndo better liaisons between the different areas. The Friday\nof the first week could discuss applications issues which\nmight be of special interest to the other areas, and the\nMonday of the second week would schedule other groups which\nmight be of special interest to applications people, so\nsome people could attend Monday-Monday or Friday-Friday.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-7484738"}, {"subject": "different WG task", "content": "I observed that we have often recurring discussions in a BOF on what\na working group should tackle. The participants have interest in\nvarious areas, generally there is not time enough to do a thorough\njob in all areas and in the right sequence.\n\nIn the current, complex Internet world a working group needs to go\nthrough a number of steps:\n1  Document what is around already. Challenge: make it complete\n   and finish at a certain time.\n2  Identify the problems which need to be solved. Challenge: agree\n   on the problems\n3  Collect the requirements: Challenge: keep this to a minimum to\n   allow a solution\n5  Define the architecture: Challenge: agree on a common view for\n   the future\n6  Specify the protocols: Challenge: find dedicated authors and keep\n   community interested until the very end\n\nIn earlier times it was OK to roughly touch 2 and then directly jump to 6.\nAll project management theories (or software development strategies)\nshow something among the lines of the 6 steps above and definitely warn\nto ignora step. This takes time and needs a lot of work. But since\nthe world got more complex, we need better thought out solutions,\nand following the easiest rules of software development would help.\n\n\nUrs Eppenberger, SWITCH\n\n\n\n", "id": "lists-007-7492672"}, {"subject": "Area director overloa", "content": "It is clear to all who are responsible for staff members, that more than\n6-8 staff members can't be coached anymore. Having more than 0 working\ngroups per Area director just does not work neither.\n\nI fully agree with someone who stated, that we should not reorganise\n(especially not without a clear idea where to go) but to do little steps.\nThis means you will have to cope with more than 20 groups in the near\nfuture.\n\nYou have been chosen area directors for your experience, for your techncial\noverview. Let's figure outhow you can psend time in this areas and not\nin the administrative hassles. Can you identify tasks which you can\ndelegate?\no  let do the meeting schedule by someone else, define a form where WG\n   chairs can apply for a slot, publish draft schedules on the Web\no  keep all APPS information on the Web up-to-date\no  chase WG chairs for updated charters and deliverables\no  get rid of the one chapter summary at the end of the IETF meeting\n   (is this still needed, who reads it anyway?)\n\nOffloading the I-D reading is a very good idea in the right direction.\n\nDo we need an APPS area secretariat?\n\njust thoughts I wnated to share.\n\nUrs.\n\n\n\n", "id": "lists-007-7499831"}, {"subject": "inter-group communicatio", "content": "Hi guys,\n  One of the things that was discussed in the apps meeting was how to \nbetter handle some of the inter-group coordination. I'm currently\nexperiencing some of this with the NAPTR drafts since they depend\non what is going on with SRVs. What I think would help is, in \naddition to the paragraph summary, the chairs also provide their current\nview of any external dependencies. In my case I would provide\na few short sentences showing the dependency of NAPTR on the SRV process.\n\nIts a small change but it would make it easier to check on dependencies\nso that bottlenecks are easily detected...\n\n-MM\n\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | www.rwhois.net/michael\nSr. Research Engineer   |   www.ga.lp.org/gwinnett     | ICQ#:         14198821\nNetwork Solutions|          www.lp.org          |  michaelm@netsol.com\n\n\n\n", "id": "lists-007-7506913"}, {"subject": "Re: Extending IETF meetings to two weeks", "content": "Jacob Palme wrote:\n>The IETF meetings tend to become too large, creating\nlogistics and planning problems. ...\n\nMy problem over the past year or so is that there are\nonly a few session I wish to attend, but I cannot know\nfor sure when they will be scheduled, so I cannot make\nreasonable travel arrangements (a week in Orlando for\n6 hours of meetings is hard to sell to management).  Now\nI know there is a rationale here, and that one is encouraged\nto participate broadly.  And I am hopeful that new activities\n(my own and in the IETF) will give me many more reasons to\nattend.  \n\nBut firmer scheduling would be a big win.\n\nregards, Terry\n\n  Terry Allen    Electronic Commerce and Publishing Consultant    \ntallen[at]sonic.net\n                   http://www.sonic.net/~tallen/\n          DocBook:  http://www.ora.com/davenport/index.html\n Common Business Library:  http://www.veosystems.com/\n\n\n\n", "id": "lists-007-7514189"}, {"subject": "Re: Extending IETF meetings to two weeks", "content": "Terry,\n\nWG Chairs already are asked to specify which clashes they want to\navoid, but clash avoidance is an iterative problem. I just don't\nsee how late changes can be completely avoided. Obviously,\neverybody knows they need to be minimised.\n\nJacob,\n\nNo way. Taking one week out of our calendars 3 times a year\nis already very painful, and a lot of people really do\nneed and want to track multiple areas of the IETF. Spreading\nit thinner would be awful.\n\n  Brian\n\n\n\n", "id": "lists-007-7522621"}, {"subject": "create 'final' IETF agenda schedule earlier", "content": "Working groups don't seem to decide at the last minute whether\nor not they need a meeting, or what their conflict avoidance\ncriteria needs to be. This leads me to believe that we could\ncreate the IETF schedule earlier without causing significant pain.\n\nFor example, it would be very useful so that the final WG\nschedule was available more than 21 days in advance, in order\nto get advanced purchase tickets. This would mean that the\napps area schedule should be set tentatively 30-35 days in\nadvance, so that the draft IETF schedule could be published\nand conflicts reviewed.\n\nLarry\n \n\n\n\n", "id": "lists-007-7530525"}, {"subject": "Fax WG Summar", "content": "To all - \n\nThe one paragraph summary for the Internet Fax WG meeting of December 10\nfollows:\n\nRegards, \n\nJames Rafferty\nInternet Fax WG chair\n\n_____________________________________________________________\n\nInternet Fax Dec 98 Meeting Summary\n\nThe meeting began with a review of the results of the last ITU Study Group\n8 meeting held in November.    At that meeting, a draft amendment of T.37\nwas \"determined\" for the full mode; the technical details are specified by\nreference to the \"eifax\" Internet Draft, as well as the \"reporting\nextensions\" and \"fax-feature-schema\" documents.   The ITU needs RFC numbers\nand copies of the final documents as soon as possible as part of the\napproval process, which is targeted for completion in April 1999.   There\nare three completed drafts \"Goals\", \"eifax\" and \"reporting-extensions\". \nThe latter two documents will be submitted to the IESG once the\n\"fax-feature-schema\" document is complete.   The schema document was\nreviewed by the authors and a new version will be posted after the meeting.\n  It was agreed there would be a final one week Last Call on this document.\n  The status of three documents referenced by \"eifax\" from the CONNEG\nworking group was reviewed; all but the \"syntax\" document are in review by\nthe IESG.  The group also reviewed additional charter milestones and\nsupported updating of the simple mode RFCs, an implementor's guide and\ndocuments on onramp/offramps.   An updated set of charter milestones will\nbe posted after the meeting.   There were various interworking activities\nfor the simple mode and TIFF profiles which were reviewed.   In Japan, 8\ncompanies tested simple mode implementations.  In San Jose, 13 companies\ntested simple mode and about 4 companies tested TIFF profiles; almost all\nfeatures of RFC 2305 are supported in multiple implementations.   A new IPP\nover fax concept was also presented briefly and a mailing list is being set\nup which is a separate activity from the Fax WG.     \n\n\n\n", "id": "lists-007-7538731"}, {"subject": "Re: create 'final' IETF agenda schedule earlier", "content": ">For example, it would be very useful so that the final WG\n>schedule was available more than 21 days in advance, in order\n>to get advanced purchase tickets. This would mean that the\n>apps area schedule should be set tentatively 30-35 days in\n>advance, so that the draft IETF schedule could be published\n>and conflicts reviewed.\n>\n\nI'd like to second this notion.  Many folks in smaller companies are under\nsevere budget constraints and have difficulty justifying participation in\nIETF meetings.  The advance notice helps reduce travel costs, which in turn\nhelps more people attend.\n\nIt would make my life easier.\n\n\n\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nRichard Shockey\nShockey Consulting LLC                  \n8045 Big Bend Blvd. Suite 110    \nSt. Louis, MO 63119\nVoice 314.918.9020\nFax   314.918.9015\nINTERNET Mail & IFAX : rshockey@ix.netcom.com  \n<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n\n\n", "id": "lists-007-7547790"}, {"subject": "security&#64;apps.ietf.org", "content": "I think these apps-area lists are a good idea. What about a \nsecurity@apps.ietf.org list? Or, should we nominate the ietf-apps-tls@imc.org \nas being that list?\n\nJeff\n\n\n\n", "id": "lists-007-7555943"}, {"subject": "Re: security&#64;apps.ietf.org", "content": "On Mon, 14 Dec 1998 Jeff.Hodges@stanford.edu wrote:\n\n> I think these apps-area lists are a good idea. What about a \n> security@apps.ietf.org list? Or, should we nominate the ietf-apps-tls@imc.org \n> as being that list?\n\nIt may not be appropriate for the Application area:  TLS is in the\nSecurity area (even though TLS provides application-level security).\n\n-Dan Wing\n\n\n\n", "id": "lists-007-7564010"}, {"subject": "XML and MIME type", "content": "A few folks asked that I join this mailing list\nto join the discussion on XML and MIME types.\nThey forwarded (some of?) the messages to me.\n\nI asked for a pointer to a hypertext archive,\nbut no joy.\n\nSo... I dunno if I've seen all the stuff, but\nhere I am.\n\nI have to say I was a little lost as to what\nthe issues were.\n\nOne interesting bit I picked up was an\nXML namespace analagous to the set\nof MIME multipart types. Sounds nifty.\nIs that what folks were talking about?\n\n-- \nDan Connolly\nhttp://www.w3.org/People/Connolly/\n\n\n\n", "id": "lists-007-7572339"}, {"subject": "Re: security&#64;apps.ietf.org", "content": "On Mon, 14 Dec 1998 Jeff.Hodges@stanford.edu wrote:\n> I think these apps-area lists are a good idea. What about a \n> security@apps.ietf.org list?\n\nSounds like a good idea to me.\n\nThe problem of integrating security services into applications is a very\nimportant issue.  There are a number of us in the apps area who have\nbeen through the pain and would be willing to help others on a relatively\nlow-volume list.  Pointing new apps WGs at such a list would be helpful.\n\n> Or, should we nominate the ietf-apps-tls@imc.org as being that list?\n\nThat list has too narrow a focus.  TLS isn't the right solution for all\napps.\n\n- Chris\n\n\n\n", "id": "lists-007-7578751"}, {"subject": "Re: security&#64;apps.ietf.org", "content": "> Dan Wing said:\n> It may not be appropriate for the Application area:  TLS is in the\n> Security area\n\nThe topic isn't \"designing security protocols\", rather it is \"how do we make \nsense of and utilize the plethora of security protocols and mechanisms we have \nat our disposal?\"\n\nDiscussing this under our umbrella is entirely appropriate IMHO. Tho, it'd be \ngreat if some of the security folks would join in.\n\nSpeaking of which, Eric Rescola & I need to discuss \"server identity check\" \nstuff and see ifn we can't normalize language between..\n\n  draft-ietf-tls-https-01.txt\n\n  draft-ietf-ldapext-ldapv3-tls-04.txt\n\n..which I suppose we'll do on ietf-apps-tls, since there isn't a specific \napps.ietf.org security list.\n\nJeff\n\n\n\n", "id": "lists-007-7587539"}, {"subject": "Re: security&#64;apps.ietf.org", "content": "On Mon, 14 Dec 1998 Jeff.Hodges@stanford.edu wrote:\n> What about a security@apps.ietf.org list?\n\nChris.Newman@innosoft.com said:\n> Sounds like a good idea to me. \n\nSo, Keith & Patrick, we gonna set such a list up (i.e. \nsecurity@apps.ietf.org)? What do you folks think?\n\nthanks,\n\nJeff\n\n\n\n", "id": "lists-007-7595148"}, {"subject": "IMAP extensions for voic", "content": "Folks,\n\nFollowing on from the informal BOF in Orlando we have set up a mailing list\nto discuss extensions to IMAP4 in support of voice messaging system\nrequirements.  The goal is to standardize these extensions in the IETF.\n\nAs discussed in Orlando, the current featrues of interest are:\n  - Binary attachment transfer\n  - External reference (e.g., use phone for playback)\n  - Alternate codec request (i.e., server please transcode) \n  - Streaming audio attachments\n  - Message length indicator (seconds for voice, pages for fax)\n  - Body part read indicator (separate for voice, fax and other)\n\n> To subscribe to the mailing list, send a message to\n>      ietf-imap-voice-request@imc.or\n> with the single word\n>      subscribe\n> in the body of the message. There is a description of the list and archive\n> at <http://www.imc.org/ietf-imap-voice/>.\n> \nCheers,\nGlenn\n\n\n\n", "id": "lists-007-7602905"}, {"subject": "need reviewers for HTTP Extension Framewor", "content": "[Please DO NOT send replies to web@apps.ietf.org]\n\nHi.  Henrik Nielsen of W3C has asked the Apps ADs to consider \n\"HTTP Extension Framework\" <draft-frystyk-http-extensions-01>\nas a Proposed Standard.  We haven't had time to do a detailed\nreview ourselves, but we would like other folks' opinions as to \nwhether this draft is reasonably complete (i.e. that it addresses \nenough aspects of the problem) and ready for standardization,\nbefore we do an official Last Call.\n\nAs HTTP reuse is of concern to the entire Applications Area, please \nsend comments to discuss@apps.ietf.org, NOT to web@apps.ietf.org.\n\nThe draft can be found at\nftp://ftp.ietf.org/internet-drafts/draft-frystyk-http-extensions-01.txt\n\nThanks!\n\nKeith\n\n\n\n", "id": "lists-007-7611690"}, {"subject": "RE: need reviewers for HTTP Extension Framewor", "content": "Does having made so many comments on the draft that I get \"special mention\"\nin the acknowledgements section disqualify me as a reviewer?\n\nYaron\n\n-----Original Message-----\nFrom: Keith Moore [mailto:moore@cs.utk.edu]\nSent: Wednesday, December 16, 1998 1:53 PM\nTo: discuss@apps.ietf.org; web@apps.ietf.org\nCc: moore@cs.utk.edu\nSubject: need reviewers for HTTP Extension Framework\n\n\n[Please DO NOT send replies to web@apps.ietf.org]\n\nHi.  Henrik Nielsen of W3C has asked the Apps ADs to consider \n\"HTTP Extension Framework\" <draft-frystyk-http-extensions-01>\nas a Proposed Standard.  We haven't had time to do a detailed\nreview ourselves, but we would like other folks' opinions as to \nwhether this draft is reasonably complete (i.e. that it addresses \nenough aspects of the problem) and ready for standardization,\nbefore we do an official Last Call.\n\nAs HTTP reuse is of concern to the entire Applications Area, please \nsend comments to discuss@apps.ietf.org, NOT to web@apps.ietf.org.\n\nThe draft can be found at\nftp://ftp.ietf.org/internet-drafts/draft-frystyk-http-extensions-01.txt\n\nThanks!\n\nKeith\n\n\n\n", "id": "lists-007-7620264"}, {"subject": "Re: need reviewers for HTTP Extension Framewor", "content": "> Does having made so many comments on the draft that I get \"special mention\"\n> in the acknowledgements section disqualify me as a reviewer?\n\nnot unless you think the current version needs no comments.\n\nKeith\n\n\n\n", "id": "lists-007-7630679"}, {"subject": "Archive of this list", "content": "Greetings. I said last week that I would start an \"applicaitons using XML\"\nmailing list, but wanted to be know what had been said on this mailing list\nbefore I did. Has anyone been keeping a complete archive?\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-7638074"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "[...draft-frystyk-http-extensions-01...]\n\n[....]\n> >From: Keith Moore <moore@cs.utk.edu>\n[....]\n> >  We haven't had time to do a detailed\n> >review ourselves, but we would like other folks' opinions as to \n> >whether this draft is reasonably complete (i.e. that it addresses \n> >enough aspects of the problem) and ready for standardization,\n> >before we do an official Last Call.\n\nAs far as I can see the draft is reasonably sound as an extension to HTTP.\nSome more discussion of caching implications is needed though.\n \nThere could be some more discussion of caching related considerations, in\nparticular\n\n  - I would like to see and example of correct use of the Vary header\n    (hinted at in 3.1)\n\n  - I would like explicit mention of the fact that things can break\n    horribly if extensions are added to a 304 response.  See\n    http://lists.w3.org/Archives/Public/ietf-http-ext/1998JanMar/0105.html\n    for a discussion of the problem. \n\n   [On a related note: it is non-trivial to piggy-back something not\n   directly related to the response body onto a HTTP/1.x response and\n   have it work correctly through caches.  Having it work and also be\n   cache-friendly is _extremely_ non-trivial.  This is one of the\n   things I would like to see addressed in any future HTTP-NG/1.2/2.0\n   effort]\n\nMaking responses to M-GET (or other mandatory methods) cachable is\nnot as simple as it looks from the examples at the end of the draft.  In\nthe example of 15.1, all of the proxies in the chain will cache the\nresponse as a response to an M-GET request, and these cannot be used to\nrespond to future GET requests on the same resource.  Also, if the user\nagent would send a subsequent M-GET+Man request, it probably wants the Man\nheader to reach the origin server, so it would have to include a\nCache-Control: no-cache in its request.  The only case where the cached\nresponse could do some good is if a proxy along the chain transforms a GET\nrequest into an M-GET+C-opt request, but this subtle benefit is not clear\nfrom the example. \n\nIn short I would call the example in 15.1 misleading. Rather than examples\nencouraging people to put Cache-Control in M-GET responses, I would have a\ndiscussion of the subtle failure modes involved, and some simple, not\nnecessarily cache-friendly, guidelines for avoiding all failure modes. \n\nWith respect to the draft solving a problem, I will repeat some points\nI have made before elsewhere:\n\n - The header field prefixes stuff is just unnecessary complexity in\n   my opinion.  It would be easier for everyone to put all extension\n   related data as decl-extensions in the Man or Opt header.\n\n - If the goal is to prevent clashes between header fields invented by\n   independent developers (whether inside the IETF or outside it), an\n   open header field registry would be far better at achieving this\n   goal. (Weren't there efforts to set up such a registry?  What\n   happened to them?).  The usual way for people to prototype an HTTP\n   extension is to hack together a CGI script which emits or responds\n   to a few newly invented headers.  I can't see how the proposed\n   mechanism would change this practice.  The barrier of entry to\n   using Man/Opt with a newly invented URI will always be slightly\n   higher, as one has to implement parsing of the Man/Opt headers at\n   least.\n\nKoen.\n\n\n\n", "id": "lists-007-7644525"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "I only skimmed the HTTP extensions draft and got the impression it was\nunnecessarily complex.  I won't have time to give a detailed critique\nbefore going on vacation, so I hope someone else will.  The following\npoint is important:\n\nOn Fri, 18 Dec 1998, Koen Holtman wrote:\n>  - The header field prefixes stuff is just unnecessary complexity in\n>    my opinion.  It would be easier for everyone to put all extension\n>    related data as decl-extensions in the Man or Opt header.\n\nFYI, there was a long discussion in the USEFOR WG on header field prefixes\nfor headers with various characteristics.  At the last IETF meeting of\nUSEFOR, the room reached the conclusion that adding such prefixes was\nunnecessary complexity.  The current model where all headers are optional \nseems sufficient for extensibility.  There was even a discussion of\nlabelling hop-to-hop headers in Netnews which is similar to the HTTP proxy\nproblem, and the same conclusion about unnecessary complexity was reached.\n\n- Chris\n\n\n\n", "id": "lists-007-7657373"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "At 14:53 12/18/98 +0100, Koen Holtman wrote:\n\n>There could be some more discussion of caching related considerations, in\n>particular\n>\n>  - I would like to see and example of correct use of the Vary header\n>    (hinted at in 3.1)\n\nIt works exactly as for accept* headers with q-values in case you are using\nns and without q-values if not. Btw, I don't know if you have seen the\nextended set of scenarios at\n\nhttp://www.w3.org/Protocols/HTTP/ietf-http-ext/Scenarios.html\n\nalthough they do not contain a vary example.\n\n>  - I would like explicit mention of the fact that things can break\n>    horribly if extensions are added to a 304 response.  See\n>    http://lists.w3.org/Archives/Public/ietf-http-ext/1998JanMar/0105.html\n>    for a discussion of the problem. \n\nI don't think the situation you describe is any different than what can\nhappen if any header field is tagged onto a 304 response. This is the\nreason for the restrictions on what a 304 response can contain, see\n\nhttp://www.ietf.org/internet-drafts/draft-ietf-http-v11-spec-rev-06.txt\n\nsection \"10.3.5 304 Not Modified\", where it says:\n\n   If the conditional GET used a strong cache validator (see section\n   13.3.3), the response SHOULD NOT include other entity-headers.\n   Otherwise (i.e., the conditional GET used a weak validator), the\n   response MUST NOT include other entity-headers; this prevents\n   inconsistencies between cached entity-bodies and updated headers.\n\n>   [On a related note: it is non-trivial to piggy-back something not\n>   directly related to the response body onto a HTTP/1.x response and\n>   have it work correctly through caches.  Having it work and also be\n>   cache-friendly is _extremely_ non-trivial.  This is one of the\n>   things I would like to see addressed in any future HTTP-NG/1.2/2.0\n>   effort]\n>\n>Making responses to M-GET (or other mandatory methods) cachable is\n>not as simple as it looks from the examples at the end of the draft.  In\n>the example of 15.1, all of the proxies in the chain will cache the\n>response as a response to an M-GET request, and these cannot be used to\n>respond to future GET requests on the same resource.\n\nM-GET is semantically different from GET - the difference being exactly one\nor more mandatory extensions. It therefore doesn't make sense to say that a\nresponse to a M-GET request can be cached and served to another client\nissuing a GET request.\n\n>  Also, if the user\n>agent would send a subsequent M-GET+Man request, it probably wants the Man\n>header to reach the origin server, so it would have to include a\n>Cache-Control: no-cache in its request.  The only case where the cached\n>response could do some good is if a proxy along the chain transforms a GET\n>request into an M-GET+C-opt request, but this subtle benefit is not clear\n>from the example. \n\nNope - by default, an HTTP client is interested in the nearest fresh\nresponse it can get for that method. It is no different with a client\nissuing a M-GET request - by default it is interested in the nearest fresh\nresponse for that method. However, as the semantics of the M-GET method\nisn't defined by the M- prefix but rather by the extension declaration, it\ncan only be served by a cache who knows that extension.\n\n>With respect to the draft solving a problem, I will repeat some points\n>I have made before elsewhere:\n>\n> - The header field prefixes stuff is just unnecessary complexity in\n>   my opinion.  It would be easier for everyone to put all extension\n>   related data as decl-extensions in the Man or Opt header.\n\nThis proposal was voted down after discussion on the <ietf-http-ext>\nmailing list:\n\nhttp://lists.w3.org/Archives/Public/ietf-http-ext/1998AprJun/0029.html\n\n> - If the goal is to prevent clashes between header fields invented by\n>   independent developers (whether inside the IETF or outside it), an\n>   open header field registry would be far better at achieving this\n>   goal. (Weren't there efforts to set up such a registry?  What\n>   happened to them?).\n\nHTTP extensions has no problem working with centrally registered header\nfields as long as they are referencable by a URI or in the special case of\nbeing defined by a standards track RFC.\n\n>  The barrier of entry to\n>   using Man/Opt with a newly invented URI will always be slightly\n>   higher, as one has to implement parsing of the Man/Opt headers at\n>   least.\n\nThe purpose of a framework is that you only have to implement it once and\nthen can reuse it as often you like. However, you are right that it has to\nbe implemented at least once but I can't see how that makes it differ from\nany other feature in HTTP.\n\nHenrik\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-7665777"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "At 09:31 12/18/98 -0800, Chris Newman wrote:\n>I only skimmed the HTTP extensions draft and got the impression it was\n>unnecessarily complex.  I won't have time to give a detailed critique\n>before going on vacation, so I hope someone else will.  The following\n>point is important:\n\nThings have to be as simple as possible but no simpler. The choice between\nparameters vs. name spaces have been discussed for a long time and the\nconsensus is to go with name spaces. Both solutions have pros and cons -\nnone is significantly simpler than the other.\n\n>FYI, there was a long discussion in the USEFOR WG on header field prefixes\n>for headers with various characteristics.  At the last IETF meeting of\n>USEFOR, the room reached the conclusion that adding such prefixes was\n>unnecessary complexity.  The current model where all headers are optional \n>seems sufficient for extensibility.  There was even a discussion of\n>labelling hop-to-hop headers in Netnews which is similar to the HTTP proxy\n>problem, and the same conclusion about unnecessary complexity was reached.\n\nWhat I believe you are saying is that HTTP is sufficient as is without an\nextension mechanism like the one proposed. I think the experience from the\nmultiple ways HTTP is actually being extended clearly indicates that this\nis not the case.\n\nHenrik\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-7679701"}, {"subject": "a proposed modification to the Nagle algorith", "content": "Members of the end2end-interest list,\n\nI am enclosing a draft which discusses a proposed modification to the Nagle \nalgorithm (in particular, the algorithm Nagle described in RFC896 to deal with \nthe \"small-packet problem\".\n\nHopefully, the draft does an adequate job of describing the current Nagle \nalgorithm as well as the proposed modification.\n\nThe draft also discusses some of the motivation for suggesting this change.  \nHowever, more motivation is included in a paper:\n\nNielsen, Henrik Frystyk, et al, \"Network Performance Effects\nof HTTP/1.1, CSS1, and PNG\", in Proceedings, ACM SIGCOMM 1997.\n\nA web page associated with that paper may also be of interest to people \ninterested in this topic:\n\nhttp://www.w3.org/Protocols/HTTP/Performance/Nagle/\n\n(Please note that while, in certain cases, the current Nagle algorithm can \nhave a negative performance impact for certain applications, turning OFF the \nNagle algorithm can have a very serious negative impact on the internet.  \nThus, nothing in this e-mail message, or in the enclosed draft, should be \ntaken as advice to any application developer to disable the Nagle algorithm.  \nThe current Nagle algorithm is very important in protecting the health of the \ninternet; the proposed modification [hopefully] provides the same level of \nprotection.)\n\nI would be very interested in hearing people's thoughts about the proposed \nmodification.  In particular, if people can think of ways in which the \nproposed modification might have a serious negative impact on the internet \n(see the section \"A Failure Mode\" for one possible line of reasoning), that \nwould be very interesting to hear!\n\n(You may notice that the paper includes a discussion of a possible API change \nto give applications better control over TCP's transmission of small packets.  \nWhile i believe this to be a beneficial change to the API, this is not the \nmain thrust of the paper and would not, therefore, be the main thrust of our \nsubsequent discussion of the paper.)\n\nThanks in advance for your careful reading and comments,\n\nCheers,  Greg Minshall\n\nps -- I am about to disappear for a week's vacation.  I wanted to get this \ndraft out now in order to give people a chance to comment on it, but *i* won't \nbe able to participate in the discussion in real time until the week of \nDecember 28.  Think of all those flames you are about to send me as being \ncommunity Christmas cards!\n\n----\n\nInternet Engineering Task Force                            Greg Minshall\nINTERNET-DRAFT                                             Siara Systems\ndraft-minshall-nagle-00                                December 18, 1998\n\n\n     A Proposed Modification to Nagle's Algorithm\n\n\nStatus of This Memo\n\n   This document is an Internet-Draft.  Internet-Drafts are working\n   documents of the Internet Engineering Task Force (IETF), its areas,\n   and its working groups.  Note that other groups may also distribute\n   working documents as Internet-Drafts.\n\n   Internet-Drafts are draft documents valid for a maximum of six\n   months and may be updated, replaced, or obsoleted by other\n   documents at any time.  It is inappropriate to use Internet- Drafts\n   as reference material or to cite them other than as ``work in\n   progress.''\n\n   To view the entire list of current Internet-Drafts, please check\n   the ``1id-abstracts.txt'' listing contained in the Internet-Drafts\n   Shadow Directories on ftp.is.co.za (Africa), ftp.nordu.net\n   (Northern Europe), ftp.nis.garr.it (Southern Europe), munnari.oz.au\n   (Pacific Rim), ftp.ietf.org (US East Coast), or ftp.isi.edu (US\n   West Coast).\n\n   This draft proposes a modification to Nagle's algorithm (as\n   specified in RFC896) to allow TCP, under certain conditions, to\n   send a small sized packet immediately after one or more maximum\n   segment sized packet.\n\n\nAbstract\n\n   The Nagle algorithm is one of the primary mechanisms which protects\n   the internet from poorly designed and/or implemented applications.\n   However, for a certain class of applications (notably,\n   request-response protocols) the Nagle algorithm interacts poorly\n   with delayed acknowledgements to give these applications poorer\n   performance.\n\n   This draft is NOT suggesting that these applications should di\n   sable the Nagle algorithm.\n\n   This draft suggests a fairly small and simple modification to the\n   Nagle algorithm to preserve Nagle as a means of protecting the\n   internet while at the same time giving better performance to a\n   wider class of applications.\n\n\nIntroduction to the Nagle algorithm\n\n   The Nagle algorithm [RFC896] protects the internet from\n   applications (most notably Telnet, at the time the algorithm was\n   developed) which tend to dribble small amounts of data to TCP.\n   Without the Nagle algorithm, TCP would transmit a packet, with a\n   small amount of data, in response to each of the application's\n   writes to TCP.  With the Nagle algorithm, a first small packet will\n   be transmitted, then subsequent writes from the application will be\n   buffered at the sending TCP until either i) enough application data\n   has accumulated to enable TCP to transmit a maximum sized packet,\n   or ii) the initial small packet is acknowledged by the receiving\n   TCP.  This limits the number of small packets to one per round trip\n   time.\n\n   While the current Nagle algorithm does a very good job of\n   protecting the internet from such applications, there are other\n   applications, such as request-response protocols (with HTTP 1.1\n   being a topical example) in which the current Nagle algorithm\n   produces non-optimal results.  In this context, the Nagle algorithm\n   is interacting with TCP's ``delayed ACK'' policy [RFC1122].\n\n\nDelayed ACKs\n\n   A receiving TCP tries to avoid acknowledging every received data\n   packet.  This process, known as ``delayed ACKing'' [RFC1122],\n   typically causes an ACK to be generated for every other received\n   (full-sized) data packet.  In the case of an ``isolated'' TCP\n   packet (i.e., where a second TCP packet is not going to arrive\n   anytime soon), the delayed ACK policy causes an acknowledgement for\n   the data in the isolated packet to be sent within 200 milliseconds\n   of the receipt of the isolated packet.  (The way delayed ACKs are\n   implemented in some systems causes the delayed ACK to be generated\n   anytime between 0 and 200ms; in this case, the average amount of\n   time before the delayed ACK is generated is 100ms.)\n\n\nThe interaction of delayed ACKs and Nagle\n\n   If a TCP has more application data to transmit than will fit in one\n   packet, but less than two full-sized packets' worth of data, it\n   will transmit the first packet.  As a result of Nagle, it will not\n   transmit the second packet until the first packet has been\n   acknowledged.  On the other hand, the receiving TCP will delay\n   acknowledging the first packet until either i) a second packet\n   arrives (which, in this case, won't arrive), or ii) approximately\n   100ms (and a maximum of 200ms) has elapsed.\n\n   When the sending TCP receives the delayed ACK, it can then transmit\n   its second packet.\n\n   In a request-response protocol, this second packet will complete\n   either a request or a response, which then enables a succeeding\n   response or request.\n\n   Note two (related) bad results of the interaction of delayed ACKs\n   and the Nagle algorithm in this case: the request-response time may\n   be increased by up to 400ms (if both the request and the response\n   are delayed); and, the number of transactions per second is\n   substantially reduced.\n\n\nA proposed modification to the Nagle algorithm\n\n   The current Nagle algorithm can be described as follows:\n\nIf a TCP has less than a full-sized packet to transmit,\nand if any previous packet has not yet been acknowledged,\ndo not transmit a packet.\n\n   The proposed Nagle algorithm modifies this as follows:\n\nIf a TCP has less than a full-sized packet to transmit,\nand if any previous less than full-sized packet has not\nyet been acknowledged, do not transmit a packet.\n\n   In other words, when running Nagle, only look at the recent\n   transmission (and acknowledgement) of small packets (rather than\n   all packets, as in the current Nagle).\n\n   (In writing the above, I am aware that TCP acknowledges BYTES, not\n   packets.  However, expressing the algorithm in terms of packets\n   seems to make the explanation a bit clearer.)\n\n\nImplementation of the modified Nagle algorithm in a system\n\n   The current Nagle algorithm does not require any more state to be\n   kept by TCP on a system.  SND_NXT is a TCP variable which names the\n   next byte of data to be transmitted.  SND_UNA is a TCP variable\n   which names the next byte of data to be acknowledged.  If SND_NXT\n   equals SND_UNA, then all previous packets have been acknowledged.\n\n   The proposed modification to the Nagle algorithm does,\n   unfortunately, require one new state variable to be kept by TCP.\n   SND_SML is a TCP variable which names the last byte of data in the\n   most recently transmitted small packet.\n\n   An implementation could be as follows:\n\n1.  When transmitting a small packet, record the sequence\nnumber of the last byte of the small packet in SND_SML.\n\n2.  When deciding whether or not to transmit a small packet,\ncheck to ensure that SND_SML is less than, or equal to,\nSND_UNA.\n\n\nA Failure Mode\n\n   If an application sends a large amount of data, followed by a small\n   amount of data, followed by a large amount of data, the current\n   Nagle algorithm would perform better than the proposed\n   modification.  The current Nagle algorithm would send at most one\n   small packet (possibly the last packet), delaying the middle\n   (small) amount of data which would allow the application to send\n   the following large amount of data; the proposed Nagle algorithm\n   would send two small packets (the middle packet, plus possibly a\n   last packet).\n\n\nA separate, but desirable, system facility\n\n   In addition to the Nagle algorithm (or the modification proposed by\n   this draft), it would be desirable for a system providing TCP\n   service to applications to allow the application to set TCP into a\n   mode in which the TCP would only transmit small packets at the\n   explicit direction of the application.  For example, a system based\n   on BSD might implement a socket option (using setsockopt(2))\n   SO_EXPLICITPUSH, as well as a flag to sendto(2) (possibly\n   overloading the semantics of an existing flag, such as MSG_EOF).\n\n   In this scenario, an application would set a socket into\n   SO_EXPLICITPUSH mode, then enter a mode of writing data to the\n   socket and, at the last write, using send(2) with the MSG_EOF flag.\n   The underlying TCP would recognize the MSG_EOF flag as an indicator\n   to transmit the (possibly) small packet.\n\n   Like the proposed modification to the Nagle algorithm, this is\n   fairly simple to implement.\n\n   If a system were to implement this interface, it would be important\n   to NOT disable Nagle when using this interface.  In other words,\n   when using this interface, the default mode for TCP would be to NOT\n   transmit a small packet (even in the presence of MSG_EOF) if a\n   previously transmitted small packet was as yet unacknowledged.\n\n   Note, also, that implementing this interface does not eliminate the\n   desirability of using the modification of the Nagle as the default\n   for applications.  More sophisticated networking applications might\n   well use the new interface, but naive applications will often be\n   adequately served by the modified Nagle algorithm.\n   \n\nAcknowledgements\n\n   Jim Gettys, Henrik Frystyk Nielsen, Jeff Mogul, and Yasushi Saito,\n   as well as a message forwarded to the end2end-interest list by Sean\n   Doran, have motivated my current interest in the Nagle algorithm.\n   John Heidemann's work related to the Nagle algorithm has informed\n   some of the thinking in this draft; discussions with John have also\n   been helpful.  Members of the End-to-End Research Group (under\n   the direction of Bob Braden) patiently listened to my discussion of\n   the current state of the Nagle algorithm and to the modifications\n   proposed in this document.\n\n\nSecurity Considerations\n\n   The Nagle algorithm does not have major security consequences.\n\n   Implementation of this algorithm should not negatively impact\n   the performance of the internet.  The negative impact of\n   implementation of this algorithm should be significantly less\n   than disabling the Nagle algorithm.\n\n\nReferences\n\n[RFC896]        Nagle, J., \"Congestion control in IP/TCP internetworks\",\nJan-06-1984.\n[RFC1122]       Braden, R. T., \"Requirements for Internet hosts -\ncommunication layers\", Oct-01-1989.\n\nAuthor's Addresses\n\n   Greg Minshall\n   Siara Systems\n   1399 Charleston Road\n   Mountain View, CA  94043\n   USA\n\n   <minshall@siara.com>\n\n\n\n", "id": "lists-007-7688932"}, {"subject": "Notes from the IETF meeting in Orland", "content": "My personal notes (not official minutes) from the IETF\nmeeting in Orlando in December 1998 can be found at URL\n   http://www.dsv.su.se/~jpalme/meetings/dec-98-notes/\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-7708565"}, {"subject": "IPP2IFAX Proposed WG and Charter Bashin", "content": "During IETF Orlando I made a presentation to both the Internet Print Protocol\nWG as well as the FAX WG on the issue of the using IPP as a Facsimile Service\nbased on a personal ID that I submitted. [draft-shockey-ipp2ifax-01.txt]\n\nThere was considerable discussion of this issue in the IPP WG and there was\ngeneral consensus that this was a area that could use some work.\n\nSeveral individuals at both meetings indicated a desire to contribute.\n\nIt was the suggestion of the APP Area Director Keith Moore that this be set up\nas a separate IETF WG to facilitate discussion between the IPP and FAX WG's on\nthis issue\n\nOn December 16 & 17 I presented the results of the IETF meetings to a group of\nPWG/IPP members in San Diego.\n\nThe consensus at that meeting was that this concept has merit and should\nproceed. Several individuals at that meeting offered to participate in the work\nand the suggestion was put forward that I be proposed as the Chair of this new\nWG/BOF should it be chartered.\n\nBefore I formally submit a request for a new WG to the AD's I'd like to bash\nout a Charter.\n\nThe proposed charter below was discussed at the PWG/IPP meetings in San Diego.\n\nAny comments, suggestions, flames etc would be appreciated.\n\n##############\n\n\nInternet Print Protocol and Internet Fax  (ipp2ifax)\n------------------\n\nChair(s):   Richard Shockey  <rshockey@ix.netcom.com>  [PROPOSED]\n     \n \nApplications Area Director(s):\nKeith Moore             <moore+iesg@cs.utk.edu>\n        Patrik F?ltstr?m        <paf@swip.net>\n\n Area Advisor\n        Keith Moore  <moore+iesg@cs.utk.edu>\n\n Mailing lists:\n        General Discussion:     ifx@pwg.org\n        To Subscribe:           majordomo@pwg.org\n                In Body:                subscribe ifx  [your-email-address]    \nThe subject line should be blank        \n\nArchive:          \n<http://www.pwg.org/hypermail/ifx>\n\nDescription of Working Group:\n\nThe Internet Print Protocol [IPP] has been developed within the IETF to\nfacilitate the remote printing of documents over the Internet. At a sufficient\nlevel of abstraction FAX on the General Switched Telephone Network [GSTN] could\nalso be considered a remote printing or document transfer technology.\n\nThe purpose of the work group will be to investigate and document those\nelements of IPP that qualify as a facsimile service. A goal of the WG will be\nto note the legal as well as general custom and practice of GSTN FAX and apply\nthose principals to IPP transactions.\n\nCurrent work within the IETF on FAX has centered on using Internet Mail\nstandards in a Store and Forward mode. Considerable evidence exists that there\nis a need for protocols that more closely approximate the real-time and point\nto point model of traditional GSTN FAX.\n\nTraditional GSTN FAX is limited to the type and quality of output. IETF\nInternet Fax standards are also limited to a specific set of MIME Content-Types\nspecified in RFC 2301.  IPP has no such restrictions on the quality of document\nto be printed or displayed.\n\nThe WG will not propose any revisions to the current Internet Print Protocol\nspecifications but may use normal IPP Attribute Extensions and behavioral\npractice requirements to facilitate interoperability with GSTN FAX and RFC2305\nusing elements of RFC2301 as needed.\n\nThe WG will not propose any revisions or extensions to IETF Internet Fax\nstandards [RFC2305] and its successors.\n\nThe group will take note of other areas within the IETF that may have direct\nbearing on IPP and FAX interworking.\n\nRelevant areas include:  \n\n-       Security, Authentication and Encryption (SSL3 -TLS)\n-       Sender Identification (vCard)\n\n\nThe working group will take note of quality of service issues.    \n\nThe working group will coordinate its activities with the Internet Print\nProtocol working group [IPP] and the Internet Fax working group [FAX] as well\nother facsimile-related standards bodies and related work groups, notably the\nITU-T Study Group 8.   \n\n\nGoals and Milestones:  \n  \nMarch 1999 : Submit Internet Draft of Goals and Requirements for the use of the\nInternet Print Protocol as a Facsimile Service\n\nApril 1999 : Submit Internet Draft for IPP Behavior as a Facsimile Service\n\nMay 1999 : Submit Internet Draft of IPP as a Gateway to SMTP and GSTN Facsimile\nServices\n\n\n\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nRichard Shockey\nShockey Consulting LLC                  \n8045 Big Bend Blvd. Suite 110    \nSt. Louis, MO 63119\nVoice 314.918.9020\nFax   314.918.9015\nINTERNET Mail & IFAX : rshockey@ix.netcom.com  \n<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n\n\n", "id": "lists-007-7715600"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "On Fri, 18 Dec 1998, Henrik Frystyk Nielsen wrote:\n> >FYI, there was a long discussion in the USEFOR WG on header field prefixes\n> >for headers with various characteristics.  At the last IETF meeting of\n> >USEFOR, the room reached the conclusion that adding such prefixes was\n> >unnecessary complexity.  The current model where all headers are optional \n> >seems sufficient for extensibility.  There was even a discussion of\n> >labelling hop-to-hop headers in Netnews which is similar to the HTTP proxy\n> >problem, and the same conclusion about unnecessary complexity was reached.\n> \n> What I believe you are saying is that HTTP is sufficient as is without an\n> extension mechanism like the one proposed. I think the experience from the\n> multiple ways HTTP is actually being extended clearly indicates that this\n> is not the case.\n\nI was suggesting that the optional header model is sufficient for\nextensible headers.  There probably does need to be something along the\nlines of the EHLO command added to SMTP.  Sorry I wasn't clear.\n\n- Chris\n\n\n\n", "id": "lists-007-7730170"}, {"subject": "RE: Looking for comments on the HTTP Extension draf", "content": "> I was suggesting that the optional header model is sufficient for\n> extensible headers.  There probably does need to be something along the\n> lines of the EHLO command added to SMTP.  Sorry I wasn't clear.\n\nDoing so would be inconsistent with the stateless model for HTTP.\n\nI believe the conclusion to draw from this discussion is that while\nheader field prefixes do add complexity, and that such complexity\nwas found unnecessary in other protocols, it's needed here.\n\nI don't know whether this design rationale belongs in the document\nbefore it's published as an RFC. Probably a brief paragraph to that\neffect would be useful, if only to point out that this isn't an\nexample that is necessarily to be followed for other protocols.\n\nLarry\n\n\n\n", "id": "lists-007-7739259"}, {"subject": "Re: IPP2IFAX Proposed WG and Charter Bashin", "content": "On Sat, 19 Dec 1998, Richard Shockey wrote:\n\n> Internet Print Protocol and Internet Fax  (ipp2ifax)\n[...]\n> The purpose of the work group will be to investigate and document those\n> elements of IPP that qualify as a facsimile service. \n\n\"... and extend IPP where necessary to more closely perform the functions\nof facsimile.\"  [see below]\n\n> A goal of the WG will be to note the legal as well as general custom\n> and practice of GSTN FAX and apply those principals to IPP\n> transactions.\n> \n> Current work within the IETF on FAX\n\nClarify by changing to:\n\n  \"Current work within the IETF's Internet Fax Working Group ...\"\n\n> has centered on using Internet Mail standards in a Store and Forward\n> mode. Considerable evidence exists that there is a need for protocols\n> that more closely approximate the real-time and point to point model\n> of traditional GSTN FAX.\n> \n> Traditional GSTN FAX is limited to the type and quality of output.\n> IETF Internet Fax standards are also limited to a specific set of MIME\n> Content-Types specified in RFC 2301.  IPP has no such restrictions on\n> the quality of document to be printed or displayed.\n> \n> The WG will not propose any revisions to the current Internet Print Protocol\n> specifications but may use normal IPP Attribute Extensions and behavioral\n> practice requirements to facilitate interoperability with GSTN FAX and RFC2305\n> using elements of RFC2301 as needed.\n\nI could see the IFX group proposing extensions or revisions to IPP,\nactually -- for example a mechanism to indicate This Is a Fax and should\ncontain timestamps.  I wouldn't want such extensions to be out of scope.\n\n> The WG will not propose any revisions or extensions to IETF Internet Fax\n> standards [RFC2305] and its successors.\n> \n> The group will take note of other areas within the IETF that may have direct\n> bearing on IPP and FAX interworking.\n> \n> Relevant areas include:  \n> \n> -       Security, Authentication and Encryption (SSL3 -TLS)\n> -       Sender Identification (vCard)\n\nConneg?\n\n> The working group will take note of quality of service issues.    \n\nOn the Internet, \"Quality of Service\" has distinct meaning -- be careful\nhere.  QoS usually means bounded delay of packet delivery -- much\ndifferent from what you mean (which is likely bounded delay of the\nphysical output).\n\nPerhaps something like: \"The WG will attempt to provide mechanisms to\nallow interoperable implementations to be created which closely emulate\nthe existing end-user- expected functionality of fax.\" but shorter-winded.\n\n[...]\n\n-Dan Wing\n\n\n\n", "id": "lists-007-7748786"}, {"subject": "Re: IPP2IFAX Proposed WG and Charter Bashin", "content": ">> The group will take note of other areas within the IETF that may have direct\n>> bearing on IPP and FAX interworking.\n>> \n>> Relevant areas include:  \n>> \n>> -       Security, Authentication and Encryption (SSL3 -TLS)\n>> -       Sender Identification (vCard)\n>\n>Conneg?\n\nExcellent Point... at the regular IPP/PWG meeting in San Diego myself and\nRandy Turner of Sharp noted the need for IPP to make contact with the\nCONNEG WG and exchange ideas and concepts since IPP is pretty deep into\ndefining capabilities for IPP Printer Objects.\n\nThe CONNEG framework is IMHO perfect for printers...at the very least the\nframework IPP is considering should not conflict with CONNEG, though 3WC\nhas several proposals on the table for similar concepts specifically in the\nmobile device area using XML [suprise?].  \n\nI'm very hopeful that the fine work of CONNEG can extend out into other\napplication areas.\n\n\n\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nRichard Shockey\nShockey Consulting LLC                  \n8045 Big Bend Blvd. Suite 110    \nSt. Louis, MO 63119\nVoice 314.918.9020\nFax   314.918.9015\nINTERNET Mail & IFAX : rshockey@ix.netcom.com  \n<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n\n\n", "id": "lists-007-7760093"}, {"subject": "RE: Looking for comments on the HTTP Extension draf", "content": "At 10:20 12/21/98 PST, Larry Masinter wrote:\n>I don't know whether this design rationale belongs in the document\n>before it's published as an RFC. Probably a brief paragraph to that\n>effect would be useful, if only to point out that this isn't an\n>example that is necessarily to be followed for other protocols.\n\nSounds good to me.\n\nHenrik\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-7770060"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "I am wondering whether the design of this extensions mechanism\nis different enough from the base design of HTTP 1.x to require\na rev in the protocol number.  In particular:\n\n1) Headers in HTTP 1.x can be processed in any order; headers in the\nextension model may be required to be processed in the order\ndetermined by the extension, and the namespace designation header\n*must* be processed first.  We have talked informally about how this\naffects the use of \"headers\" in footers, but that needs to be formally\nspecified and it does differ from 1.x for chunked encodings.\n \n\n2) The semantics of the M- methods derive from their originals to the\nextent that the semantics of those originals get applied *first*, but\nthere is no restriction on the semantics applied after.  Think of a\nGET which increments a counter, for example, like the baker's order\nnumber machine--the semantics of GET are applied first, but the\nsecondary semantics make it very different from a traditional GET.\n\n3) The treatment of URIs as identifiers is very different from\nwhat many will expect--there is currently an expectation in the\nweb community that a single URI can reference changing resources,\nand its use in this context needs to be very well specified.  Think,\nfor example, of vendors who commonly refer to a product by a single\nname no matter what patch rev it is; quashing that so that specific\nrevs are always matched by changes to the URI needs real work.\n\n4) The content negotiation implied by the document is also not\nworkable within the current CONNEG framework, because the set\nintersection model CONNEG uses presumes that the resource is intended\nfor a single purpose; it has no provision for a resource that is a\ntoken, a description, and machine-usable code.  In the current\nframework, a device selects among multiple values in a set\nintersection by q-value, not purpose.  It can't really select \"one for\nthis and one for that\" in the same operation.\n\nI would not normally see the need for a protocol rev for an optional\nextension, but the current draft says that a server can send these\nwhen they are fully optional or based on \"a priori\" knowledge.  That,\nto me, shouts that the possibility of their use must be somehow\nindicated up front.  Revving the protocol does that; there may, of\ncourse, be other ways which would serve just as well, and I would be\nopen to them.\nregards,\nTed Hardie\nhardie@equinix.com\n\n\n\n\n\n\n> At 10:20 12/21/98 PST, Larry Masinter wrote:\n> >I don't know whether this design rationale belongs in the document\n> >before it's published as an RFC. Probably a brief paragraph to that\n> >effect would be useful, if only to point out that this isn't an\n> >example that is necessarily to be followed for other protocols.\n> \n> Sounds good to me.\n> \n> Henrik\n> --\n> Henrik Frystyk Nielsen,\n> World Wide Web Consortium\n> http://www.w3.org/People/Frystyk\n> \n\n\n\n", "id": "lists-007-7778641"}, {"subject": "Re: IPP2IFAX Proposed WG and Charter Bashin", "content": "At 21:14 21/12/98 -0600, Richard Shockey wrote:\n[...]\n>The CONNEG framework is IMHO perfect for printers...at the very least the\n>framework IPP is considering should not conflict with CONNEG, though 3WC\n>has several proposals on the table for similar concepts specifically in the\n>mobile device area using XML [suprise?].  \n\n[Speaking as editor of some of the 'conneg' work...]\n\nI have already made contact with Franklin Reynolds who is author/editor of\nsome W3C work in that field, and hope to maintain a constructive liaison.\n\n>I'm very hopeful that the fine work of CONNEG can extend out into other\n>application areas.\n\nMe too!\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-7790254"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "text/enriched attachment: stored\n\n\n\n\n", "id": "lists-007-7799226"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "Henrik,\nThanks for your reply to my comments; I believe, however, that\nsome inexactness on my part may have led you astray, as we still seem\nto be talking at cross-purposes on some issues.  I will endeavor below\nto clarify those areas.\nBefore going into the details, however, I want to make clear\nthat I was not proposing that the HTTP *minor* version number be\nrevved, but its *major* version number.  This document seems to me to\npropose a framework that will encompass changes sufficiently great to\nwarrant that change--the landscape of the web will be changed\ncompletely if this is adopted, and that calls to me for some pretty\nclear signposts.  \nI will repeat that I would not see the need for the rev if the\ndocument did not allow responses to contain extensions based on \"a\npriori\" knowledge.  Without that \"a priori\" extension, HEAD, OPTIONS,\nor the other methods you describe would suffice.  Without a very clear\nspecification of very specific cases where those \"a priori\" extensions\nare allowed, they will be used in many, many cases that we cannot now\nforesee.  That means a big, big flag needs to be raised.\n\n\n> Furthermore, there is no reason why an application MUST read the\n> declaration first - the ns prefixed header fields are just unknown\n> extension header fields until the extension declaration has been\n> interpreted. This kind of \"two-pass\" header field parsing is not new to\n> HTTP - the same is the case for the connection header field and the\n> cache-control header field, for example.\n\n\nI did not say it must *read* the declaration first; I said it must\n*process* it first.  Whether that is a one pass or a two pass header\nfield parsing makes no difference to the requirement.  As written, if\na Man: or an Opt: header exists, it must be processed with its\nnamespace headers first, as the meanings of the other headers may\nchange based on the extensions.\n\nThis is, in fact, a point I don't feel I am making well, and I'd like\nLarry to speak to it if he can.  During the CONNEG meetings in Orlando,\nhe expressed very well the principle that the meaning of a feature must\nnot depend semantically on the values of *other* features (so \"Warm\" must\nmean the same thing whether we are talking about beer or the weather).  \nThis has a lot of implications for feature design (You don't use \"Warm\",\nyou use \"33c\").  Many of the same issues apply even more strongly for \nextensions to HTTP, and I don't see them addressed in the draft. \n\n\n>   3.  If 2) did not result in a 510 (Not Extended) status code, then\n> \n>       strip the \"M-\" prefix from the method name and process the\n> \n>       remainder of the request according to the semantics of the\n> \n>       extensions and of the existing HTTP/1.1 method name as defined in\n> \n>       [5].\n> \n\nAgain, I don't seem to be getting my point across here.  The example I\ngave was possibly too local.  I was trying to imply that the apparent\nmethod for extending a method might seem to imply constraints which\naren't there.  In the M-GET example, you may have the base semantics\nof GET, but you also have the possibility of secondary effects (like\nthe M-GET popping a stack and causing a new value to be present at the\nURL) which substantially change the original semantics and cause\npreviously expected characteristics of GET (like idempotence) to\nchange.  The implication of this is that anyone examining a method for\nsecurity reasons (like a firewall administrator) cannot rely on the\nmethod to the right of the M- for any real expectations of the\nmethod's semantics.\n\n\n> I can think of plenty of examples where this is not the case - for\n> example published papers, released software packages etc. However, you\n> are right that this is an issue and extension designers have to be\n> careful (as should everybody else) when selecting a spot in the URI name\n> space. This is also the reason for the careful wording in [2] section \n> 8:\n> \n> \n> <paraindent><param>left</param>It is strongly recommended that the\n> integrity and persistence of the extension identifier be maintained and\n> kept unquestioned throughout the lifetime of the extension. Care should\n> be taken not to distribute conflicting specifications that reference the\n> same name. Even when an extension specification is made available at the\n> address of the URI, care must be taken that the specification made\n> available at that address does not change over time. One agent may\n> associate the identifier with the old semantics, and another might\n> associate it with the new semantics.\n> \n> </paraindent>\n\nThe fact that people get identifiers right in other contexts doesn't\nreally change the fact that this a major change to how URLs are used\nin the current web context.  Given that current context, I am afraid I\nfind \"strongly recommended\" to be weakly worded.  It's not even a\nSHOULD requirement, and I believe that it ought to be the most\nstrongly worded MUST we can design.  Without that strong requirement,\ninteroperability is based on the good will of the market players, some\nof whom will have strong disincentives to admit some kinds of changes.\n\n\n> >4) The content negotiation implied by the document is also not\n> \n> >workable within the current CONNEG framework, because the set\n> \n> >intersection model CONNEG uses presumes that the resource is intended\n> \n> >for a single purpose; it has no provision for a resource that is a\n> \n> >token, a description, and machine-usable code.  In the current\n> \n> >framework, a device selects among multiple values in a set\n> \n> >intersection by q-value, not purpose.  It can't really select \"one for\n> \n> >this and one for that\" in the same operation.\n> \n> \n> Unless this is different from HTTP then the q values describe the value\n> on the axis and not the dimension of the axis. q values can be applied to\n> any dimension be it type or some other property. In fact, the negotiation\n> hinted at here only spans the media type.\n>\n> As metadata is moving on the Web and the ways of describing capabilities\n> get more powerful, so is content negotiation likely to get more powerful.\n> The extension framework doesn't depend on any particular content\n> negotiation mechanism (including no mechanism at all) and can actually be\n> used to introduce improved content negotiation schemes as they evolve.\n\nYour first point is exactly what I am trying to get across: q values\ndescribe the value on the axis and not *which* axis is being given the\nvalue.  For a content negotiation mechanism to handle the problem you\npropose, it would have to be able to designate the axis and the value.\nI am not aware of any content negotiation mechanism, current or\nproposed, that can handle that at the level of complexity your\ndocument implies.  The correct operation of content negotiation for a\nsingle-URI resource which potentially has everything from\nmachine-executable code to multi-lingual, multi-character set\ndescriptions is not an easy problem.  If you must imply that you want\nit, please be very sure that you describe it as an unsolved problem\nrequiring further work.\n\nTo be brutally honest, I believe that those who ought to be giving this\nframework the very careful review it deserves are simply too tired to\ngo over it with the fine-toothed comb it needs.  We must be careful\nto get that review and those problems worked at before it is released,\nthough, as the work required to fix this post facto would be enormous.\n\nThanks again for all your continuing work on it,\nbest regards,\nTed Hardie\nhardie@equinix.com\n\n\n\n", "id": "lists-007-7807651"}, {"subject": "RE: Looking for comments on the HTTP Extension draf", "content": "<Defining the Problem>\nI suspect we all at least agree that there is a need for a mandatory\nextension mechanism. The functionality for this header being something on\nthe order of \"If you don't understand the header names specified in this\nheader then you MUST fail this method.\"\n\nOne could make the argument that if one needs to add a header with semantics\nthat can't be ignored then one should change the method name and require\nthat the new method not ignore this header. However the management\ncomplexities of this solution are exponential, thus this proposal is not\nacceptable.\n\nI suspect we all can also agree that this mechanism must work with HTTP/1.0\nand HTTP/1.1. The tools available to achieve this goal are:\n1) Servers must fail methods they don't understand.\n2) Servers must ignore headers they don't understand.\n\nSince the only guaranteed failure mode is a method name that isn't\nunderstood then it is this mechanism which must be leveraged in order to\nguarantee that a mandatory header will be properly honored. This is what the\n\"M-\" prefix achieves. By adding \"M-\" we guarantee that all existing\nfirewalls, proxies, servers, etc. will either turn themselves into a pipe or\nfail the method if they do not understand the mandatory mechanism.\n\nServers/firewalls/proxies which do understand the mechanism also understand\nthat they can infer nothing from the method name without having first\nchecked the mandatory prefix. I agree that this is a significantly\nsub-optimal solution. Additionally, when processing the method one needs to\nfirst find out if there is a mandatory header so one can find the prefix\ntranslation and thus \"decode\" the HTTP headers, an equally sub-optimal\nsolution.\n\nHowever there is a second problem lurking here which I don't believe has\nbeen fully called out. There does not exist a decentralized mechanism to\nallow for the introduction of new methods and headers. Currently the best\none can do is get an RFC and hope that no one else is already using that\nmethod/header name. We already know this doesn't work as method name\ncollisions have already occurred. Mandatory provides a mechanism to\nassociate a URI with a method or header and in so doing provides the very\ndecentralized mechanism we so desperately need.\n</Defining the Problem>\n\n<Henrik, put down that knife!>\nHowever, given the previous pointed out sub-optimalities, I'm not sure that\nthe cure is all that much better than the disease. As such, I would like to\npropose an alternative design.\n\n1) The creation of a hierarchical namespace encoding for methods and headers\nala what is being discussed in the URLREG WG. For example V!MS!FOO where V\nis a stand in for vnd or vendor.\n\n2) The creation of a standardized encoding mechanism to allow for the use of\na fully qualified URIs as a method of header name. Because both use the\ntoken production, standard URI characters such as : and / can not be used\nwithout encoding.\n\nThese two mechanisms will allow for decentralized extension without fear of\ncollision, exactly as is being attempted now in the URLREG WG. The cost,\nhowever, of this mechanism is byte bloat. Mandatory's use of prefixing\nallows short names to be used with short prefixes which are then translated\nto their full names. In essence, mandatory has created relative URIs.\nHowever the cost is double processing the headers. Thus every mandatory\naware proxy/firewall/server must process each request twice. There is a\ntrade off to be made here. My proposal leverages the existing HTTP\ninfrastructure as the cost of byte bloat. Henrik's proposal solves the byte\nbloat problem but at the cost of causing us to have to completely re-write\nour parsers to do double parsing. I suspect maintaining the current\ninfrastructure is probably the better goal.\n\nThe downside of my simplification proposal is that it doesn't provide a\ngeneric mechanism to say \"The functionality represented by this URI is now\nassociated with this method.\" Instead you have to use a header hack. You\nhave to add a header with the specified URI and then include its name in\nMandatory. I can live with this. How about you?\n</Henrik, put down that knife!>\n\n<So spoke Ted Hardie>\n> Before going into the details, however, I want to make clear\n> that I was not proposing that the HTTP *minor* version number be\n> revved, but its *major* version number.  This document seems to me to\n> propose a framework that will encompass changes sufficiently great to\n> warrant that change--the landscape of the web will be changed\n> completely if this is adopted, and that calls to me for some pretty\n> clear signposts.  \n> I will repeat that I would not see the need for the rev if the\n> document did not allow responses to contain extensions based on \"a\n> priori\" knowledge.  Without that \"a priori\" extension, HEAD, OPTIONS,\n> or the other methods you describe would suffice.  Without a very clear\n> specification of very specific cases where those \"a priori\" extensions\n> are allowed, they will be used in many, many cases that we cannot now\n> foresee.  That means a big, big flag needs to be raised.\n> \n</So spoke Ted Hardie>\n\n<Yes, Dorothy, we are still in Kansas>\nI must take issue with the fundamental logic of this statement. The power of\nthe Mandatory's design is that it is backwards compatible with HTTP/1.0 and\nHTTP/1.1. That backwards compatibility comes from the fact that Mandatory\nleverages the fail/ignore principals of HTTP so as to allow an existing\nserver to properly fail a Mandatory enhanced method without knowing anything\nabout Mandatory. Thus, by the very definition of the feature, we have\nabsolutely no requirement to up the major version number. Upping the version\nnumber means we have made a non-backwards compatible semantic change.\nMandatory, by properly leveraging HTTP's extension design, makes a 100%\nbackwards compatible semantic change. Please see below for comments\nspecifically addressing the ramifications of Mandatory for firewalls and\nproxies.\n</Yes, Dorothy, we are still in Kansas>\n\n<Our weapons are fear, uncertainty and doubt>\nThe \"a priori\" language was added at my insistence. The reason being that\npreviously the standard allowed for the return of mandatory headers on\nresponses without the client having first identified to the server that it\ncould understand the mandatory extensions. The spec had some vague language\nabout what a client was supposed to do when it got an unrecognized Mandatory\nextension on a response. I felt the language was absolutely unacceptable and\ndemanded, without exception, that a client MUST have somehow expressed to\nthe server that it understands a particular mandatory extension before the\nserver is allowed to use that extension on a response. I did not, however,\ndemand an actual specification of what \"a priori\" meant because I recognize\nthat such a definition was futile. Given that the very nature of a mandatory\nextension means that extension specific code has been added to the\nclient/server I believe it is in our interest to retain maximum flexibility\nin defining how client signaling of support is accomplished.\n</Our weapons are fear, uncertainty and doubt>\n\n<So spoke Ted Hardie>\n> I did not say it must *read* the declaration first; I said it must\n> *process* it first.  Whether that is a one pass or a two pass header\n> field parsing makes no difference to the requirement.  As written, if\n> a Man: or an Opt: header exists, it must be processed with its\n> namespace headers first, as the meanings of the other headers may\n> change based on the extensions.\n</So spoke Ted Hardie>\n\n<Nothing is fool proof, fools are too ingenious>\nTo follow your logic, we should require that the major version # of HTTP be\nraised every time a new method is introduced. I am free to design the \"FOO\"\nmethod which stipulates that if the content-location header and the location\nheader are both present then the location header should be seen as a pointer\nto a backup server where subsequent requests can be made. Thus the only way\nto fully understand the headers on a FOO method is to read in all the\nheaders and see if both content-location and location are present. This is,\nof course, bad design but it certainly is not a reason to up the major\nversion number on HTTP.\n</Nothing is fool proof, fools are too ingenious>\n\n<So spoke Ted Hardie>\n> This is, in fact, a point I don't feel I am making well, and I'd like\n> Larry to speak to it if he can.  During the CONNEG meetings \n> in Orlando,\n> he expressed very well the principle that the meaning of a \n> feature must\n> not depend semantically on the values of *other* features (so \n> \"Warm\" must\n> mean the same thing whether we are talking about beer or the \n> weather).  \n> This has a lot of implications for feature design (You don't \n> use \"Warm\",\n> you use \"33c\").  Many of the same issues apply even more strongly for \n> extensions to HTTP, and I don't see them addressed in the draft. \n> \n</So spoke Ted Hardie>\n\n<Nothing is fool proof, fools are too ingenious>\nAgreed, but this is an issue of a particular Mandatory extension. There is\nnothing in Mandatory which requires this sort of behavior. This is the same\nissue as my previous FOO method example.\n</Nothing is fool proof, fools are too ingenious>\n\n<So spoke Ted Hardie>\n> Again, I don't seem to be getting my point across here.  The example I\n> gave was possibly too local.  I was trying to imply that the apparent\n> method for extending a method might seem to imply constraints which\n> aren't there.  In the M-GET example, you may have the base semantics\n> of GET, but you also have the possibility of secondary effects (like\n> the M-GET popping a stack and causing a new value to be present at the\n> URL) which substantially change the original semantics and cause\n> previously expected characteristics of GET (like idempotence) to\n> change.  The implication of this is that anyone examining a method for\n> security reasons (like a firewall administrator) cannot rely on the\n> method to the right of the M- for any real expectations of the\n> method's semantics.\n> \n</So spoke Ted Hardie>\n\n<It's a feature!>\nAbsolutely true! Nor is there any implication in the draft that an\nadministrator could do so. In fact I assume our readers are just as smart as\nyou are and will, as you did, figure out that for their firewall to have any\nchance of parsing the method they MUST parse the mandatory header itself,\nsee if they recognize the extension and if they do then and only then do\nthey have sufficient information to deal with the method. Otherwise the\nfirewall must treat the method as any other method it knows absolutely\nnothing about. The beauty of mandatory is that this is what a firewall which\nknows nothing about mandatory, much less the enhanced method, will do with a\nmandatory request. Everything just works. However a note about this in the\nsecurity section is probably appropriate.\n</It's a feature!>\n\n<So spoke Ted Hardie>\n> The fact that people get identifiers right in other contexts doesn't\n> really change the fact that this a major change to how URLs are used\n> in the current web context.  Given that current context, I am afraid I\n> find \"strongly recommended\" to be weakly worded.  It's not even a\n> SHOULD requirement, and I believe that it ought to be the most\n> strongly worded MUST we can design.  Without that strong requirement,\n> interoperability is based on the good will of the market players, some\n> of whom will have strong disincentives to admit some kinds of changes.\n> \n</So spoke Ted Hardie>\n\n<Deja Vu, all over again>\n1) This is not new, WebDAV does the exactly same thing.\n2) I trust the market a hell of a lot more than I trust some text in a\nstandards document. If people choose to use someone's extension and that\nperson does not properly maintain their extension then people will stop\nusing that extension. No \"MUST\" in a standard can change that one way or\nanother. I think the language is actually quite clear and well written. I\ndisagree that any word smithing is necessary.\n</Deja Vu, all over again>\n\n<So spoke Ted Hardie>\n> Your first point is exactly what I am trying to get across: q values\n> describe the value on the axis and not *which* axis is being given the\n> value.  For a content negotiation mechanism to handle the problem you\n> propose, it would have to be able to designate the axis and the value.\n> I am not aware of any content negotiation mechanism, current or\n> proposed, that can handle that at the level of complexity your\n> document implies.  The correct operation of content negotiation for a\n> single-URI resource which potentially has everything from\n> machine-executable code to multi-lingual, multi-character set\n> descriptions is not an easy problem.  If you must imply that you want\n> it, please be very sure that you describe it as an unsolved problem\n> requiring further work.\n> \n</So spoke Ted Hardie>\n\n<Ick>\nSince I don't generally believe in negotiation I will leave this argument to\ny'all.\n</Ick>\n\n<So spoke Ted Hardie>\n> To be brutally honest, I believe that those who ought to be \n> giving this\n> framework the very careful review it deserves are simply too tired to\n> go over it with the fine-toothed comb it needs.  We must be careful\n> to get that review and those problems worked at before it is released,\n> though, as the work required to fix this post facto would be enormous.\n> \n</So spoke Ted Hardie>\n\n<Ohhhhhh Ted..... I love it when your brutal!>\nSigh... I have to agree. December is a lousy month to try to perform a\nreview. Half the necessary people are gone and the rest are too busy to deal\nwith it.\n</Ohhhhhh Ted..... I love it when your brutal!>\n\n\n<So spoke Ted Hardie>\n> Thanks again for all your continuing work on it,\n> best regards,\n> Ted Hardie\n> hardie@equinix.com\n</So spoke Ted Hardie>\n\n<Nobody here but us Chickens>\nOhh goodie... Henrik can commit a double homicide. I just love company. =)\n</Nobody here but us Chickens>\n\n\n\n", "id": "lists-007-7824121"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "<Yaron, do you dream in XML?>\n\nLo, Yaron spake thusly:\n> I suspect we all can also agree that this mechanism must work with HTTP/1.0\n> and HTTP/1.1. The tools available to achieve this goal are:\n\nIf I'm willing to rev the protocol number, obviously I don't believe\nthat this mechanism must be one which fits in the 1.x framework.  A\nreally good extension mechanism that had to have one incompatible\nchange would be fine by me.  Once this extension mechanism takes\noff, there will be no more major or minor protocol number changes,\nonly extensions.  One big change to note that shift isn't that hard\nis it?  It's not as if all of the old clients out there are going\nto become extension aware anyway.\n\n> Servers/firewalls/proxies which do understand the mechanism also understand\n> that they can infer nothing from the method name without having first\n> checked the mandatory prefix. I agree that this is a significantly\n> sub-optimal solution. Additionally, when processing the method one needs to\n> first find out if there is a mandatory header so one can find the prefix\n> translation and thus \"decode\" the HTTP headers, an equally sub-optimal\n> solution.\n\nSub-optimal is certainly nice phrasing.  In large-scale production\nenvironments, I would bet it would be sub-optimal enough to be\ndescribed as \"broken\" or \"very expensive\".  The need for more review\nby those designing firewalls, proxies, and the like is a persistent\nrefrain in this little exchange, but let's let it run through our\nminds one more time.\n\n\n> <Our weapons are fear, uncertainty and doubt>\n> The \"a priori\" language was added at my insistence. The reason being that\n> previously the standard allowed for the return of mandatory headers on\n> responses without the client having first identified to the server that it\n> could understand the mandatory extensions. The spec had some vague language\n> about what a client was supposed to do when it got an unrecognized Mandatory\n> extension on a response. I felt the language was absolutely unacceptable and\n> demanded, without exception, that a client MUST have somehow expressed to\n> the server that it understands a particular mandatory extension before the\n> server is allowed to use that extension on a response. I did not, however,\n> demand an actual specification of what \"a priori\" meant because I recognize\n> that such a definition was futile. Given that the very nature of a mandatory\n> extension means that extension specific code has been added to the\n> client/server I believe it is in our interest to retain maximum flexibility\n> in defining how client signaling of support is accomplished.\n> </Our weapons are fear, uncertainty and doubt>\n\nI prefer \"fear, surprise, and a ruthless and fanatical devotion to\ninteroperability.\"\n\nI think you saw the right problem, but I don't think your demands\nweren't quite met.  \"a client MUST have somehow expressed to the\nserver that it understands a particular mandatory extension before the\nserver is allowed to use that extension on a response\" is great principle,\nand one I wish this spec followed.  The spec describes a way for the\nclient to indicate it understands a particular mandatory extension, but it\ndoesn't *require* that the server wait for that indication; it allows\nthe server to send it based on \"a priori\" knowledge.  As I said in\nmy mail to Larry, anything outside of the protocol-defined indication\nis a guess, and if you are going to allow guessing, you have some problems\nto solve that this doesn't solve.  \n\n> <It's a feature!>\n> Absolutely true! Nor is there any implication in the draft that an\n> administrator could do so. In fact I assume our readers are just as smart as\n> you are and will, as you did, figure out that for their firewall to have any\n> chance of parsing the method they MUST parse the mandatory header itself,\n> see if they recognize the extension and if they do then and only then do\n> they have sufficient information to deal with the method. Otherwise the\n> firewall must treat the method as any other method it knows absolutely\n> nothing about. The beauty of mandatory is that this is what a firewall which\n> knows nothing about mandatory, much less the enhanced method, will do with a\n> mandatory request. Everything just works. However a note about this in the\n> security section is probably appropriate.\n> </It's a feature!>\n\nThe document seems to me to imply to security folk \"that if you allow\n'GET' you ought to allow 'M-GET'.  If the authors agree with your\ninterpretation, wordsmithing in the security section might fix the\nproblem.  Other changes in the way the document describes methods\nmight also be needed, but that would be wordsmithing rather than a\ndesign change.\n\n\n> 2) I trust the market a hell of a lot more than I trust some text in a\n> standards document. If people choose to use someone's extension and that\n> person does not properly maintain their extension then people will stop\n> using that extension. No \"MUST\" in a standard can change that one way or\n> another. I think the language is actually quite clear and well written. I\n> disagree that any word smithing is necessary.\n\nWill manufacturers willingly give different URLs to different patch\nreleases of a product, when the URLs are being used as *tokens* in a\nsystem like this?  Remember,\n\"http://www.bigcompany.com/products/foo/v1\" and\n\"http://www.bigcompany.com/products/foo/v2\" are completely different;\nthere is no defined relationship and no way to presume if you do one\nyou can do the other.  Especially, there is no way for a proxy to know\nwhether allowing one through implies *anything* about letting the\nother through.  Hint: I have had systems in which all had the same\nproduct, with the same identifier, but a substantial percentage did\nnot interoperate because of a patch release mis-match.  Trust the\nmarket all you like, but make damn sure that implementors understand\nthe consequences of not doing the right way; \"strongly recommended\"\ndoesn't say \"fail to do this and die horribly, unspeakable rascal\"\nto me, and I suspect it ought to.\n\n\n> <Ohhhhhh Ted..... I love it when your brutal!>\n> Sigh... I have to agree. December is a lousy month to try to perform a\n> review. Half the necessary people are gone and the rest are too busy to deal\n> with it.\n> </Ohhhhhh Ted..... I love it when your brutal!>\n\nHmm, if half the people necessary people are gone, and the rest are too busy,\nthose actually performing the review are...sorry, didn't mean to go there.\n\n> <Nobody here but us Chickens>\n> Ohh goodie... Henrik can commit a double homicide. I just love company. =)\n> </Nobody here but us Chickens>\n\n\n</Yaron, do you dream in XML?>\n\n\nregards,\nTed Hardie\nhardie@equinix.com\n\n\n\n\n\n", "id": "lists-007-7848249"}, {"subject": "RE: Looking for comments on the HTTP Extension draf", "content": "Words from the engineer formerly known as NASA Boy:\n\n> <Yaron, do you dream in XML?>\n\nYes, but only in my nightmares. Do remind me to write up the paper I have\nbeen thinking about on an analysis of XML performance as a protocol\ntransport. Scary reading, I assure you.\n\n> If I'm willing to rev the protocol number, obviously I don't believe\n> that this mechanism must be one which fits in the 1.x framework.  A\n> really good extension mechanism that had to have one incompatible\n> change would be fine by me.  Once this extension mechanism takes\n> off, there will be no more major or minor protocol number changes,\n> only extensions.  One big change to note that shift isn't that hard\n> is it?  It's not as if all of the old clients out there are going\n> to become extension aware anyway.\n> \n\nUsing ISAPI/NSAPI/CGI/Modules/etc we can extend existing servers (and some\nproxies) with all sorts of goodies. My customers are much happier doing such\nextensions then rolling out incompatible upgrades, especially to new\nprotocols their existing infrastructure don't support. This is why HTTP/1.1\nwas such an easy sell. We could piece meal roll it out. You up the major\nversion # and you will find you have a great design with very few customers.\n\n> I think you saw the right problem, but I don't think your demands\n> weren't quite met.  \"a client MUST have somehow expressed to the\n> server that it understands a particular mandatory extension before the\n> server is allowed to use that extension on a response\" is \n> great principle,\n> and one I wish this spec followed.  The spec describes a way for the\n> client to indicate it understands a particular mandatory \n> extension, but it\n> doesn't *require* that the server wait for that indication; it allows\n> the server to send it based on \"a priori\" knowledge.  As I said in\n> my mail to Larry, anything outside of the protocol-defined indication\n> is a guess, and if you are going to allow guessing, you have \n> some problems\n> to solve that this doesn't solve.  \n> \n\nIf someone defines the FOOBAZ method and specifies that anyone using FOOBAZ\nmust support the foobaz extension then the server is well within its rights\nto return a response, at some later point, to the same client that uses the\nfoobaz extension in the mandatory header. We can rewrite the previous\nscenario using a header or even just using a particular transport (if you\nuse the TLS V10.9 encryption transport then your HTTP client MUST\nsupport...).\n\nSo knowing that this isn't an interoperability issue we can do anything\nabout, I suppose I will be happy with whatever language you would like to\nthrow in.\n\n> The document seems to me to imply to security folk \"that if you allow\n> 'GET' you ought to allow 'M-GET'.  If the authors agree with your\n> interpretation, wordsmithing in the security section might fix the\n> problem.  Other changes in the way the document describes methods\n> might also be needed, but that would be wordsmithing rather than a\n> design change.\n> \n\nAgreed.\n\n> Will manufacturers willingly give different URLs to different patch\n> releases of a product, when the URLs are being used as *tokens* in a\n> system like this?  Remember,\n> \"http://www.bigcompany.com/products/foo/v1\" and\n> \"http://www.bigcompany.com/products/foo/v2\" are completely different;\n> there is no defined relationship and no way to presume if you do one\n> you can do the other.  Especially, there is no way for a proxy to know\n> whether allowing one through implies *anything* about letting the\n> other through.  Hint: I have had systems in which all had the same\n> product, with the same identifier, but a substantial percentage did\n> not interoperate because of a patch release mis-match.  Trust the\n> market all you like, but make damn sure that implementors understand\n> the consequences of not doing the right way; \"strongly recommended\"\n> doesn't say \"fail to do this and die horribly, unspeakable rascal\"\n> to me, and I suspect it ought to.\n> \n\nThis is akin to the dll hell problems and believe me, I know it well.\nUnfortunately a standard won't fix this. Still, if you just want to\nwordsmith the language, we might as well. Put in whatever terrible cries of\ndamnation that will make you happy. BUT you can only complain if you come up\nwith alternate language. =)\n\n\nYaron\n\n\n\n", "id": "lists-007-7864848"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "Yaron,\n\nNeedless to say, I don't really want to argue for incompatible\nupgrades.  I do want us to be very, very sure that we balance\nextensibility and interoperability.  My first message and my responses\nsince are my feeble attempts to delineate where I believe this\nproposal runs the risk of sacrificing interoperability, by the use of\ncertain behaviors which are either not current practice in HTTP 1.x or\nnot current expectations for URLs.\n\nRevving the protocol number makes sure everybody knows about the new\nrules.  As I've said before, I don't think it is the only possible way\nto ensure that.  I don't really even think it's the best.  Thinking\nabout it in those terms, though, may be what it takes to get us to the\nright design choices.\n\nOn the issue of \"a priori\" knowledge, this design allows a client to\nsend a vanilla request like:\n\nGET /someresource.foo HTTP/1.1\nHost: www.foobar.nl\nUser-Agent: Diva 98.2\n\nand have the server derive from some information (which URL was\nchosen, the User-Agent, whatever) that the client *could* support an\nextended response.  That \"a priori\" knowledge is based on assumptions\n(that the client has not turned off the capability, that the firewall\nisn't configure to stop that, that the URL wasn't typed in from a\nfriend's bookmarks, whatever).  If those assumptions are wrong, a\nresponse is sent that the client cannot handle properly and may not be\nable to handle at all.  In the extensible world that has been\ndescribed, we have to acknowledge that capabilities change over\ntime--sometimes resulting in the removal of capabilities.  You can't\neven rely on my previously stated support, as I may support FOOBAZ\ntoday and give it up tomorrow when it interferes with my\nmission-critical BARFUZZ extension.  Our lives and the lives of our\ncustomers would be easier if we stuck to the idea you set forth and\nonly used FOOBAZ in a response when the client volunteered that it was\nwilling to use it in the request.\n\nOn the issue of multiple versions behind a single URL, this is,\nindeed, like the dll hell you describe.  If we cannot solve the problem\nin the standard, we can at least point others where that road leads so\nthat they don't take us down it too often.\n\nregards,\nTed Hardie\nhardie@equinix.com\n\n\n\n", "id": "lists-007-7878455"}, {"subject": "RE: Looking for comments on the HTTP Extension draf", "content": "Given that everything you say is motherhood and apple pie there isn't much\nfor me to respond to. You are right, people shouldn't do bad things. You are\nalso right that we should think carefully about what we do. But outside of\nthe issues I have already pointed out, which really haven't been part of\nthis conversation, I haven't heard anything to convince me that this\nstandard is seriously broken. But of course, that is just my opinion.\n\nYaron\n\n> -----Original Message-----\n> From: Ted Hardie [mailto:hardie@equinix.com]\n> Sent: Monday, December 28, 1998 5:46 PM\n> To: Yaron Goland\n> Cc: hardie@equinix.com; frystyk@w3.org; masinter@parc.xerox.com;\n> Chris.Newman@INNOSOFT.COM; discuss@apps.ietf.org; Josh Cohen\n> Subject: Re: Looking for comments on the HTTP Extension draft\n> \n> \n> Yaron,\n> \n> Needless to say, I don't really want to argue for incompatible\n> upgrades.  I do want us to be very, very sure that we balance\n> extensibility and interoperability.  My first message and my responses\n> since are my feeble attempts to delineate where I believe this\n> proposal runs the risk of sacrificing interoperability, by the use of\n> certain behaviors which are either not current practice in HTTP 1.x or\n> not current expectations for URLs.\n> \n> Revving the protocol number makes sure everybody knows about the new\n> rules.  As I've said before, I don't think it is the only possible way\n> to ensure that.  I don't really even think it's the best.  Thinking\n> about it in those terms, though, may be what it takes to get us to the\n> right design choices.\n> \n> On the issue of \"a priori\" knowledge, this design allows a client to\n> send a vanilla request like:\n> \n> GET /someresource.foo HTTP/1.1\n> Host: www.foobar.nl\n> User-Agent: Diva 98.2\n> \n> and have the server derive from some information (which URL was\n> chosen, the User-Agent, whatever) that the client *could* support an\n> extended response.  That \"a priori\" knowledge is based on assumptions\n> (that the client has not turned off the capability, that the firewall\n> isn't configure to stop that, that the URL wasn't typed in from a\n> friend's bookmarks, whatever).  If those assumptions are wrong, a\n> response is sent that the client cannot handle properly and may not be\n> able to handle at all.  In the extensible world that has been\n> described, we have to acknowledge that capabilities change over\n> time--sometimes resulting in the removal of capabilities.  You can't\n> even rely on my previously stated support, as I may support FOOBAZ\n> today and give it up tomorrow when it interferes with my\n> mission-critical BARFUZZ extension.  Our lives and the lives of our\n> customers would be easier if we stuck to the idea you set forth and\n> only used FOOBAZ in a response when the client volunteered that it was\n> willing to use it in the request.\n> \n> On the issue of multiple versions behind a single URL, this is,\n> indeed, like the dll hell you describe.  If we cannot solve \n> the problem\n> in the standard, we can at least point others where that road leads so\n> that they don't take us down it too often.\n> \n> regards,\n> Ted Hardie\n> hardie@equinix.com\n> \n> \n\n\n\n", "id": "lists-007-7889886"}, {"subject": "Re: Looking for comments on the HTTP Extension draf", "content": "At 21:38 23/12/98 -0500, Henrik Frystyk Nielsen wrote:\n\n>At 12:21 12/22/98 -0800, Ted Hardie wrote:\n>>4) The content negotiation implied by the document is also not\n>>workable within the current CONNEG framework, because the set\n>>intersection model CONNEG uses presumes that the resource is intended\n>>for a single purpose; it has no provision for a resource that is a\n>>token, a description, and machine-usable code.  In the current\n>>framework, a device selects among multiple values in a set\n>>intersection by q-value, not purpose.  It can't really select \"one for\n>>this and one for that\" in the same operation.\n>\n>Unless this is different from HTTP then the q values describe the value on\nthe axis and not the dimension of the axis. q values can be applied to any\ndimension be it type or some other property. In fact, the negotiation\nhinted at here only spans the media type.\n\n\n\nIf my understanding of HTTP is correct (and, for the purposes of this\ndistinction, not including TCN), each of the dimensions of variability\n(indicated by Accept:, Accept-charset:, Accept-language:) is presumed to\nindependently variable.  Thus, it makes sense to permit q-values to be\ndetermined independently for each such dimension.\n\nThe 'conneg' framework greatly increases the number of dimensions of\nvariability (through feature registration), and also provides a general\nframework for constraining variations in one dimension with respect to\nvariations in some other dimension(s).  Thus it seems more helpful to apply\nthe q-value unidimensionally to a combination of variable features, rather\nthan independently to each dimension of variability.  TCN [RFC2295] adopts\na similar approach when describing the source quality of a resource, and\navoids allowing a client to indicate quality values associated with feature\ntags.\n\nThe 'conneg' framework does not preclude further development of some more\nfine grained q-value indication, but has not attempted to specify such at\nthis time.\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-7903964"}, {"subject": "Notes from IETF meeting in Minneapoli", "content": "My personal notes from some of the applications area\nmeetings of IETF in Minneapolis in March 1999 can be found\nat: http://www.dsv.su.se/~jpalme/ietf/ietf-march-99-notes.html\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-7959074"}, {"subject": "Choice of coding format for Senior Onlin", "content": "I am involved in an EU-funded project Senior Online\n(http://cmc.dsv.su.se/sol/) which aims at making the\nInternet more suitable for elderly people. As part of this\nproject, we are to develop groupware systems and\nportal/directory systems. We are just now at the stage\nwhere we are to start specifying the protocols to be used\n(a) between two groupware systems, (b) between groupware\nsystems and portal/directory systems.\n\nThe protocols, which we define, may in the future be\nsubmitted as standards proposals in IETF. We will start\nimplementing them based on two groupware systems under\ndevelopment, KOM 2000 (http://cmc.dsv.su.se/KOM2000/) and\nWeb for Groups (http://www.webforus.com/). We are\ninterested in getting other groupware vendors to try our\nprotocols, for example First Class\n(http://www.business.softarc.com/works/index.shtml) and\nLotus Notes/Domino (http://www.lotus.com/).\n\nOne important issue, when starting applications area\nprotocol development, is the choice of coding method. I\nhave written an overview of the alternatives with their\nadvantages and drawbacks. Please give input with comments\non this table and on which choices to recommend.\n\nHere is the overview:\n\n--- --- cut here --- ---\n\nChoice of Coding Format for Senior Online\n=========================================\n\nAn important, and difficult, choice is the selection of coding\nformat and base web protocol for the communication between servers\nin Senior Online. Two major such types of communication are\nenvisaged:\n\n(1) The protocol for communication between groupware servers\n\n(2) The protocol for communication between groupware servers and\nportal servers\n\nHere is a short description of the choices:\n\nCoding format choices:\n---------------------\n\nNote: Some of these formats can be combined. For example, the e-mail\nformats can be used for coding of the actual text of messages,\ncombined with the other formats for other information.\n\nFormat                        Description\n------                        -----------\n\nMIME                          The standard format for complex e-mail messages,\n                              where the body can be split recursively into\n                              multiple body parts.\n\nMFORM = Multipart/formdata    Variant of MIME, one of the formats used, when a\n                              web user fills in a form in a web page and pushes\n                              the SEND button.\n\nMHTML =                       Variant of MIME, the commonly used format for\nMultipart/alternative,        sending HTML-formatted messages via e-mail. Used\nText/html and                 by KOM 2000 when sending\nmessages from KOM 2000 to\nMultipart/related             e-mail. (? Web for Groups probably also uses this\n                              format in communication with e-mail?)\n\nXML                           A currently very popular format, strongly\n                              supported by IBM and Microsoft, for sending\n                              structured information on the Internet. Good for\n                              complex structures, not so good for binary\n                              information (like pictures or attachments)\n\nASN.1                         A complex and powerful binary format, used by\n                              LDAP.\n\nLDAP                          The currently most popular format for\n                              communication with directory systems. Good for\n                              complex structures and for distributed directory\n                              data bases. Uses ASN.1.\n\nLDIF                          A variant of LDAP with\ntextual, instead of binary,\n                              encoding.\n\nRFC822 header format          A simple format common in many protocols,\n                              including e-mail headers and HTTP headers.\n\nCorba                         A \"remote procedure call\" protocol for\n                              communication between program modules on\n                              different servers, written in common\n                              programming languages.\n\nAs an aid in selecting this format, here is a table of choices and\ntheir pros and cons. Question marks indicate that I do not know or\nam not sure.\n\nFormat:       MFORM    MIME      XML      LDAP     LDIF      RFC822   Corba\n------        -----    ----      ---      ----     ----      ------   -----\n\nEasy to       Very     Yes (4)   Yes (4)  Bad (1)  Yes (4)   Very     Yes (4)\nproduce       much                                           much\nmanually and  (5)                                            (5)\ndebug\n\nEase of       OK (3)   OK (3)    OK (3)   Diffi    OK (3)    Easy     Very\ncoding                                    cult               (4)      easy\n                                          (1)                         (5)\n\nPortability   Good     Good      Good     Good     Good      Good     Bad (1)\n              (4)      (4)       (4)      (4)      (4)       (4)\n\nBinary data   Good     Good      No (1)   ? (3)    ? (3)     No (3)   Yes?\n              (4)      (4)                                            (4)\n\nAcceptabi     Good     Good      Very     Very     Good      Good     Bad (1)\nlity as a     (4)      (4)       good     good     (4)       (4)\nfuture                           (5)      (5)\nstandard\n\nEase of       OK (3)   OK (3)    Good     Good     Good      Good     Good?\nspecifica                        (4)      (4)      (4)       (4)      (4)\ntion\n\nTotal score   23       22        21       18       22        25       19\n\nRecommendation: I suggest that we start with the RFC822 header format,\ncombined with MIME for the format of messages.\n\nProtocol format choice:\n----------------------\n\nPossible choices for the protocol (to be extended for our needs):\n\nChoice            SMTP               HTTP               Corba\n\nDescription       The Internet e-    The WWW protocol,  A remote\n                  mail format,       based on direct    procedure call\n                  based on store-    connections,       method, popular\n                  and-forward of     popular as a base  in the telecom\n                  messages.          for new            industry.\n                                     protocols.\n\nAdvantage         Good for sending   Easy to use,       Easy to use.\n                  messages, we have  popular.\n                  to implement it\n                  anyway in order\n                  to handle e-mail\n                  connectivity,\n                  built-in queing\n                  and resending\n                  facility when the\n                  destination\n                  server is down.\n\nDisadvantage      Store and forward  Complex, but you   Limited platform\n                  means that you     can choose a       availability, not\n                  get no direct      subset suitable    acceptable for a\n                  responses to       for your needs.    standard\n                  queries.                              protocol.\n\nRecommendation: I suggest we use HTTP for all communication except\nthe sending of messages. For the sending of messages, I am not sure\nwhether to recommend SMTP or HTTP.\n\nCharacter set format choices\n----------------------------\n\nChoice          ISO Latin 1           Charset                UTF-7, UTF-8\n------          -----------           -------                ------------\n\nDescription     ISO 8859-1            Several, with          UTF-7, UTF-8\n                standard              charset parameter      encodings of\n                                                             Unicode/ISO 10646\n\nAdvantage       Easy to use           The format used\nExpected to be what\n                                      today in web and e-    all computers use\n                                      mail                   in the future, but\n                                                             not yet well\n                                                             supported by all\n                                                             platforms\n\nDisadvantage    Only good for         Difficult to           Some debugging\n                Western European      implement,\nproblems because it\n                languages (not, for   especially for the     is not well\n                example, Polish,      search engine          supported by\n                Hungarian, Cyrillic,                         existing protocol\n                Arabic, Hebrew,                              debugging software\n                Asian languages)                             like telnet and\n                                                             text editors\n\nUTF-7 and UTF-8 are encodings of the future character set standards\nUnivode and ISO 10646. These encodings of Unicode/ISO 10646 are\nespecially suitable for Internet protocols, because all Latin letters\nand digits and some common punctuation characters are the same as in\nASCII. IETF recommends UTF-8. The only advantage with UTF-7 is that\n it can be sent without further encoding in e-mail.\n\nRecommendation: I recommend that we start with the Charset choice,\nbut only using one charset, ISO Latin 1. This can in the future be\nextended to either full Charset or Charset with a choice between\nISO Latin 1 and UTF-7 or UTF-8.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-7966947"}, {"subject": "Re: Choice of coding format for Senior Onlin", "content": "At 18:07 99/04/04 +0200, Jacob Palme wrote:\n\n> Recommendation: I recommend that we start with the Charset choice,\n> but only using one charset, ISO Latin 1. This can in the future be\n> extended to either full Charset or Charset with a choice between\n> ISO Latin 1 and UTF-7 or UTF-8.\n\n\nThis is more or less what HTTP has done. It prooved to be detrimental,\nbecause ISO Latin 1 was used as a default (without explicit \"charset\"\nparamenter) and in various parts of the world, there was a rather low\nincentive to actually implement handling the \"charset\" parameter, or\nadding one where it was needed. As a result, most HTTP trafic, whether\nin ISO Latin 1 or not, is not correctly tagged.\n\n\nRegards,   Martin.\n\n\n#-#-#  Martin J. Du\"rst, World Wide Web Consortium\n#-#-#  mailto:duerst@w3.org   http://www.w3.org\n\n\n\n", "id": "lists-007-7984178"}, {"subject": "Re: Choice of coding format for Senior Onlin", "content": "At 10.33 +0200 99-04-05, Martin J. Duerst wrote:\n> This is more or less what HTTP has done. It prooved to be detrimental,\n> because ISO Latin 1 was used as a default (without explicit \"charset\"\n> paramenter) and in various parts of the world, there was a rather low\n> incentive to actually implement handling the \"charset\" parameter, or\n> adding one where it was needed. As a result, most HTTP trafic, whether\n> in ISO Latin 1 or not, is not correctly tagged.\n\nI think his arguments are rather valid.\n\nIf we start using Unicode/ISO 10646 from the beginning, how much more\ndifficulty will this cause in our development work (we have limited\nresources, being a publicly financed research project, not a\ncommercial software development venture)?\n\nI can see two ways of doing this.\n\nMethod 1: Use ISO Latin 1 internally, and just translate to UTF-8\nbefore we send things using our new protocol, and translate back\nto ISO Latin 1 again the first thing when we get things back.\n\nThis method would not cause much difficulty, just add two translation\nroutines and some reduced CPU efficiency. However, this method\nis a kind of \"fake\" UTF-8, if someone tryes to send real UTF-8,\ncontaining other characters than those in ISO Latin 1 (such\nas for example Hungarian) then our software will not perform correctly.\n\nMethod 2: Really use UTF-8 all the way interally, and send UTF-8\nto the web browsers which people use as clients to Senior Online.\nThis method will only work if all users have web browsers which\nsupport UTF-8.\n\nAnother disadvantage with method 2 is that we will have to\ntranslate to ISO Latin 1 or some other simpler character set,\nwhen we send things via e-mail, since most e-mailers in the\nworld do not support UTF-8 yet.\n\n--- ---\n\nIf we do not use method 1 or 2, and if we start using only\n\"ISO Latin 1\", we should at least employ a charset parameter\nwhich is mandatory, and which does not default to ISO Latin 1.\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-7992976"}, {"subject": "RE: need review for draft-ietf-ldapext-acl-reqts-01.tx", "content": "I've read the LDAP ACLs requirements document, and here are my comments.\n\n\n1.  Things that I like\n----------------------\n\n1.1 \"More specific policies must override less specific ones\".  I absolutely\nagree.\n\n1.2 Support for DENY of rights is required.  I agree this is a MUST.\n\n1.3 Attribute-level and user-level ACLs are required.  I agree, but this\nneeds more definition.  Do attributes get their own ACLs?  if so, can you\nspecify who can set the ACLs on an attribute separately from who can set the\nACLs on the parent?  I suggest that the set of rights that can be\ngranted/denied on an attribute should be more limited than the set of rights\nthat can be granted/denied on an object.\n\n1.4 An administrator must be able to delegate ACL management.  I agree, and\nI suggest that the concept of \"ownership\" should be borrowed from various\nexisting systems.  Briefly:  the person listed in the ACL as the \"owner\" of\nthe object is the person from whom \"write ACL\" right cannot be removed.\n\n1.5 \"Policy resolution MUST NOT depend on the order of ACL entries\"  -- This\nis great; however there must be some way of resolving policy that is\nreproducible across implementations that does not require order.  See 2.1\n\n1.6 Requires support for \"list entries\" right separate from \"read entries\"\nright -- This is also great, but there also needs to be a \"read this item\"\nright that can be applied to an individual attribute.\n\n1.7  Support for anonymous access is required -- Good\n\n2.  Interoperability Problems\n-----------------------------\n\n2.1 Resolving multiple policies that are equally specific\n\nThe requirements draft does NOT require the ACL model to specify how to\nresolve multiple policies of the same specificity. I think that should be a\nrequirement so that interoperability is possible. I hope this is a\nreasonable requirement.  \n\nThe example situation is:   A is a member of 2 groups named in an ACL.  The\n2 groups have different rights (e.g. one is granted \"read\", and the other is\ndenied \"read\" access)\n\nSuggested resoultion:  There should be ONE way to determine A's privileges\nin this case.  I strongly suggest that for stricter security, denies should\noverride grants.\n\n2.2  Forbidding side-effects\n\nI think this is an unreasonable constraint on systems, and could result in\ninteroperability problems because clients may count on no side-effects,\nwhereas server implementors may require side-effects.  Workflow is an area\nwhere there can be all sorts of side-effects:  the server is aware of some\nmodel that must be imposed on all objects that are part of the workflow\nprocess, such that if \"list\" is denied on a container then \"read\" will be\ndenied on all objects in the container.\n\nThe goal is understandable and seductive:  it would be good for the system\nto be predictable.  However, an access control system cannot realistically\nbe 100% predictable.  You can never prevent the super-user from changing the\nrights of an object even when the super-user is not even listed as having\nthe ability to change the rights of the object.\n\n\n3.  Major suggestions\n----------------------\n\n3.1  The draft suggests that naming principals which the directory\nadministrator cannot administer is bad. I don't understand -- why this is a\nproblem?   What if at my site I want to deny read access to any user\naccessing my directory from *.microsoft.com?  (see 3.2).  What if the\ndirectory in question is managed by a different administrator from a site's\nuser administrator? I suggest that the draft remove this restriction.\n\n3.2  The draft discourages use of IP addresses to identify ACL principals.\nWeb sites do this today; it's certainly not perfect, but it's not insecure\nas long as the administrator realizes what it actually does.  I would\nsuggest that the requirements draft remove this restriction.\n\n\n4.  Minor suggestions\n-------------------------\n\n4.1  Draft says:  \"ACL information MUST be an LDAP attribute\" Suggested\nrewording:  \"ACL information MUST be ACCESSIBLE as an LDAP attribute\".  In\ngeneral, the draft document tries to constrain implementations, when it\nshould focus on constraining the protocol to be designed.\n\n4.2  Draft says:  \"Administrators SHOULD be able to administer access to\ndirectories and their attributes based on their sensitivity\" What does\n\"sensitivity\" mean?  It is not defined. Sensitivity should be defined, or\nleft out of the requirements.  I prefer to leave it out of the requirements\nbecause I think it will be a rathole and lead to inconsistencies with other\nACL models and existing systems.  If ACL inheritance is required (which it\nis), then I suggest that setting sensitivity levels is not so important.\n\nSimilarly, the draft requires support for grouping of attributes by similar\nsensitivity.  Same issues.\n\n4.3 The \"all rights\" right and the \"all principals\" principal are pretty\nuseful concepts in ACLs.  It's easy to grant \"all rights\" and then deny some\nindividual rights.\n\n4.4  There should be a \"write ACL\" right and a \"read ACL\" right.\n\nI hope these comments and suggestions are helpful.\n\nLisa Lippert\n\n-----Original Message-----\nFrom: Keith Moore [mailto:moore@cs.utk.edu]\nSent: Friday, March 26, 1999 3:19 PM\nTo: discuss@apps.ietf.org\nCc: moore@cs.utk.edu\nSubject: need review for draft-ietf-ldapext-acl-reqts-01.txt\n\n\nFolks,\n\nThe LDAPEXT working group has submitted a document called\nAccess Control Requirements for LDAP for IESG approval.\nI'd appreciate some review of this document by the extended community.\n\nThe issue is not so much whether we should publish the document\nor whether they've dotted their i's and crossed their t's.\nWhat I want to know is, do people think that these are reasonable \ndesign goals for LDAP ACLs?  \n\nThe reason I'm taking this unusual step is that I'd rather have \ntheir design goals reviewed now, than to question them when the \nprotocol specification goes to Proposed Standard.  In addition \nto this list, I've also asked IESG to recruit security and \noperational experts to review this.\n\nKeith\n\np.s. yes, we should change the title to \"design goals\" rather than \n\"requirements\", and this should be published as Informational rather \nthan Proposed Standard (as it was Last Called).  We will ask for \nthese things to be fixed in the next revision.  But right now we're \nmore concerned with the criteria in the document, and we don't want \nto ask the authors to revise the document to fix the wording  \nbefore we submit it for additional review.\n\n\n\n", "id": "lists-007-8002610"}, {"subject": "RE: need review for draft-ietf-ldapext-acl-reqts-01.tx", "content": ">            S2.  More specific policies must override less specific\n>            ones (e.g. individual user entry in ACL SHOULD take\n>            precedence over group entry) for the evaluation of an\n\nThis is one spot where these requirements disagree with the ACAP (RFC\n2244) model.  The ACAP model makes no specificity distinctions.  However,\nI suspect the distinction in this case is largely aesthetic so I don't\nobject to this.\n\n>             S3.  Multiple policies of equal specificity SHOULD be\n>             combined in some easily-understood way (e.g. union or\n>             intersection).\n\nThis needs to be made more precise (I concur with Lisa Lippert's comment\n2.1).  In the IMAP ACL model (RFC 2086) we tried to be very generic, but\nthe outcome was that it's very hard or impossible to produce a usable GUI.\nBoth the ACAP (RFC 2244) and AFS ACL models are very specific in this\nregard.  They both use \"union of positive rights - union of deny rights\",\nwhich has proved to be very usable in practice.\n\n>            S6.  Access policy SHOULD NOT be expressed in terms of\n>            attributes which are easily forged (e.g. IP addresses).\n\nThis should be changed to \"If access policy is expressed in terms of\nattributes which are easily forged (e.g., IP addresses) the\nbehavior/implications of doing that MUST be documented.\"  So I generally\nagree with Lisa's comment 3.2.\n\nIn combination with a border packet filter, the \"internal IP addresses\"\nconcept is very useful.  When I worked at CMU, it was sufficiently\nuseful that we spent developer time making patches to AFS for this\nfacility.  (A reasonable compromise with S7 is to only allow IP address\nbased restrictions in a named group -- that way IP addresses don't get\ndirectly embedded in directory object ACLs).\n\n>             S8.  It MUST be possible to deny a subject the right to\n>             invoke a directory operation.  The system SHOULD NOT\n>             require a specific implementation of denial (e.g.\n>             explicit denial, implicit denial).\n\nI don't understand the second sentence.  Either deny rights are in the\nmodel or they aren't.  If they're in the model, either they're mandatory,\nor an implementation without them is permitted, but such implementations\ncan't support ACL replication with a system that does support deny rights.\n\n>             S10.  The system MUST be able to support either union\n>             semantics or intersection semantics for aggregate\n>             subjects (not simultaneously).\n\nThis seems gratuitous.  Intersection is very non-intuitive and has little\nvalue, IMHO.  However, if the system is allowed to support both, then an\nACL MUST have a label as to which is to be used in order to have\ninteroperability. \n\n>             S12.  ACL policy resolution MUST NOT depend on the order\n>             of entries in the ACL.\n\nI have no objection to this requirement, but I will note that one possibly\nunintended side-effect is that native NT ACLs can't be used on a system\nwith both DENY rights and this restriction. \n\n>             S13.  Rights management MUST have no side effects.\n\nContrary to Lisa's comment 2.2, I think this is an excellent idea.  In the\nIMAP ACL model we tried to allow rights to be \"tied\".  This just made\nthings too complex for client authors to do a GUI.  The ACAP model does\nnot allow rights to be \"tied\". \n\n>             U2.  Subjects MUST be drawn from the \"natural\" LDAP\n>             namespace; they should be DNs.\n\nI disagree _very_ strongly.  If at all possible ACLs should use the same\nidentifiers used to log into the directory (which may or may not be DNs). \nDNs are generally not suitable for presentation to humans. I'd change this\nto: \n\n  U2.  If subjects are DNs, there MUST be a defined mapping to\n  a human readable format (e.g., user@realm).  If subjects are not DNs,\n  there MUST be a defined mapping to DNs.\n\n>             U5.  Administrators SHOULD be able to administer access\n>             to directories and their attributes based on their\n>             sensitivity, without having to understand the semantics\n>             of individual schema elements and their attributes (see\n\nI don't know what this means.  I concur with Lisa's comment 4.2.\n\nI'd also mention that the white pages application, a primary application\nfor directories, has a very interesting requirement which I didn't see\nlisted:\n\n * It MUST be possible to allow a user to modify some attributes of their\n own white pages entry, while retaining administrative control over other\n attributes.  It SHOULD be possible to express this in an ACL which\n applies to all entries within a subtree.\n\n\n\nIn general, the spec seems fairly good and is quite closely aligned with\nwhat ACAP did.  I particularly like the goals of usability and simplicity\nas this will hopefully prevent ludicrous models like the Posix ACL model.\n\n- Chris\n\n\n\n", "id": "lists-007-8017665"}, {"subject": "IETF VPIM Mailing Lis", "content": "FYI,\n\nA new mailing list has been set up for the IETF VPIM BOF/WG.\n\nPosting address vpim@lists.neystadt.org\nTo subscribe send \"subscribe\" in the body of message to\nmajordomo@lists.neystadt.org. To leave send \"unsubscribe\" \nMajordomo archives all the mail. To learn how to retrieve archive send\n\"help\" to majordomo@lists.neystadt.org. \n\nVPIM (Voice Profile for Internet Mail) is a profile of Internet Mail\nstandards intended for use between voice mail systems.  VPIM v2 is defined\nin RFC 2421.  The group is being chartered to advance VPIM v2 on the IETF\nstandards track and to design a VPIM v3 that is more compatible with desktop\nand unified messaging systems as well as voice mail systems.\n\nInteroperability testing, deployment trials, directory issues and\nconformance are currently worked on in the EMA, as well as the VMA & TMIA.\n\nMore information can be found on the VPIM web site at:\nhttp://www.ema.org/vpim\n\nCheers,\nGlenn.\n\n\n\n", "id": "lists-007-8053575"}, {"subject": "An Inventory of Functions in Forum softwar", "content": "I have written a short paper with the title \"An Inventory of \nFunctions in Forum software\". You can find it at: \nhttp://cmc.dsv.su.se/kom/forum-function-inventory.html\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-8063099"}, {"subject": "Re: Lawsuit (this is unsolicited email", "content": "Would you please be a witness in the \nclass action suit against www. syndicate. \nDetails at http://NewAmerica.org/\n=========================================\nPs:You don't need to request to be REMOVE.\nAfter this mailing, your email address will\nautomatically be deleted from our list.\n\nHowever,your might be receiving more email,\nif your address is posted in many places \non the Internet,because we are extracting \nemail addresses directly from search engines.\nTo avoid receiving any unsolicited email,\nrequest your ISP to make your email address \nunlisted (same way as a phone company does).\n\nIs unsolicited email legal? Yes,it is.\nThe sending of unsolicited email is perfectly \nlegal. See the rules at  http://NewAmerica.org/\n===========================================\nNCAE ALERT send via \nNCAE(National Consumer Alert Email)\nOn Sunday August/8/1999 - AOL shut down without \nwarning, the account of Anthony Costanza\nfrom California, saying \"we have shut you down,\nbecause your friend is sending spam.\"\nAnthony asked can you give me proof? \nThe AOL answer \" Write us a letter.\"\n\nAt this point Anthony has been proscuted without \na trial.Guilty till proven innocent. He has lost \nhis business contacts which he accumulated for \nthree years, while having his account with AOL.\n\nHow can AOL get-a-way with committing such \ncrimes of destroying small businesses and \npeople.Is this the American way? Guess what AOL, \nyou just joined the www. syndicate suit. \nThis is the American way!\n\nThank You\nNU@NewAmerica.org\n\n\n\n\n \n \n \n \n \n \n \n \n \n \n\n\n\n", "id": "lists-007-8070456"}, {"subject": "PERSONAL POSTCARDS - PART TIME BUSINESS - FULL TIME INCOME", "content": "text/html attachment: stored\n\n\n\n\n", "id": "lists-007-8078623"}, {"subject": "RE: HTTP Extensions Framework status", "content": "On Tue, 30 Nov 1999, Scott Lawrence wrote:\n\n> > From: mpresler@us.ibm.com\n> > Subject: HTTP Extensions Framework status?\n> \n> >      I saw that a new draft was issued in March, but that's\n> > expired, and I\n> > can't find anything further. Can anyone enlighten me as to\n> > the status of\n> > this work?\n> \n> We've been trying to get it published as an RFC.\n\nOne data point: I asked Keith Moore about the status at WWW8 (May this\nyear), he told me that they were thinking about it, but it did not sound\nlike anything would happen soon.\n \n> So far, there has been support within the IESG for making it an\n> Experimental, but that would make it a no-no to reference in\n> standards-track documents.  Since there are a number of things that\n> would like to use it and go to standards-track, we are trying to get\n> that changed.\n\nI guess I should mention here that I am one of the main proponents of\nmaking it experimental only, at least until we have more experience etc,\nand I have told the IESG so. I'm not convinced that using the -ext-\nframework is superior to just defining some new methods/headers.\n\nKoen.\n\n\n\n", "id": "lists-007-8107881"}, {"subject": "Re: HTTP Extensions Framework status", "content": "It's been approved by IESG (at the last IESG teleconference)\nfor publication as Experimental.\n\nKeith\n\n\n\n", "id": "lists-007-8119364"}, {"subject": "RE: HTTP Extensions Framework status", "content": "     My first motivation for asking was because P3P\n(http://www.w3.org/P3P/) is making use of the HTTP extensions framework -\nP3P messages may be added to responses as optional extensions (using Opt:),\nand I wanted to see if the extensions framework was going forward to be\nstandardized any time soon.\n\n     My other question is what other protocols/applications have been\ninterested in using the HTTP extensions framework? I have been considering\nwhat it'd take to add P3P support to Apache, and this led me down to the\nidea of implementing the HTTP extensions framework as an Apache module, but\nthere's little point if there aren't any users expected any time soon.\n\n     Thanks,\n\n     Martin\n\nMartin Presler-Marshall - P3P Champion\nE-mail: mpresler@us.ibm.com\nPhone: (919) 254-7819 (tie-line 444-7819) Fax: (919) 543-4118 (tie-line\n441-4118)\n\n\n\n", "id": "lists-007-8127468"}, {"subject": "RE: HTTP Extensions Framework status", "content": "> From: moore@cs.utk.edu\n\n> It's been approved by IESG (at the last IESG teleconference)\n> for publication as Experimental.\n\nWill we get a note from the IESG explaining why Experimental and what\nwould be needed to move it to standards track?  There are some efforts\nthat hope to be standards track that have been planning to use and\nreference it; this will create a problem for them.\n\n--\nScott Lawrence           Director of R & D        <lawrence@agranat.com>\nAgranat Systems, Inc.  Embedded Web Technology   http://www.agranat.com/\n\n\n\n", "id": "lists-007-8135546"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> Will we get a note from the IESG explaining why Experimental and what\n> would be needed to move it to standards track?\n\nThe document did not have enough community support for standards-track.\n\nKeith\n\n\n\n", "id": "lists-007-8144328"}, {"subject": "RE: HTTP Extensions Framework status", "content": "SSDP (http://search.ietf.org/internet-drafts/draft-cai-ssdp-v1-03.txt) and\nSOAP (http://search.ietf.org/internet-drafts/draft-box-http-soap-00.txt)\nboth use it.\n\nMaking MAN experimental is just silly. Man has been implemented, deployed\nand tested. We know it works.\n\nFor example, Microsoft will be shipping Man as part of SSDP in our next Win\n9x release (code name: Millennium).\n\nMan is a done deal. Not only is the spec fully baked, many other specs\nalready depend on it.\n\nRunning code and rough consensus at its best...\n\nYaron\n\n> -----Original Message-----\n> From: mpresler@us.ibm.com [mailto:mpresler@us.ibm.com]\n> Sent: Wed, December 01, 1999 5:56 AM\n> To: discuss@apps.ietf.org\n> Subject: RE: HTTP Extensions Framework status?\n> \n> \n> \n> \n>      My first motivation for asking was because P3P\n> (http://www.w3.org/P3P/) is making use of the HTTP extensions \n> framework -\n> P3P messages may be added to responses as optional extensions \n> (using Opt:),\n> and I wanted to see if the extensions framework was going \n> forward to be\n> standardized any time soon.\n> \n>      My other question is what other protocols/applications have been\n> interested in using the HTTP extensions framework? I have \n> been considering\n> what it'd take to add P3P support to Apache, and this led me \n> down to the\n> idea of implementing the HTTP extensions framework as an \n> Apache module, but\n> there's little point if there aren't any users expected any time soon.\n> \n>      Thanks,\n> \n>      Martin\n> \n> Martin Presler-Marshall - P3P Champion\n> E-mail: mpresler@us.ibm.com\n> Phone: (919) 254-7819 (tie-line 444-7819) Fax: (919) 543-4118 \n> (tie-line\n> 441-4118)\n> \n\n\n\n", "id": "lists-007-8152284"}, {"subject": "Re: HTTP Extensions Framework status", "content": "The most important thing is to get an RFC number attached to it because\npeople think that the current draft has expired.\n\nIt is also important to note that there are no public outstanding\ntechnical issues with the current spec nor have there to my knowledge been\nsince March where it was sent to last call for proposed. I hope that this\nwill be made clear in the status note of the document.\n\nThe term \"community support\" is inherently hard to define - especially as\nthere was no working group chartered. I agree with Scott that there may be\ndependency problems with standard track specs using it but as I understand\nthe process, it is possible to change the status from experimental to\nproposed without chartering a wg. Keith, can you please confirm this?\n\nHenrik Frystyk Nielsen,\nmailto:frystyk@microsoft.com\n\n----- Original Message -----\nFrom: \"Keith Moore\" <moore@cs.utk.edu>\nTo: \"Scott Lawrence\" <lawrence@agranat.com>\nCc: <moore@cs.utk.edu>; <discuss@apps.ietf.org>\nSent: Wednesday 01 December, 1999 14:35\nSubject: Re: HTTP Extensions Framework status?\n\n\n> > Will we get a note from the IESG explaining why Experimental and what\n> > would be needed to move it to standards track?\n>\n> The document did not have enough community support for standards-track.\n>\n> Keith\n>\n\n\n\n", "id": "lists-007-8163433"}, {"subject": "Re: HTTP Extensions Framework status", "content": ">  it is possible to change the status from experimental to\n> proposed without chartering a wg. Keith, can you please confirm this?\n\nyes, this is possible within the process.  but basically you face\nthe same hurdle - which is to convince the community to endorse\nthis as the proper way to extend HTTP.\n\nKeith\n\n\n\n", "id": "lists-007-8174453"}, {"subject": "RE: HTTP Extensions Framework status", "content": "At 09:13 01.12.99 -0500, Scott Lawrence wrote:\n> > From: moore@cs.utk.edu\n>\n> > It's been approved by IESG (at the last IESG teleconference)\n> > for publication as Experimental.\n>\n>Will we get a note from the IESG explaining why Experimental and what\n>would be needed to move it to standards track?  There are some efforts\n>that hope to be standards track that have been planning to use and\n>reference it; this will create a problem for them.\nStandard Operating Procedure for features that we're uncertain about the \nvalue of is that we issue them as Experimental so that people can \nexperiment with them from a stable reference, and when someone needs it for \nsomething we all agree should go standards-track, it is reissued as Proposed.\n\nHappening with DNS SRV records, for instance.\nOr (for those with long memories) to the X.400/SMTP gateway specs.\n\n                Harald\n\n--\nHarald Tveit Alvestrand, EDB Maxware, Norway\nHarald.Alvestrand@edb.maxware.no\n\n\n\n", "id": "lists-007-8182484"}, {"subject": "Re: HTTP Extensions Framework status", "content": "Certainly. It hasn't made it through the RFC machinery yet but is\navailable as a draft:\n\n\nhttp://www.ietf.org/internet-drafts/draft-frystyk-http-extensions-03.txt\n\nwhich despite the \"Expires: Sep 15 1999\" in the header hasn't expired as\nthe draft has been through last call.\n\nHenrik Frystyk Nielsen,\nmailto:frystyk@microsoft.com\n\n----- Original Message -----\nFrom: \"Jacob Palme\" <jpalme@dsv.su.se>\nTo: \"Henrik Frystyk Nielsen\" <frystyk@microsoft.com>\nSent: Monday, December 06, 1999 09:33\nSubject: Re: HTTP Extensions Framework status?\n\n\n> Where can I find this document. Everybody is writing about\n> it, but no one says where it is (now, not in the future\n> when it gets published as an RFC). Possibly you should\n> answer this question to the whole list, there may be other\n> people than me with the same need.\n\n\n\n", "id": "lists-007-8191685"}, {"subject": "RE: HTTP Extensions Framework status", "content": "The IETF has lots of problems with apps. The number of working groups has\nover whelmed the IETF apparatus, both the IESG and the ADs have been\noverloaded. Maybe it is time that we declare that apps are just too big and\ntoo complicated for the IETF architecture. Maybe it's time that Apps leaves\nthe IETF and forms its own organization.\n\nEventually the kids have to grow up and move on, maybe that time has come\nfor apps.\n\nJust a thought,\nYaron\n\n> -----Original Message-----\n> From: Harald Tveit Alvestrand [mailto:Harald@Alvestrand.no]\n> Sent: Mon, December 06, 1999 1:30 AM\n> To: Scott Lawrence; moore@cs.utk.edu\n> Cc: discuss@apps.ietf.org\n> Subject: RE: HTTP Extensions Framework status? \n> \n> \n> At 09:13 01.12.99 -0500, Scott Lawrence wrote:\n> > > From: moore@cs.utk.edu\n> >\n> > > It's been approved by IESG (at the last IESG teleconference)\n> > > for publication as Experimental.\n> >\n> >Will we get a note from the IESG explaining why Experimental and what\n> >would be needed to move it to standards track?  There are \n> some efforts\n> >that hope to be standards track that have been planning to use and\n> >reference it; this will create a problem for them.\n> Standard Operating Procedure for features that we're \n> uncertain about the \n> value of is that we issue them as Experimental so that people can \n> experiment with them from a stable reference, and when \n> someone needs it for \n> something we all agree should go standards-track, it is \n> reissued as Proposed.\n> \n> Happening with DNS SRV records, for instance.\n> Or (for those with long memories) to the X.400/SMTP gateway specs.\n> \n>                 Harald\n> \n> --\n> Harald Tveit Alvestrand, EDB Maxware, Norway\n> Harald.Alvestrand@edb.maxware.no\n> \n\n\n\n", "id": "lists-007-8200968"}, {"subject": "RE: HTTP Extensions Framework status", "content": "-----Original Message-----\nFrom: Yaron Goland (Exchange) [mailto:yarong@Exchange.Microsoft.com]\nSent: Monday, December 06, 1999 11:27 AM\nTo: 'Harald Tveit Alvestrand'; Scott Lawrence; moore@cs.utk.edu;\ndiscuss@apps.ietf.org\nCc: Josh Cohen (Exchange); Peter Ford (Exchange)\nSubject: RE: HTTP Extensions Framework status? \n\n\n\nThe IETF has lots of problems with apps. The number of working groups has\nover whelmed the IETF apparatus, both the IESG and the ADs have been\noverloaded. Maybe it is time that we declare that apps are just too big and\ntoo complicated for the IETF architecture. Maybe it's time that Apps leaves\nthe IETF and forms its own organization.\n\nEventually the kids have to grow up and move on, maybe that time has come\nfor apps. \n\n                Just a thought, \n                                Yaron \n\n \n\nNot such a farfetched idea. If you can split up Microsoft, you ought to be\nable to split up the IETF as well..\n\n                Just a thought,\n\n                Carl-Uno      \n\n\n\n", "id": "lists-007-8213733"}, {"subject": "RE: HTTP Extensions Framework status", "content": "--On 99-12-06 11.26 -0800 \"Yaron Goland (Exchange)\"\n<yarong@Exchange.Microsoft.com> wrote:\n\n> Maybe it's time that Apps leaves\n> the IETF and forms its own organization.\n\nThis has been discussed a number of times, and every time the answer that\ncomes back states that having meetings at the same time (i.e. at the same\nIETF meetings) is a good thing. It has also been discussed whether the\nvarious areas should be meeting at different dates, and the answer to that\nquestions has also been the same. Take for example the MMMS or iDNS BOF or\nthe IMPP effort which all depend on interest from more areas than APPS.\n\nThe problem we have in apps is that we have too many things on the table,\nand you point that out in your mail. Too many things are \"almost done\" and\nthat take 100% of the energy we all have.\n\nI hope that the ADs with help from wg's can clean the table substantially\nthis winter, but if things are not better at the winter -00 IETF, I am\nhappy to discuss this problem again.\n\n    Patrik\n\n\n\n", "id": "lists-007-8225100"}, {"subject": "RE: HTTP Extensions Framework status", "content": "> This has been discussed a number of times, and every time the answer that\n> comes back states that having meetings at the same time (i.e. at the same\n> IETF meetings) is a good thing. It has also been discussed whether the\n> various areas should be meeting at different dates, and the answer to that\n> questions has also been the same. Take for example the MMMS or iDNS BOF or\n> the IMPP effort which all depend on interest from more areas than APPS.\n\nMuch as I'd like for such an approach to be workable, I am in complete\nagreement with Patrik about this. Indeed, we already have quite a bit of\ndifficulty with cross-area coordination, and I anticipate that this will be\neven harder to do in the future. A separate meeting would drastically reduce\nour ability for multiple area review, and that would be a very bad thing.\n\n> The problem we have in apps is that we have too many things on the table,\n> and you point that out in your mail. Too many things are \"almost done\" and\n> that take 100% of the energy we all have.\n\nExactly. What we need to do is to work really, really hard on getting all the\nnearly done work DONE. And I'm not talking about the ADs here, I'm talking\nabout everyone else who hasn't completed a revision of a draft, who hasn't\nsent in those comments, or whatever.\n\nNed\n\n\n\n", "id": "lists-007-8235276"}, {"subject": "RE: HTTP Extensions Framework status", "content": "I think there is a more fundamental problem, the bar for reaching proposed\nstandard for an APP draft must be different than the bar for a transport\ndraft.\n\nChanging DNS is a serious thing that effects the fundamental architecture of\nthe Internet. As such it is something to be done very carefully.\n\nChanging IP is even more scary and thus requires even more effort.\n\nApp protocols, these days at least, have a shelf life measured in minutes.\nIDs are moving so quickly from first draft to deployed implementation that\nthe application community is forced to come up with its own rules as to when\nsomething is done. Now a days a draft is considered fair game as soon as it\npasses working group last call. The rest of the process is considered\nirrelevant.\n\nThis is not a workable long term solution as the draft can still be changed\nby the IESG even after surviving working group last call.\n\nHence app types need a faster system which, once consensus has been reached\nin the working group, quickly ensures that the draft is frozen. There are no\n\"experimental\" app protocols and no IETF/IESG last call. If all the members\nof the working group buy off then you have something that will be\nimplemented. That is the process the apps world needs. That isn't the IETF\nprocess. \n\nAs I see it we have three choices:\n\n1) Invent a new status above ID but below RFC that let's app developers know\nthey have a frozen draft they can develop off of but one that hasn't met all\nthe IETF quality bars.\n\n2) Change the RFC process for APPs to lower the bar to working group\nconsensus.\n\n3) Form a new, separate, standards group specifically for application\nprotocols.\n\nYaron\n\n> -----Original Message-----\n> From: Patrik F?ltstr?m [mailto:paf@swip.net]\n> Sent: Mon, December 06, 1999 7:22 PM\n> To: Yaron Goland (Exchange); 'Harald Tveit Alvestrand'; Scott \n> Lawrence;\n> moore@cs.utk.edu; discuss@apps.ietf.org\n> Cc: Josh Cohen (Exchange); Peter Ford (Exchange)\n> Subject: RE: HTTP Extensions Framework status? \n> \n> \n> --On 99-12-06 11.26 -0800 \"Yaron Goland (Exchange)\"\n> <yarong@Exchange.Microsoft.com> wrote:\n> \n> > Maybe it's time that Apps leaves\n> > the IETF and forms its own organization.\n> \n> This has been discussed a number of times, and every time the \n> answer that\n> comes back states that having meetings at the same time (i.e. \n> at the same\n> IETF meetings) is a good thing. It has also been discussed whether the\n> various areas should be meeting at different dates, and the \n> answer to that\n> questions has also been the same. Take for example the MMMS \n> or iDNS BOF or\n> the IMPP effort which all depend on interest from more areas \n> than APPS.\n> \n> The problem we have in apps is that we have too many things \n> on the table,\n> and you point that out in your mail. Too many things are \n> \"almost done\" and\n> that take 100% of the energy we all have.\n> \n> I hope that the ADs with help from wg's can clean the table \n> substantially\n> this winter, but if things are not better at the winter -00 IETF, I am\n> happy to discuss this problem again.\n> \n>     Patrik\n> \n> \n> \n\n\n\n", "id": "lists-007-8245447"}, {"subject": "RE: HTTP Extensions Framework status", "content": "At 22:21 06.12.99 -0800, Yaron Goland (Exchange) wrote:\n\n>I think there is a more fundamental problem, the bar for reaching proposed \n>standard for an APP draft must be different than the bar for a transport draft.\n\nNope.\nThe difference is between affecting the infrastructure and affecting only \nitself - the bar for routing protocols is SIGNIFICANTLY higher than the bar \nfor almost anything else, but there should be no higher bar for Service \nLocation or IP-over-vertical-blanking-interval than there should be for \nIMPP or IPP.\n\n\n>Changing DNS is a serious thing that effects the fundamental architecture \n>of the Internet. As such it is something to be done very carefully.\n>\n>Changing IP is even more scary and thus requires even more effort.\n>\n>App protocols, these days at least, have a shelf life measured in minutes. \n>IDs are moving so quickly from first draft to deployed implementation that \n>the application community is forced to come up with its own rules as to \n>when something is done. Now a days a draft is considered fair game as soon \n>as it passes working group last call. The rest of the process is \n>considered irrelevant.\n\nThat's the same process as in all other IETF groups - see PPP, MLPS, \nDiffServ. Often they don't wait for WG Last Call before shipping sillicon \neither.\nAnd sometimes the predictable disasters result.\n\n\n>This is not a workable long term solution as the draft can still be \n>changed by the IESG even after surviving working group last call.\n>\n>Hence app types need a faster system which, once consensus has been \n>reached in the working group, quickly ensures that the draft is frozen. \n>There are no \"experimental\" app protocols and no IETF/IESG last call. If \n>all the members of the working group buy off then you have something that \n>will be implemented. That is the process the apps world needs. That isn't \n>the IETF process.\n>\n>As I see it we have three choices:\n>\n>1) Invent a new status above ID but below RFC that let's app developers \n>know they have a frozen draft they can develop off of but one that hasn't \n>met all the IETF quality bars.\n\nWe've got one. It's called EXPERIMENTAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n\n>2) Change the RFC process for APPs to lower the bar to working group \n>consensus.\n\nThat would mean starting to ship Proposed Standard RFCs that a significant \nportion of a WG objects to. Do you really think that's good?\n\n\n>3) Form a new, separate, standards group specifically for application \n>protocols.\n\nFeel free to start one. The IETF process rules have a very flexible \nlicensing scheme. The W3C, the DMTF, the WAP forum and a dozen others are \nalready trying, too.\nAnd, as we saw with HTML, separating those concerns from those things that \nconcern the network deeply can in fact improve the attention it's possible \nto give to those things, to all our benefit.\n\nThe unique things about the IETF as a protocol forum are:\n\n- It works (however badly)\n- It has a certain reputation\n- It has contact with a large number of networking experts\n\nIf all the things that didn't need all these criteria were done elsewhere, \nthe IETF workload would be smaller.\n\n                      Harald A\n\n\n\n--\nHarald Tveit Alvestrand, EDB Maxware, Norway\nHarald.Alvestrand@edb.maxware.no\n\n\n\n", "id": "lists-007-8259962"}, {"subject": "RE: HTTP Extensions Framework status", "content": "> -----Original Message-----\n> From: Harald Tveit Alvestrand [mailto:Harald@Alvestrand.no]\n> Sent: Tuesday, December 07, 1999 6:34 PM\n> To: Yaron Goland (Exchange); 'Patrik F?ltstr?m'; Yaron Goland\n> (Exchange); Scott Lawrence; moore@cs.utk.edu; discuss@apps.ietf.org\n> Cc: Josh Cohen (Exchange); Peter Ford (Exchange)\n> Subject: RE: HTTP Extensions Framework status? \n> \nFirst, Im not in favor of a separate body, yet.\nI beleive that there can be progress made in IETF process\nto allow APPS what it needs..\n\n>\n> >1) Invent a new status above ID but below RFC that let's app \n> developers \n> >know they have a frozen draft they can develop off of but \n> one that hasn't \n> >met all the IETF quality bars.\n> \n> We've got one. It's called EXPERIMENTAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n>\nWell, its no good if a standards track document cant reference it.\nFollowing that, one might say then that effort should be experimental\nas well.  This isnt a bad thing, necessarily.  I think there is\njust a stigma about experimental that prevents it from being\nappealing to the community.\nIt would help if the IAB could paint a nicer picture of it,\nperhaps as \"short term standard\".   Whatever it is, we need\nto imply that the standard in question ( experimental) has\nthe agreement of the interested vendors/parties, is likely\nto proceed to \"standards track\", and is something that\nthe community should invest in.   Today, the common view \nof experimental, IMHO, is \"this is never going to go anywhere,\nbut you can go play with this freak of nature of you want, just\ndont have any expectations of it being around in the future\".\n\nMaybe all APPS standards should have experimental, or an\nequivalent, as a necessary first step in getting to standards\ntrack proposed.\n \n> \n> >2) Change the RFC process for APPs to lower the bar to working group \n> >consensus.\n> \n> That would mean starting to ship Proposed Standard RFCs that \n> a significant \n> portion of a WG objects to. Do you really think that's good?\n> \n> \nMaybe in the early stages it would be wise to have the IETF\nmake two standards for a given area, perhaps as \"quasi-experimental\".\nThis way the market can decide, and when it does, it wont be\na choice of \"the IETF approved standard, or the other one\".\nPeople should build products, standards, and such due to\nthe usefulness and market acceptability of a protocol, not\nbecause one is \"IETF sanctioned\".\n\n> \n> --\n> Harald Tveit Alvestrand, EDB Maxware, Norway\n> Harald.Alvestrand@edb.maxware.no\n> \n\n\n\n", "id": "lists-007-8273157"}, {"subject": "RE: HTTP Extensions Framework status", "content": "At 08.33 +0100 99-12-07, Harald Tveit Alvestrand wrote:\n>>3) Form a new, separate, standards group specifically for application\n>>protocols.\n>\n> Feel free to start one. The IETF process rules have a very flexible\n> licensing scheme. The W3C, the DMTF, the WAP forum and a dozen others are\n> already trying, too.\n\nThis would make it much more difficult for people in Europe to follow\nwhat is happening.\n\n> And, as we saw with HTML, separating those concerns from those things that\n> concern the network deeply can in fact improve the attention it's possible\n> to give to those things, to all our benefit.\n\nFor me, the openness of the IETF process is very important, compared\nto the closedness of W3C work.\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-8286764"}, {"subject": "IETF split? (was: HTTP Extensions Framework  status?", "content": "At 04.22 +0100 99-12-07, Patrik F?ltstr?m wrote:\n> This has been discussed a number of times, and every time the answer that\n> comes back states that having meetings at the same time (i.e. at the same\n> IETF meetings) is a good thing. It has also been discussed whether the\n> various areas should be meeting at different dates, and the answer to that\n> questions has also been the same. Take for example the MMMS or iDNS BOF or\n> the IMPP effort which all depend on interest from more areas than APPS.\n\nMy suggestion is that APPS have their meeting one week and\nall other IETF groups the next week. People can then stay\nfor two weeks if they want to cover both areas, which I\nexpect IESG members will do, but the load on the single\nweeks will be less.\n\nSome topics which are of special interest to both APPS \nand other areas could be scheduled for the weekend\nbetween APPS and the rest, or the Friday the first\nweek or the Monday the next week.\n\nThis proposal might actually increase cross-fertilization,\nbecause with the present scheme, very few people have time\nto go to working groups within both APPS and the other\nareas!\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-8294903"}, {"subject": "Re: HTTP Extensions Framework status", "content": "At 17.35 -0500 99-12-01, Keith Moore wrote:\n> The document did not have enough community support for standards-track.\n\nThe way I remember it, this proposal was not accepted because\npeople wanted something more general-purpose, which was to\nbe developed by applecore group. But that group has gone\nto sleep, so we should reconsider\nhttp://www.ietf.org/internet-drafts/draft-frystyk-http-extensions-03.txt\ninto the standards track.\n\nI have read through the proposal once again. The think I react\nto (may be because I did not understand) is the requirement\nto base new applications on HTTP/1.1. It should at least\nbe allowed for new applications to use a subset of HTTP/1.1,\nand to specify which subset they are using.\n\nThe full HTTP/1.1 is much more than what many new applications,\nbuilt on top of HTTP, need.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-8304021"}, {"subject": "Re: HTTP Extensions Framework status", "content": "[I feel compelled to point out at the outset that none of the discussoin\nbelow has anything to do with the HTTP Extensions Framework document -\n(a) this was an indivdual submission, not an HTTP working group document, \nand (b) the document received mixed reviews both within the HTTP WG\nand during Last Call, which is why it was not approved as Proposed.]\n\n> I think there is a more fundamental problem, the bar for reaching proposed\n> standard for an APP draft must be different than the bar for a transport\n> draft.\n\nIn a sense, the bars *are* different - the criteria are generally the \nsame regardless of area but things that seem to have the potential to \nhave a disruptive effect on the infrastructure are scruitinized \nmore closely, and IESG has the power to declare those Pxperimental\neven if they otherwise meet the requirement for Proposed.\n\n> App protocols, these days at least, have a shelf life measured in minutes.\n> IDs are moving so quickly from first draft to deployed implementation that\n> the application community is forced to come up with its own rules as to when\n> something is done. Now a days a draft is considered fair game as soon as it\n> passes working group last call. The rest of the process is considered\n> irrelevant.\n\nPeople can ship code whenever they want - there's nothing IETF could \ndo to stop them - but that doesn't mean that IETF should rubber stamp\nthe output of a working group.  One of the biggest problems in\nInternet protocol development these days is the tendency for groups to\nwork at cross purposes to one another.  So just because something gets\npast one working group doesn't mean that there aren't problems with it.\nIdeally, of course, we identify those problems well before the working \ngroup thinks it's done with a document.  \n\n> This is not a workable long term solution as the draft can still be changed\n> by the IESG even after surviving working group last call.\n> \n> Hence app types need a faster system which, once consensus has been reached\n> in the working group, quickly ensures that the draft is frozen. There are no\n> \"experimental\" app protocols and no IETF/IESG last call. If all the members\n> of the working group buy off then you have something that will be\n> implemented. That is the process the apps world needs. That isn't the IETF\n> process.\n\nWhat you are saying is that there's no need for independent review of a \ngroup's work.  I've seen too many groups go completely off into the weeds, \nor produce documents full of technical errors and/or security holes, to \nbelieve that.  It is unfortuntely the case that working grups often \nreach consensus due to exhaustion rather than because the work is complete;\nwhen that happens, someone outside the working group - whether it be \nsomeone responding to the Last Call or an IESG member -  needs to call them \non things that are broken.  And when groups threaten to work at cross \npurposes with one another, there needs to be a mechanism to push back on \nthose groups to get them to work together.  This wouldn't happen if there \nwere no IETF-wide Last Call and IESG review.\n\nAs it is, IESG feels tremendous pressure to approve any document that\ncomes out of a working group - or at least, to find a way to let it\nbe approved without making major changes to the document (and \nwithout making changes to the protocol if it is deployed).  IESG members\noften feel that they cannot push back much on WG documents even when\nthey are of really dubious quality, especially when a WG is so tired\nand non-functional that it's unlikely to be able to make useful changes\nin finite time.  So IESG members often try to content themselves with \ndisclaimer language even when they have serious technical concerns about \nthe protocol or the quality of the document.  Relabelling a working group \ndocument as Experimental is something IESG does only very rarely - probably \nless than once a year for the entire IETF and its O(100) working groups.\n\n> As I see it we have three choices:\n> \n> 1) Invent a new status above ID but below RFC that let's app developers know\n> they have a frozen draft they can develop off of but one that hasn't met all\n> the IETF quality bars.\n\nExperimental already exists for this purpose.\n \n> 2) Change the RFC process for APPs to lower the bar to working group\n> consensus.\n\nas explained above, that's a really bad idea.\n \n> 3) Form a new, separate, standards group specifically for application\n> protocols.\n\nfolks do this all the time.\n\nLook, IETF has a good reputation at least partially because its protocols\nwork well and have a high liklihood of being deployable.  The IETF process\nis geared toward upholding protocol quality and making sure that things\nwork together.  External review and oversight are fundamental parts of\nthat process, and it's difficult to understand how the quality/deployability\nof IETF protocols could be maintained without them.  \n\nTo the extent that our process is bogging things down without improving\nthe quality of the output, I agree that we would do well to streamline\nthings.  But while I like to think we can improve turn-around times, I \ndon't think we can do without external review.\n\nKeith\n\n\n\n", "id": "lists-007-8312773"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> First, Im not in favor of a separate body, yet.\n> I beleive that there can be progress made in IETF process\n> to allow APPS what it needs..\n> \n> >\n> > >1) Invent a new status above ID but below RFC that let's app\n> > >developers know they have a frozen draft they can develop off of but\n> > >one that hasn't met all the IETF quality bars.\n  > >\n> > We've got one. It's called EXPERIMENTAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n> >\n> Well, its no good if a standards track document cant reference it.\n\nif you allow a document of quality 'A' to reference a document of\nquality  'B', (where A is higher quality than B) you dilute the\nquality of A documents to be no better than B.  because people\nwill just develop documents of quality B and incorporate those\nby refernece into another document and claim that the second document\nis of quality A. (and yes, people try to do this from time to time)\n\nso if you want to publish documents as Experimental, you need to\ncontent yourself with the notion that any document that makes\na normative reference to those documents can have no higher \nquality rating.\n\n> Following that, one might say then that effort should be experimental\n> as well.  This isnt a bad thing, necessarily.  I think there is\n> just a stigma about experimental that prevents it from being\n> appealing to the community.\n> It would help if the IAB could paint a nicer picture of it,\n> perhaps as \"short term standard\".   Whatever it is, we need\n> to imply that the standard in question ( experimental) has\n> the agreement of the interested vendors/parties, is likely\n> to proceed to \"standards track\", and is something that\n> the community should invest in.   \n\nperhaps.  but I can't see how IETF should make any statement\nabout future direction of a protocol (i.e. its liklihood\nof being on the standards track in the future) without extended\ncommunity review of that protocol - precisely because of the\ntendency for groups to work at cross purposes.  \n\nactually, it seems like Proposed Standard is really very close to\nyour notion of \"short term standard\" - in that it is likely to\nadvance on the standard track and eventually proceed to full standard.\n\n> Today, the common view\n> of experimental, IMHO, is \"this is never going to go anywhere,\n> but you can go play with this freak of nature of you want, just\n> dont have any expectations of it being around in the future\".\n\nand this is precisely because Experimental documents either\na) don't have widespread community support  \nb) are considered to have a high potential for being operational\ndisruptive.\nc) have known technical problems\n\nagain, if you want some sort of statement that \"things will probably\ngo this way\" then you need at least tacit support from a lot larger\ncommunity than a single working group, and you need independent\nreview to overcome the tendency of editors and working groups \n(and human beings in general) to miss flaws after they've been \nworking on something too long.  and that's basically what you\nget with Proposed Standard.\n\n> Maybe all APPS standards should have experimental, or an\n> equivalent, as a necessary first step in getting to standards\n> track proposed.\n\nI've wondered about this - maybe groups should have to publish\nas Experimental, and implement the protocol, before going to\nProposed.  It might get people focused on \"running code\" sooner\nrather than later, and some groups need that.  I'd like to see \na few groups try it before recommending it for everyone in APPS.  \n\n> Maybe in the early stages it would be wise to have the IETF\n> make two standards for a given area, perhaps as \"quasi-experimental\".\n> This way the market can decide, and when it does, it wont be\n> a choice of \"the IETF approved standard, or the other one\".\n\noccasionally we do make two standards in a given area, call \nthem both Proposed, and let the market decide.  but usually \nthe conflict isn't between two different ways to do X\n(working groups are fairly good at sorting those out),\nthe conflict is where protocol X intereferes with your ability\nto use protocol Y, or vice versa.   and some of the market \ndecides to use X and some of the market decides to use Y, with\nthe result that the ability to deploy both X and Y are diminished\neven though X and Y don't directly compete with one another.\nfor example, NAT boxes interfere with the ability to deploy\nmany different kinds of protocols, but people don't realize\nthat when they are choosing a NAT box they are implicitly\nchoosing not to run those other protocols.\n\n> People should build products, standards, and such due to\n> the usefulness and market acceptability of a protocol, not\n> because one is \"IETF sanctioned\".\n\nagreed.  but IETF sanction is often a good indicator of the \nusefulness and deployability of a protocol.\n\nKeith\n\n\n\n", "id": "lists-007-8327142"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> [I feel compelled to point out at the outset that none of the\ndiscussoin\n> below has anything to do with the HTTP Extensions Framework document -\n> (a) this was an indivdual submission, not an HTTP working group\ndocument,\n> and (b) the document received mixed reviews both within the HTTP WG\n> and during Last Call, which is why it was not approved as Proposed.]\n\nActually I think this has a lot to do with it.\n\nThe HTTP Extension Framework was originally a work item of the HTTP WG\nbut was because of the desire to close HTTP WG put off to another WG -\nthe HTTP extension working group along with two other items on \"Policy\nfor how to extend HTTP\" and the OPTIONS draft. However, this group was\nnever chartered due to what I consider political problems.\n\nThere didn't seem to be any other way than to make this draft an\nindividual submission - something that I don't recommend anybody to try\nas there is no protection what so ever from arbitrary comments that\nnormally get filtered out by \"rough concensus\" in a wg.\n\nIf you refer to the comments that were sent in during last call then\nthese were a) after I had made an informal last call on the HTTP WG\nmailing list and b) after the draft had been pending for a while without\ncomments. Regardless, the comments were resolved during the last call\nwhich I believe is the whole purpose of this mechanism, especially in\nthe case of individual submissions.\n\nWhat I am opposed to is for work items to be needlessly delayed by\nprocess because of architectural differences in where we as a comunity\nwant to go. I am not claiming that the HTTP extension spec is flawless\nbut I am calling for open and timely discussion.\n\nIf the openness of the IETF has to be for real then such differences are\nsupposed to be dealt with on a public mailing list, not by dropping\nspecs into process holes. IESG can not at the same time be the driving\nforce of Internet Standards and an architectural guardian using the very\nsame process.\n\nOne solution to this is to appoint a app area directorate which can\nobject to proposals and provide timely technical/philosophical feedback\nrather than having IESG use process to slow work down.\n\nHenrik\n\n\n\n", "id": "lists-007-8341213"}, {"subject": "Re: IETF split? (was: HTTP Extensions Frameworkstatus?", "content": "Jacob,\n\n<b><i>*Very violent disagreement*</i></b>\n\nIf the IETF has one virtue, it is cross-fertilisation between infrastructure\npeople and applications people. Being in the same hotel at the same time is vital.\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nBrian E Carpenter (IAB Chair)\nProgram Director, Internet Standards & Technology, IBM \nOn assignment for IBM at http://www.iCAIR.org \nAttend INET 2000: http://www.isoc.org/inet2000\nNon-IBM email: brian@icair.org\nEthernet address: 00-00-AC-CF-5B-82\n\n\nJacob Palme wrote:\n> \n> At 04.22 +0100 99-12-07, Patrik F?ltstr?m wrote:\n> > This has been discussed a number of times, and every time the answer that\n> > comes back states that having meetings at the same time (i.e. at the same\n> > IETF meetings) is a good thing. It has also been discussed whether the\n> > various areas should be meeting at different dates, and the answer to that\n> > questions has also been the same. Take for example the MMMS or iDNS BOF or\n> > the IMPP effort which all depend on interest from more areas than APPS.\n> \n> My suggestion is that APPS have their meeting one week and\n> all other IETF groups the next week. People can then stay\n> for two weeks if they want to cover both areas, which I\n> expect IESG members will do, but the load on the single\n> weeks will be less.\n> \n> Some topics which are of special interest to both APPS\n> and other areas could be scheduled for the weekend\n> between APPS and the rest, or the Friday the first\n> week or the Monday the next week.\n> \n> This proposal might actually increase cross-fertilization,\n> because with the present scheme, very few people have time\n> to go to working groups within both APPS and the other\n> areas!\n> \n> ------------------------------------------------------------------------\n> Jacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\n> for more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-8353651"}, {"subject": "Re: IETF split? (was: HTTP Extensions Frameworkstatus?", "content": "Jacob Palme wrote:\n> \n> My suggestion is that APPS have their meeting one week and\n> all other IETF groups the next week. People can then stay\n> for two weeks if they want to cover both areas, which I\n> expect IESG members will do, but the load on the single\n> weeks will be less.\n\nI don't think you'll ever get a significant number of people or\ncompanies to commit two weeks at a time, 3 times a year, to being away\nfrom work and their families. The end result will be less cross over and\ncross pollination than currently happens. It will be almost impossible\nto get people who focus mostly on SEC, ROUTING, TRANSPORT or OPS to pop\nin to help out in their specific areas of expertise, or to be available\nfor consultation. Similarly, it will be impossible to get significant\nnumbers of APPS folks to participate in such areas as XMLSIG, S/MIME,\nPKIX, OPENPGP and STIME (to pick a few). In all, I think such a breakup\nwould cause a significant decrease in expertise levels across the board.\nAnd that would NOT be a good idea.\n\nTony Hansen\ntony@att.com\n\n\n\n", "id": "lists-007-8363971"}, {"subject": "RE: HTTP Extensions Framework status", "content": "See one comment on the practical use of Experimental in an\nAPPS project recently.\n\nCarl-Uno\n\n> -----Original Message-----\n> From: Keith Moore [mailto:moore@cs.utk.edu]\n> Sent: Tuesday, December 07, 1999 7:50 AM\n> To: Josh Cohen (Exchange)\n> Cc: Harald Tveit Alvestrand; Yaron Goland (Exchange); 'Patrik\n> F?ltstr?m'; Scott Lawrence; moore@cs.utk.edu; discuss@apps.ietf.org;\n> Peter Ford (Exchange)\n> Subject: Re: HTTP Extensions Framework status? \n> \n> snip, snip\n> \n> > Maybe all APPS standards should have experimental, or an\n> > equivalent, as a necessary first step in getting to standards\n> > track proposed.\n> \n> I've wondered about this - maybe groups should have to publish\n> as Experimental, and implement the protocol, before going to\n> Proposed.  It might get people focused on \"running code\" sooner\n> rather than later, and some groups need that.  I'd like to see \n> a few groups try it before recommending it for everyone in APPS.  \n>\n\n--- snip, snip --- \n\nThe IPP WG produced a set of drafts which were sent to the IESG in \nMarch 1998. After some comments from ADs, slightly revised drafts \nwere given to the IESG again in July 1998. These documents were \nprocessed by the IESG in early 1990 and published as Experimental\nRFCs in April 1999. By that time, the IPP WG in collaboration with\nthe Printer Working Group (PWG), had held an interoperability\nevent with more than 30 vendors. A new set of drafts were sent to \nthe IESG in early July 1999 with a request to have them published\nas RFCs. The only crucial differences from the July 1998 drafts\nwas the introduction of the ipp:// scheme (as a synonym for\nhttp://...:631) and swapping SSL3 for TLS, which had been done\nin between. By now, some 30 products from 20 vendors are\nin the market place. An optimistic outlook is to see the RFCs\nfor the Proposed Standard some time first quarter of the\nnext millennium.\n\nCarl-Uno\n\n\n\n", "id": "lists-007-8372768"}, {"subject": "Re: IETF split? (was: HTTP Extensions Frameworkstatus?", "content": "Jacob Palme wrote:\n>\n> My suggestion is that APPS have their meeting one week and\n> all other IETF groups the next week. People can then stay\n> for two weeks if they want to cover both areas, which I\n> expect IESG members will do, but the load on the single\n> weeks will be less.\n> \n\nAs others have pointed out, this is logistically infeasible.  Right now,\nI'm not even getting to current IETF meetings, much less larger cuts\nout of life.\n\nI believe the overlap is essential: we've seen what happens when\na \"killer app\" gets deployed without anyone understanding what is\ngoing on.  The hallway conversations again and again educate both\napps and infrastructure people as to the problems presented by protocols.\n\nI gave alot of thought some years ago whether doing HTTP in W3C say,\nwould make more sense, and finally concluded that it would not: the\nfeedback and conversations with people getting the packets from point\nA to point B were necessary.\n\nThe big issue the IETF does have in APPS is one of scaling: as editor\nof HTTP, the big issue I saw was delays caused by insufficient cycles\nin AD's to read and comment on specifications.  These caused unnecessary\nmany month delays.\n\nThere are ways to \"fix\" this: another Apps AD, or some reader mechanism,\nor trying to make sure that Apps AD's can spend full or nearly full time\non IETF business.  I suggest these long before doing application protocol\nstandards work in other venues.\n- Jim Gettys\n\n\n--\nJim Gettys\nTechnology and Corporate Development\nCompaq Computer Corporation\njg@pa.dec.com\n\n\n\n", "id": "lists-007-8385521"}, {"subject": "Re: HTTP Extensions Framework status", "content": "Henrik,\nFrom my viewpoint as a participant, it seems clear that the\nHTTP working group ran out of steam; there was no way that group could\nhave taken on a work item as ambitious as this one.  As the chair of a\nworking group whose entropy rate risks exceeding its production, I\nthoroughly sympathize with the desire to get it out of the group so\nthat the energy of the group could focus on getting closed.  I also\nsympathize, however, with your desire to get timely review for this\nwork.  \nKeith and Patrik asked for reviewers from discuss@apps last\nyear to get focus on the draft from a broad group.  I think that was a\ngood thing, and I hope we can keep it as a review mechanism (Maybe we\nshould even make it an earlier part of the standard\nindividual-submission review process; rather than wait until one of\nthe two ADs has cycles for a review, get some input early on and let\nthem review a later version with some of the design rational clarified\nand arguments worked out).  Some of the reviewers were actually HTTP\nparticipants (Larry, Koen, et al); others were familiar with similar\nissues in other groups (Chris Newman, Graham Klyne).  There probably\nwasn't enough review (it was December then, too), but some of the\narchitectural differences you allude to below did get exposed.\nGiven that there were architectural differences, the question\nbecomes, what should have happened next to resolve them?  There were\nthree options: a working group to consider the problem (note: not the\ndraft, but the problem it attempts to solve) could have been formed so\nthat rough concensus could have developed around a solution; the draft\ncould have been kicked back and forth between the ADs and document\nauthor until the ADs were satisfied that the architectural problems\nhad been handled (this takes a *lot* of cycles from people who have\nfew available); and the draft could go to experimental as a stable\nspecification and basis for work that may eventually get standardized.\nDepending how you understand the problem, the effort to get\napplecore going could be seen as theory 1; it did not take for granted\na basic design principle of this document (must interoperate with HTTP\n1.x), but it did have as a goal a stable application core so that\nextensions could re-use it.  That effort took time, and it did not get\na groundswell of support.  Shifting after that to an experimental\nmodel for this draft makes sense to me as a way of nailing the\nstandard down so people can work from it.  It gives the community a\nway of working out the architectural issues in practice without\ntotally presuming the answer.\nYour note below that appointing an app directorate which can\n\"object to proposals and provide timely technical/philosophical\nfeedback\" as a solution seems to me to indicate that you would have\nprefered theory 2 to either theory 1 or theory 3.  It also seems to\nmiss the point.  The ADs aren't the app area; they are the technical\nmanagers of the area.  The app area itself needs to have the cycles\nand interest in providing timely technical/philosophical feedback.\nPart of the area directors work as managers is to encourage that\nfeedback and channel the response so that it solves the underlying\nproblems rather than just editing the drafts.  By putting this forward\nas experimental, the ADs have approved a stable specification for\nfurther work--that, hopefully, will give us a way to channel feedback\non whether this draft solves the underlying problem.\nregards,\nTed Hardie\n\n\n> Actually I think this has a lot to do with it.\n> \n> The HTTP Extension Framework was originally a work item of the HTTP WG\n> but was because of the desire to close HTTP WG put off to another WG -\n> the HTTP extension working group along with two other items on \"Policy\n> for how to extend HTTP\" and the OPTIONS draft. However, this group was\n> never chartered due to what I consider political problems.\n> \n> There didn't seem to be any other way than to make this draft an\n> individual submission - something that I don't recommend anybody to try\n> as there is no protection what so ever from arbitrary comments that\n> normally get filtered out by \"rough concensus\" in a wg.\n> \n> If you refer to the comments that were sent in during last call then\n> these were a) after I had made an informal last call on the HTTP WG\n> mailing list and b) after the draft had been pending for a while without\n> comments. Regardless, the comments were resolved during the last call\n> which I believe is the whole purpose of this mechanism, especially in\n> the case of individual submissions.\n> \n> What I am opposed to is for work items to be needlessly delayed by\n> process because of architectural differences in where we as a comunity\n> want to go. I am not claiming that the HTTP extension spec is flawless\n> but I am calling for open and timely discussion.\n> \n> If the openness of the IETF has to be for real then such differences are\n> supposed to be dealt with on a public mailing list, not by dropping\n> specs into process holes. IESG can not at the same time be the driving\n> force of Internet Standards and an architectural guardian using the very\n> same process.\n> \n> One solution to this is to appoint a app area directorate which can\n> object to proposals and provide timely technical/philosophical feedback\n> rather than having IESG use process to slow work down.\n> \n> Henrik\n> \n\n\n\n", "id": "lists-007-8395245"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> Your note below that appointing an app directorate which can\n> \"object to proposals and provide timely technical/philosophical\n> feedback\" as a solution seems to me to indicate that you would have\n> prefered theory 2 to either theory 1 or theory 3. It also seems to\n> miss the point.  The ADs aren't the app area; they are the technical\n> managers of the area.  The app area itself needs to have the cycles\n> and interest in providing timely technical/philosophical feedback.\n\nMy proposal is not to have more app ADs - it is to have a body next to\nthe ADs that frees them from making architectural decisions and focus on\nprocess. The diversity of the Apps area makes it hard to have an\nend2end-interest equivalent and I think such a group has to be chartered\nto review documents and to call out dependencies between groups. The\ngroup has to contain app people with a broad knowledge of the app area\nand with commitment to actually produce output.\n\nI used the word \"directorate\" as I believe such groups have existed in\nthe past in other areas and that this was the term used.\n\nHenrik\n\n\n\n", "id": "lists-007-8410267"}, {"subject": "Re: HTTP Extensions Framework status", "content": "Thanks for clearing that up.  I agree that having one or more review\ngroups working with the ADs would be a good idea.  I think the review\ngiven by discuss@apps and wgchairs is a step toward that model, and it\nmay give us base from which to produce such a group.\nregards,\nTed Hardie\n\n\n> My proposal is not to have more app ADs - it is to have a body next to\n> the ADs that frees them from making architectural decisions and focus on\n> process. The diversity of the Apps area makes it hard to have an\n> end2end-interest equivalent and I think such a group has to be chartered\n> to review documents and to call out dependencies between groups. The\n> group has to contain app people with a broad knowledge of the app area\n> and with commitment to actually produce output.\n> \n> I used the word \"directorate\" as I believe such groups have existed in\n> the past in other areas and that this was the term used.\n> \n> Henrik\n> \n\n\n\n", "id": "lists-007-8421513"}, {"subject": "Re: IETF split? (was: HTTP Extensions Frameworkstatus?", "content": "> Jacob,\n\n> <b><i>*Very violent disagreement*</i></b>\n\n> If the IETF has one virtue, it is cross-fertilisation between infrastructure\n> people and applications people. Being in the same hotel at the same time is vital.\n\nPlus one has only to look at our ability to fill Friday session slots to\nbe able to see that extending the IETF meeting to two weeks for everybody\nisn't going to work very well.\n\nNed\n\n\n\n", "id": "lists-007-8432261"}, {"subject": "Re: IETF split? (was: HTTP Extensions Frameworkstatus?", "content": ">\n>There are ways to \"fix\" this: another Apps AD, or some reader mechanism,\n>or trying to make sure that Apps AD's can spend full or nearly full time\n>on IETF business.  I suggest these long before doing application protocol\n>standards work in other venues.\n>                                 - Jim Gettys\n\n\nI have specifically suggested adding a 3rd Apps AD to NONCOM. I do not \nthink this will solve all of the problems but it could certainly help.\n\nI also suggested a specific TELEPHONY area. With all of the related work \nthat is going on it seems reasonable to seperate it out to permit TEL AD's \na more focused approach to some of the looming and unresolved architectural \nissues.\n\nI also totally reject the idea that APPS should meet separately from other \nIETF WG's.\n\n\n >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nRichard Shockey\nShockey Consulting LLC\n8045 Big Bend Blvd. Suite 110\nSt. Louis, MO 63119\nVoice 314.918.9020\neFAX Fax to EMail 815.333.1237 (Preferred for Fax)\nINTERNET Mail & IFAX : rshockey@ix.netcom.com\nGSTN Fax 314.918.9015\nMediaGate iPost VoiceMail and Fax 800.260.4464\n<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n\n\n", "id": "lists-007-8440417"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> Thanks for clearing that up.  I agree that having one or more review\n> groups working with the ADs would be a good idea.  I think the review\n> given by discuss@apps and wgchairs is a step toward that model, and it\n> may give us base from which to produce such a group.\n\nWe've tried such groups in the past, with fairly poor results\n(at least in recent history).  We used to have an apps area\ndirectorate, but it was difficult to get the directorate to\nreview anything or to discuss architectural issues at length.\nThe various apps.ietf.org lists were an attempt to replace\nthe appointed directorate with self-appointed community members\nwith interests in various subjects (web, messaging, etc.).\nWe've had better results from these lists, but still have not\nfound them very good at providing architectural direction.\nOne problem is that if there are diverging opinions, as is\nusually the case, it's still up to the area directors to sort \nthings out.  So this takes more time for the ADs without reliving\nthem of much burden.\n\nI'm starting to think that even architectural groups need\nto be working toward a tangible goal (say, a document of some\nsort) in order to get people focused on any particular problem.\n\nKeith\n\n\n\n", "id": "lists-007-8449541"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> I'm starting to think that even architectural groups need\n> to be working toward a tangible goal (say, a document of some\n> sort) in order to get people focused on any particular problem.\n\n    No deliverables = no accountability = nothing happens.\n\nIt has to be chartered as a group with deliverables. Reviews of\ndocuments are deliverables and so one possibility is to charter a group\nto review drafts from related working groups and individuals; write up\nconcerns and comments and ensure that coordination happens and feedback\nprovided to the IESG.\n\nHenrik\n\n\n\n", "id": "lists-007-8460432"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> The HTTP Extension Framework was originally a work item of the HTTP WG\n> but was because of the desire to close HTTP WG put off to another WG -\n> the HTTP extension working group along with two other items on \"Policy\n> for how to extend HTTP\" and the OPTIONS draft. However, this group was\n> never chartered due to what I consider political problems.\n\nYes.  This document, and other work peripheral to the HTTP WG, were\ndistracting the HTTP WG from getting HTTP 1.1 draft standard out the\ndoor.  Of course, the reason that HTTP 1.1 was taking so long is that \nit is a tremendously complex specification.  Given that, it\nis worth asking whether making HTTP even more complex, or layering\nother protocols on top of HTTP, or especially adding explicit\nsupport for intermediaries in other protocol (which causes most\nof HTTP's complexity) are good ideas and things that  IETF should\nspend its time on.  IETF has limited resources and cannot form a \nnew working group for every new idea - especially when that group \nwould have a lot of the same people already participating in other \nHTTP-related groups such as webdav and dasl.  There was lots of \ninterest in the latter two groups and a relatively small amount of \ninterest in HTTP extensions, so webdav and dasl got the cycles.\n\nAnd the reviews of HTTP extensions were always fairly mixed - whether \nin the HTTP WG list, on the discuss@apps list, or in Last Call comments.\nBasically, there never seemed to be much evidence of support for it,\nand several of the comments actually suggested Experimental status.\nI suspect this is not so much due to unresolved technical issues\nas due to questions about the premise of the work itself.\n\n> There didn't seem to be any other way than to make this draft an\n> individual submission - something that I don't recommend anybody to try\n> as there is no protection what so ever from arbitrary comments that\n> normally get filtered out by \"rough concensus\" in a wg.\n\nIndividual submissions work better when the work is non-controversial.\nThat doesn't mean that they're not useful, but that they're not intended\nto replace the working group process.\n\n> If you refer to the comments that were sent in during last call then\n> these were a) after I had made an informal last call on the HTTP WG\n> mailing list and b) after the draft had been pending for a while without\n> comments. Regardless, the comments were resolved during the last call\n> which I believe is the whole purpose of this mechanism, especially in\n> the case of individual submissions.\n\nIn the case of a working group submission, the fact that the working \ngroup exists is usually sufficient evidence that there is support for \nthe work.  In the case of individual submissions it's harder to be sure.\nSo the Last Call comments do serve a differnet role, and individual\nsubmissions often receive more scruitiny than working group submissions.\n\n> What I am opposed to is for work items to be needlessly delayed by\n> process because of architectural differences in where we as a comunity\n> want to go. I am not claiming that the HTTP extension spec is flawless\n> but I am calling for open and timely discussion.\n\nArchitectural differences sound like a lack of consensus to me.\n\nOpen and timely discussion seems entirely appropriate, and I apologize \nfor my poor handling of this document.  But I think that the author of \nan individual subimssion needs to demonstrate both technical quality \nand widespread community support for the document, and that objections \nduring Last Call need to be taken as potential evidence of a lack of \nconsensus.  In the absence of clear community consensus support for the \ndocument to be on the standards track, we need to take the conservative \nview, and this means not approving the document as a standard.\n\nKeith\n\n\n\n", "id": "lists-007-8471421"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> > I'm starting to think that even architectural groups need\n> > to be working toward a tangible goal (say, a document of some\n> > sort) in order to get people focused on any particular problem.\n> \n>     No deliverables = no accountability = nothing happens.\n> \n> It has to be chartered as a group with deliverables. Reviews of\n> documents are deliverables and so one possibility is to charter a group\n> to review drafts from related working groups and individuals; write up\n> concerns and comments and ensure that coordination happens and feedback\n> provided to the IESG.\n\nwe've occasionally chartered 'review groups' in the past, for instance\nwe did (a very short-lived) one a few years ago for email extensions.  \nat that time, iirc, we had a lot of requests for email extensions appear\nin a short time.  and those extensions were relatively small and \nself-contained and easy to think about.  \n\nhttp architectural issues seem thornier and more difficult to sort out.  \nchartering a group to consider http extension mechanisms seems wrong -\nseems like the first question is whether http should be extended \n(in scope) at all.\n\n\n\n", "id": "lists-007-8484545"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> http architectural issues seem thornier and more difficult to sort out.  \n> chartering a group to consider http extension mechanisms seems wrong -\n> seems like the first question is whether http should be extended \n> (in scope) at all.\n\nIndeed.  I was rather happy with the partitioning of HTTP we started\nin the HTTP NG effort.  Moving the low level details to the Transport\nArea, and allowing the Apps Area to concentrate on, well, apps, still\nseems a good idea to me.\n\nBill\n\n\n\n", "id": "lists-007-8495483"}, {"subject": "RE: HTTP Extensions Framework status", "content": "> -----Original Message-----\n> From: Keith Moore [mailto:moore@cs.utk.edu]\n> Sent: Wednesday, December 08, 1999 2:50 AM\n> To: Josh Cohen (Exchange)\n> Cc: Harald Tveit Alvestrand; Yaron Goland (Exchange); 'Patrik\n> Faltstrom'; Scott Lawrence; moore@cs.utk.edu; discuss@apps.ietf.org;\n> Peter Ford (Exchange)\n> Subject: Re: HTTP Extensions Framework status? \n> \n> \n> \n> > Maybe all APPS standards should have experimental, or an\n> > equivalent, as a necessary first step in getting to standards\n> > track proposed.\n> \n> I've wondered about this - maybe groups should have to publish\n> as Experimental, and implement the protocol, before going to\n> Proposed.  It might get people focused on \"running code\" sooner\n> rather than later, and some groups need that.  I'd like to see \n> a few groups try it before recommending it for everyone in APPS.  \n> \nI like this response.  It sounds like a good thing to trial.\nHowever, its still tough to take the stigma of experimental,\nwould be it possible to have the state called \"standards-track\nexperimental\"?\n\n\n\n", "id": "lists-007-8505968"}, {"subject": "RE: HTTP Extensions Framework status", "content": "> -----Original Message-----\n> From: Keith Moore [mailto:moore@cs.utk.edu]\n> Sent: Wednesday, December 08, 1999 9:29 AM\n> To: Henrik Frystyk Nielsen\n> Cc: Keith Moore; Yaron Goland (Exchange); 'Patrik Faltstrom'; 'Harald\n> Tveit Alvestrand'; Scott Lawrence; discuss@apps.ietf.org; Josh Cohen\n> (Exchange); Peter Ford (Exchange)\n> Subject: Re: HTTP Extensions Framework status? \n> \n> \n> Open and timely discussion seems entirely appropriate, and I \n> apologize \n> for my poor handling of this document.  But I think that the \n> author of \n> an individual subimssion needs to demonstrate both technical quality \n> and widespread community support for the document, and that \n> objections \n> during Last Call need to be taken as potential evidence of a lack of \n> consensus.  In the absence of clear community consensus \n> support for the \n> document to be on the standards track, we need to take the \n> conservative \n> view, and this means not approving the document as a standard.\n>\nCall me ignorant, but my understanding was that last call comments\nwere to be delivered openly to the WG or submitter.  \nHenrik, have you seen the comments that keith is referring to?\nI haven't.  It seems that there wasnt a good opportunity for \nopen discussion on the comments.\n \n> Keith\n> \n\n\n\n", "id": "lists-007-8517409"}, {"subject": "RE: HTTP Extensions Framework status", "content": "> -----Original Message-----\n> From: Keith Moore [mailto:moore@cs.utk.edu]\n> Sent: Wednesday, December 08, 1999 9:40 AM\n> To: Henrik Frystyk Nielsen\n> Cc: Keith Moore; hardie@equinix.com; \"\"Yaron Goland (Exchange)\"\";\n> 'Patrik Faltstrom'; 'Harald Tveit Alvestrand'; Scott Lawrence;\n> discuss@apps.ietf.org; \"\"Josh Cohen (Exchange)\"\"; \"\"Peter Ford\n> (Exchange)\"\"\n> Subject: Re: HTTP Extensions Framework status? \n> \n> http architectural issues seem thornier and more difficult to \n> sort out.  \n> chartering a group to consider http extension mechanisms seems wrong -\n> seems like the first question is whether http should be extended \n> (in scope) at all.\n>\nAnd that is the key issue which is, IMHO, the root of the problem.\nGoing back to what henrik said, its difficult to be in the position\nof being an open forum where vendors can create interoperable standards\nas well as being an architectural demigod. (for lack of a better word)\n\nI am not saying I have the answer, but I dont know if its right that\nthe IETF should say \"You must not expand the scope of HTTP\".  If I want\nto represent, lets say, my email store as a web server (with HTTP and DAV)\nand I want to use it as my client mail protocol, then I should be able to.\nIf other vendors wish to do the same, and we want to do it in an\ninteroperable\nway, then the IETF should provide the forum to do so.\nIf it does not, then maybe the right place for this is in the W3C, which\nrepresents the \"web community\", a subset of the Internet Community.\n\n<soapbox>\n As an outsider, I feel as if the W3c has delegated the protocol work \nof HTTP to the IETF to avoid overlapping work.  IETF does protocols.\nIf the IETF is simply taking HTTP and keeping it locked up in a cage\nin the basement, then it is not holding up its end of the bargain.\nAs a result, IMHO, its stifling (my interpretation) of timbl's view of \nthe web.  Every document, email message,buddy list, etc is a resource\nwith a URL and can be manipulated by web transport protocols, a la HTTP.\n</soapbox>\n \n\n\n\n", "id": "lists-007-8528974"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> And that is the key issue which is, IMHO, the root of the problem.\n> Going back to what henrik said, its difficult to be in the position\n> of being an open forum where vendors can create interoperable standards\n> as well as being an architectural demigod. (for lack of a better word)\n\neven open fora have limited resources that need to be managed\nand  there is a balance to be struck between letting every working \ngroup go off in its own direction  (no matter what the cost \nor how much it conflicts with other groups) and providing direction\nfrom above (leaving direction-setting in the hands of a few\npeople with limited resources and imperfect vision)\n\nnobody is an architectural demigod.  if there had been solid\ncommunity support for the http extension framework it would\nhave gone to proposed standard.    if there is solid support\nin the future it can still go forward, but at this point it\nis not at all clear that there is solid support for extending\nhttp at all, much less via the proposed mechanisms.\n \n> I am not saying I have the answer, but I dont know if its right that\n> the IETF should say \"You must not expand the scope of HTTP\".  \n\nthe IETF is the entire community of participants.  but the 'leaders'\nof that community have to be careful to not misrepresent the \nconsensus of that community by mislabelling things as proposed\nwhen they don't have the necessary community support.  \n\n> If I want\n> to represent, lets say, my email store as a web server (with HTTP and DAV)\n> and I want to use it as my client mail protocol, then I should be able to.\n\nyou can do whatever you want, but don't expect IETF to endorse it\njust because you do it\n\n> If other vendors wish to do the same, and we want to do it in an\n> interoperable  way, then the IETF should provide the forum to do so.\n\nif IETF were to adopt that logic, it would end up wasting resources\non every hairbrained scheme that any particular set of vendors came up \nwith.  it would be a self-induced denial-of-service attack.\n\n>  As an outsider, I feel as if the W3c has delegated the protocol work \n> of HTTP to the IETF to avoid overlapping work.  IETF does protocols.\n> If the IETF is simply taking HTTP and keeping it locked up in a cage\n> in the basement, then it is not holding up its end of the bargain.\n\nHTTP is not in a cage, but it is abundantly clear that HTTP is\noptimized for web-page access and that it is  pessimized\nfor many other purposes - and the notion that one should \ntry to extend HTTP for random other purposes is one that\nhas met with skepticism and some opposition.\n\nremember the t-shirt with the hammers?  why do you think one\nof them was labelled HTTP? \n\n> As a result, IMHO, its stifling (my interpretation) of timbl's view of \n> the web.  \n\nnobody is an architectural demigod.\n\n> Every document, email message,buddy list, etc is a resource\n> with a URL and can be manipulated by web transport protocols, a la HTTP.\n\nthe second part doesn't follow from the first.  URL notation is \nhighly useful but HTTP is ill-suited for transport of many of \nthe things that one would use URLs for.\n\n\n\n", "id": "lists-007-8541927"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> Call me ignorant, but my understanding was that last call comments\n> were to be delivered openly to the WG or submitter.  \n\nIn practice, last call comments are delivered to any of:\n\nIESG, the ADs, the WG mailing list, the IETF list, the document authors\n\none of the real difficulties of the present system is tracking \nall of them down.\n\nAlso it seems useful to allow privately-submitted Last Call comments,\nthough one hopes that most comments are public.\n\nKeith\n\n\n\n", "id": "lists-007-8555110"}, {"subject": "RE: HTTP Extensions Framework status", "content": "So be it. It would appear that all HTTP extensions (GENA, SSDP, SOAP, etc.)\nwill now be marked experimental. It will be annoying to educate the press on\nthese issues but that sounds easier than getting the IESG enthusiastic about\nHTTP.\n\nYaron\n\n\n\n", "id": "lists-007-8564775"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> I like this response.  It sounds like a good thing to trial.\n> However, its still tough to take the stigma of experimental,\n> would be it possible to have the state called \"standards-track\n> experimental\"?\n\nwell, you can go to poisson and see whether you can convince them :)\n\nbut my guess is - no.  if you want some IETF statement that the \nwork will be standards-track (that is, that this is indicative\nof the direction that IETF will be taking) you need review from \nthe wider community, and some assurance that you're not working\nat cross purposes  with other groups.  you have the option of\nasking for Last Call for Experimental, but this is as much work\nas asking for Proposed Standard.\n\nKeith\n\n\n\n", "id": "lists-007-8575802"}, {"subject": "Re: HTTP Extensions Framework status", "content": "To expand a bit on what Keith has mentioned, HTTP is not designed to be\na transport protocol.  It is a transfer protocol in which the messages\nreflect the semantics of the Web architecture by performing actions on\nresources through the transfer and manipulation of representations of\nthose resources.  It is possible to achieve a wide range of functionality\nusing this very simple interface, but following the interface is required\nin order for HTTP semantics to remain visible to intermediaries.\n\nThat is why HTTP goes through firewalls.  Most of the extensions that\nhave been proposed lately (aside from DAV and its ilk) have merely used\nHTTP as a way to move other application protocols through a firewall,\nwhich is a fundamentally stupid idea.  Not only does it defeat the purpose\nof having a firewall, but it won't work for the long term because firewall\nvendors will simply have to perform protocol filtering to continue their\nexistance.  It therefore makes no sense to do those extensions on top of\nHTTP, since the only thing HTTP accomplishes in that situation is to add\noverhead from a legacy syntax.\n\nHowever, this is not an argument against the HTTP extensions framework.\nGiven the unavoidable (at this point) presence of protocol filtering,\nthe best way to accomplish real extensions within HTTP is through an\nextension framework that identifies each extension in such a way that an\nintermediary can strip it if it isn't wanted.  The only real question\nthen is whether there is any desire for such mandatory extensions within\nHTTP/1.x applications, which I think is the main reason the framework\ndeserves the Experimental tag.\n\nAs an implementer, my primary objection to the HTTP/1.x extensions framework\nhas always been that it excessively complicates the interface to the\npoint where it would be far more efficient for us to just redesign HTTP\nand issue HTTP/2.0 using a syntax that incorporates the design goals of\nthe extension framework.  However, again that does not argue against the\ncreation of an HTTP/1.x extensions framework, since the more experience\nwe have with these things IN PRACTICE, the better.  I can worry about the\nnew protocol at a later time.\n\nAs far as the Experimental tag hindering the progression of other protocols,\nI can say from experience that none of the HTTP extensions proposed so far,\naside from the DAV ones, have deserved the status of anything better than\nExperimental.  I am certain that the extensions framework will progress\nonto the standards track before any of those half-baked ideas.\n\nIf people are in such a hurry to extend HTTP/1.x, what they should be\nworking on is a set of specifications that establish a registry for the\nvarious protocol elements not defined by MIME.  That task is so boring\nthat nobody has volunteered to do it, even though it is necessary for\nHTTP to be extended in a coherent manner.\n\n....Roy\n\n\n\n", "id": "lists-007-8585665"}, {"subject": "Re: HTTP Extensions Framework status", "content": "Somebody wrote:\n\n> > Every document, email message,buddy list, etc is a resource\n> > with a URL and can be manipulated by web transport protocols, a la HTTP.\n\nAt 19:10 1999/12/07 -0500, Keith Moore wrote:\n\n> the second part doesn't follow from the first.  URL notation is \n> highly useful but HTTP is ill-suited for transport of many of \n> the things that one would use URLs for.\n\nEven much easier, email messages and buddy lists and others\ncan have or do have their own URI schemes. The web is not,\nand never was, the collection of things addressable by http.\nURIs always covered more than that.\n\n\nRegards,   Martin.\n\n\n#-#-#  Martin J. Du\"rst, World Wide Web Consortium\n#-#-#  mailto:duerst@w3.org   http://www.w3.org\n\n\n\n", "id": "lists-007-8595640"}, {"subject": "Re: HTTP Extensions Framework status", "content": "One main purpose of the HTTP extensions spec is not to\n(mis)use HTTP for completely new things, but to allow\nadditions/extensions to HTTP proper. A very good example\nis P3P (http://www.w3.org/TR/P3P), where the extension spec\nis used to indicate which privacy policies the pages exchanged\nby HTTP work under (http://www.w3.org/TR/P3P#HTTP_Extensions).\n\nMaking things extensible, and reducing the amount of\nwork needed for each extension at a central point such\nas the IETF Apps Area directors, looks like a very\nworthwile goal.\n\nRegards,   Martin.\n\n\nAt 13:46 1999/12/07 +0100, Jacob Palme wrote:\n> At 17.35 -0500 99-12-01, Keith Moore wrote:\n\n> http://www.ietf.org/internet-drafts/draft-frystyk-http-extensions-03.txt\n\n> I have read through the proposal once again. The think I react\n> to (may be because I did not understand) is the requirement\n> to base new applications on HTTP/1.1. It should at least\n> be allowed for new applications to use a subset of HTTP/1.1,\n> and to specify which subset they are using.\n> \n> The full HTTP/1.1 is much more than what many new applications,\n> built on top of HTTP, need.\n> ------------------------------------------------------------------------\n> Jacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\n> for more info see URL: http://www.dsv.su.se/jpalme/\n> \n> \n\n\n#-#-#  Martin J. Du\"rst, World Wide Web Consortium\n#-#-#  mailto:duerst@w3.org   http://www.w3.org\n\n\n\n", "id": "lists-007-8606379"}, {"subject": "Re: HTTP Extensions Framework status", "content": "At 18:14 1999/12/07 -0800, Roy T. Fielding wrote:\n\n> That is why HTTP goes through firewalls.  Most of the extensions that\n> have been proposed lately (aside from DAV and its ilk) have merely used\n> HTTP as a way to move other application protocols through a firewall,\n> which is a fundamentally stupid idea.  Not only does it defeat the purpose\n> of having a firewall, but it won't work for the long term because firewall\n> vendors will simply have to perform protocol filtering to continue their\n> existance.  It therefore makes no sense to do those extensions on top of\n> HTTP, since the only thing HTTP accomplishes in that situation is to add\n> overhead from a legacy syntax.\n\nJust an observation. I think the main reason why HTTP is still\nchosen in this case is the following:\n\nIf you design your own protocol, then the default/initial firewall\nbehaviour is to shut it out. If you piggiback on top of HTTP, then\nthe default/initial behaviour is to pass things through.\n\nThere is probably a better chance to get people to use a protocol,\nand to get security people understand a protocol, and set the\nright restrictions, if at the start you can just use it.\n\n\nRegards,   Martin.\n\n\n#-#-#  Martin J. Du\"rst, World Wide Web Consortium\n#-#-#  mailto:duerst@w3.org   http://www.w3.org\n\n\n\n", "id": "lists-007-8615825"}, {"subject": "RE: HTTP Extensions Framework status", "content": "It seems like there are two contradictory things being requested:\n\na) Proposed Standard is too hard, let's have something like\n   <small>temporary possible maybe proposed</small> <em>Standard</em>\n   so that we can ship code based on poorly written specs\n   and let our marketing department say the \"temporary possible\n   maybe proposed\" part softly and the \"standard\" part loudly.\n\nb) Proposed Standard is too easy, let's require everyone to publish\n   something as Experimental first.\n\nI don't think we need to change the IETF standards track.\n\nI think that far more coordination is needed than we have\nbetween APPS and other areas, since APPS protocols often\nseem to reinvent things at the application layer that are\nbest done at other layers, and vice versa.\n\nAnd I don't think we need to accomodate the marketing departments\nthat want to call something \"standard\". For decades, there\nhave been successful companies shipping networking systems\nwithout the benefit of calling it \"standard\". The value\nof the standards process is to create specifications of\nlasting value.\n\nThe main thing I'd look for is not to change any of the criteria,\nbut to focus on process improvements that would allow IETF working\ngroups to reach conclusions more quickly.\n\nPersonally, I think a small amount of Internet-based collaboration\nsupport for tracking issues in working groups, coupled with\nsome better group focus and management would go a long way toward\nmaking the process more responsive.\n\nYou can't solve a deployment problem (\"no one implemented\nthis specification, oh my\") with a specification (\"so here's\nanother specification for how to do the same thing, oh my\").\n\nAnd you can't solve a process implementation problem by inventing\nmore process.\n\nLet's just focus on making the IETF process work.\n\nAs for HTTP extensions, I think draft-frystyk-http-extensions-03.txt\nis inadequate as an extension framework for HTTP.\n\nRFC 2324 uses the following kinds of HTTP extensions:\n\nnew method\nnew URL scheme(s)\nnew header\nnew value for old header\nnew MIME type for POST body\nnew return code\nnew interpretation for old return code\n\nand even then, it only was exploring a limited number of\npossible HTTP extensions (the most obvious being the\nuse of Java applets as dynamic content.)\n\nOf these, frystyk-http-extension only covers a few,\nand in a haphazard way.\n\n# So be it. It would appear that all HTTP extensions \n# (GENA, SSDP, SOAP, etc.) will now be marked experimental...\n\nIf 10% of the effort that is going into trying to find\nsome way of calling these \"standard\" were instead applied to\nactually fixing them so that they worked as documented,\nthey'd be a lot further along toward standards track.\n\nLarry\n-- \nhttp://larry.masinter.net\n\n\n\n", "id": "lists-007-8624433"}, {"subject": "Re: HTTP Extensions Framework status", "content": "In my previous mails, I deliberately did not discuss whether Experimental\nis right or not right for the Extension Framework as I don't think this is\nan interesting issue (especially as Experimental doesn't preclude Proposed\nlater on).\n\nWhether extensions using the framework are solid or not is also besides\nthe point. The whole purpose of the Extension Framework is in fact to\nallow people to be able to experiment with distributed extensions in an\norderly manner without requireing the extensions to be fully baked and be\nable to transition from experiment to solid extension over time.\n\nAs Roy points out, we need experience with how managed distributed\nextensibility can work but the problem has been we didn't have a stable\nreference to the spec because it has an unknown status, namely the\ntwilight zone between last call and publication.\n\nThis twilight zone is what I am unhappy about and I would like to see\nchanged. It is not hard to see from the current discussion that there are\narchitectural issues involved as well as straight forward work load\nproblems. This is fine but I don't think these issues should be argued\nwith \"lack of wide spread support\" kind of arguments (as these are always\nrelative). Nor should the process black holes be used as arguments. I\n\nThe way this is normally solved in working groups is that \"if you don't\nagree, go write your own draft\". There has been no alternative\nextensibility draft for HTTP than what eventually led to the Extension\nFramework.\n\nThe proposal I hava for a review/discussion working group was intended as\na mechanism to ensure that architectural concerns are being addressed in\nan accountable manner. It fully works within the current process so no new\nprocess is needed. It is not intended specifically for HTTP although I\nthink it would be useful. I for one is not happy about the tendency to\ncopy the HTTP spec and use it word for word in other protocols left and\nright.\n\nHenrik Frystyk Nielsen,\nmailto:frystyk@microsoft.com\n\n----- Original Message -----\nFrom: \"Keith Moore\" <moore@cs.utk.edu>\nTo: \"Josh Cohen (Exchange)\" <joshco@exchange.microsoft.com>\nCc: \"Keith Moore\" <moore@cs.utk.edu>; \"Henrik Frystyk Nielsen\"\n<frystyk@microsoft.com>; <hardie@equinix.com>; \"\"\"Yaron Goland\n(Exchange)\"\"\" <yarong@exchange.microsoft.com>; \"'Patrik Faltstrom'\"\n<paf@swip.net>; \"'Harald Tveit Alvestrand'\" <Harald@Alvestrand.no>; \"Scott\nLawrence\" <lawrence@agranat.com>; <discuss@apps.ietf.org>; \"\"\"Peter Ford\n(Exchange)\"\"\" <peterf@exchange.microsoft.com>\nSent: Tuesday 07 December, 1999 16:10\nSubject: Re: HTTP Extensions Framework status?\n\n\n> > And that is the key issue which is, IMHO, the root of the problem.\n> > Going back to what henrik said, its difficult to be in the position\n> > of being an open forum where vendors can create interoperable\nstandards\n> > as well as being an architectural demigod. (for lack of a better word)\n>\n> even open fora have limited resources that need to be managed\n> and  there is a balance to be struck between letting every working\n> group go off in its own direction  (no matter what the cost\n> or how much it conflicts with other groups) and providing direction\n> from above (leaving direction-setting in the hands of a few\n> people with limited resources and imperfect vision)\n>\n> nobody is an architectural demigod.  if there had been solid\n> community support for the http extension framework it would\n> have gone to proposed standard.    if there is solid support\n> in the future it can still go forward, but at this point it\n> is not at all clear that there is solid support for extending\n> http at all, much less via the proposed mechanisms.\n>\n> > I am not saying I have the answer, but I dont know if its right that\n> > the IETF should say \"You must not expand the scope of HTTP\".\n>\n> the IETF is the entire community of participants.  but the 'leaders'\n> of that community have to be careful to not misrepresent the\n> consensus of that community by mislabelling things as proposed\n> when they don't have the necessary community support.\n>\n> > If I want\n> > to represent, lets say, my email store as a web server (with HTTP and\nDAV)\n> > and I want to use it as my client mail protocol, then I should be able\nto.\n>\n> you can do whatever you want, but don't expect IETF to endorse it\n> just because you do it\n>\n> > If other vendors wish to do the same, and we want to do it in an\n> > interoperable  way, then the IETF should provide the forum to do so.\n>\n> if IETF were to adopt that logic, it would end up wasting resources\n> on every hairbrained scheme that any particular set of vendors came up\n> with.  it would be a self-induced denial-of-service attack.\n>\n> >  As an outsider, I feel as if the W3c has delegated the protocol work\n> > of HTTP to the IETF to avoid overlapping work.  IETF does protocols.\n> > If the IETF is simply taking HTTP and keeping it locked up in a cage\n> > in the basement, then it is not holding up its end of the bargain.\n>\n> HTTP is not in a cage, but it is abundantly clear that HTTP is\n> optimized for web-page access and that it is  pessimized\n> for many other purposes - and the notion that one should\n> try to extend HTTP for random other purposes is one that\n> has met with skepticism and some opposition.\n>\n> remember the t-shirt with the hammers?  why do you think one\n> of them was labelled HTTP?\n>\n> > As a result, IMHO, its stifling (my interpretation) of timbl's view of\n> > the web.\n>\n> nobody is an architectural demigod.\n>\n> > Every document, email message,buddy list, etc is a resource\n> > with a URL and can be manipulated by web transport protocols, a la\nHTTP.\n>\n> the second part doesn't follow from the first.  URL notation is\n> highly useful but HTTP is ill-suited for transport of many of\n> the things that one would use URLs for.\n>\n\n\n\n", "id": "lists-007-8636549"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> The main thing I'd look for is not to change any of the criteria,\n> but to focus on process improvements that would allow IETF working\n> groups to reach conclusions more quickly.\n>\n> Personally, I think a small amount of Internet-based collaboration\n> support for tracking issues in working groups, coupled with\n> some better group focus and management would go a long way toward\n> making the process more responsive.\n\nManagement/coordination without accountability is useless. However, there\nis no reason why the accountability should be any different than for any\nother working group so we should just use that mechanism already in place.\nHowever, that coordination and review has to be there.\n\n> As for HTTP extensions, I think draft-frystyk-http-extensions-03.txt\n> is inadequate as an extension framework for HTTP.\n\nThat's interesting but unfortunately wrong. Larry - you didn't do your\nhomework:\n\n> RFC 2324 uses the following kinds of HTTP extensions:\n>\n> new method\n\nThis is what you have the mandatory mechanism for. Think of M- as a macro\nfacility.\n\n> new URL scheme(s)\n\nThis has hardly anything to do with HTTP extensions and is already handled\nby HTTP.\n\n> new header\n\nThis is what you have the optional mechanism for.\n\n> new value for old header\n\nThis is a bad idea in any case\n\n> new MIME type for POST body\n\nThere already is a registry for this so why come up with another one?\n\n> new return code\n\nThis is what you have 510 status code is for. Think of 510 as a macro\nfacility.\n\n> new interpretation for old return code\n\nYour example is solved using the optional mechanism (bad description of\nproblem)\n\n> Of these, frystyk-http-extension only covers a few,\n> and in a haphazard way.\n\nCome on, Larry - don't be silly. Stick to constructive arguments.\n\nHenrik\n\n\n\n", "id": "lists-007-8656307"}, {"subject": "RE: HTTP Extensions Framework status", "content": "> > RFC 2324 uses the following kinds of HTTP extensions:\n> >\n> > new method\n>\n> This is what you have the mandatory mechanism for. Think of M- as a macro\n> facility.\n\nBut the problem is that it just pushes the complexity one level down.\nThe important step in the process:\n\n   2.  Examine all extensions identified in 1) and determine if they\n       are supported for this message. If not, respond with a 510 (Not\n       Extended) status-code (see section 7);\n\nis non-determinite. There is no effective way to compute whether extensions\n\"are supported\" or not, because extensions have extensions, and the\nextensions to the extension mechanisms don't have an extension mechanism.\n\nSo you can have a mandatory header that requires the recipient to\nhave implemented the \"copyright\" feature, but the \"copyright\" feature\nitself evolves with uncontrolled complexity; there is no leverage\nin ever renaming the features any more than there was in renaming\nthe methods.\n\n> > new URL scheme(s)\n>\n> This has hardly anything to do with HTTP extensions and is already handled\n> by HTTP.\n\nBut new URLs and new URL schemes are a fine way of extending web\napplications that don't require any kind of changes to HTTP.\nAfter all, the use of new URLs are the only mandatory end-to-end\nextension mechanism that is uniformly deployed.\n\n> > new header\n>\n> This is what you have the optional mechanism for.\n>\n> > new value for old header\n>\n> This is a bad idea in any case\n\nOh, surely not. There has to be some kind of extensibility mechanism\nfor the value space of each HTTP header. In most cases, it is some\nkind of registry, but don't you need the same mechanisms for mandatory\nand optional for things like TRANSFER-ENCODING?  frystyk-http-extensions\ndoesn't have much to say about these kinds of extensions.\n\n> > new MIME type for POST body\n>\n> There already is a registry for this so why come up with another one?\n\nThe MIME type of a POST body is also a mandatory extensibility\nmechanism, although I imagine it's not widely implemented. But\nyour document purports to cover how HTTP can be extended, and it\ndoesn't address this possibility.\n\n\n> > new return code\n>\n> This is what you have 510 status code is for. Think of 510 as a macro\n> facility.\n\n??? 510 Not Extended doesn't give you a way of adding new status\ncodes. The extension mechanism seems to be only one way; the client\ncan request an extension, but the server can't return anything\nnew unless asked.\n\n> > new interpretation for old return code\n>\n> Your example is solved using the optional mechanism (bad description of\n> problem)\n\n\nThere is no mechanism laid out in your draft for reuse of an\nold return code for a new purpose, or for defining new return\ncodes. I don't see how the \"optional\" mechanism applies.\n\n> > Of these, frystyk-http-extension only covers a few,\n> > and in a haphazard way.\n>\n> Come on, Larry - don't be silly. Stick to constructive arguments.\n\nThe argument is that the extensibility mechanism is on the one\nhand too complicated and on the other, insufficient to deal with\nmany of the kinds of extensibility that people want. The silly\nexamples in RFC 2324 were based on real proposals for HTTP extensions.\n\nLarry\n\n\n\n", "id": "lists-007-8668193"}, {"subject": "Re: HTTP Extensions Framework status", "content": "At 19:16 07.12.99 -0500, Keith Moore wrote:\n> > I like this response.  It sounds like a good thing to trial.\n> > However, its still tough to take the stigma of experimental,\n> > would be it possible to have the state called \"standards-track\n> > experimental\"?\n>\n>well, you can go to poisson and see whether you can convince them :)\n>\n>but my guess is - no.  if you want some IETF statement that the\n>work will be standards-track (that is, that this is indicative\n>of the direction that IETF will be taking) you need review from\n>the wider community, and some assurance that you're not working\n>at cross purposes  with other groups.  you have the option of\n>asking for Last Call for Experimental, but this is as much work\n>as asking for Proposed Standard.\n\nIMHO:\n\nDocuments have two versions of status: One that the \"great unwashed\" reads \ninto it, and one that careful people read into it.\n\nThe first one is a lost cause.\n\nThe second one can be influenced by such things as introductory paragraphs.\nIf you have an intro that says \"This technology is intended by the authors \nto go on IETF standards track, but it is of such world-shaking importance \nthat the community felt it best to get a little deployment experience \nbefore gaining consensus that this is the Way To Go and do standards \ntrack\", some careful people might read it, and some might even believe it.\n\nIf there are a few dozen experimentals like that, and the next step HAPPENS \nto some of them, the \"experimental stigma\" (if it exists) is likely to fade \nover time.\n\n                   Harald\n\n--\nHarald Tveit Alvestrand, EDB Maxware, Norway\nHarald.Alvestrand@edb.maxware.no\n\n\n\n", "id": "lists-007-8681160"}, {"subject": "RE: HTTP Extensions Framework status", "content": "On Mon, 6 Dec 1999, Josh Cohen (Exchange) wrote:\n\n> > -----Original Message-----\n> > From: Harald Tveit Alvestrand [mailto:Harald@Alvestrand.no]\n[...]\n> > We've got one. It's called EXPERIMENTAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n> >\n> Well, its no good if a standards track document cant reference it.\n\nYou can't reference it, but can't you just do a copy&paste of the parts\nyou need?\n\nOne of the main objections to making Mandatory proposed is that we are\nnot convinced, as a community, that using Mandatory is superior to all\nthe other ways of extending HTTP.  So we should not recommend that\neverybody make exclusive use of Mandatory by making it proposed. \n\nI am against making a strong IETF recommendation to use Mandatory. \nHowever, I don't feel that Mandatory is so bad that it must not be used at\nall. \n\nSo if you just want to use Mandatory in a single standards track protocol,\nI would have no big technical objections to that.  I'm more than happy to\nleave the Mandatory vs. new headers vs. new methods vs. whatever tradeoff\nto you.\n\nTo pull this use of Mandatory off procedurally, you'd have to copy&paste\nthe parts of Mandatory you really need into your own standards track\ndocument.  Maybe you'd need to add a disclaimer that the use of elements\nof the Mandatory mechanism in this particular protocol should not be seen\nas an endorsement of the idea that Mandatory is the one true way of\nextending HTTP. \n\nWhy not?  I'd never do it myself, because I would just define a bunch of\nnew headers and/or methods as a way of extending HTTP, but I would not\nobject if you go this route.  Of course others may have more extreme\nviews.\n\nKoen.\n\n\n\n", "id": "lists-007-8692453"}, {"subject": "Experimental standards (was: HTTP Extensions  Framework status?", "content": "At 15.44 -0800 99-12-07, Josh Cohen (Exchange) wrote:\n> I like this response.  It sounds like a good thing to trial.\n> However, its still tough to take the stigma of experimental,\n> would be it possible to have the state called \"standards-track experimental\"?\n\nThe problem is that many implementors are not interested\nin implementing things which are marked as \"experimental\".\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-8704429"}, {"subject": "RE: HTTP Extensions Framework status", "content": "At 16.11 -0800 99-12-07, Yaron Goland (Exchange) wrote:\n> So be it. It would appear that all HTTP extensions (GENA,\n>SSDP, SOAP, etc.) will now be marked experimental. It will\n>be annoying to educate the press on these issues but that\n>sounds easier than getting the IESG enthusiastic about\n>HTTP.\n\nOne of the most important HTTP extensions, WEBDAV, is a\nProposed standard. It is important because it is so\ngeneral-purpose, can be used for much more than distributed\nauthoring.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-8712484"}, {"subject": "RE: HTTP Extensions Framework status", "content": "--On 99-12-08 15.50 +0100 Koen Holtman <Koen.Holtman@cern.ch> wrote:\n\n>> Well, its no good if a standards track document cant reference it.\n> \n> You can't reference it, but can't you just do a copy&paste of the parts\n> you need?\n\nYou have to differ between normative and non-normative references. It is\nonly normative references which can not be made in whatever way you want.\n\nIn most cases the difference between a normative and non-normative is just\na matter of wording. So, if you just is careful you can have your document\ngoing to proposed with (non-normative) references to documents which are\nexperimental.\n\n   paf\n\n\n\n", "id": "lists-007-8720405"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> But the problem is that it just pushes the complexity one level down.\n> The important step in the process:\n>\n>    2.  Examine all extensions identified in 1) and determine if they\n>        are supported for this message. If not, respond with a 510 (Not\n>        Extended) status-code (see section 7);\n>\n> is non-determinite. There is no effective way to compute whether\nextensions\n> \"are supported\" or not, because extensions have extensions, and the\n> extensions to the extension mechanisms don't have an extension\nmechanism.\n>\n> So you can have a mandatory header that requires the recipient to\n> have implemented the \"copyright\" feature, but the \"copyright\" feature\n> itself evolves with uncontrolled complexity; there is no leverage\n> in ever renaming the features any more than there was in renaming\n> the methods.\n\nExtension declarations give you identification, very much like XML name\nspaces. They don't provide any information about what is behind the\nidentifier. The rule is that semantics of an extension should only\nchange if the identifier changes as well. This is what is covered by\nsection 8 \"Publishing an extension\" which at the heart is about how\npeople in practice will do extensions.\n\nYou don't have to resolve all the dependencies in order to determine\nwhether you support an extension or not - just look at the identifier at\nhand. This is equivalent of saying that it's ok to do a GET request\nknowing that the document you get back may have references to things you\ndon't understand.\n\nOnce we solve the problem of identification (and thereby grouping) we\nmay be able to move on to look at higher level semantics but we have to\nlearn to crawl before we can walk.\n\n> > > new URL scheme(s)\n> >\n> > This has hardly anything to do with HTTP extensions and is already\nhandled\n> > by HTTP.\n>\n> But new URLs and new URL schemes are a fine way of extending web\n> applications that don't require any kind of changes to HTTP.\n> After all, the use of new URLs are the only mandatory end-to-end\n> extension mechanism that is uniformly deployed.\n\nThis is really an orthogonal issue. The URI is an identifier and may be\nresolvable in many ways - or maybe not at all. In the case of using HTTP\nfor resolving URIs of any type, HTTP is the resolver, if you like, and\nHTTP extension framework is a mechanism for extending HTTP, not the URI\nspace.\n\n> > > new value for old header\n> >\n> > This is a bad idea in any case\n>\n> Oh, surely not. There has to be some kind of extensibility mechanism\n> for the value space of each HTTP header. In most cases, it is some\n> kind of registry, but don't you need the same mechanisms for mandatory\n> and optional for things like TRANSFER-ENCODING?\nfrystyk-http-extensions\n> doesn't have much to say about these kinds of extensions.\n>\n> > > new MIME type for POST body\n> >\n> > There already is a registry for this so why come up with another\none?\n>\n> The MIME type of a POST body is also a mandatory extensibility\n> mechanism, although I imagine it's not widely implemented. But\n> your document purports to cover how HTTP can be extended, and it\n> doesn't address this possibility.\n\nThere is no way the extension framework in any way is able to modify\nwhat is already spec'ed and deployed in HTTP, nor should it. If you\nchoose to use the existing HTTP extension facilities then that is fine\nand the Extension Framework doesn't in any way prevent you from doing\nthat.\n\nSeveral of the comments on the framework are of the type: \"I can get by\nwith existing means\" . I have no objections against this what so ever.\nBut what is good for one if not necessarily good for everybody else. One\nof the reoccuring problems with the existing extension mechanisms is\nthat it is hard to deploy extensions in a distributed way and even more\nimportant, it is hard to get rid of them again. This is what the\nextension framework is all about.\n\nThis is why the purpose of the extension framework is stated \"to address\nthe tension between private agreement and public specification and to\naccommodate extension of applications using HTTP clients, servers, and\nproxies.\". It doesn't say anything about replacing existing mechanisms.\n\nIf you think this has to be stated clearer then that's fine with me.\nMaybe something like:\n\n\"The Extension Framework provides a mechanism for extending HTTP using a\ncertain extensibility model that is designed to work in a distributed\nenvironment without central control. It does not disallow using any\nexisting HTTP extension hook instead of or in conjunction with this\nmechanism.\"\n\n> ??? 510 Not Extended doesn't give you a way of adding new status\n> codes. The extension mechanism seems to be only one way; the client\n> can request an extension, but the server can't return anything\n> new unless asked.\n\nThe 510 Not Extended is a place holder where several extensions can be\nplaced in the header fields explaining what is needed. The problem with\na status code is that there can be only one - what if I have two\nextensions that both are placed in the same message and both need a\nstatus code? They can't do this. Instead, the extension framework uses\nthe only \"open-ended\" space in HTTP which is the header.\n\nTherefore, don't think in terms of: \"I need a 4xx HTTP status code and a\nFOOBAR HTTP method\" but rather: \"I have an extension that defines a\nFOOBAR mechanism and an error state\". The extension framework allows you\nto express this without conflicting with other extensions that you don't\nknow about.\n\n> There is no mechanism laid out in your draft for reuse of an\n> old return code for a new purpose, or for defining new return\n> codes. I don't see how the \"optional\" mechanism applies.\n\nThe new semantics is really in the header field you added and as a\nheader field, you just use an optional declaration.\n\n> The argument is that the extensibility mechanism is on the one\n> hand too complicated and on the other, insufficient to deal with\n> many of the kinds of extensibility that people want. The silly\n> examples in RFC 2324 were based on real proposals for HTTP extensions.\n\nThe current Extension Framework spec is making a very conscious\nbalancing act between what is needed and what you get. I agree with Roy\nthat it is already complex and there is no reason to make it even\nharder. You can quite easily use the extension framework to implement\nrfc 2324 but you have to be following the decentralized model it\nprovides. You can't think of it in terms of the centralized\nextensibility model currently in HTTP.\n\nHenrik\n\n\n\n", "id": "lists-007-8730735"}, {"subject": "RE: HTTP Extensions Framework status", "content": "> -----Original Message-----\n> From: Larry Masinter [mailto:lmm@acm.org]\n> Sent: Wednesday, December 08, 1999 3:52 PM\n> To: moore@cs.utk.edu; Josh Cohen (Exchange)\n> Cc: Harald Tveit Alvestrand; Yaron Goland (Exchange); 'Patrik\n> Faltstrom'; Scott Lawrence; discuss@apps.ietf.org; Peter Ford \n> (Exchange)\n> Subject: RE: HTTP Extensions Framework status? \n> \n> \n> It seems like there are two contradictory things being requested:\n> \n> a) Proposed Standard is too hard, let's have something like\n>    <small>temporary possible maybe proposed</small> <em>Standard</em>\n>    so that we can ship code based on poorly written specs\n>    and let our marketing department say the \"temporary possible\n>    maybe proposed\" part softly and the \"standard\" part loudly.\n> \n> And I don't think we need to accomodate the marketing departments\n> that want to call something \"standard\". For decades, there\n> have been successful companies shipping networking systems\n> without the benefit of calling it \"standard\". The value\n> of the standards process is to create specifications of\n> lasting value.\n> \nLarry, this is pure flamebait and its implying ridiculous things.\nYou know me, Alex, Yaron and the rest of us.  We are far\nfrom marketing people.  For the purposes of this discussion\nI could care less about the marketing labels of standards.\nThe point here is about INTEROP, not marketing labels.\n\nAgain, if we want to do X over Y in an interoperable fashion\nwe need a forum to work it out in an open way.   \n(Substitute your fav APP and protocol for X and Y respectively).\n\nPlease dont cloud this discussion with FUD about intentions\nwhich are irrelevant.  Shame on you..\n\n\n\n", "id": "lists-007-8747353"}, {"subject": "RE: HTTP Extensions Framework status", "content": "> -----Original Message-----\n> From: Koen Holtman [mailto:Koen.Holtman@cern.ch]\n> Sent: Thursday, December 09, 1999 1:51 AM\n> To: Josh Cohen (Exchange)\n> Cc: Harald Tveit Alvestrand; Yaron Goland (Exchange); 'Patrik\n> Faltstrom'; Yaron Goland (Exchange); Scott Lawrence; moore@cs.utk.edu;\n> discuss@apps.ietf.org; Peter Ford (Exchange); Koen Holtman\n> Subject: RE: HTTP Extensions Framework status? \n> \n> \n> \n> \n> One of the main objections to making Mandatory proposed is that we are\n> not convinced, as a community, that using Mandatory is superior to all\n> the other ways of extending HTTP.  So we should not recommend that\n> everybody make exclusive use of Mandatory by making it proposed. \n> \nThis implies that there are other \"ways\" on the table.  I have seen\nnone, and none have been proposed as alternatives.\nWhen functionality is desired, and no other good alternative\nshows its head, our obligation is to move forward with the\none that is at hand.\n\"proposed\" means proposed.  If a new scheme comes along\nit could easily obsolete the current spec.\n\n\n\n", "id": "lists-007-8759456"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> When functionality is desired, and no other good alternative\n> shows its head, our obligation is to move forward with the\n> one that is at hand.\n\nour obligation is to follow the process rules.\n\nand (not specifically referring to this proposal)\njust because we don't have a good idea about how to do so something\ndoesn't mean that we need to bless a bad idea for how to do it.\nsometimes we need to say \"we don't think this is good enough yet,\nbut here's the best thing we have come up with\".  but if it doesn't\nmeet the criteria for standards-track, it can't get published\nas standards-track.\n\n> \"proposed\" means proposed.\n\n\"proposed\" means what it says in RFC 2026.\n\nKeith\n\n\n\n", "id": "lists-007-8771090"}, {"subject": "Re: HTTP Extensions Framework status", "content": "At 22.40 -0500 99-12-08, Keith Moore wrote:\n> \"proposed\" means what it says in RFC 2026.\n\nThe IETF terminology is quite confusing.\nThe stages a document passes are:\n\n(1) IETF draft\n(2) Sometimes Experimental standard\n(3) Proposed standard\n(4) Draft standard\n(5) Standard\n\nIt is rather confusing that the word\n\"draft\" occurs twice in different places\nin this list.\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/jpalme/\n\n\n\n", "id": "lists-007-8781156"}, {"subject": "Re: HTTP Extensions Framework status", "content": "> (2) Sometimes Experimental standard\n\nthe word \"standard\" doesn't belong here\n\n> It is rather confusing that the word\n> \"draft\" occurs twice in different places\n> in this list.\n\nyes, this is confusing.  I spend a lot of time explaining it to reporters.\n\nKeith\n\n\n\n", "id": "lists-007-8789060"}, {"subject": "Announcement of the Internet Spatial Location Foru", "content": "Dear Colleagues: \n\nInternet Spatial Location Forum, a discussion list on IP-related \nlocation issues is now active.\n\nThe setting up of the forum is sparked by the huge practical value \nand the unreadiness of the spatial location capability for the \nInternet. The missing capability becomes even more demanded with \nthe integration of IP and various network technologies including \ncellular and mobile systems. The forum is thus set up after our \ndiscussions with the leaders and some other members of IETF. \nIt serves as a pre-BOF mailing list for applying a BOF in 47th IETF \nto address those location issues. The detailed description can be \nfound at 'http://www-nrc.nokia.com/ip-location'.\n\nIts immediate goals are: (1) Collect the interests, concerns, and \nsuggestions on an IP spatial location protocol, (2) Identify the \nfurther requirements of the location protocol, (3) Seek partners \nand enthusiasts for the joint effort, (4) Invite volunteers for \ntheir presentations on the location issues, and (5) Prepare the \nBOF charter for the location protocol.\n\nIn brief, there is now a well-evaluated concept in its pregnancy. \nPlease add your own influences onto its progress.\n\nTo subscribe to the list, just email 'majordomo@research.nokia.com'\nwith 'subscribe ext-ip-location' in the mail body. To discuss , just \nemail the mailing list 'ext-ip-location@research.nokia.com'. More \ninformation (detailed forum description, mailing list archive, etc.) \ncan be found at the web page 'http://www-nrc.nokia.com/ip-location'.\n\nThank you for reading this far! Please forward this mail to anyone \nelse who may be interested. Please visit the forum's web page and \ncontribute by sending email to the mailing list. Thanks again!\n\n\nYours truly,\n\nHaitao Tang / Eric Brunner\n\n\n\n", "id": "lists-007-8796158"}, {"subject": "IRC/Realtime Chat W", "content": "Has any thought been given to the creation of an IRC or other realtime chat\nworking group?\n\nAs an ircd developer, client hacker, and frustrated user, the lack of\nstandards is becoming a greater problem. The only standard to turn to is a\nvery outdated RFC, which doesn't cover much of the ambiguity that's causing\nproblems now.\n\nAny thoughts before I persue this further?\n\nKevin Day\n\n\n\n", "id": "lists-007-8809012"}, {"subject": "Re: IRC/Realtime Chat W", "content": "In a related note, I know of one group that wishes to register an irc\nURL scheme and standardize handling of channel handling; I'll forward\nyour mail to one of the salient folk.\nregards,\nTed Hardie\n\n\n\n> \n> \n> Has any thought been given to the creation of an IRC or other realtime chat\n> working group?\n> \n> As an ircd developer, client hacker, and frustrated user, the lack of\n> standards is becoming a greater problem. The only standard to turn to is a\n> very outdated RFC, which doesn't cover much of the ambiguity that's causing\n> problems now.\n> \n> Any thoughts before I persue this further?\n> \n> Kevin Day\n> \n\n\n\n", "id": "lists-007-8816499"}, {"subject": "Re: IRC/Realtime Chat W", "content": "At 15:08 30.12.99 -0600, Kevin Day wrote:\n\n>Has any thought been given to the creation of an IRC or other realtime chat\n>working group?\n>\n>As an ircd developer, client hacker, and frustrated user, the lack of\n>standards is becoming a greater problem. The only standard to turn to is a\n>very outdated RFC, which doesn't cover much of the ambiguity that's causing\n>problems now.\n>\n>Any thoughts before I persue this further?\nThe only activity I've seen in this space recently is Christoph Kalt's \nattempt to document the existing protocol before going any further - see \ndraft-kalt-irc-* for the details. Helping him get it out the door would be \na Good Thing - last updates were in October, according to my timestamps.\n\nIRC seems to be among the areas with a large number of people who want to \nsee something done, but a very low ability to get agreement on what that \n\"something\" is. I hope this will change.....\n\n                            Harald A\n\n--\nHarald Tveit Alvestrand, EDB Maxware, Norway\nHarald.Alvestrand@edb.maxware.no\n\n\n\n", "id": "lists-007-8824123"}, {"subject": "Re: IRC/Realtime Chat W", "content": "> Has any thought been given to the creation of an IRC or other realtime chat\n> working group?\n\nhttp://www.ietf.org/html.charters/impp-charter.html\n\nNed\n\n\n\n", "id": "lists-007-8832502"}, {"subject": "Re: IRC/Realtime Chat W", "content": "> \n> > Has any thought been given to the creation of an IRC or other realtime chat\n> > working group?\n> \n> http://www.ietf.org/html.charters/impp-charter.html\n> \n> Ned\n> \n\nYeah, I saw impp, however it really doesn't apply to IRC, and seems to have\nquite a different target that what I was looking for.\n\nThe goals I was more considering were a new IRC RFC that takes into account\nmost/all of the server/client communications(which I realize someone is\nworking on now), as well as architecting enhancements to the IRC protocol in\na standard way.\n\nMany IRC networks are all trying to add the same features, but doing them in\ndrastically different ways. Right now, the acid test to see if a new feature\nwill suceed is if you can convince Khaled Mardam-Bey to add support for it\nin mIRC. I have a great respect for Khaled, and have worked with him in the\npast. However, all client authors face the problem of deciding what to spend\ntime on. \n\nDocumenting and extending the IRC protocol is quite a task of its own, which\nI believes differs from impp. I'd also like to at lesat consider the notion\nof overlapping work between an irc and impp group, since they do share many\ncommon ideas.\n\nKevin\n\n\n\n", "id": "lists-007-8839819"}, {"subject": "Re: IRC/Realtime Chat W", "content": "> > > Has any thought been given to the creation of an IRC or other realtime chat\n> > > working group?\n\n> > http://www.ietf.org/html.charters/impp-charter.html\n\n> Yeah, I saw impp, however it really doesn't apply to IRC, and seems to have\n> quite a different target that what I was looking for.\n\nWhile it may not apply to IRC specifically, it definitely does touch on the\narea of realtime chat.\n\n> The goals I was more considering were a new IRC RFC that takes into account\n> most/all of the server/client communications(which I realize someone is\n> working on now), as well as architecting enhancements to the IRC protocol in\n> a standard way.\n\nIt would certainly be a nice thing to do. But frankly, I don't think the IETF\nhas the bandwidth at present to undertake two such efforts.\n\nNed\n\n\n\n", "id": "lists-007-8848331"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "Chris,\n\nAt 12:20 29/01/99 -0800, Chris Newman wrote:\n>On Fri, 29 Jan 1999, Graham Klyne wrote:\n>> Specifically, I find the idea that we can \"design a simple core protocol to\n>> address these problems\" is something of a tall order.\n>\n>You may be right.  But what if we can?  Just because it might be hard does\n>that mean we shouldn't try?\n\nI wouldn't say we shouldn't try \"just because...\".  (I might argue that\ngiven a choice between useful goals, I'd pick one more likely to succeed.)\n\n\n>I'll note one ad-hoc attempt at such a \"core protocol\" was published as\n>draft-earhart-ap-spec-01.txt (January 1998).\n\nScanning through that, and re-reading your original proposal message, has\nhelped me to focus some issues.  I don't think our views are miles apart here.\n\nA passage from \"draft-earhart-ap-spec-01.txt\" particularly struck me:\n\n   It is recognized that not all application level protocols will fit\n\ninto this model; TELNET is a good example of a protocol that does not\n\nbelong in this framework.  Nevertheless, it is believed that this is\n   of\nsufficient utility to enough protocols to be worth advancing as an\n   IETF\nstandard.\n\nFor me, this begs the question:  what are the characteristics of these\n\"enough protocols\" for which such a framework is maybe \"of sufficient\nutility\"?  You have already enunciated part of the answer I was seeking:\n\"based on the connection-based stateful client-server structure ...\"\n\nWhat are the key components of \"draft-earhart-ap-spec-01.txt\"?  I perceive:\n\n(1) a \"session state\" model dealing with initiation, authentication,\ntermination and application-specific states.\n(2) a framework for declaring server capabilities\n(3) a request/response framework, with tagging to allow overlapped operations.\n(4) a framework for unsolicited status updates\n(5) some syntax elements for construction of requests and responses,\nincluding some formats for simple and structured data\n(6) some core capabilities, request verbs, response codes\n\nIn my view, this could be seen as a small number of separate work items:\n\n(a) a small core protocol document could cover (2)-(5).\n\n(b) A separate document could cover the basic initiation and authentication\nframework, associated server states, request verbs, response codes, etc.\n\n(c) A guidelines document could describe how to build application protocols\nusing (a) and (b), together with other considerations that should be\naddressed by a protocol specification.  (I think this could usefully draw\nupon your -protocol-design- document.)\n\n\nSome additional random thoughts I have:\n\n- It would help if there were clear mechanisms for transferring MIME\nobjects with both requests and responses.  On my brief scan, it's not clear\nhow to do this with the -ap-spec- framework.  (I don't mean to necessarily\nadapt the protocol for MIME specifically, just make it clear how MIME (and\nmaybe other arbitrary objects) are transferred within the overall framework.)\n\n- If each application protocol based on the framework were identified by\nits own capability, any server would automatically be completely\nself-identifying in that respect (see also section 6 of -ap-spec-).\n\n- Should the request framework have any explicit provision for using URIs\nto identfy objects?\n\n- I'd personally like to see a development of the RFC 1893 status code\nframework for more widespread use (providing language-neutral status\nindicators).\n\n- I do think that there are some issues of interaction beytween server\nstate and overlapped requests that must be carefully considered (or flagged\nfor application designers to carefully consider).  E.g.  what happens if a\nLOGOUT is presented while some other command is being processed?\n\n\nTo summarize:\n\nIn practice, I don't think a core-protocol plus application-specification\nwould be a complete application protocol definition.  References to other\ncomponents (e.g. MIME, TLS, SASL, RFC1893, S/MIME, etc.) would, I think, be\nthe norm.  This is the respect in which I saw protocol components being\nimportant;  I now perceive that you did not mean to exclude this, just not\ntake these other protocol elements into scope.  I would still like to see\nsome separation of concepts in the core components, as indicated above, but\nnot fragmentation.\n\nIn preparation for undertaking such a design, I do think it would be\nhelpful to enumerate some commonly-used current application protocols and\nnote their strengths and weaknesses in practical deployment.  I also think\nthat work from other groups like the HTTP NG effort should be examined for\nsuitability before embarking on yet another protocol design effort.\n\nI hope you find this constructive,\n\n#g\n\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-8913817"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Mon, 1 Feb 1999, Graham Klyne wrote:\n> At 12:20 29/01/99 -0800, Chris Newman wrote:\n> >On Fri, 29 Jan 1999, Graham Klyne wrote:\n> >> Specifically, I find the idea that we can \"design a simple core protocol to\n> >> address these problems\" is something of a tall order.\n> >\n> >You may be right.  But what if we can?  Just because it might be hard does\n> >that mean we shouldn't try?\n> \n> I wouldn't say we shouldn't try \"just because...\".  (I might argue that\n> given a choice between useful goals, I'd pick one more likely to succeed.)\n\nWe have solved most of the \"core\" protocol problem every time we've\ndesigned a new application protocol.  Having a generalized \"core protocol\" \nwhich was popular would greatly simplify the design of new protocols and\nmulti-protocol software as well as providing a viable alternative to\nabusing existing protocols.  That justifies trying in my book.\n\n> For me, this begs the question:  what are the characteristics of these\n> \"enough protocols\" for which such a framework is maybe \"of sufficient\n> utility\"?  You have already enunciated part of the answer I was seeking:\n> \"based on the connection-based stateful client-server structure ...\"\n\nWhat protocol facilities are common to most of FTP, HTTP, IMAP, LDAP,\nNNTP, POP, SMTP/ESMTP, Telnet and our other successful protocols?  And I\nwon't answer because I think that's a question the proposed WG should\nanswer as part of the first draft.\n\n> In my view, this could be seen as a small number of separate work items:\n> \n> (a) a small core protocol document could cover (2)-(5).\n> \n> (b) A separate document could cover the basic initiation and authentication\n> framework, associated server states, request verbs, response codes, etc.\n> \n> (c) A guidelines document could describe how to build application protocols\n> using (a) and (b), together with other considerations that should be\n> addressed by a protocol specification.  (I think this could usefully draw\n> upon your -protocol-design- document.)\n\nIt could be seen that way.  But why break a 25 page spec into three 15\npage specs?  It'd be more useful to have a single \"core protocol\" document\nto reference, even if it's internally structured into the three parts you\nsuggest.\n\n> In practice, I don't think a core-protocol plus application-specification\n> would be a complete application protocol definition.  References to other\n> components (e.g. MIME, TLS, SASL, RFC1893, S/MIME, etc.) would, I think, be\n> the norm.\n\nThe proposed charter certainly permits this.\n\n> I would still like to see\n> some separation of concepts in the core components, as indicated above, but\n> not fragmentation.\n\nIf you think there's something wrong with the proposed charter, please\nsuggest alternative wording.\n\n> In preparation for undertaking such a design, I do think it would be\n> helpful to enumerate some commonly-used current application protocols and\n> note their strengths and weaknesses in practical deployment.\n\nThat's the point of the first draft described in the proposed charter.\n\n> I also think\n> that work from other groups like the HTTP NG effort should be examined for\n> suitability before embarking on yet another protocol design effort.\n\nIf I end up as chair or co-chair of this effort, I would go to other\ngroups to get candidate solutions.  A subset of the HTTP NG work might be\na candidate solution if they're far enough along.  The DIAMETER core\nprotocol is also close to a candidate solution, as is the Earhart draft.\nThe problem is that each of these efforts is only illuminated by a small\nsubset of the operational experience we have collectively with application\nprotocol \"cores.\"\n\n- Chris\n\n\n\n", "id": "lists-007-8927864"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": ">I'd prefer to focus on a single \"core protocol\" based on the\n>connection-based stateful client-server structure that most successful\n>IETF application protocols follow.  There are obviously other protocol\n>models with which we have far less experience, but most of those _are_\n>research problems and thus out-of-scope. \n\nIt has been my experience that an application protocol must match\nthe interaction style of the application components.  Otherwise, it will\nfail to meet the minimal performance requirements of that application\nand be replaced by an application protocol that does.  For example,\n\"stateful\" excludes HTTP and any reasonable transfer protocol for\nthe Web.\n\nI think that it won't be useful to come up with a \"core\" application\nprotocol unless those core components can adapt according to multiple\ninteraction styles and multiple underlying transports.  If that is too\nlarge a scope, then the \"common core\" being developed must be limited\nto a single interaction style.  Besides, if you are going to limit the\ncore to things occurring in two or more successful IETF protocols, then\nthe only application being supported is store-and-forward messaging.\nI think a \"store-and-forward core\" is far more likely to be usable by\nfuture protocols than a general application core that only considers\na subset of applications.\n\n....Roy\n\n\n\n", "id": "lists-007-8939514"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Fri, 29 Jan 1999 13:56:22 +0000 Graham Klyne <GK@dial.pipex.com> wrote:\n\n> While I applaud the general intent, I echo other concerns that the goal \n> is too ambitious.\n> \n> Specifically, I find the idea that we can \"design a simple core protocol to\n> address these problems\" is something of a tall order.  What I do think may\n> be achievable is to identify a range of problems, and then make\n> recommendations about solutions to these.\n\nI think that the term \"core protocol\" is misleading in many ways.    We \nreally don't want a complete protocol in and of itself.     Seems to me \nthat you could organize it into two distinct classes of thing that would \nbe described:\n\n1.   A general set of design guidelines for application protocols.   This \nwould include things like binary vs. text commands and payload, encoding \nschemes, specification syntaxes, etc.\n\n2.   A set of protocol components that you can assemble into a specific \nprotocol.   This would include many of the things that Chris had in his \nmessage like authentication, ACL's, capabilities/extensions, etc.    \nNot unlike a set of protocol subroutines or object classes.     The list of\naccepted components can be quite small to begin with. \n\nCheers.\n\n---  \nSteve Hole                           \nExecmail Inc.\nMailto:Steve.Hole@execmail.com \nPhone: 780-424-4922\n\n\n\n", "id": "lists-007-8948734"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Mon, 1 Feb 1999, Roy T. Fielding wrote:\n> It has been my experience that an application protocol must match\n> the interaction style of the application components.  Otherwise, it will\n> fail to meet the minimal performance requirements of that application\n> and be replaced by an application protocol that does.  For example,\n> \"stateful\" excludes HTTP and any reasonable transfer protocol for\n> the Web.\n\n  There're two basic issues which every application protocol has had to\ndeal with: the set of actions, and how those actions are represented on\nthe wire.  On top of that, there's some overlap -- not a lot, but some --\nin the set of actions that application protocols support; you need to have\na way to negotiate extensions and security, for example. \n\n  I would argue that there's some utility in providing a common encoding\nand a set of basic commands which application protocols appear to have in\ncommon; this is really the drudgework of designing an applications\nprotocol, and we *know* how to do it well. \n\n  Applications could then simply define their specific commands on top of\nthe basic set and standard encoding, and people could argue about the\ninteresting things, such as whether the protocol should be stateful or\nstateless, or whether it should be a store and forward model, instead of\narguing over whether it should be based on HTTP's syntax or LDAP's syntax\nor IMAP's syntax, which to my mind is a fairly boring issue best put aside\nas quickly as possible.\n\n  (It's akin to arguing over the transport layer; sure, you can always\ndesign a better one, but TCP's honestly good enough and is relatively kind\nto a network, and I'm really glad that everything's based on top of TCP\ninstead of having each applications protocol specify its own, wildly\ndifferent way of getting its messages to where they're supposed to go.)\n\n  )Rob\n\n\n\n", "id": "lists-007-8958770"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "I think a key question here is how to determine what the requirements are.  You've enunciated a \"newness test\" for features.  I suspect you don't mean to say that the requirements are \"every feature that isn't 'new'\".  What we've seen so far is a proposed list of \"problems to solve\"; on what basis should we argue for a problem to be included or excluded from this list?\n\nI'm skeptical that the given list can really be addressed in 25 pages or less.  For example, ONC RPC (RFCs 1831 and 1832) addresses just about exactly a subset of your proposed problems, isn't very complex, and the two RFCs add up to more than 25 pages.\n\nI also have a couple of things to say about your response to Carl-Uno's question of why ONC RPC didn't succeed.  You wrote: [[\nMy speculation, which I can't back up with research, is that RPC\nmechanisms are a poor choice in general for standards-based protocols.\nIt's much harder to design an extensible and simple API than it is to\ndesign an extensible and simple wire protocol.  In addition, APIs by their\nnature tend to have significant biases in the direction of programming\nlanguage or operating system.  Finally, RPCs are designed to \"hide\" the\nnetwork -- I think the network and network latency in particular needs to\nbe explicitly factored into the design at several levels.  Non-RPC\nprotocols tend to force that to happen in practice.\n]]\n\nI think it's critical to not confuse API design with wire protocol design.  HTTP/1.1, for example, *is* a request-response (i.e., RPC) protocol; it is also a wire protocol (I'm not sure I'd be willing to call it \"simple\", given that its spec is way over 25 pages).  API design brings in an additional set of problems, which the IETF has traditionally (though not completely --- witness GSS API) avoided.  For example, when I think about this kind of effort, I wonder about things like how to enable flexible mappings into programming languages for the standard data type system of the protocol (experience shows that a single standard mapping will not well serve all apps); I think the right solution is to have a flexible mapping mechanism, which is not a wire protocol problem (although presumption of such a thing may lessen requirements on the wire protocol).\n\nI do think one thing that has hampered adoption of existing general-purpose solutions is their monolithicity (inusually in both spec and implementation; while people do sometimes write subset implementations from scratch, that's a lot of work and sorely tempts the implementor to specialize the protocol).  I think that what we really need is a radically modularized standard protocol (in both spec *and* implementation), so that an application layered over it can get just what it needs and pay for no more.\n\nMike\n\n\n\n", "id": "lists-007-8968024"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "Chris Newman wrote:\n> \n> I'm interested in feedback on the following BOF/WG idea.  Do you think\n> this is a good/bad idea?  Any suggestions to improve the proposed charter?\n> Anyone interested in being a document editor of either of the two\n> proposed documents or interested in WG chair/co-chair position?\n> \n>                 - Chris\n> ------\n> The APPLCORE BOF will discuss the following proposed charter:\n> \n> Application core protocol WG  (APPLCORE)\n> \n> The IETF has traditionally developed application protocols directly on top\n> of a raw TCP stream.  However, there is a growing set of problems which\n> many application protocols have to solve regardless of what the protocols\n> do.  This WG will identify these problems, identify the successes and\n> failures that deployed IETF protocols made when addressing these problems\n> and design a simple core protocol to address these problems.  This core\n> protocol may then be used by future application protocols to simplify both\n> the process of protocol design and the complexity of implementing\n> multi-protocol servers.\n> ...\n\nInterestingly enough, this I-D was just published. It looks like it\nwould be relevant to this discussion.\n\nTony Hansen\ntony@att.com\n\n=============\nINTERNET-DRAFT                                               Tom Harding\nExpires: 1 August 1999                                ThinLink Solutions\n<draft-harding-extensible-protocol-00.txt>               1 February 1999\n\n                          Extensible Protocol\n\nAbstract\n\n   This memo defines the Extensible Protocol (XP).  XP is a generic\n   application-level protocol meant to serve as the foundation for\n   specific protocols, in a manner analogous to the way in which the\n   Extensible Markup Language (XML) recommendation of the World Wide Web\n   Consortium serves as the foundation for specific markup languages. XP\n   is a bidirectional protocol on which XML documents are exchanged\n   between two endpoints.\n=============\n\n\n\n", "id": "lists-007-8978456"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Mon, 1 Feb 1999, Roy T. Fielding wrote:\n> It has been my experience that an application protocol must match\n> the interaction style of the application components.  Otherwise, it will\n> fail to meet the minimal performance requirements of that application\n> and be replaced by an application protocol that does.\n\nIt's not uncommon in the IETF to hear similar mantras.  Every protocol\nneeds it's own custom framework.  Every protocol needs it's own custom\nsecurity protocols.  Perhaps we should encourage every protocol to use\nsomething other than TCP since TCP isn't a perfect fit for most protocols?\n\nThen you hear the flip side -- people who want to layer everything on top\nof HTTP because there's too much work to do if you start with raw TCP and\nthey want to reuse code.\n\nThere is an eternal tension between \"everything has to be perfectly\ndesigned for the task from the ground-up\" and \"let's reuse as much of\nwhat's out there as possible regardless of how well it fits.\"  Building\napps on TCP is a bit too far in the former direction for today's\nenvironment and building apps on HTTP is much too far in the latter\ndirection.  We need to achieve a better balance.\n\n> I think that it won't be useful to come up with a \"core\" application\n> protocol unless those core components can adapt according to multiple\n> interaction styles and multiple underlying transports.\n\nObviously an adaptable modular core would be more useful than a very\nrestrictive core.  But that's not a justification to avoid the problem.\n\n> If that is too\n> large a scope, then the \"common core\" being developed must be limited\n> to a single interaction style.  Besides, if you are going to limit the\n> core to things occurring in two or more successful IETF protocols, then\n> the only application being supported is store-and-forward messaging.\n> I think a \"store-and-forward core\" is far more likely to be usable by\n> future protocols than a general application core that only considers\n> a subset of applications.\n\nAlthough SMTP is used to create a store-and-forward messaging model, it\nlooks very similar in protocol structure to FTP and POP3 both of which use\na direct client-server command-response model.  The \"core\" is intended to\ncapture common protocol structure and provide a foundation for new\napplication protocols, not to provide high-level application services like\nstore-and-forward messaging, web browsing or the like.\n\n- Chris\n\n\n\n", "id": "lists-007-8988021"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Mon, 1 Feb 1999, Steve Hole wrote:\n> I think that the term \"core protocol\" is misleading in many ways.    We \n> really don't want a complete protocol in and of itself.     Seems to me \n> that you could organize it into two distinct classes of thing that would \n> be described:\n> \n> 1.   A general set of design guidelines for application protocols.   This \n> would include things like binary vs. text commands and payload, encoding \n> schemes, specification syntaxes, etc.\n> \n> 2.   A set of protocol components that you can assemble into a specific \n> protocol.   This would include many of the things that Chris had in his \n> message like authentication, ACL's, capabilities/extensions, etc.    \n> Not unlike a set of protocol subroutines or object classes.     The list of\n> accepted components can be quite small to begin with. \n\nIn one sense, I like the idea.  Personally, I'd have no trouble hunting\nthrough RFCs for good components to collect together and write up in a new\nprotocol.  But I don't mind designing protocols directly on top of TCP,\neither.  We really need a one-stop-shopping \"core protocol\" so one can\ndefine a new protocol by saying \"take the core protocol and AUTH command\nfrom RFC XXXX then add the following commands and run on port P\". \nOtherwise people will just say \"add these 20 methods to HTTP and you've\ngot whiz-bang protocol\" because that would be so much easier than\ncollecting together components and subtle design choice options from\nseveral RFCs into a coherent protocol.\n\n- Chris\n\n\n\n", "id": "lists-007-8998317"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Tue, 2 Feb 1999 spreitze@parc.xerox.com wrote:\n> I think a key question here is how to determine what the requirements\n> are.  You've enunciated a \"newness test\" for features.  I suspect you\n> don't mean to say that the requirements are \"every feature that isn't\n> 'new'\".  What we've seen so far is a proposed    \n>  list of \"problems to solve\"; on what basis should we argue for a\n> problem to be included or excluded from this list?\n\nWe're looking for problems that have to be solved in many or most\napplication protocols.  Furthermore, in order to keep such an effort from\nspinning off into a research project, it has to be restricted to only\naddressing the problems we're familiar with in the initial core document.\nOnce the core is done, perhaps people will make reusable pieces that can\nbe layered on top of it, just as people have made a few reusable pieces\nthat can be layered on TCP (e.g. TLS) -- but a WG has to be narrowly\nfocused and driven to succeed.\n\n> I'm skeptical that the given list can really be addressed in 25 pages or\n> less.  For example, ONC RPC (RFCs 1831 and 1832) addresses just about\n> exactly a subset of your proposed problems, isn't very complex, and the\n> two RFCs add up to more than 25 pages. \n\nXDR isn't a bad binary data encoding for the wire (certainly better than\nASN.1 BER), but it solves problems (like floating point numbers) which\nalmost never appear in real protocols.  The RPC spec had to go into a lot\nof detail about the model since RPCs are more constraining than\ntraditional IETF protocols.  So there's a lot of stuff there that a \"core\nprotocol\" wouldn't need. \n\nIt may not be possible to do a \"core protocol\" in under 25 pages, but it's\ncertainly a goal worth striving for and the proposed charter is worded so\nthe WG could change the simplicity litmus test by rough concensus as long\nas it has one.\n\n> I think that what we really need is a radically modularized standard\n> protocol (in both spec *and* implementation), so that an application\n> layered over it can get just what it needs and pay for no more. \n\nPrecisely.  I'd clarify that by noting I'd prefer one \"front end\" spec\nwhich would gather components from others (e.g. SASL, TLS) into a coherent\ncore protocol. \n\n- Chris\n\n\n\n", "id": "lists-007-9007688"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "Chris Newman wrote:\n> XDR isn't a bad binary data encoding for the wire (certainly better than\n> ASN.1 BER), but it solves problems (like floating point numbers) which\n> almost never appear in real protocols.  The RPC spec had to go into a lot\n> of detail about the model since RPCs are more constraining than\n> traditional IETF protocols.  So there's a lot of stuff there that a \"core\n> protocol\" wouldn't need.\n\nI think ONC RPC is pretty \"thin\" as RPC protocols go.  Is it really\nloaded with unnecessary baggage that disqualifies it as a candidate\nfor core protocol ?\n\nIt's been around for about 15 years, it's on IETF standards track,\nand hundreds of protocols have used it as a \"core\" protocol.\n\nWhat are the constraints that prevent ONCRPC from being the\n\"core\" protocol ?  Can those constraints be removed by extending\nit to version 3 ?  This discussion seems highly relevant to the\nONCRPC mailing list: oncrpc-wg-request@sunroof.eng.sun.com.\n\nBrent\n\n\n\n", "id": "lists-007-9018296"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "Roy Fielding wrote:\n> I think that it won't be useful to come up with a \"core\" application\n> protocol unless those core components can adapt according to multiple\n> interaction styles and multiple underlying transports.  If that is too\n> large a scope, then the \"common core\" being developed must be limited\n> to a single interaction style.\n\nI agree with this (whoa, I'll bet Roy is surprised :-)  Right away, the\nAPPLCORE protocol needs to decide whether it will be a set of protocol\ncomponents for a client to server protocol, or a server to server protocol.\nThis design choice has many repercussions, and cannot easily be abstracted\naway.  Similarly, already APPLCORE seems to be biased in favor of a stateful\nprotocol.  How do you resolve the stateful vs. stateless argument without\nthe problem domain supplying design descriminators?  Or, perhaps as Roy\nsuggests, the protocol needs to be usable with multiple interaction styles.\n\nBut, since a useful protocol can't be developed without making *some* design\nchoices, and since those design choices will not be applicable to all future\ndomains of use, perhaps developing a *protocol* as a deliverable is the\nwrong way to achieve the APPLCORE goals.\n\nThe proposed charter states:\n> An Informational RFC documenting the problems identified to solve,\n> and giving examples of existing deployed IETF protocols which\n> succeeded or made mistakes when solving those problems.  A starting\n> list of problems for the WG to discuss (the WG may choose not to\n> address some of these) follows:\n\nI support this deliverable, since it will provide a useful overview of the\ncommon applications protocol design space.  Although, instead of calling it\nthe \"problem identification\" draft, why not call this the \"design space\"\ndraft, since it will essentially be sketching the commonly occurring\nelements of the application protocol design space.\n\n> A standards track core application protocol specification which uses\n> the lessons learned from the informational document and fits the\n> litmus test above.  An open source implementation of the complete\n> core protocol must exist prior to IETF last call.  The problem\n> identification draft (above) must be completed prior to IETF last\n> call.\n\nI think that developing one \"core\" protocol is the wrong approach.\n\nIf the intent is to save time in the development of future protocols, a\nuseful output would be a collection of application protocol *design\npatterns* (note that I'm using design patterns in a more general sense that\nthe typical, heavily tied to object-methodology religion sense.  Substitute\nthe term \"design discussion\" if you wish, it's synonymous in my discussion).\nThese patterns can capture how a given problem has been commonly solved,\ngiving rationale both for and against the given solution.  A collection of\napplication protocol design patterns would have the benefit of being easily\napplied to a wide range of new protocol designs, yet wouldn't have the\ndrawback of the APPLCORE of having embedded design decisions (and there will\nbe implicit design decisions no matter how hard people think they're\navoiding them) which are inappropriate for a given domain of use.\nFurthermore, the design patterns will have a focus on design rationale,\nrather than creating a protocol where the design rationale is implicit in\nthe protocol elements (and 25 pages doesn't leave much room for design\nrationale).\n\nA collection of design patterns will speed the development of new protocols,\nsince a protocol which makes use of a pattern won't need to repeat all of\nthe rationale for the design choice, and will be able to more easily benefit\nat design time from existing protocol experience.  Thus it seems to me that\na collection of application protocol design patterns can achieve the goals\nof an APPLCORE protocol without needing to create a protocol which will be\ninappropriate for some use cases.  The design patterns approach has much\nbroader applicability than just a single protocol.\n\nMy recommendation is to replace the \"core application protocol\nspecification\" deliverable with this:\n\n* An Informational RFC which provides a collection of application protocol\ndesign patterns, where each design pattern distills the successful solutions\nof application protocols for each entry in the problem identification\ndocument.  While specific examples from individual protocols will provide\nrationale for the design pattern, each pattern will described in a\nprotocol-neutral manner.  The goal of this document is to capture the design\nrationale and solutions for common problems encountered by application layer\nprotocols so these \"lessons learned\" can quickly be applied to the design of\nnew protocols.\n\nWhy?\n\n- Because design patterns focus on design rationale, not on syntax\n- Because design patterns have applicability to more domains of use than a\nsingle protocol\n- Because design patterns expose design tradeoffs, rather than hiding them\nbehind a single normative choice\n\n- Jim\n\n\n\n", "id": "lists-007-9026329"}, {"subject": "RE: Application &quot;core protocol&quot; BOF/WG ide", "content": "Amen.\n\n> -----Original Message-----\n> From: Jim Whitehead [mailto:ejw@ics.uci.edu]\n> Sent: Thursday, February 04, 1999 12:52 PM\n> To: discuss@apps.ietf.org\n> Cc: Chris.Newman@INNOSOFT.COM\n> Subject: Re: Application \"core protocol\" BOF/WG idea\n> \n> \n> Roy Fielding wrote:\n> > I think that it won't be useful to come up with a \"core\" application\n> > protocol unless those core components can adapt according \n> to multiple\n> > interaction styles and multiple underlying transports.  If \n> that is too\n> > large a scope, then the \"common core\" being developed must \n> be limited\n> > to a single interaction style.\n> \n> I agree with this (whoa, I'll bet Roy is surprised :-)  Right \n> away, the\n> APPLCORE protocol needs to decide whether it will be a set of protocol\n> components for a client to server protocol, or a server to \n> server protocol.\n> This design choice has many repercussions, and cannot easily \n> be abstracted\n> away.  Similarly, already APPLCORE seems to be biased in \n> favor of a stateful\n> protocol.  How do you resolve the stateful vs. stateless \n> argument without\n> the problem domain supplying design descriminators?  Or, \n> perhaps as Roy\n> suggests, the protocol needs to be usable with multiple \n> interaction styles.\n> \n> But, since a useful protocol can't be developed without \n> making *some* design\n> choices, and since those design choices will not be \n> applicable to all future\n> domains of use, perhaps developing a *protocol* as a \n> deliverable is the\n> wrong way to achieve the APPLCORE goals.\n> \n> The proposed charter states:\n> > An Informational RFC documenting the problems identified to solve,\n> > and giving examples of existing deployed IETF protocols which\n> > succeeded or made mistakes when solving those problems.  A starting\n> > list of problems for the WG to discuss (the WG may choose not to\n> > address some of these) follows:\n> \n> I support this deliverable, since it will provide a useful \n> overview of the\n> common applications protocol design space.  Although, instead \n> of calling it\n> the \"problem identification\" draft, why not call this the \n> \"design space\"\n> draft, since it will essentially be sketching the commonly occurring\n> elements of the application protocol design space.\n> \n> > A standards track core application protocol specification which uses\n> > the lessons learned from the informational document and fits the\n> > litmus test above.  An open source implementation of the complete\n> > core protocol must exist prior to IETF last call.  The problem\n> > identification draft (above) must be completed prior to IETF last\n> > call.\n> \n> I think that developing one \"core\" protocol is the wrong approach.\n> \n> If the intent is to save time in the development of future \n> protocols, a\n> useful output would be a collection of application protocol *design\n> patterns* (note that I'm using design patterns in a more \n> general sense that\n> the typical, heavily tied to object-methodology religion \n> sense.  Substitute\n> the term \"design discussion\" if you wish, it's synonymous in \n> my discussion).\n> These patterns can capture how a given problem has been \n> commonly solved,\n> giving rationale both for and against the given solution.  A \n> collection of\n> application protocol design patterns would have the benefit \n> of being easily\n> applied to a wide range of new protocol designs, yet wouldn't have the\n> drawback of the APPLCORE of having embedded design decisions \n> (and there will\n> be implicit design decisions no matter how hard people think they're\n> avoiding them) which are inappropriate for a given domain of use.\n> Furthermore, the design patterns will have a focus on design \n> rationale,\n> rather than creating a protocol where the design rationale is \n> implicit in\n> the protocol elements (and 25 pages doesn't leave much room for design\n> rationale).\n> \n> A collection of design patterns will speed the development of \n> new protocols,\n> since a protocol which makes use of a pattern won't need to \n> repeat all of\n> the rationale for the design choice, and will be able to more \n> easily benefit\n> at design time from existing protocol experience.  Thus it \n> seems to me that\n> a collection of application protocol design patterns can \n> achieve the goals\n> of an APPLCORE protocol without needing to create a protocol \n> which will be\n> inappropriate for some use cases.  The design patterns \n> approach has much\n> broader applicability than just a single protocol.\n> \n> My recommendation is to replace the \"core application protocol\n> specification\" deliverable with this:\n> \n> * An Informational RFC which provides a collection of \n> application protocol\n> design patterns, where each design pattern distills the \n> successful solutions\n> of application protocols for each entry in the problem identification\n> document.  While specific examples from individual protocols \n> will provide\n> rationale for the design pattern, each pattern will described in a\n> protocol-neutral manner.  The goal of this document is to \n> capture the design\n> rationale and solutions for common problems encountered by \n> application layer\n> protocols so these \"lessons learned\" can quickly be applied \n> to the design of\n> new protocols.\n> \n> Why?\n> \n> - Because design patterns focus on design rationale, not on syntax\n> - Because design patterns have applicability to more domains \n> of use than a\n> single protocol\n> - Because design patterns expose design tradeoffs, rather \n> than hiding them\n> behind a single normative choice\n> \n> - Jim\n> \n\n\n\n", "id": "lists-007-9039264"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Thu, 4 Feb 1999, Jim Whitehead wrote:\n> I agree with this (whoa, I'll bet Roy is surprised :-)  Right away, the\n> APPLCORE protocol needs to decide whether it will be a set of protocol\n> components for a client to server protocol, or a server to server protocol.\n\nSMTP is both a client->server and a server->server protocol.  The only\ndistinction in protocol structure I see between client->server and\nserver->server is that the two are likely to have different security\nmechanism requirements (mutual authentication is more important for the\nserver->server).  But since most IETF protocols are client->server, that's\nthe direction I'd be biased.\n\n> This design choice has many repercussions, and cannot easily be abstracted\n> away.  Similarly, already APPLCORE seems to be biased in favor of a stateful\n> protocol.\n\nI'm biased in the direction of stateful protocols; APPLCORE is not (it's\nnot even an approved BOF yet :-). This may not even be an issue for a core\nprotocol, except with respect to stateful security services like TLS and\nSASL.\n\n> But, since a useful protocol can't be developed without making *some* design\n> choices, and since those design choices will not be applicable to all future\n> domains of use, perhaps developing a *protocol* as a deliverable is the\n> wrong way to achieve the APPLCORE goals.\n\nA core protocol would have structure but no direct operations (with the\npossible exception of NOOP :-).  Where design choices are necessary, the\nproposed charter would constrain the group to go only in directions that\nat least two past successful IETF protocols have gone but otherwise those\ndesign choices would be up to the proposed WG.  Now is not the right time\nto discuss design choices at that level.\n\n> A collection of design patterns will speed the development of new protocols,\n> since a protocol which makes use of a pattern won't need to repeat all of\n> the rationale for the design choice, and will be able to more easily benefit\n> at design time from existing protocol experience.  Thus it seems to me that\n> a collection of application protocol design patterns can achieve the goals\n> of an APPLCORE protocol without needing to create a protocol which will be\n> inappropriate for some use cases.  The design patterns approach has much\n> broader applicability than just a single protocol.\n\nPerhaps we should have never built TCP, but instead built a bunch of\ndesign patterns for doing retransmission, sequencing and reliability for\nraw packets?  It would certainly be more flexible.  But having TCP as a\nfixed point in the protocol stack is extremely helpful and leads to a lot\nof code reuse.  There are even applications where TCP is far from perfect,\nbut it's good enough that it's not worth developing a new transport layer. \n\nIf programming cycles were free, your proposal would be superior to mine. \nBut what's driving people to abuse existing protocols rather than\ncarefully design new ones is code reuse.  That has to be factored into the\nproposed WGs output.  The goal is to do all the boring gruntwork core\nprotocol stuff one last time so future protocol designers have the option\nof skipping it and there's a code reuse benefit.  It may not fit everyone,\nbut neither does TCP.\n\n> * An Informational RFC which provides a collection of application protocol\n> design patterns, where each design pattern distills the successful solutions\n> of application protocols for each entry in the problem identification\n> document.  While specific examples from individual protocols will provide\n> rationale for the design pattern, each pattern will described in a\n> protocol-neutral manner.  The goal of this document is to capture the design\n> rationale and solutions for common problems encountered by application layer\n> protocols so these \"lessons learned\" can quickly be applied to the design of\n> new protocols.\n\nI predict nobody would work on this sort of document, unless there is some\ntangible benefit beyond helping future protocol designers.\n\nTo put it bluntly, I'm willing to be the masochist who edits the\n\"history/problem identification\" (or \"design patterns\" if you prefer)\ndocument only under the condition that the charter permits the group to\ncreate a simple core protocol proposal.  That way, I'd have a good chance\nof getting a code reuse benefit in the future.\n\n- Chris\n\n\n\n", "id": "lists-007-9053742"}, {"subject": "APPLCORE rough concensus", "content": "I get the following sense of this list on the APPLCORE proposal:\n\n* There is significant interest in the problem\n\n* As long as the effort avoids research areas (i.e., is constrained to\n  problems we've solved before), it's within IETF's scope.\n\n* The proposed charter does a good job at constraining the problem, but\n  perhaps not good enough (specific suggestions welcome).\n\n* Some have suggested the \"core protocol\" task be dropped but that a group\n  doing the history/problem identification task would be valuable.\n\n* Some have suggested the second work item be changed from a \"core\n  protocol\" to \"reusable protocol components\" or \"design patterns\"\n\n* This should be coordinated with the HTTP-NG team and ONCRPC WG who\n  are doing related work with different scopes.\n\nI believe the first three suffice to justify a BOF on the topic.  The next\ntwo are good issues to discuss at a BOF and unlikely to be resolved on\nthis list. \n\nPlease speak up if you disagree with this characterization of the\ndiscussion so far.\n\nA new mailing list has been set up for further discussion.  The\nsubscription address is <ietf-applcore-request@imc.org>.  The list will\nbecome active in about a week (feel free to subscribe now).\n\n- Chris\n\n\n\n", "id": "lists-007-9065921"}, {"subject": "Re: APPLCORE rough concensus", "content": "At 18:50 99/02/07 -0800, Chris Newman wrote:\n> I get the following sense of this list on the APPLCORE proposal:\n\n> * The proposed charter does a good job at constraining the problem, but\n>   perhaps not good enough (specific suggestions welcome).\n\nOne thing I have not seen mentionned is internationalization. Depending\non what exactly will be in the charter, what acually has to be done\nmight rage from a reference to RFC 2277 to some serious work.\n\nRegards,   Martin.\n\n\n#-#-#  Martin J. Du\"rst, World Wide Web Consortium\n#-#-#  mailto:duerst@w3.org   http://www.w3.org\n\n\n\n", "id": "lists-007-9074639"}, {"subject": "MIME message/external-body access type", "content": "RFCs 2046 and 2048 call for IANA registration of access-type parameter\nvalues for message/external-body.  I cannot find any registrations at the\nIANA site.\n\nHave any access-type values other than those in RFC2046 been defined?\n\nIn particular, is there a defined access-type that allows the body part to\nbe designated by URI?\n\nThanks for any pointers.\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-9082345"}, {"subject": "Re: APPLCORE rough concensus", "content": "I wonder exactly what \"should be coordinated with the HTTP-NG team and ONCRPC WG\" means.  Does it mean that harmony with the HTTP-NG and/or ONCRPC protocols is a requirement?  Does it mean that harmony with the HTTP-NG and/or ONCRPC protocols counts for something when making design choices?\n\nThanks,\nMike\n\n\n\n", "id": "lists-007-9089852"}, {"subject": "APPLCORE: An architectural questio", "content": "I perceive that there is an early decision that this group could make with\nvery significant downstream consequences.  It concerns the handling of\nmultiple overlapped requests.\n\n(A) The approach taken by IMAP/AP is to build the concurrency into the\nbasic request/response protocol, including identifying tags as part of the\ndata stream.\n\n(B) The aproach taken by HTTP-NG is to have a separate multiplexing layer\nthat allows a number of virtual duplex stream communications to be\nconducted on a single underlying connection.  Thus, each concurrent\nrequest/response is conducted in a separate data stream.\n\nI see parallels here with development of multitasking operating systems:\n(A) with asynchronous notification mechanisms built into the operaing\nsystem interface (e.g. VMS);\n(B) systems built using a synchronous basic interface and multithreading to\nachieve concurrency within a process (e.g. Unix).\n\nThe MUX approach involves layering (with the overhead that implies),  while\nrequest/response concurrency adds complexity to the application protocol.\n\nI don't have a definite view on which way is best, but I tend to lean in\nfavour of the mux approach.\n\n#g\n\nPS:  is T/TCP alive or dead these days?\n\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-9097332"}, {"subject": "Re: APPLCORE rough concensus", "content": "At 08:04 08/02/99 PST, spreitze@parc.xerox.com wrote:\n>\n>I wonder exactly what \"should be coordinated with the HTTP-NG team and\nONCRPC WG\" means.  Does it mean that harmony with the HTTP-NG and/or ONCRPC\nprotocols is a requirement?  Does it mean that harmony with the HTTP-NG\nand/or ONCRPC protocols counts for something when making design choices?\n\n\nWhat *I* would mean is that I see some overlap between the goals of\nAPPLCORE and HTTP-NG (and some overlap between HTTP-NG and ONC RPC goals),\nand that if one solution serves both that would be better than two solutions.\n\nE.g. see my separate comments on handling concurrency.\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-9106925"}, {"subject": "Re: APPLCORE rough concensus", "content": "> ... I see some overlap between the goals of\n> APPLCORE and HTTP-NG (...),\n> and that if one solution serves both that would be better than two solutions.\n\nIt looks to me like the goals of APPLCORE are just about exactly a subset of the goals of HTTP-NG (and to make them truly a subset involves some minor quibbles I think we can cover with a little discussion).  What that tells me is that APPLCORE's solution should be part of HTTP-NG's solution.  I'm trying to find out how strongly others feel about making this relationship hold.\n\n\n\n", "id": "lists-007-9115475"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "Graham Klyne said this:\n> I perceive that there is an early decision that this group could make with\n> very significant downstream consequences.  It concerns the handling of\n> multiple overlapped requests.\n> \n> (A) The approach taken by IMAP/AP is to build the concurrency into the\n> basic request/response protocol, including identifying tags as part of the\n> data stream.\n> \n> (B) The aproach taken by HTTP-NG is to have a separate multiplexing layer\n> that allows a number of virtual duplex stream communications to be\n> conducted on a single underlying connection.  Thus, each concurrent\n> request/response is conducted in a separate data stream.\n\nIMHO, this decision illustrates a much earlier decision about what class\nof protocols we're talking about. Over the years I've seen two classes\nof protocols come out of the apps area: narrowly defined limited use\nprotocols used only for one thing and very widely used protocols that\nhave large applicability and stringent scalability requirements. IMAP, \nPOP, SMTP, etc fit in the first category whereas HTTP, HTTP-NG, NFS, ONC-RPC\nfit in the latter.\n\nIn any charter or documents for this group I would like to see some sort\nof scoping as to which class the group would be focusing. IMHO I think\nthe latter class is going to use techniques that are specific to that\nparticular problem. I think the much more doable and useful output would\nbe to focus on the former. \n\nIf this has already been discussed then I apologies for the repeat...\n\n-MM\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | www.rwhois.net/michael\nSr. Research Engineer   |   www.ga.lp.org/gwinnett     | ICQ#:         14198821\nNetwork Solutions|          www.lp.org          |  michaelm@netsol.com\n\n\n\n", "id": "lists-007-9123757"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "Graham Klyne wrote:\n\n> I don't have a definite view on which way is best, but I tend to lean in\n> favour of the mux approach.\n\nI wonder how much complexity the protocol software can actually hide from the\napplication.  It seems that structures for tracking all of the outstanding\nrequests and handling their responses are bound to make it into the application\ncode, especially if multiple responses to the same request are allowed.\n\nOn another note, has anyone here had a chance to look at my XP draft?  We are\nusing XML for everything on the wire, and I thought it would be useful to take\na stab at formalizing that fact as a basis for many different kinds of\nprotocols.  It tags requests and responses, as a wire protocol must, but a\nsoftware implementation could still take the \"mux\" approach.\n\n\nTom Harding\n\n\n\n", "id": "lists-007-9133301"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "> I wonder how much complexity the protocol software can actually hide from the\n> application.\n\nIt can actually reduce complexity, by replacing two problems (multiple connections and multiple outstanding requests on a connection) with one (multiple connections).\n\n> It seems that structures for tracking all of the outstanding\n> requests and handling their responses are bound to make it into the application\n> code\n\nMost server-side software that takes itself seriously allows for multiple connections to be active at once.  I think general-purpose client-side software should too.  So \"tracking all of the outstanding requests and handling their responses\" is something that will be done anyway, as a consequence of handling multiple active connections.\n\n> especially if multiple responses to the same request are allowed.\n\nThat's an entirely different can of worms, orthogonal to muxing.\n\n> On another note, has anyone here had a chance to look at my XP draft?\n\nI have.\n\n>  ... It tags requests and responses, as a wire protocol must, but a\n> software implementation could still take the \"mux\" approach.\n\nNo, the kind of muxing that's done in HTTP-NG's muxing protocol isn't about code in the peers, it's about what happens on the wire.  It interleaves messages chunk by chunk (where a \"chunk\" is only a piece of a message, and choosing the chunking is up to the peers).  An advantage of this fine-grained interleaving is that one message doesn't get held up by slow or blocked consumption of another.  You can't get that back in software if your wire protocol says one message has to be sent in its entirety before another can be started.\n\n\n\n", "id": "lists-007-9140934"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "> PS:  is T/TCP alive or dead these days?\n\nAFAIK, it is rather dead, due to problems inherent in the 1/2 RT startup.  There is a comment on this in the minutes of the RUTS BOF at IETF-43 (http://www.ietf.org/proceedings/98dec/43rd-ietf-98dec-142.html).\n\n\n\n", "id": "lists-007-9150203"}, {"subject": "Drafting mux WG charte", "content": "At the HTTP-NG BOF at IETF-43 it was agreed to proceed chartering a WG\nto work on a muxing protocol.  This protocol addresses a subset of the\nproblems outlined for APPLCORE.  As I've said before, I think the right\napproach for APPLCORE (and HTTP-NG as well) is to produce very modular\nspecifications.  In particular, the two communities should get together\non the problems addressed by the mux protocol.  I've been working on a\ncharter for a mux WG, with discussion on the ietf-http-ng@w3.org mailing\nlist (to join, see HTTP-NG home page at\nhttp://www.w3.org/Protocols/HTTP-NG/).  I've just posted a new mux WG\ncharter draft, at\n\n<http://www.w3.org/Protocols/HTTP-NG/1999/02/mux-Charter-209.html>\n\n\n\n", "id": "lists-007-9158178"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "spreitze@parc.xerox.com wrote:\n\n> > I wonder how much complexity the protocol software can actually hide from the\n> > application.\n>\n> It can actually reduce complexity, by replacing two problems (multiple connections and multiple outstanding requests on a connection) with one (multiple connections).\n>\n> > It seems that structures for tracking all of the outstanding\n> > requests and handling their responses are bound to make it into the application\n> > code\n>\n> Most server-side software that takes itself seriously allows for multiple connections to be active at once.  I think general-purpose client-side software should too.  So \"tracking all of the outstanding requests and handling their responses\" is something that will be done anyway, as a consequence of handling multiple active connections.\n>\n> > especially if multiple responses to the same request are allowed.\n>\n> That's an entirely different can of worms, orthogonal to muxing.\n>\n> > On another note, has anyone here had a chance to look at my XP draft?\n>\n> I have.\n>\n> >  ... It tags requests and responses, as a wire protocol must, but a\n> > software implementation could still take the \"mux\" approach.\n>\n> No, the kind of muxing that's done in HTTP-NG's muxing protocol isn't about code in the peers, it's about what happens on the wire.  It interleaves messages chunk by chunk (where a \"chunk\" is only a piece of a message, and choosing the chunking is up to the peers).  An advantage of this fine-grained interleaving is that one message doesn't get held up by slow or blocked consumption of another.  You can't get that back in software if your wire protocol says one message has to be sent in its entirety before another can be started.\n\nTaking clues from your message (as a lousy substitute for actually poring over the HTTP-NG work), I gather that the idea is for clients and servers to think they are creating multiple connections, when in fact everything gets routed over the same connection?  That should be a big improvement for the web, although it does solve the same problem that TCP does already when there are multiple real connections open at once.\n\nAnother approach is for a higher-layer application protocol, or the application itself, to choose when to use multiple requests and when to open another connection.  Just like the choices involved in writing multithreaded code that uses a serial resource like a system event queue.\n\n\n\n", "id": "lists-007-9166314"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "> Taking clues from your message (as a lousy substitute for actually poring over the HTTP-NG work), I gather that the idea is for clients and servers to think they are creating multiple connections, when in fact everything gets routed over the same connection?\n\nExactly.\n\n\n> That should be a big improvement for the web, although it does solve the same problem that TCP does already when there are multiple real connections open at once.\n\nWell, there's not universal satisfaction with how well the current commonly deployed TCP implementations serve the needs of apps that do concurrent request/response protocols.  Please do follow the pointer into the HTTP-NG work, which itself builds on a lot of discussion in various IETF circles about whether and what to do in this regard.\n\n\n> Another approach is for a higher-layer application protocol, or the application itself, to choose when to use multiple requests and when to open another connection.\n\nThat's not an alternative.  The mere availability of a message muxing protocol doesn't relieve the higher layer of the responsibility of deciding how to use it.  This is a matter of the software in the peers, not the wire protocol (although the design of each naturally influences the design of the other).\n\n\n\n", "id": "lists-007-9176413"}, {"subject": "Re: MIME message/external-body access type", "content": "On Mon, 8 Feb 1999, Graham Klyne wrote:\n> RFCs 2046 and 2048 call for IANA registration of access-type parameter\n> values for message/external-body.  I cannot find any registrations at the\n> IANA site.\n> \n> Have any access-type values other than those in RFC2046 been defined?\n> \n> In particular, is there a defined access-type that allows the body part to\n> be designated by URI?\n> \n> Thanks for any pointers.\n\nRFC 2017\n\n- Chris\n\n\n\n", "id": "lists-007-9185545"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "spreitze@parc.xerox.com wrote:\n\n> > Another approach is for a higher-layer application protocol, or the application itself, to choose when to use multiple requests and when to open another connection.\n>\n> That's not an alternative.  The mere availability of a message muxing protocol doesn't relieve the higher layer of the responsibility of deciding how to use it.  This is a matter of the software in the peers, not the wire protocol (although the design of each naturally influences the design of the other).\n\nI heartily agree that if webmux or another message multiplexing protocol is available, an application layer protocol like XP doesn't need any request/response tagging mechanism.  You just use multiple connections for everything instead of only when you explicitly want concurrency below the level of whole responses.\n\n\n\n", "id": "lists-007-9193221"}, {"subject": "Re: Drafting mux WG charte", "content": "On Tue, 9 Feb 1999, Mike Spreitzer wrote:\n> At the HTTP-NG BOF at IETF-43 it was agreed to proceed chartering a WG\n> to work on a muxing protocol.  This protocol addresses a subset of the\n> problems outlined for APPLCORE.  As I've said before, I think the right\n> approach for APPLCORE (and HTTP-NG as well) is to produce very modular\n> specifications.  In particular, the two communities should get together\n> on the problems addressed by the mux protocol.  I've been working on a\n> charter for a mux WG, with discussion on the ietf-http-ng@w3.org mailing\n> list (to join, see HTTP-NG home page at\n> http://www.w3.org/Protocols/HTTP-NG/).  I've just posted a new mux WG\n> charter draft, at\n> \n> <http://www.w3.org/Protocols/HTTP-NG/1999/02/mux-Charter-209.html>\n\nI'm concerned about the idea of the IETF designing a protocol which\ncompletely punts on security issues.  If this is a protocol with a port\nnumber, then it needs to explain how security is activated for that port.\nIf it's just a layer, then it needs to explain how it's integrated into\nlower-level security services or explain the consequences of security\nattacks if a higher-level security service is used.  Security tends to\npervade all layers of all stacks in a truly secure system, so I'm dubious\nit can be punted as this charter proposes.\n\nI'm also uncomfortable with the idea of replicating all the flow-control\nmachinery of TCP in a layer above it.  The consequences of doing so should\nbe documented and justified.\n\n- Chris\n\n\n\n", "id": "lists-007-9201621"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "> > That's not an alternative.  The mere availability of a message muxing protocol doesn't relieve the higher layer of the responsibility of deciding how to use it.  This is a matter of the software in the peers, not the wire protocol (although the design of each naturally influences the design of the other).\n\n> I heartily agree that if webmux or another message multiplexing protocol is available, an application layer protocol like XP doesn't need any request/response tagging mechanism.  You just use multiple connections for everything instead of only when you explicitly want concurrency below the level of whole responses.\n\nActually, that's just one way of deciding how to use the mux's services; I can imagine others.  For example, you might still want to: distinguish requests from responses, so that each side can be a client of the other; put request/response IDs in the messages (at the request/response layer), so you can admit the possibility of more or less than 1 response per request; and/or have additional message types, such as \"interrupt\" and \"clean shutdown\".  And there's a whole other raft of issues involved in chosing what goes above and below the mux layer.  If you starting thinking about interactions with security and other services, you quickly start thinking about multiple substacks and how to create them, choose among them, etc.\n\n\n\n", "id": "lists-007-9211380"}, {"subject": "RE: Drafting mux WG charte", "content": "I dont think that the authors of the charter truly intend\nto \"punt all security\".\n\nIt seems to me that a reasonable MUX effort can get underway\nand provide good security.\n\nObviously, the group needs to keep security considerations in mind\nand will have some serious work ahead of them beyond just\nthe security issue.  I'd like to see the group get started\nand discuss the issues going forward instead of objecting\nto the charter now.\n\n\n\n\n> -----Original Message-----\n> From: Chris Newman [mailto:chris@INNOSOFT.COM]\n> Sent: Tuesday, February 09, 1999 12:28 PM\n> To: Mike Spreitzer\n> Cc: ietf-http-ng@w3.org; discuss@apps.ietf.org\n> Subject: Re: Drafting mux WG charter\n> \n> \n> On Tue, 9 Feb 1999, Mike Spreitzer wrote:\n> > At the HTTP-NG BOF at IETF-43 it was agreed to proceed \n> chartering a WG\n> > to work on a muxing protocol.  This protocol addresses a \n> subset of the\n> > problems outlined for APPLCORE.  As I've said before, I \n> think the right\n> > approach for APPLCORE (and HTTP-NG as well) is to produce \n> very modular\n> > specifications.  In particular, the two communities should \n> get together\n> > on the problems addressed by the mux protocol.  I've been \n> working on a\n> > charter for a mux WG, with discussion on the \n> ietf-http-ng@w3.org mailing\n> > list (to join, see HTTP-NG home page at\n> > http://www.w3.org/Protocols/HTTP-NG/).  I've just posted a \n> new mux WG\n> > charter draft, at\n> > \n> > <http://www.w3.org/Protocols/HTTP-NG/1999/02/mux-Charter-209.html>\n> \n> I'm concerned about the idea of the IETF designing a protocol which\n> completely punts on security issues.  If this is a protocol \n> with a port\n> number, then it needs to explain how security is activated \n> for that port.\n> If it's just a layer, then it needs to explain how it's \n> integrated into\n> lower-level security services or explain the consequences of security\n> attacks if a higher-level security service is used.  Security tends to\n> pervade all layers of all stacks in a truly secure system, so \n> I'm dubious\n> it can be punted as this charter proposes.\n> \n> I'm also uncomfortable with the idea of replicating all the \n> flow-control\n> machinery of TCP in a layer above it.  The consequences of \n> doing so should\n> be documented and justified.\n> \n> - Chris\n> \n\n\n\n", "id": "lists-007-9220384"}, {"subject": "Re: Drafting mux WG charte", "content": "> I'm concerned about the idea of the IETF designing a protocol which\n> completely punts on security issues.\n\nI agree.  I wasn't trying to suggest a complete punt.  I was trying to say that the \"heavy lifting\" is done in other layers.  The mux layer would naturally do what's necessary to enable effectively secured stacks to be built using both a mux layer and some security layer(s) (and that would naturally include the mux layer \"not blowing it\" on its own).\n\n\n> I'm also uncomfortable with the idea of replicating all the flow-control\n> machinery of TCP in a layer above it.  The consequences of doing so should\n> be documented and justified.\n\nYeah, we heard some of this before IETF-43.  You'll see documentation like you've suggested appearing in early drafts of the HTTP-NG charter.  As we progressed on drafting the charter, we got to thinking it would be included in the MUX spec (as design rationale) rather than broken out into a separate document.  To my surprise, this was not even raised at the HTTP-NG BOF, held under Transport aegis, at IETF-43; I took this to mean the community was getting comfortable with the arguments we were making on this point.\n\nNote also that we haven't proposed replicating all of TCP's flow control machinery.  TCP's flow-control machinery includes both sender-side restraint (AKA slow-start) and reciever-given restraint (the windowing explicit on the wire).  The mux needs the latter (at least for applications where you expect some real independence of the message streams), but not the former.  The sender-side restraint is there to avoid flooding the network, and TCP will do that for us even with a mux above it.\n\nNote that the charter isn't explicit on this point.  I anticipate the WG to debate this, and decide that the reciever-given restraint in the mux layer should be an optional module, because some applications will need it and some won't.\n\n\n\n", "id": "lists-007-9231857"}, {"subject": "RE: Drafting mux WG charte", "content": "On Tue, 9 Feb 1999, Josh Cohen wrote:\n> I dont think that the authors of the charter truly intend\n> to \"punt all security\".\n> It seems to me that a reasonable MUX effort can get underway\n> and provide good security.\n> \n> Obviously, the group needs to keep security considerations in mind\n> and will have some serious work ahead of them beyond just\n> the security issue.  I'd like to see the group get started\n> and discuss the issues going forward instead of objecting\n> to the charter now.\n\nThe excludes integrated security functions and is otherwise silent on the\nissue of security.  Too many WGs have left security as an afterthought and\nhad their output delayed months or years as a result.  The charter has to\nat least say \"the group will address security considerations of a MUX\nlayer and how security services in other layers interact with the MUX\nlayer\".\n\nOne function of a charter is to serve as an informal contract between the\nIETF and the WG.  It needs to state up front things which the WG must do\nto fulfill its mission.\n\nEven if I don't formally object to the charter on these grounds, I'd\nexpect the security ADs to do so if they're being vigilant.  It might be\nfaster to fix the charter now than try to push it through unchanged.\n\n- Chris\n\n\n\n", "id": "lists-007-9241484"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "> > PS:  is T/TCP alive or dead these days?\n> \n> AFAIK, it is rather dead, due to problems inherent in the 1/2 RT\n> startup.  There is a comment on this in the minutes of the RUTS BOF at\n> IETF-43 (http://www.ietf.org/proceedings/98dec/43rd-ietf-98dec-142.html).\n\nWhich comment in the minutes are you referring to?\n\nVern\n\n\n\n", "id": "lists-007-9250669"}, {"subject": "RE: Drafting mux WG charte", "content": "Ok, Im in agreement then, I thought you were objecting\nmore to the effort than the language of the charter.\n\n\n> -----Original Message-----\n> From: Chris Newman [mailto:chris@innosoft.com]\n> Sent: Tuesday, February 09, 1999 3:52 PM\n> To: Josh Cohen\n> Cc: Mike Spreitzer; ietf-http-ng@w3.org; discuss@apps.ietf.org\n> Subject: RE: Drafting mux WG charter\n> \n> \n> On Tue, 9 Feb 1999, Josh Cohen wrote:\n> > I dont think that the authors of the charter truly intend\n> > to \"punt all security\".\n> > It seems to me that a reasonable MUX effort can get underway\n> > and provide good security.\n> > \n> > Obviously, the group needs to keep security considerations in mind\n> > and will have some serious work ahead of them beyond just\n> > the security issue.  I'd like to see the group get started\n> > and discuss the issues going forward instead of objecting\n> > to the charter now.\n> \n> The excludes integrated security functions and is otherwise \n> silent on the\n> issue of security.  Too many WGs have left security as an \n> afterthought and\n> had their output delayed months or years as a result.  The \n> charter has to\n> at least say \"the group will address security considerations of a MUX\n> layer and how security services in other layers interact with the MUX\n> layer\".\n> \n> One function of a charter is to serve as an informal contract \n> between the\n> IETF and the WG.  It needs to state up front things which the \n> WG must do\n> to fulfill its mission.\n> \n> Even if I don't formally object to the charter on these grounds, I'd\n> expect the security ADs to do so if they're being vigilant.  \n> It might be\n> faster to fix the charter now than try to push it through unchanged.\n> \n> - Chris\n> \n\n\n\n", "id": "lists-007-9258578"}, {"subject": "Re: APPLCORE rough concensus", "content": "Excuse me for being blunt but that approach (true subset of HTTPng)\ncould imply that HTTPng is the basis for all future applications\nprotocols.\n\nI doubt that the IETF is ready to make that step. Rather, we should \nsay that HTTPng is one user of whatever APPLCORE becomes.\n\n  Brian Carpenter\n\nspreitze@parc.xerox.com wrote:\n> \n> > ... I see some overlap between the goals of\n> > APPLCORE and HTTP-NG (...),\n> > and that if one solution serves both that would be better than two solutions.\n> \n> It looks to me like the goals of APPLCORE are just about exactly a subset of the goals of HTTP-NG (and to make them truly a subset involves some minor quibbles I think we can cover with a little discussion).  What that tells me is that APPLCORE's solution should be part of HTTP-NG's solution.  I'm trying to find out how strongly others feel about making this relationship hold.\n\n\n\n", "id": "lists-007-9268566"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "Graham Klyne wrote:\n...\n> (A) The approach taken by IMAP/AP is to build the concurrency into the\n> basic request/response protocol, including identifying tags as part of the\n> data stream.\n\nThose who actually listened to the IETF plenary talk on transaction\nprocessing at the Chicago IETF will realise that this is a very\nnon-trivial mechanism to get right. (BTW, XP doesn't even come\nclose to dealing with the requirements of a transactional\napplication.) However, it is a valid approach to build a generic\ntransactional layer, but then we are talking XA, Java RMI, or CORBA\nIIOP, which takes us into another league and it is not obvious\nthat the IETF has anything to bring to the table.\n\n> \n> (B) The aproach taken by HTTP-NG is to have a separate multiplexing layer\n> that allows a number of virtual duplex stream communications to be\n> conducted on a single underlying connection.  Thus, each concurrent\n> request/response is conducted in a separate data stream.\n\nThat's where RUTS comes in: don't do an HTTP-specific solution,\nand build on the T/TCP experience. As others have said, this\napproach separates the problems and provides a better chance\nof satisfying transactional requirements in a simple manner.\n\n  Brian Carpenter\n\n\n\n", "id": "lists-007-9277318"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "At 08:16 09/02/99 -0800, Tom Harding wrote:\n[...]\n>On another note, has anyone here had a chance to look at my XP draft?  We are\n>using XML for everything on the wire, and I thought it would be useful to\ntake\n>a stab at formalizing that fact as a basis for many different kinds of\n>protocols.  It tags requests and responses, as a wire protocol must, but a\n>software implementation could still take the \"mux\" approach.\n\nI have noted and very briefly scanned the draft, but not taken it in in any\ndepth.\n\nAt this stage, I think the choice of representation is secondary issue:\nfirst I think it is important to determine the semantics of what is to be\nachieved.\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-9285956"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "> > > PS:  is T/TCP alive or dead these days?\n> > \n> > AFAIK, it is rather dead, due to problems inherent in the 1/2 RT\n> > startup.  There is a comment on this in the minutes of the RUTS BOF ...\n> \n> Which comment in the minutes are you referring to?\n\nIn the minutes in the proceedings, under \"Other (unattributed comments)\", item 3 identifies a dilemma that T/TCP faces and points to a discussion in the next full paragraph.\n\n\n\n", "id": "lists-007-9293974"}, {"subject": "Re: APPLCORE rough concensus", "content": "> ... that approach (true subset of HTTPng)\n> could imply that HTTPng is the basis for all future applications\n> protocols.\n\nIt seems to me that the implication goes the other way (assuming we're willing to assemble a given application's protocol stack from various protocols that solve subsets of the application's problems): the smaller the set of protocol problems you address, the larger the set of applications whose problem set includes the set you address.  Put another way: if HTTP-NG is layered over APPLCORE, then APPLCORE is used for everything HTTP-NG is and potentially also things that HTTP-NG is not used for.\n\n\n\n", "id": "lists-007-9302721"}, {"subject": "Re: APPLCORE rough concensus", "content": "I second Brian's comments on HTTPng...\n\nI don't want to be in a situation where HTTPng is believed to be the \"one \nsize that fits all\", even if HTTPng works out (and its not soup yet), \nand would want it free to optimize to web operations, which have a different \nset of constraints than many other applications protocols: e.g. low latency, \nsince a user is driving it is important for interactive feel, which is \nNOT a requirement on, say, mail.  It is those kinds of requirements (along \nwith the \"brittleness\" of current systems like CORBA), that have made \nme believe something other than CORBA or Java RMI is needed for the web.\n\nIt is also not clear to me that HTTPng requirements should bind APPLCORE\nhands, as the requirements may be found to be disjoint.\n\nWhile the web is a common application protocol, it should not,\nin my opinion, be the only one.\n\n- Jim\n--\nJim Gettys\nIndustry Standards and Consortia\nCompaq Computer Corporation\nVisting Scientist, World Wide Web Consortium, M.I.T.\nhttp://www.w3.org/People/Gettys/\njg@w3.org, jg@pa.dec.com\n\n\n\n", "id": "lists-007-9311356"}, {"subject": "Re: APPLCORE rough concensus", "content": "My point is only that the word \"subset\" is open to the wrong\ninterpretation; if we just speak of layering there is no\npossible misinterpretation.\n\n    Brian\n\nspreitze@parc.xerox.com wrote:\n> \n> > ... that approach (true subset of HTTPng)\n> > could imply that HTTPng is the basis for all future applications\n> > protocols.\n> \n> It seems to me that the implication goes the other way (assuming we're willing to assemble a given application's protocol stack from various protocols that solve subsets of the application's problems): the smaller the set of protocol problems you address, the larger the set of applications whose problem set includes the set you address.  Put another way: if HTTP-NG is layered over APPLCORE, then APPLCORE is used for everything HTTP-NG is and potentially also things that HTTP-NG is not used for.\n\n\n\n", "id": "lists-007-9320561"}, {"subject": "Continuing to draft mux WG charte", "content": "OK, I've taken Chris Newman's hint and expanded a bit on security, and\nalso Jim Whitehead's hint to clarify the nature of the goals document. \nYou can view the latest draft at:\n<http://www.w3.org/Protocols/HTTP-NG/1999/02/mux-Charter-210.html>\n\n\n\n", "id": "lists-007-9328885"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "> > > > PS:  is T/TCP alive or dead these days?\n> > > \n> > > AFAIK, it is rather dead, due to problems inherent in the 1/2 RT\n> > > startup.  There is a comment on this in the minutes of the RUTS BOF ...\n> > \n> > Which comment in the minutes are you referring to?\n> \n> In the minutes in the proceedings, under \"Other (unattributed comments)\",\n> item 3 identifies a dilemma that T/TCP faces and points to a discussion\n> in the next full paragraph.\n\nThat comment isn't specific to T/TCP.  Any single-round-trip transaction\nprotocol faces that problem.\n\nVern\n\n\n\n> Other (unattributed comments):\n> ...\n> (3) Dilemma: eliminating the three-way handshake to make for faster\n>     transactions reduces security [see below].\n> ...\n> \n> Steve Bellovin then discussed some security implications of the requirements.\n> First, removing the three-way handshake opens up security holes.  The issue\n> of sequence number guessing attacks is serious.  IPSEC is reasonably cheap\n> for 'over the wire' security, but a key question is where do you get the\n> IPSEC keys?  Unfortunately, multiple RTTs are needed to connect with a\n> key manager, and one needs loosely-synchronized clocks (to address replay\n> attacks).  Other public key management systems will be similarly expensive.\n> The best you can hope for is to cache key management state.  But this\n> doesn't work if you talk to a lot of other entities over a short time.\n> \n> However, it might be that object security is in fact cheaper than transport\n> security (though you still need to watch for replays).\n\n[there's a bug in the minutes above - it should be \"*or* one needs loosely-\nsynchronized clocks ...\"]\n\n\n\n", "id": "lists-007-9336299"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "> That comment isn't specific to T/TCP.  Any single-round-trip transaction\n> protocol faces that problem.\n\nRight.  I hadn't intended to suggest otherwise.\n\n\n\n", "id": "lists-007-9345671"}, {"subject": "Re: APPLCORE: An architectural questio", "content": "first, the relevant portion of those notes (about removing the 3WHS,\nnot specifically about T/TCP)\n\n> First, removing the three-way handshake opens up security holes. The\n> issue of sequence number guessing attacks is serious. IPSEC is\n> reasonably cheap for 'over the wire' security, but a key question is\n> where do you get the IPSEC keys? Unfortunately, multiple RTTs are\n> needed to connect with a key manager, and one needs\n> loosely-synchronized clocks (to address replay attacks). Other public\n> key management systems will be similarly expensive. The best you can\n> hope for is to cache key management state. But this doesn't work if\n> you talk to a lot of other entities over a short time.\n> \n> However, it might be that object security is in fact cheaper than\n> transport security (though you still need to watch for replays).\n\nokay, first when we say \"opens up security holes\", we need to ask\n\"compared to what?\"  Seems like the important point is that a\nconnection that lacks a 3WHS may be more vulnerable to some kinds of\nhijacking attacks than a traditional TCP connection.  I'm by no means\nan expert on security and my brain hurts too much today to analyze\nthis in detail.  But I wonder how much this really hurts us.\n\nFor example, in the case of a very short \"connection\" of one request\nand one response packet each, I don't immediately understand the\ndifference between a connection hijacking attack, and a simple\nimpersonation of the client or server host.  The danger of using T/TCP\nrelative to using TCP, it seems, is that we will use some sort of\nauthentication mechanism which doesn't guarantee integrity for the\nwhole session, allowing someone else to steal the connection and\nimpersonate the authenticated party.  But you cannot \"hijack\" a\nconnection when the server sends a FIN in response to the first SYN,\nand for longer connections it's not difficult to define ways to\nprevent connection hijacking - i.e. to make sure you're still talking\nto the same host as when you started the connection.  \n\nSo I don't think we should consider T/TCP \"dead\"; but we might need to\ntweak it (not unusual for an experimental protocol), or ensure that\nother kinds of protection (such as object security) are provided by\nany \"applcore\" protocol that we define.  But we knew we had to do that\nanyway, didn't we?\n\nKeith\n\n(real authentication of your peer is of course still very difficult to\ndo, especially without adding steps.  but we don't always need real\nauthentication, and in the cases we do, perhaps we can find a way to\npiggyback that authentication along with payload - as long as we don't\ntrust the payload to be authentic until the authenticaiton is\ncomplete.)\n\n\n\n", "id": "lists-007-9353726"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "What's the vision of where APPLCORE would be used?  (In a world that already has HTTP, being used and abused for many and increasingly many things, plus CORBA, Java RMI, and DCOM --- what's left?)\n\nWhat will be the requirements for efficiency?  Will we be hearing arguments like: because we know there's a large textual payload, the headers and data parts don't have to be particularly compact?  Or: this is not going to be used in demanding environments (e.g., not more than a single or a few request/response interactions have to happen in a single user-ineraction amount of time) so it doesn't have to be fast?\n\n\n\n", "id": "lists-007-9364181"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "spreitze@parc.xerox.com said this:\n> What's the vision of where APPLCORE would be used?  (In a world that already \n> has HTTP, being used and abused for many and increasingly many things, plus \n> CORBA, Java RMI, and DCOM --- what's left?)\n\nHere's an example: in house we've built a few text based protocols\nbetween different vendor supplied services (credit card transactions is\none example). It would help me if I could circulate this document around\nthe company as a standard starting place for simple protocols.\n\nAt least in my mind these are light weight, low to medium demand, very\nnarrowly defined protocols that never used 95% of the features and overhead\nof HTTP much less CORBA, RMI or DCOM...\n\n-MM\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | www.rwhois.net/michael\nSr. Research Engineer   |   www.ga.lp.org/gwinnett     | ICQ#:         14198821\nNetwork Solutions|          www.lp.org          |  michaelm@netsol.com\n\n\n\n", "id": "lists-007-9372674"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "I'm surprised to hear you use word like \"light weight, low to medium demand\" together with \"credit card transactions\".  Maybe that's because it's not clear to me where your protocols fit into the whole financial system; the slots that are obvious to me have fairly high requirements for performance and security.\n\nIt seems to me that most big complicated things started out as small simple things that succeeded and grew; how much do you want to plan for further development of your protocols?\n\n\n\n", "id": "lists-007-9382366"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "spreitze@parc.xerox.com said this:\n> I'm surprised to hear you use word like \"light weight, low to medium demand\" \n> together with \"credit card transactions\".  Maybe that's because it's not \n> clear to me where your protocols fit into the whole financial system; the \n> slots that are obvious to me have fairly high requirements for performance \n> and security.\n\nThe slot for this particular example is between a server that frontends\ncommunication to the clearinghouse provider and our billing backend. \nIt's secure but it only has 3 transaction types (verify, charge and refund).\nSince each transaction is small and atomic the load is no where near what \nsomething like our web servers put up with.\n\n> It seems to me that most big complicated things started out as small simple \n> things that succeeded and grew; how much do you want to plan for further \n> development of your protocols?\n\nFor this one? None. Unless some huge paradigm shift happens in credit \ncard processing I can't think of any changes we would ever make. \n\n-MM\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | www.rwhois.net/michael\nSr. Research Engineer   |   www.ga.lp.org/gwinnett     | ICQ#:         14198821\nNetwork Solutions|          www.lp.org          |  michaelm@netsol.com\n\n\n\n", "id": "lists-007-9390739"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Thu, 11 Feb 1999 spreitze@parc.xerox.com wrote:\n> What's the vision of where APPLCORE would be used?  (In a world that already has HTTP, being used and abused for many and increasingly many things, plus CORBA, Java RMI, and DCOM --- what's left?)\n\nI'd say it would be an option for new protocols not related to HTML\ndocument retrieval/updating/versioning, email transfer, user directory\naccess, or other new services that are not an explicitly documented\npurpose of an IETF standards track protocol.\n\nMy thought was to target it for people who care about simplicity and\nengineering rather than those who like to build things akin to the OSI\nprotocol stack.\n\n> What will be the requirements for efficiency?  Will we be hearing arguments like: because we know there's a large textual payload, the headers and data parts don't have to be particularly compact?  Or: this is not going to be used in demanding environments (e.g., not more than a single or a few request/response interactions have to happen in a single user-ineraction amount of time) so it doesn't have to be fast?\n\nWhat does this have to do with the proposed charter?  Are you suggesting\nthe charter needs explicit efficiency constraints?  I can't predict what\npeople who attend the BOF/WG will find to be important constraints.  If in\ndoubt, the WG should go with what has been successful in past IETF\nprotocols, IMHO.\n\n- Chris\n\n\n\n", "id": "lists-007-9400484"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "> I'd say it would be an option for ...\n> ... new services that are not an explicitly documented\n> purpose of an IETF standards track protocol.\n\nIs it aimed at new IETF protocols, new non-IETF protocols, or both?\n\n\n> > What will be the requirements for efficiency? ...\n\n> What does this have to do with the proposed charter?  Are you suggesting\n> the charter needs explicit efficiency constraints?    I can't predict what\n> people who attend the BOF/WG will find to be important constraints.\n\nWell, I certainly can't claim to be an authority on how to write a successful charter, but I was thinking that a useful part of the chartering process would be to look into the question of what, if anything, is the consensus on efficiency requirements.\n\n\n\n", "id": "lists-007-9410229"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Thu, 11 Feb 1999 spreitze@parc.xerox.com wrote:\n> > I'd say it would be an option for ...\n> > ... new services that are not an explicitly documented\n> > purpose of an IETF standards track protocol.\n> \n> Is it aimed at new IETF protocols, new non-IETF protocols, or both?\n\nI'd target APPLCORE towards new simple engineered application protocols\nakin to past IETF success stories.  I wouldn't try to design for people\nwho want the latest\nActive/Java/Open/Object-Oriented/Push-technology/Jini/Trendy Protocol.  A\nnew core protocol won't stop them from making a mess. \n\n> > What does this have to do with the proposed charter?  Are you suggesting\n> > the charter needs explicit efficiency constraints?    I can't predict what\n> > people who attend the BOF/WG will find to be important constraints.\n> \n> Well, I certainly can't claim to be an authority on how to write a\n> successful charter, but I was thinking that a useful part of the\n> chartering process would be to look into the question of what, if\n> anything, is the consensus on efficiency requirements.\n\nEfficiency brings in all sorts of tradeoffs.  One can make a protocol use\na few fewer bytes on the wire by using a binary encoding, but this has the\nexpense of requiring significant additional programmer time to develop\ndebugging and testing suites since \"telnet\" doesn't work any more.  One\ncan make binary encodings smaller by packing them (akin to OSI's PER) at\nthe expense of making it hopeless to ever have a human interpret the data\nand make machine parsing and debugging thereof much harder.  One can use a\ncompression layer (e.g. the one in TLS or secure shell) which may chew up\nmore CPU at the ends, but will pack both the protocol encoding and data\npayload regardless of text/binary encoding issues.\n\nI can't predict what a careful study of IETF protocol history and\ncomparison of candidate solutions will suggest.  If you have ideas on what\na charter should say to constrain the problem space, please suggest\nwording. Otherwise I think it's adequate for the proposed charter to\nmention this is an issue to consider. \n\n- Chris\n\n\n\n", "id": "lists-007-9418946"}, {"subject": "Re: Continuing to draft mux WG charte", "content": "On Wed, 10 Feb 1999, Mike Spreitzer wrote:\n> OK, I've taken Chris Newman's hint and expanded a bit on security, and\n> also Jim Whitehead's hint to clarify the nature of the goals document. \n> You can view the latest draft at:\n> <http://www.w3.org/Protocols/HTTP-NG/1999/02/mux-Charter-210.html>\n\nWhat I don't find acceptable is wording akin to \"security's not our\nproblem\" which is basically what this proposed charter says.\n\nHere an example of wording I would find acceptable:\n\n----\n   The MEMUX WG will not design new security services.  The document will\n   describe how MEMUX interacts with existing security services (such as\n   IPsec, TLS and SASL) and what impact it will have on higher or\n   lower-level security services.\n----\n\nThere are subtle issues which need to be dealt with:\n\n* If user authentication is done below the MEMUX layer, how will\n  higher-level protocols \"know\" that?\n* If user authentication is done above the MEMUX layer, what\n  damage can passive or active attacks at the MEMUX layer cause?\n* What impact will MEMUX have on firewalls when used to multiplex\n  multiple services on the same port?\n\nSecurity most definitely is part of the problem.\n\n- Chris\n\n\n\n", "id": "lists-007-9429389"}, {"subject": "Re: APPLCORE rough concensus", "content": "On Wed, 10 Feb 1999, Jim Gettys wrote:\n> I don't want to be in a situation where HTTPng is believed to be the \"one \n> size that fits all\", even if HTTPng works out (and its not soup yet), \n> and would want it free to optimize to web operations, which have a different \n> set of constraints than many other applications protocols: e.g. low latency, \n> since a user is driving it is important for interactive feel, which is \n> NOT a requirement on, say, mail.  It is those kinds of requirements (along \n> with the \"brittleness\" of current systems like CORBA), that have made \n> me believe something other than CORBA or Java RMI is needed for the web.\n> \n> It is also not clear to me that HTTPng requirements should bind APPLCORE\n> hands, as the requirements may be found to be disjoint.\n> \n> While the web is a common application protocol, it should not,\n> in my opinion, be the only one.\n\nI agree with all of this.\n\nPerhaps APPLCORE and HTTPng will have sufficiently similar components that\nthey should be aligned for code re-use purposes.  Perhaps APPLCORE should\ntarget simple low-end protocols akin to POP/SMTP/etc and HTTPng target\nmore complex high-end protocols (or even just web browsing) and they'll\nbe separate but useful tools for our toolbox.\n\n- Chris\n\n\n\n", "id": "lists-007-9438840"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "Excerpts from mail: 11-Feb-99 Re: Application \"core proto.. Chris\nNewman@innosoft.co (2105*)\n\n> I can't predict what a careful study of IETF protocol history and\n> comparison of candidate solutions will suggest.\n\nI feel that I can, since that's what we did for the W3C HTTP-NG project.\n I suspect you'd come up with something very like the proposed HTTP-NG\nprotocol stack.\n\nBill\n\n\n\n", "id": "lists-007-9447208"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "On Thu, 11 Feb 1999, Bill Janssen wrote:\n> Excerpts from mail: 11-Feb-99 Re: Application \"core proto.. Chris\n> Newman@innosoft.co (2105*)\n> > I can't predict what a careful study of IETF protocol history and\n> > comparison of candidate solutions will suggest.\n> \n> I feel that I can, since that's what we did for the W3C HTTP-NG project.\n>  I suspect you'd come up with something very like the proposed HTTP-NG\n> protocol stack.\n\nDo you have a public document explaining your observations of past IETF\nprotocol successes and failures?  Perhaps your work could form the basis\nfor the \"history/problem statement\" draft which several people felt should\nbe done instead of identifying/developing a \"core application protocol\"? \n\nI'd certainly be interested in reading the sections on Telnet, IMAP, POP,\nand SMTP as I've written my own and examined other people's protocol\nengines for them.  There are a lot of interesting design lessons from that\nset of protocols, let alone the others I've studied in less detail. \n\n- Chris\n\n\n\n", "id": "lists-007-9455753"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "No, we never put together a formal document, but that's not a bad idea. \nI'd certainly be interested in working on such a document.\n\nBill\n\n\n\n", "id": "lists-007-9465098"}, {"subject": "Re: Continuing to draft mux WG charte", "content": "I agree with Chris re security, but I have another concern or possibly\na confusion. The draft is written very aggressively to assume TCP\nas the substrate; IMHO this is wrong. If a new transport protocol\nof the general flavour of T/TCP emerges, MEMUX must be able to use\nit.\n\nAnother thing I would like to see is a clear goal of being\nindependent of IPv4 v IPv6, and able to function in a dynamic\naddress environment such as NAT. In fact this is key to success.\n\n   Brian\n\nChris Newman wrote:\n> \n> On Wed, 10 Feb 1999, Mike Spreitzer wrote:\n> > OK, I've taken Chris Newman's hint and expanded a bit on security, and\n> > also Jim Whitehead's hint to clarify the nature of the goals document.\n> > You can view the latest draft at:\n> > <http://www.w3.org/Protocols/HTTP-NG/1999/02/mux-Charter-210.html>\n> \n> What I don't find acceptable is wording akin to \"security's not our\n> problem\" which is basically what this proposed charter says.\n> \n> Here an example of wording I would find acceptable:\n> \n> ----\n>    The MEMUX WG will not design new security services.  The document will\n>    describe how MEMUX interacts with existing security services (such as\n>    IPsec, TLS and SASL) and what impact it will have on higher or\n>    lower-level security services.\n> ----\n> \n> There are subtle issues which need to be dealt with:\n> \n> * If user authentication is done below the MEMUX layer, how will\n>   higher-level protocols \"know\" that?\n> * If user authentication is done above the MEMUX layer, what\n>   damage can passive or active attacks at the MEMUX layer cause?\n> * What impact will MEMUX have on firewalls when used to multiplex\n>   multiple services on the same port?\n> \n> Security most definitely is part of the problem.\n> \n>                 - Chris\n\n\n\n", "id": "lists-007-9472938"}, {"subject": "Re: Continuing to draft mux WG charte", "content": "You wrote: [[\nThere are subtle issues which need to be dealt with:\n\n* If user authentication is done below the MEMUX layer, how will\n  higher-level protocols \"know\" that?\n* If user authentication is done above the MEMUX layer, what\n  damage can passive or active attacks at the MEMUX layer cause?\n* What impact will MEMUX have on firewalls when used to multiplex\n  multiple services on the same port?\n]]\n\nAs for the first: how do higher layers ever \"know\" about authentication done in lower layers?  This is an issue of software in the peers, not the protocol, right?  What goes on the wire makes it clear (assuming the protocols above and below MEMUX were prepared to be separated at all --- which they would of course be if they're separate protocols); the issue is that an API for using MEMUX must enable authentication to pass through the MEMUX software layer appropriately.  As this WG is not about designing the API, I figure that issue is out of scope.\n\nI think the other two issues are clearly in scope.\n\n\n\n", "id": "lists-007-9482898"}, {"subject": "Re: Continuing to draft mux WG charte", "content": "> The draft is written very aggressively to assume TCP\n> as the substrate; IMHO this is wrong. If a new transport protocol\n> of the general flavour of T/TCP emerges, MEMUX must be able to use\n> it.\n\nHuh?  The draft is written very aggressively in terms of a general statement about the services expected from the underlying layer, rather than identifying TCP as *the* underlying layer.  I think that set of services is a \"general flavour\", and is delivered by T/TCP.\n\n> Another thing I would like to see is a clear goal of being\n> independent of IPv4 v IPv6, and able to function in a dynamic\n> address environment such as NAT. In fact this is key to success.\n\nI hadn't expected the protocol to carry any addresses, so I hadn't expected these kinds of issues to come up at all.  Wouldn't you agree that it goes without saying that wherever addresses *do* appear in current IETF work, the demands of the currently underway evolutionary steps of the Internet must be taken into account?\n\n\n\n", "id": "lists-007-9491918"}, {"subject": "Another revision of the mux WG charter", "content": "OK guys, have at it:\n<http://www.w3.org/Protocols/HTTP-NG/1999/02/mux-Charter-212.html>\n\n\n\n", "id": "lists-007-9501464"}, {"subject": "Re: Application &quot;core protocol&quot; BOF/WG ide", "content": "At 14:27 11/02/99 -0800, Chris Newman wrote:\n[...]\n>Efficiency brings in all sorts of tradeoffs.  One can make a protocol use\n>a few fewer bytes on the wire by using a binary encoding, but this has the\n>expense of requiring significant additional programmer time to develop\n>debugging and testing suites since \"telnet\" doesn't work any more.\n\nHere is an interesting possible win...  If the APPLCORE framework provides\nsufficient structure that a generic test/debug suite can be created to\nassist protocol implementors.\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-9508173"}, {"subject": "Re: Last Call: HTTP Extension Framework to Proposed Standar", "content": "To the IESG:\n\nThis is to notify you of the current status of the situation around\ndraft-frystyk-http-extensions-02.  My main problems with it have not\nbeen resolved by Henrik's recent reply to my last call comments.  We\nare trying to resolve things in private e-mail, but I can't tell yet\nwhether we will actually converge.  It is quite possible that, when\nHenrik releases the next draft, it will not resolve all my comments.\n\nI won't post a detailed reply to Henrik's comments on my comments\nhere, at least not right now.  Replies to some parts are below.\n\n\nHenrik Frystyk Nielsen:\n>Koen Holtman:\n[....]\n>>By allowing for cachable extended responses, the spec opens up a\n>>rather large can of worms.  Below I have identified several places\n>>where the spec does not handle these worms with sufficient care, but\n>>my list is probably not complete.  In my opinion this stuff should be\n>>fixed by avoiding the problem all-together, i.e. by simply making all\n>>extended responses uncachable, and making sure that extended requests\n>>can never be responded to by a plain HTTP/1.x cache.\n>\n>That would certainly be one solution, however, I think it would be\n>unfortunate to propose an extension mechanism to a protocol that short\n>circuits the several years of detailed caching design that has been going\n>on in HTTP/1.1.\n\nAs you know I was heavily involved in these `several years of detailed\ncaching design' in HTTP/1.1.  I can tell you that correctness was a\nmajor goal and that you are breaking it in several places.  You have a\nchoice between two options: either you specify a correct and simple\ncaching discipline, or you do a lot of more work and specify a correct\nand subtle one with slightly better performance.  The discipline you\nspecify now is incorrect: it does not contain the necessary elements\nneeded if independently developed extensions are to reconcile their\ncaching needs without error, and it specifies some other necessary\nelements a wrong or overly simplistic way (like the 'include a\nCache-Control' in section 9).  This incorrect discipline will lead to\nall kinds of breakage and is therefore simply unacceptable.  \n\nIf you don't believe things will break then try some implementation\nexperiments with multiple mandatory extensions in several cascaded\nproxies, with all these extensions attaching some dynamic information\nto the response which will become stale at different rates.  Oh yes,\nthe exact nature of the information added depends of course on the\nparameter headers sent with the extension requests, and the origin\nserver which you are contacting contains resources which require\ndifferent caching disciplines, with some of the resources being\naccessible only if a payment extension is used.  Your user agent sends\na request with an if-none-match header whenever it revalidates a stale\nresponse.  The proxy chain contains some plain 1.1 proxies too, and\nyou try adding some 1.0 ones if you feel lucky.\n\nYou can look at protocol extensions like RFC2227 and RFC2295 to find\nsome of the things which are needed to safely extend HTTP if caching\ngets involved.  Your job is even bigger because you are writing a\nmeta-protocol to co-ordinate unspecified extensions!\n\n\n[...]\n>>- Sec 5 point 3:\n>>\n>>          3.  If 2) did not result in a 510 (Not Extended) status code, then\n>>              strip the \"M-\" prefix from the method name and process the\n>>              remainder of the request according to the semantics of the\n>>              extensions and of the existing HTTP method name as defined in\n>>              HTTP/1.1 [5] or later versions of HTTP.\n>>\n>>This implies that a proxy which has processed an end-to-end mandatory\n>>extension should _not_ strip the existing Man header in the request\n>>when forwarding the request towards the origin server (when\n>>'processing the remainder according to the semantics of the existing\n>>HTTP method name as defined in HTTP/1.1').  Not stripping the header\n>>is of course wrong.  If the proxy adds its own M- extension to the\n>>outgoing request without stripping the processed Man header first,\n>>this will cause the ultimate recipient of that extension to process\n>>the old Man extension again.  This will have fun effects especially if\n>>the extension is for a payment protocol.\n>\n>The algorithm that you refer to says nothing about how to *forward* a\n>mandatory request [...]\n\nIt talk about 'processing the remainder', and this can mean forwarding\nin a proxy, so yes, it does talk about forwarding, and tells us that\nthe M- should be stripped in this case.\n\n[...]  Therefore, I think the text is exactly correct in that\n>it doesn't make the assumption you infer, namely that the only right way \n>is to strip the extension.\n\nYes, the text does not say that you should strip the extension.  My\npoint is that *the text is wrong in not saying this*.  Above I\ndescribe a scenario where the lack of this stripping requirement leads\nto trouble because the extension is invoked two times.  You should\neither\n\n a) explain why this scenario cannot happen, or\n b) explain why I am incorrect in my assesment that the protocol is broken\n    if this scenario can happen.\n\n\n[...]\n>>- Sec 5 point 4:\n>>\n>>              A server MUST NOT fulfill a request without\n>>              understanding and obeying all mandatory extension\n>>              declaration(s) in a request.\n>>\n>>This implies that a request cannot contain two mandatory extensions\n>>which are to be executed by different upstream servers.  For example,\n>>if I want my browser to send a mandatory extension to my firewall\n>>proxy to enable some privacy processing, I cannot at the same time use\n>>a browser plugin which sends a mandatory extension to trigger some\n>>plugin-related functionality in the origin server.  Not being able to\n>>combine two extensions in this way is a rather severe restriction\n>>which kills the whole protocol for me.  It means that plugin vendors\n>>cannot use the protocol for fear of proxies getting in the way, and\n>>that proxy vendors cannot use the protocol for fear of plugin vendors\n>>getting in the way.  Result: nobody can use it.\n>\n>This has in fact little to do with the extension framework. What you are\n>questioning is the basic notion of scope in HTTP/1.1.\n\nNo, this has nothing to do with scope in HTTP/1.1, I am perfectly\nhappy with the basic notion of scope in HTTP.  To address my concern\nabove you should either\n\n a) explain that I am wrong in saying that \n \n     For example,\n     if I want my browser to send a mandatory extension to my firewall\n     proxy to enable some privacy processing, I cannot at the same time\n     use a browser plugin which sends a mandatory extension to trigger\n     some plugin-related functionality in the origin server.\n\n or b) explain why I am wrong in my reasoning that this\n\n      means that plugin vendors\n      cannot use the protocol for fear of proxies getting in the way, and\n      that proxy vendors cannot use the protocol for fear of plugin \n      vendors getting in the way.  Result: nobody can use it.\n\nKoen.\n\n\n\n", "id": "lists-007-9516619"}, {"subject": "Re: Continuing to draft mux WG charte", "content": "spreitze@parc.xerox.com wrote:\n> \n> > The draft is written very aggressively to assume TCP\n> > as the substrate; IMHO this is wrong. If a new transport protocol\n> > of the general flavour of T/TCP emerges, MEMUX must be able to use\n> > it.\n> \n> Huh?  The draft is written very aggressively in terms of a general statement about the services expected from the underlying layer, rather than identifying TCP as *the* underlying layer.  I think that set of services is a \"general flavour\", and is delivered by T/TCP.\n\nWell, I read it to imply TCP as the preferred transport. \n\n> \n> > Another thing I would like to see is a clear goal of being\n> > independent of IPv4 v IPv6, and able to function in a dynamic\n> > address environment such as NAT. In fact this is key to success.\n> \n> I hadn't expected the protocol to carry any addresses, so I hadn't expected these kinds of issues to come up at all.  Wouldn't you agree that it goes without saying that wherever addresses *do* appear in current IETF work, the demands of the currently underway evolutionary steps of the Internet must be taken into account?\n\nI agree; and I'm suggesting the charter needs to say so.\n\n    Brian\n\n\n\n", "id": "lists-007-9532848"}, {"subject": "Re: Last Call: HTTP Extension Framework to Proposed Standar", "content": "Koen,\n\nThe extension framework must not automatically prevent caching.\nThere is nothing in Henrik's draft that prevents an extended request\nor response from including the EXISTING cache control mechanisms of\nHTTP/1.1.  It is not necessary, nor is it desired, for the draft to\nassume that an extended message is not cachable just because some\nparticular extension might not be cachable.  Therefore, your suggested\nchanges are contrary to the design of HTTP.\n\nIt is the responsibility of the extension to ensure that the appropriate\ncaching or cache-busting is applied based on the individual semantics of\neach specific message.  This cannot be ascertained without knowledge of\nthe extension semantics, and therefore it is not part of the extension\nframework for the same reason that the framework does not define actual\nextensions.\n\n\n ...Roy T. Fielding\n    Department of Information & Computer Science    (fielding@ics.uci.edu)\n    University of California, Irvine, CA 92697-3425    fax:+1(949)824-1715\n    http://www.ics.uci.edu/~fielding/\n\n\n\n", "id": "lists-007-9542120"}, {"subject": "Use of TELNET for testing protocol", "content": "At 23.27 +0100 99-02-11, Chris Newman wrote:\n> Efficiency brings in all sorts of tradeoffs.  One can make a protocol use\n> a few fewer bytes on the wire by using a binary encoding, but this has the\n> expense of requiring significant additional programmer time to develop\n> debugging and testing suites since \"telnet\" doesn't work any more.\n\nI know that you can use TELNET to test a server by\nsimulating a client, by a human typing or pasting the client\nparts of a textual protocol.\n\nBut how can you use TELNET to test a client by simulating a\nserver? This would certainly be very useful, and perhaps\nthis is common knowledge which I have not acquired?\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-9551987"}, {"subject": "URLs in web-based groupwar", "content": "I am involved in an EU-funded research project (Senior\nOnline, http://cmc.dsv.su.se/sol) which has decided to\ndevelop a protocol for communicating between\nnon-simultaneous forum systems (like Lotus Notes, First\nClass, etc.). We have noted that many such forums are\nweb-based or have a web-based user interface. By web-based\nis meant that the users use an ordinary web browser as a\nclient, and that many of the normal functions of a client\nis handled by the HTTP server.\n\nWe have, however, noted a technical problem, which we would\nlike to have guidance from experienced application-layer\nprotocol designers on. The technical problem is as follows:\n\nA user should be able to participate in different forums,\nwhich are hosted by different forum servers, connected\nthrough the protocol we develop. The user, however, will\nprefer to connect to only one of these servers. There are\nmany reasons for this:\n\n(a) The user wants the same user interface for all forums.\n\n(b) A facility for ordering and prioritizing new messages\n    and forums is easier provided to users if they always\n    access one server.\n\n(c) The user need not log in multiple times, if only one\n    server is used.\n\nSince ordinary web browsers are used as clients, forums and\nmessages in forums and other group communication objects\nshould all have URLs. However, the URL of a group\ncommunication object must vary from user to user, since it\nmust start with the domain name of the server which each\nparticular user is using.\n\nFor example, assume that there is a forum named\n\"tropical-flowers\". The URL of this forum may be\n http://sol.botany.com/tropical-flowers. If, however, I am a\nuser of the groupware server at http://sol.myhome.se, then\nthe URL of the forum must start with http://sol.myhome.se.\nIf its URL was http://sol.botany.com/tropical-flowers, then\nclicking on it with an ordinary web browser would connect\nme to a foreign groupware server, which is not wanted.\n\nA possible solution to this problem might be to include the\ngroupware server domain twice, first the user's server,\nthen the groupware object's server. For example, if my\nlocal groupware server is http://sol.myhome.se, then the\nURL for the forum in the example above might be\n http://sol.myhone.se/sol.botany.com/tropical-flowers.\n\nVariants of this solution:\n\n(i) Put \"?\" between the domains, thus use\n http://sol.myhone.se?sol.botany.com/tropical-flowers\nDisadvantage: Some web browsers use the same cached object\nfor all URLs with the same string before the first \"?\" in\nthe URL.\n\n(ii) Put \"/x\" or \"/external\" between them, thus use\n http://sol.myhone.se/external/sol.botany.com/tropical-flowers\n\n(iii) Require that the domain is repeated twice also when\nconnecting to the home server of the groupware object, in\nthe example above\n http://sol.botany.com/sol.botany.com/tropical-flowers\n\nQuestion: Is this a good idea, and if so, which of the\nthree syntactical variants (i), (ii) and (iii) is best?\n\nNote: Do not answer that we should use URNs. We cannot,\nsince web browsers do not at present support them.\n\nA problem will of course occur, if a user sends by e-mail,\nor puts in an ordinary web page, an URL like\n http://sol.other.com/sol.botany.com/tropical-flowers\nand a user clicks on it. The user will then be connected to\n http://sol.other.com. Our intention is to solve this, by\nhaving the welcome page of http://sol.other.com include\ntools for the user to move to his home groupware server,\nand access the same groupware object from that server.\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-9560445"}, {"subject": "Re: Continuing to draft mux WG charte", "content": "At 08:43 12/02/99 PST, spreitze@parc.xerox.com wrote:\n>As for the first: how do higher layers ever \"know\" about authentication\ndone in lower layers?  This is an issue of software in the peers, not the\nprotocol, right?  What goes on the wire makes it clear (assuming the\nprotocols above and below MEMUX were prepared to be separated at all ---\nwhich they would of course be if they're separate protocols); the issue is\nthat an API for using MEMUX must enable authentication to pass through the\nMEMUX software layer appropriately.  As this WG is not about designing the\nAPI, I figure that issue is out of scope.\n>\n>I think the other two issues are clearly in scope.\n>\n\nI think the first is also in scope, to the extent that your points above be\nnoted as a \"security consideration\".\n\n#g\n\n------------\nGraham Klyne\n(GK@ACM.ORG)\n\n\n\n", "id": "lists-007-9572165"}, {"subject": "Re: Use of TELNET for testing protocol", "content": "Jacob Palme wrote:\n> \n> At 23.27 +0100 99-02-11, Chris Newman wrote:\n> > Efficiency brings in all sorts of tradeoffs.  One can make a protocol use\n> > a few fewer bytes on the wire by using a binary encoding, but this has the\n> > expense of requiring significant additional programmer time to develop\n> > debugging and testing suites since \"telnet\" doesn't work any more.\n> \n> I know that you can use TELNET to test a server by\n> simulating a client, by a human typing or pasting the client\n> parts of a textual protocol.\n> \n> But how can you use TELNET to test a client by simulating a\n> server? This would certainly be very useful, and perhaps\n> this is common knowledge which I have not acquired?\n\nYou have to use some glueware. In particular, a program that would do\nthe trick would monitor two ports and forwards packets between the two.\nI've never seen such a program, but it should be possible to write it\nvery quickly in perl or most other languages.\n\nTony Hansen\ntony@att.com\n\n# pseudo code follows. anyone care to finish it?\n$port_telnet = $ARGV[1];# telnet to this port\n$port_client = $ARGV[2];# may need root to accept connections here\n\naccept connection on ports $port_telnet and $port_client\n\nwhile (select($port_telnet | $port_client, 0, 0, 0))\n    {\n    if ($port_telnet has input)\n        {\n        $buf = sysread($port_telnet);\n        ... check for errors, EOF, etc.\n        syswrite($port_client, $buf, length $buf);\n        }\n    if ($port_client has input)\n        {\n        $buf = sysread($port_client);\n        ... check for errors, EOF, etc.\n        syswrite($port_telnet, $buf, length $buf);\n        }\n    }\n\n\n\n", "id": "lists-007-9581415"}, {"subject": "Re: URLs in web-based groupwar", "content": "Considering only the reasons you cited for a user to want to mainly use a particular server, it seems a possible solution is to distinguish between the URL for an item's \"full presentation\" (which includes the decorations for navigation, cookies for managing the conversation between client and server, etc) and the URL for the item itself.  E.g., think of the full presentation as having frames, one of which contains the item.  The full presentation is specific to a particular server; the item itself has just one URL and you don't care where it is.\n\nThere are even more reasons for wanting a family of \"equivalent\" URLs, and these are a general problem on the web.  The classic example is motivated by mirroring, where you want each user to be fetching from a \"nearby\" mirror and yet everybody communicates with URLs that are not mirror-specific.\n\n\n\n", "id": "lists-007-9590308"}, {"subject": "Re: URLs in web-based groupwar", "content": "At 17.19 +0100 99-02-15, <spreitze@parc.xerox.com> wrote:\n> Considering only the reasons you cited for a user to want\n>to mainly use a particular server, it seems a possible\n>solution is to distinguish between the URL for an item's\n>\"full presentation\" (which includes the decorations for\n>navigation, cookies for managing the conversation between\n>client and server, etc) and the URL for the item itself.\n>E.g., think of the full presentation as having frames, one\n>of which contains the item.  The full presentation is\n>specific to a particular server; the item itself has just\n>one URL and you don't care where it is.\n\nThis would be too difficult to users, to understand and distinguish\nbetween two URLs and use the right one at the right time.\n\n> There are even more reasons for wanting a family of\n>\"equivalent\" URLs, and these are a general problem on the\n>web.  The classic example is motivated by mirroring, where\n>you want each user to be fetching from a \"nearby\" mirror\n>and yet everybody communicates with URLs that are not\n>mirror-specific.\n\nThat is handled by the URN standard, but we cannot use it,\nbecause it is not supported by current web browsers.\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-9598967"}, {"subject": "Re: URLs in web-based groupwar", "content": "Jacob Palme said this:\n> At 17.19 +0100 99-02-15, <spreitze@parc.xerox.com> wrote:\n> > There are even more reasons for wanting a family of\n> >\"equivalent\" URLs, and these are a general problem on the\n> >web.  The classic example is motivated by mirroring, where\n> >you want each user to be fetching from a \"nearby\" mirror\n> >and yet everybody communicates with URLs that are not\n> >mirror-specific.\n> \n> That is handled by the URN standard, but we cannot use it,\n> because it is not supported by current web browsers.\n> \n\nI am currently writing this into mozilla. We also have a plugin\nfor Explorer that we are working on improving. MS has made some\nnoise in the past of needing URN support. All of the software\nis available at ftp://research.netsol.com. There are also\nJava classes available for URN resolution.\n\n-MM\n\n-MM\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | www.rwhois.net/michael\nSr. Research Engineer   |   www.ga.lp.org/gwinnett     | ICQ#:         14198821\nNetwork Solutions|          www.lp.org          |  michaelm@netsol.com\n\n\n\n", "id": "lists-007-9608327"}, {"subject": "RE: Use of TELNET for testing protocol", "content": "try WRS's 'sock' program\nor Hobbits \"netcat\".\n\nBoth will give an equivalent server function.  You can bind on a port\nand when a connectoin comes in, ie from a browser, the i/o will be on\nstdin/stdout for you to manually enter.\n\n> -----Original Message-----\n> From: Jacob Palme [mailto:jpalme@dsv.su.se]\n> Sent: Sunday, February 14, 1999 9:15 AM\n> To: discuss@apps.ietf.org\n> Subject: Use of TELNET for testing protocols\n> \n> \n> At 23.27 +0100 99-02-11, Chris Newman wrote:\n> > Efficiency brings in all sorts of tradeoffs.  One can make \n> a protocol use\n> > a few fewer bytes on the wire by using a binary encoding, \n> but this has the\n> > expense of requiring significant additional programmer time \n> to develop\n> > debugging and testing suites since \"telnet\" doesn't work any more.\n> \n> I know that you can use TELNET to test a server by\n> simulating a client, by a human typing or pasting the client\n> parts of a textual protocol.\n> \n> But how can you use TELNET to test a client by simulating a\n> server? This would certainly be very useful, and perhaps\n> this is common knowledge which I have not acquired?\n> \n> --------------------------------------------------------------\n> ----------\n> Jacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\n> for more info see URL: http://www.dsv.su.se/~jpalme\n> \n\n\n\n", "id": "lists-007-9617104"}, {"subject": "Re: Use of TELNET for testing protocol", "content": "I've dealt with both binary (straight-forward marshalling onto the wire,\nnothing baroque like PER) and text protocols, and have not\nfound a particular advantage to either in terms of debugging. To me,\nuse of telnet is hardly a compelling argument one way or the other.\n\nPutting a breakpoint on the stubs on either end in a debugger,\nand dumping the data structures, has often been easier than having\nto scratch my head about syntax being correct (and the generation\nand parsing thereof) in a text based protocol.  Not having the same\nclass of parsing bugs in binary implementations helps muchly on their\nside of the equasion.\n\nNote that binary protocols must be well engineered when it comes to\nextensions, or they get into trouble in the long term.  There are\nsimilar problems with text protocols: a good example is HTTP, where there\nis about 4 different ways to figure out if a message is complete (some\nof which require fondling every byte fondly as it goes by).\n\nI find worrying about one or the other pretty close to a religious debate,\nnot amenable to rational discussion, and only an issue when either:\no latency requirements force a tight encoding\no The protocol parameters are a significant fraction of the payload,\nand bandwidth becomes an issue.\n\nSo this is/should be an engineering decision, examined in the light of\nthe application.\n\nAnd as far as I'm concerned, all this is another argument for modularity\nin any protocol stack, so that argument marshalling is one of the modules\nthat can be traded off on a per application basis.\n- Jim Gettys\n\n\n\n", "id": "lists-007-9626788"}, {"subject": "Re: Use of TELNET for testing protocol", "content": "Jim Gettys said this:\n> I've dealt with both binary (straight-forward marshalling onto the wire,\n> nothing baroque like PER) and text protocols, and have not\n> found a particular advantage to either in terms of debugging. To me,\n> use of telnet is hardly a compelling argument one way or the other.\n> \n> Putting a breakpoint on the stubs on either end in a debugger,\n> and dumping the data structures, has often been easier than having\n> to scratch my head about syntax being correct (and the generation\n> and parsing thereof) in a text based protocol.  Not having the same\n> class of parsing bugs in binary implementations helps muchly on their\n> side of the equasion.\n\nJust a minor nit, your observation is probably correct when you are\nactually writing an implementation of the protocol from scratch. I think\nwhen most of us speak about 'debugging' a server by simply telnetting\nto the port is after its been built and we are debugging particular\napplications that are using that protocol. Or also in the case where\nwe do not have debugging access to the server or client (proprietary \nbinaries).\n\nAlso, from a past sysadmin's point of view, you're never gauranteed to\nhave the libraries needed to parse a binary protocol on any given client.\nTelnet is everywhere....\n\n-MM\n\nSorry, hard to resist when your particular religion gets tweaked... ;-)\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | www.rwhois.net/michael\nSr. Research Engineer   |   www.ga.lp.org/gwinnett     | ICQ#:         14198821\nNetwork Solutions|          www.lp.org          |  michaelm@netsol.com\n\n\n\n", "id": "lists-007-9635953"}, {"subject": "Re: Use of TELNET for testing protocol", "content": "> From: Michael Mealling <michael@bailey.dscga.com>\n> Date: Wed, 17 Feb 1999 10:43:39 -0500 (EST)\n> To: jg@pa.dec.com (Jim Gettys)\n> Cc: joshco@microsoft.com, jpalme@dsv.su.se, discuss@apps.ietf.org\n> Subject: Re: Use of TELNET for testing protocols\n> -----\n> Jim Gettys said this:\n> > I've dealt with both binary (straight-forward marshalling onto the wire,\n> > nothing baroque like PER) and text protocols, and have not\n> > found a particular advantage to either in terms of debugging. To me,\n> > use of telnet is hardly a compelling argument one way or the other.\n> >\n> > Putting a breakpoint on the stubs on either end in a debugger,\n> > and dumping the data structures, has often been easier than having\n> > to scratch my head about syntax being correct (and the generation\n> > and parsing thereof) in a text based protocol.  Not having the same\n> > class of parsing bugs in binary implementations helps muchly on their\n> > side of the equasion.\n> \n> Just a minor nit, your observation is probably correct when you are\n> actually writing an implementation of the protocol from scratch. I think\n> when most of us speak about 'debugging' a server by simply telnetting\n> to the port is after its been built and we are debugging particular\n> applications that are using that protocol. Or also in the case where\n> we do not have debugging access to the server or client (proprietary\n> binaries).\n> \n> Also, from a past sysadmin's point of view, you're never gauranteed to\n> have the libraries needed to parse a binary protocol on any given client.\n> Telnet is everywhere....\n> \n> -MM\n> \n> Sorry, hard to resist when your particular religion gets tweaked... ;-)\n\nAs I said; religious argument...\n\nThen again, I've been involved in several binary protocols, one of which \nhas had literally thousands of applications written for it (the X Window \nSystem protocol).\n\nOn the systems that support it, the client libraries are either there\nfrom the vendor, or can be built from source (your preference).\n\nAnother debugging tool useful at times for X has been a pseudo-server, \nwhich dumps the protocol traffic in both directions; this is particularly\nuseful when looking at performance issues.  This has also allowed looking\nat both client and server as black boxes, without poking inside, and\neases finger pointing in binary only situations.\n\nText protocols and telnet debugging have a lower entry cost, but much \nhigher curve as things get compicated.  Binary protocols tend to have \nhigher up-front costs (building a bit more infrastructure up front), but \nlower difficultly curves, as the complexity of the protocol goes up.\n\nI stand by my opinion that it is six of one, half a dozen of the other;\nwhat is most appropriate depends on your application.  One size does not\nfit all needs.\n- Jim\n\n\n\n", "id": "lists-007-9645828"}, {"subject": "Re: Use of TELNET for testing protocol", "content": "Jim Gettys said this:\n> Text protocols and telnet debugging have a lower entry cost, but much \n> higher curve as things get compicated.  Binary protocols tend to have \n> higher up-front costs (building a bit more infrastructure up front), but \n> lower difficultly curves, as the complexity of the protocol goes up.\n\nI think it might be somewhat valuable to wrap a draft boilerplate around\nthat last paragraph and send it out as an informational RFC. IMHO, as\nsoon as complex data types and marshalling come into play, the low cost \naspects of a text based protocol go out the window. But that's just the \ntest that I personally use.\n\n> I stand by my opinion that it is six of one, half a dozen of the other;\n> what is most appropriate depends on your application.  One size does not\n> fit all needs.\n\nExactly....\n\n-MM\n\n-- \n--------------------------------------------------------------------------------\nMichael Mealling|      Vote Libertarian!       | www.rwhois.net/michael\nSr. Research Engineer   |   www.ga.lp.org/gwinnett     | ICQ#:         14198821\nNetwork Solutions|          www.lp.org          |  michaelm@netsol.com\n\n\n\n", "id": "lists-007-9658353"}, {"subject": "RE: Use of TELNET for testing protocol", "content": "agree.\n I think we are not typical of the folks who debug.  I suspect that, by far,\nthe\nmost common debugging case (in volume) is sysadmin and network people\nusing sniffers or telnet.\nText based protocols are helpful to telnet and to someone reading a simple\nnetwork trace.\nWhile sniffers have protocol modules to decipher non-text protocols for easy\nreading, not everyone has access to a sniffer or sniffer program with the\nlatest\nprotocol modules.\n\nOne thing that I think text based does for a protocol is to greatly increase\nits chances of quick adoption.  Maybe people hacked together working\nimplementations\nof web servers (for better or worse) by simply examining another working web\nserver\nwith telnet having never looked at the spec.\n\nAs an admin in the past, it was easy for me to hack up a perl script to \ndo http for quick fixes and administrative announcements, which helped\nme learn alot.   When it came to SNMP (which I was also responsible for)\nI had such a hard time figuring out what was going on because the books\nwere too theoretical for my practical mind, the tools were limited,\nand I couldnt easily hack my own in perl.\n\n\n> -----Original Message-----\n> From: Michael Mealling [mailto:michael@bailey.dscga.com]\n> Sent: Wednesday, February 17, 1999 7:44 AM\n> To: jg@pa.dec.com\n> Cc: Josh Cohen; jpalme@dsv.su.se; discuss@apps.ietf.org\n> Subject: Re: Use of TELNET for testing protocols\n> \n> \n> Jim Gettys said this:\n> > I've dealt with both binary (straight-forward marshalling \n> onto the wire,\n> > nothing baroque like PER) and text protocols, and have not\n> > found a particular advantage to either in terms of debugging. To me,\n> > use of telnet is hardly a compelling argument one way or the other.\n> > \n> > Putting a breakpoint on the stubs on either end in a debugger,\n> > and dumping the data structures, has often been easier than having\n> > to scratch my head about syntax being correct (and the generation\n> > and parsing thereof) in a text based protocol.  Not having the same\n> > class of parsing bugs in binary implementations helps \n> muchly on their\n> > side of the equasion.\n> \n> Just a minor nit, your observation is probably correct when you are\n> actually writing an implementation of the protocol from \n> scratch. I think\n> when most of us speak about 'debugging' a server by simply telnetting\n> to the port is after its been built and we are debugging particular\n> applications that are using that protocol. Or also in the case where\n> we do not have debugging access to the server or client (proprietary \n> binaries).\n> \n> Also, from a past sysadmin's point of view, you're never gauranteed to\n> have the libraries needed to parse a binary protocol on any \n> given client.\n> Telnet is everywhere....\n> \n> -MM\n> \n> Sorry, hard to resist when your particular religion gets \n> tweaked... ;-)\n> \n> -- \n> --------------------------------------------------------------\n> ------------------\n> Michael Mealling|      Vote Libertarian!       | \nwww.rwhois.net/michael\nSr. Research Engineer   |   www.ga.lp.org/gwinnett     | ICQ#:\n14198821\nNetwork Solutions|          www.lp.org          |\nmichaelm@netsol.com\n\n\n\n", "id": "lists-007-9667967"}, {"subject": "RE: Use of TELNET for testing protocol", "content": "> -----Original Message-----\n> From: Michael Mealling [mailto:michael@bailey.dscga.com]\n> Sent: Wednesday, February 17, 1999 8:50 AM\n> To: jg@pa.dec.com\n> Cc: michaelm@netsol.com; jg@pa.dec.com; Josh Cohen; jpalme@dsv.su.se;\n> discuss@apps.ietf.org\n> Subject: Re: Use of TELNET for testing protocols\n> \n> \n> Jim Gettys said this:\n> > Text protocols and telnet debugging have a lower entry \n> cost, but much \n> > higher curve as things get compicated.  Binary protocols \n> tend to have \n> > higher up-front costs (building a bit more infrastructure \n> up front), but \n> > lower difficultly curves, as the complexity of the protocol goes up.\n>\ndefinitely an insightful statement.\n\nHowever, has IMAP or POP had the same problems because its text?\nOr, is it just HTTP's loose syntax of optional and ignored stuff\nthat has cause so much pain?\nI havent noticed the same terrible cries in the IMAP/POP world,\nbut then again, maybe I dont spend enough time in that world\nto notice.  Chris ?\n\n\n\n", "id": "lists-007-9680682"}, {"subject": "Re: Last Call: HTTP Extension Framework to Proposed Standar", "content": "Roy T. Fielding:\n>\n>Koen,\n>\n>The extension framework must not automatically prevent caching.\n>There is nothing in Henrik's draft that prevents an extended request\n>or response from including the EXISTING cache control mechanisms of\n>HTTP/1.1.  It is not necessary, nor is it desired, for the draft to\n>assume that an extended message is not cachable just because some\n>particular extension might not be cachable.  Therefore, your suggested\n>changes are contrary to the design of HTTP.\n\nRoy,\n\nMy main concern about caching in the current draft is that some of the\nMUST/MAY/SHOULD rules in there (see my comments sent to the IESG) will\nsometimes cause the caching directives of upstream servers, which\ngenerated the content, to be violated by downstream caches.  This is\nunacceptable to me.\n\nCaching is like security: you should either provide a protocol which is\ncorrect in all cases or you should not provide it alltogether.\n\nThis is separate from the issue that some extensions could _want_ to\nviolate upstream caching directives.  I see no reasons to disallow\nthis but this use case cannot be used as an excuse for the broken\nMUST/MAY/SHOULD rules which apply to all extensions.\n\nThe MUST/MAY/SHOULD text in the draft can be fixed, and I am trying to\nwork on this with Henrik, but I have no idea whether we will\nconverge.  I do feel that Henrik is not treating the issue with the\ncare it deserves.\n\nI have other concerns in that the draft is very sketchy and sometimes\nmisleading in caching advice to implementers, but these are of a lower\norder than the glitches in the MUST/MAY/SHOULD discipline.\n\nKoen.\n\n\n\n", "id": "lists-007-9691649"}, {"subject": "Re: Last Call: HTTP Extension Framework to Proposed Standar", "content": "At 11:28 2/18/99 +0100, Koen Holtman wrote:\n\n>The MUST/MAY/SHOULD text in the draft can be fixed, and I am trying to\n>work on this with Henrik, but I have no idea whether we will\n>converge.  I do feel that Henrik is not treating the issue with the\n>care it deserves.\n\nKoen,\n\nBefore you go on saying what can be fixed and what not can be fixed in the\ncurrent draft I think it would be instructive to point out that you have\nyet to identify a correctness problem in the *current*design* based on what\nis *supported* by the specification.\n\nAs far as I can tell, you have until now shown what will break *if* the\ndesign was different in that a proxy could pick what it wanted to comply\nwith and forward the rest. This is *not* a part of the current design nor\ndo I believe this is in any way implied by the specification asis (in fact\nI have shown you at least one scenario where this does not work).\n\nPlease be aware that if are proposing a *different* design than what is\ncurrently described then that is fine but let's try and keep things separate.\n\nHenrik\n\n--\nHenrik Frystyk Nielsen,\nWorld Wide Web Consortium\nhttp://www.w3.org/People/Frystyk\n\n\n\n", "id": "lists-007-9702036"}, {"subject": "Re: Last Call: HTTP Extension Framework to Proposed Standar", "content": "On Thu, 18 Feb 1999, Henrik Frystyk Nielsen wrote:\n\n> At 11:28 2/18/99 +0100, Koen Holtman wrote:\n> \n> >The MUST/MAY/SHOULD text in the draft can be fixed, and I am trying to\n> >work on this with Henrik, but I have no idea whether we will\n> >converge.  I do feel that Henrik is not treating the issue with the\n> >care it deserves.\n> \n> Koen,\n> \n> Before you go on saying what can be fixed and what not can be fixed in the\n> current draft I think it would be instructive to point out that you have\n> yet to identify a correctness problem in the *current*design* based on what\n> is *supported* by the specification.\n\nSigh.  I have identified some.  See my discussion of sections 5.1 (last\npoint made) and the last remark about section 9 in my original last call\ncomments to the IESG.\n\nThis is all fixable, I believe some of the edits you proposed afterwards\nfixed at least some of the section 9 stuff.  You already fixed the\nsecond-to-last 5.1 point for me by pointing out how to get around it.  I\nsee a definite possibility of converging on this, don't worry. \n\nThen there is the 'Sec 5 para after enumerated list' thing about tunneling\nfor unknown methods.  You should really cross-check this with Jeff if you\ndon't trust my claim that this is not in http/1.1.  I have been known to\nbe wrong but I don't think I am wrong about this one.  Alternatively,\npoint me to the appropriate line in the 1.1 spec.\n\nI am much more worried about us converging on my issues re. sec 5 point 3\nand sec 5 point 4, and these have little to do with caching.\n\n> Henrik\n\nKoen.\n\n\n\n", "id": "lists-007-9712030"}, {"subject": "Re: Drafting mux WG charte", "content": "At 13:05 09.02.99 PST, spreitze@parc.xerox.com wrote:\n\n>Note that the charter isn't explicit on this point.  I anticipate the WG\nto debate this, and decide that the reciever-given restraint in the mux\nlayer should be an optional module, because some applications will need it\nand some won't.\n>\n\nIf I was to be present at the debate (which I have no reason to think I\nwould be), I'd make the argument that any kind of data transfer without\nreceiver-\ngiven restraint is tantamount to a request for assisted suicide.\n\nAn implication of muxing across TCP (I think) is that the receiver-given\nTCP window will be set by the mux layer, and depend solely on how fast the\nmux layer can put the data into queues at the layer \"above\"; blocking all\nmux channels because of one slow client will be unacceptable in many cases.\n\nHowever, losing data is also unacceptable in many cases, as is duplicating\nthe loss recovery mechanisms in TCP; this means that one must never get into\na state where the multiplex layer has to choose between throwing away data\nand refusing to pass data across *any* connection.\n\nThus, the only case I can imagine where receiver-given restraint is not needed\nis where the higher layer protocol \"guarantees\" that there will never be\na significant number of bytes passed between operations (for instance POP\nclient-to-server without command streaming).\nHowever, this leaves a wide-open door to denial-of-service attacks\n(just send \"LOGIN enormouslylongstringthatwillcertainlycauseabufferoverflow\")\nand strange results from changed enviroments (streaming mode, for instance,\nwhere it makes perfect sense to send 500 LIST requests without waiting\nfor the responses).\n\nMy off-the-top-of-my-head thinking only....\n\n                   Harald\n\n\n\n\n-- \nHarald Tveit Alvestrand, Maxware, Norway\nHarald.Alvestrand@maxware.no\n\n\n\n", "id": "lists-007-9722494"}, {"subject": "Re: Drafting mux WG charte", "content": "Followup discussion being held on ietf-http-ng@w3.org.  See <http://www.w3.org/Protocols/HTTP-NG/> for pointers to archive and instructions on how to join.\n\n\n\n", "id": "lists-007-9732925"}, {"subject": "RE: Use of TELNET for testing protocol", "content": "On Wed, 17 Feb 1999, Josh Cohen wrote:\n> > Jim Gettys said this:\n> > > Text protocols and telnet debugging have a lower entry cost, but much \n> > > higher curve as things get compicated.  Binary protocols tend to have \n> > > higher up-front costs (building a bit more infrastructure up front), but \n> > > lower difficultly curves, as the complexity of the protocol goes up.\n> >\n> definitely an insightful statement.\n> \n> However, has IMAP or POP had the same problems because its text?\n> Or, is it just HTTP's loose syntax of optional and ignored stuff\n> that has cause so much pain?\n> I havent noticed the same terrible cries in the IMAP/POP world,\n> but then again, maybe I dont spend enough time in that world\n> to notice.  Chris ?\n\nPOP is very simple, so it's a huge win that it's text.\n\nIMAP is a more interesting case as it has a number of complex\ndatastructures which use a simple S-expression style syntax.  I don't know\nof any significant problems that have been caused by these being text\nencoded.\n\nThere are certain traditions which can make text protocols painful as they\nget complicated.  For example, some people misinterpret the \"be liberal in\nwhat you accept\" principle as meaning \"accept illegal protocol\".\nThankfully most of the IMAP server implementors didn't make this mistake\nso the IMAP protocol is one of the most syntacticly interoperable text\nprotocols.\n\nIt does become harder to precisely specify a text protocol as it becomes\nmore complex.  But this may be a good thing as it makes an out-of-control\nprotocol designer suffer in a way that ASN.1 doesn't.\n\nI have a definite preference for text protocols.  I've found them much\neasier to write code for and maintain in practice than binary protocols. \nA key advantage text protocols have is that when there's an\ninteroperability problem, it is easy to prove to the customer who is at\nfault since you can show them the actual protocol.  Sometimes the customer\neven identifies who is at fault themselves.  Furthermore, a text protocol\ntrace looks the same regardless of who generates it.  Binary protocol\ndebugging info appears in whatever format was the implementor's whim if\nit's available at all.\n\nHowever, the relative advantages and disadvantages between text and binary\nprotocol encodings are negligible compared to other protocol design\nissues.  Protocol simplicity and avoiding rarely-used features are _far_\nmore important.  I'd much rather implement and maintain a simple\nwell-designed binary protocol (e.g., Secure Shell 2) than a complex text\nprotocol (e.g., HTTP 1.1).\n\nI should also point out the option of a hybrid encoding.  Use a simple\nbinary structure with fixed-length ASCII character strings for protocol\nkeywords.  You get all the advantages of binary encoding, and a protocol\ndump is at least partially useful.  Secure Shell 2 has a different\ninteresting hybrid characteristic -- it uses length-counted text strings\nfor extensibility-oriented feature lists.\n\n- Chris\n\n\n\n", "id": "lists-007-9740336"}, {"subject": "Binary data in text-based protocol format", "content": "At 04.18 +0100 99-02-20, Chris Newman wrote:\n> I should also point out the option of a hybrid encoding.  Use a simple\n> binary structure with fixed-length ASCII character strings for protocol\n> keywords.  You get all the advantages of binary encoding, and a protocol\n> dump is at least partially useful.  Secure Shell 2 has a different\n> interesting hybrid characteristic -- it uses length-counted text strings\n> for extensibility-oriented feature lists.\n\nA nice idea. Is it common in standards?\n\nBinary data in textual encodings seems to be a problem. How\nis this usually handled? Base64 is of course an option.\nMIME uses, if I understand it rightly, the convention that\n<CRLF>--boundary text<CRLF> is end marker of a binary body\npart. Not very neat.\n\nI have looked at the XML specs, and not found any good way\nof putting binary data into XML either. Have I missed\nsomething?\n\nTo indicate the end of binary data with an octet-length\nvalue before the binary data seems to me the neatest way,\nbut it seems not to be very popular in standards.\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-9750878"}, {"subject": "Re: Binary data in text-based protocol format", "content": "At 12:36 PM 2/20/99 +0100, Jacob Palme wrote:\n>I have looked at the XML specs, and not found any good way\n>of putting binary data into XML either. Have I missed\n>something?\n\nOnly the embarrassed groans of many people in the XML community. :-)\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-9759535"}, {"subject": "Re: Binary data in text-based protocol format", "content": "At 09:14 99/02/20 -0800, Paul Hoffman / IMC wrote:\n> At 12:36 PM 2/20/99 +0100, Jacob Palme wrote:\n> >I have looked at the XML specs, and not found any good way\n> >of putting binary data into XML either. Have I missed\n> >something?\n> \n> Only the embarrassed groans of many people in the XML community. :-)\n\nXML is a text format. As such, it can be transcoded by mail gateways.\nIf you label something as\n    Content-Type: text/xml; charset=us-ascii\nand it gets transcoded to EBCDIC, the binary data won't survive.\n\nThe web can easily include binary data, it's done all the time\nwith images, just use a link instead of putting things inline :-).\n\nRegards,   Martin.\n\n\n\n#-#-#  Martin J. Du\"rst, World Wide Web Consortium\n#-#-#  mailto:duerst@w3.org   http://www.w3.org\n\n\n\n", "id": "lists-007-9767432"}, {"subject": "Re: Binary data in text-based protocol format", "content": "At 03.40 +0100 99-02-21, Martin J. Duerst wrote:\n> The web can easily include binary data, it's done all the time\n> with images, just use a link instead of putting things inline :-).\n\nIf you want to include everything in one document, I assume you\nwould then use multipart/related?\n\nAnother alternative I have been thinking of would be to use\nbase64 encoding of binary data.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-9776317"}, {"subject": "Re: Binary data in text-based protocol format", "content": "At 03.40 +0100 99-02-21, Martin J. Duerst wrote:\n>\n> XML is a text format. As such, it can be transcoded by mail gateways.\n> If you label something as\n>     Content-Type: text/xml; charset=us-ascii\n> and it gets transcoded to EBCDIC, the binary data won't survive.\n>\n> The web can easily include binary data, it's done all the time\n> with images, just use a link instead of putting things inline :-).\n\nIf by link you mean an URL, I can see problems with it. If you want\nto send secret data, you may not wish part of the data to be available\nthrough an URL - not even if that URL contains a password.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-9784415"}, {"subject": "Re: Binary data in text-based protocol format", "content": "At 10:21 99/02/22 +0100, Jacob Palme wrote:\n> At 03.40 +0100 99-02-21, Martin J. Duerst wrote:\n> > The web can easily include binary data, it's done all the time\n> > with images, just use a link instead of putting things inline :-).\n> \n> If you want to include everything in one document, I assume you\n> would then use multipart/related?\n\nThis is one possibility. The problem with this is the boundaries,\nbut I guess it should be possible to construct boundaries that\ncannot appear in XML (such as something like <><>]]>]]> or something\nalong these lines). [I'm just checking this with some XML experts].\n\n> Another alternative I have been thinking of would be to use\n> base64 encoding of binary data.\n\nYes indeed.\n\n\nRegards,   Martin.\n\n\n#-#-#  Martin J. Du\"rst, World Wide Web Consortium\n#-#-#  mailto:duerst@w3.org   http://www.w3.org\n\n\n\n", "id": "lists-007-9792511"}, {"subject": "Re: Binary data in text-based protocol format", "content": "On Sat, 20 Feb 1999, Jacob Palme wrote:\n> At 04.18 +0100 99-02-20, Chris Newman wrote:\n> > I should also point out the option of a hybrid encoding.  Use a simple\n> > binary structure with fixed-length ASCII character strings for protocol\n> > keywords.  You get all the advantages of binary encoding, and a protocol\n> > dump is at least partially useful.  Secure Shell 2 has a different\n> > interesting hybrid characteristic -- it uses length-counted text strings\n> > for extensibility-oriented feature lists.\n> \n> A nice idea. Is it common in standards?\n\nHasn't happened much in the IETF, mostly because the apps area has a text\nbias and lower level areas have a binary bias.  The PNG spec (RFC 2083) \nuses four-letter ASCII labels for chunks, although that's not IETF\nstandards track.\n\n> Binary data in textual encodings seems to be a problem. How\n> is this usually handled? Base64 is of course an option.\n> MIME uses, if I understand it rightly, the convention that\n> <CRLF>--boundary text<CRLF> is end marker of a binary body\n> part. Not very neat.\n> ...\n> To indicate the end of binary data with an octet-length\n> value before the binary data seems to me the neatest way,\n> but it seems not to be very popular in standards.\n\nLength-counting has two problems:\n\n(1) It completely falls apart when common newline or charset conversions\n    are applied.\n\n(2) It requires that you know the size of the object in advance, or that\n    you use a complex chunking technique such as that used by SMTP BDAT.\n\nFor wire protocols, (1) isn't much of an issue and (2) can often be\ntolerated. In my experience, the length-counted literals in IMAP are less\nerror-prone and more efficient than the dot-stuffing in POP and SMTP\n(mostly because dot-stuffing creates a rarely used codepath and is\nintrusive when working with a canonical CRLF MIME mailstore).  But (2) \ncauses serious problems for mailstores that don't use canonical CRLF MIME\nformat.\n\nFor textual data formats, I think MIME got it right (a lot of smart people\nspent a lot of time on MIME).  In fact, well constructed MIME boundaries\nmake for a very nice Boyer-Moore search so you can find the end of the\nobject in sub-linear time.\n\nFor binary data formats, a length-counted chunking solution is most\ncommon.\n\n- Chris\n\n\n\n", "id": "lists-007-9800770"}, {"subject": "Requirements on IETF drafts: Pagination,  forbidden words, etc", "content": "I just sent in two IETF drafts, and got them rejected by\nthe IETF secretariat because they were not in the right\nformat according to\n    http://www.ietf.org/ietf/1id-guidelines.txt\n\nHere are questions about some of the requirements in that document:\n\nThey say that IETF drafts must have 58 lines/page with form\nfeed between pages. I fully agree that this is the format\nfor published RFCs, but for IETF drafts it is very common\nto have no pagination at all. To paginate a document is\nquite a lot of extra trouble unless you have software which\nwill do it automatically. I suggest that either IETF relax\nthis requirement to be only valid for RFCs, not for IETF\ndrafts, or recommend some software which will do the\npagination for me, preferably as a Word macro.\n\nThe document says \"The Internet-Draft should neither state\nnor imply that it has any standards status.\" Does this mean\nthat it is not permitted to write, in an IETF draft,\nsentences like \"this standard only is valid for e-mail, not\nfor Usenet News\" or \"to comply with this standard, an\nimplementation must ...\" or phrases like that? If the\nanswer is yes, should I change all occurences of \"standard\"\nwith the word \"specification\"?\n\nDoes this mean that it is not allowed to write for\nexample \"Category-to-be: Proposed Standard\" or\n\"This document is intended to become a Propised Standard\nif accepted by the IETF\" or something like that?\n\nSurprisingly, the document says nothing about copyright\nstatement. Does this mean that the requirement for an IETF\ncopyright statement in each draft is not valid any more?\n\nThe document says that the word \"INTERNET-DRAFT\" should\nappear in the upper left corner. Does this mean that the\nformat of the head must be changed from:\n\nNetwork Working Group                                      Name\nInternet draft                                       Affilition\nfile-name-00.txt                                        Country\nExpires August 1999                               February 1999\n\nto:\n\nINTERNET-DRAFT                                             Name\nNetwork Working Group                                Affilition\nfile-name-00.txt                                        Country\nExpires August 1999                               February 1999\n\n\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-9810423"}, {"subject": "Re: Requirements on IETF drafts: Pagination, forbidden words,   etc", "content": ">They say that IETF drafts must have 58 lines/page with form\n>feed between pages. I fully agree that this is the format\n>for published RFCs, but for IETF drafts it is very common\n>to have no pagination at all. To paginate a document is\n>quite a lot of extra trouble unless you have software which\n>will do it automatically. I suggest that either IETF relax\n>this requirement to be only valid for RFCs, not for IETF\n>drafts, or recommend some software which will do the\n>pagination for me, preferably as a Word macro.\n\nUnless they changed the rule the other day, this is not a requirement.\n\n>The document says \"The Internet-Draft should neither state\n>nor imply that it has any standards status.\" Does this mean\n>that it is not permitted to write, in an IETF draft,\n>sentences like \"this standard only is valid for e-mail, not\n>for Usenet News\" or \"to comply with this standard, an\n>implementation must ...\" or phrases like that? If the\n>answer is yes, should I change all occurences of \"standard\"\n>with the word \"specification\"?\n\nThat's probably what nailed you. \"This standard\" is inappropriate for a \ndraft. \"This document\" or \"this specification\" is much better, since you \ndon't know what status the draft will get (if any).\n\n>Does this mean that it is not allowed to write for\n>example \"Category-to-be: Proposed Standard\" or\n>\"This document is intended to become a Propised Standard\n>if accepted by the IETF\" or something like that?\n\nPersonally, I would say that those are also inappropriate. A draft is a draft.\n\n>Network Working Group                                      Name\n>Internet draft                                       Affilition\n>file-name-00.txt                                        Country\n>Expires August 1999                               February 1999\n>\n>to:\n>\n>INTERNET-DRAFT                                             Name\n>Network Working Group                                Affilition\n>file-name-00.txt                                        Country\n>Expires August 1999                               February 1999\n\nI also do not think they are sticky on this, but they may have changed the \nrules in the past two weeks.\n\n--Paul Hoffman, Director\n--Internet Mail Consortium\n\n\n\n", "id": "lists-007-9820728"}, {"subject": "IETF draft on good mailing list behaviou", "content": "I have written an IETF draft on good mailing list\nbehaviour. It has long been a need to have such a document.\nOne particular area, where this is needed, is in the design\nof groupware forum systems. Such systems often have a mail\ngateway, which cause a forum in such a system to appear, as\nseen from e-mail, as a mailing list. But the developers of\ngroupware forum systems often do not have so much\nexperience in proper mailing list behaviour, which causes\nvarious kinds of problems when their systems become\nconnected to the Internet mail transport system.\n\nThe document is available at\n  ftp://ftp.dsv.su.se/users/jpalme/draft-palme-maillist-00.txt\n\nI suggest that future discussion about this document is\ndone in the ietf-822@imc.org mailing list.\n------------------------------------------------------------------------\nJacob Palme <jpalme@dsv.su.se> (Stockholm University and KTH)\nfor more info see URL: http://www.dsv.su.se/~jpalme\n\n\n\n", "id": "lists-007-9830888"}, {"subject": "Re: Requirements on IETF drafts: Pagination,  forbidden words,  etc", "content": "At 18.06 +0100 1999-02-23, Jacob Palme wrote:\n> I just sent in two IETF drafts, and got them rejected by\n> the IETF secretariat because they were not in the right\n> format according to\n>     http://www.ietf.org/ietf/1id-guidelines.txt\n\nDid you fulfil the following requirement?\n\n> All Internet-Drafts must begin with ONE of the following three\n> statements:\n>\n> This document is an Internet-Draft and is in full conformance\n> with all provisions of Section 10 of RFC2026.\n>\n> This document is an Internet-Draft and is in full conformance\n> with all provisions of Section 10 of RFC2026 except that the\n> right to produce derivative works is not granted.\n>\n> This document is an Internet-Draft and is NOT offered in\n> accordance with Section 10 of RFC2026, and the author does not\n> provide the IETF with any rights other than to publish as an\n> Internet-Draft\n>\n> Any submission which does not include one (and only one) of the above\n> three statements will be returned to the submitter. The IETF\n> Secretariat will NOT add this text.\n\nPlease clearify.\n\n   Patrik\n\n\n\n", "id": "lists-007-9845259"}, {"subject": "mail archive for this grou", "content": "there's now a minimalist mail archive for this group available at\nhttp://www.apps.ietf.org/mail-archive\n\n(fancier alternatives will be available once I find a decent free\nhtml interface to mail...but I haven't seen one in awhile.)\n\n\n\n", "id": "lists-007-9853659"}, {"subject": "draft-earhart-acp-spec-0", "content": "  (Sorry for bothering everyone, but the ietf-applcore list still isn't\nactive for some reason.  And the discussion's been happening here\nanyway...) \n\n  I've submitted draft-earhart-acp-spec-00.txt to the internet-drafts\ndirectories; it should (hopefully) show up before the IETF.  It's also\naccessible via the web, at\n<URL:http://www.contrib.andrew.cmu.edu/~rob/draft-earhart-acp-spec-00.txt>\nand\n<URL:http://www.contrib.andrew.cmu.edu/~rob/draft-earhart-acp-spec-00.ps>\n(the ps version may or may not look nicer when printed out). \n\n  I'm not trying to come down from the mountain and say, \"This is what the\napplication core protocol should look like\"; I just wanted to throw\nsomething out there so that we'd have something to talk about (assuming\nthat we get a BOF at the next IETF).  It *is* pretty close to what I think\nwe want, and at seventeen pages it fits nicely within the proposed length\nrequirements, but I'm open to suggestions (including suggestions to throw\nit out entirely and go with something else. :-) \n\n  )Rob\n\n\n\n", "id": "lists-007-9860319"}, {"subject": "Re: IETF Agenda's and BOF'", "content": ">  I'm not trying to come down from the mountain and say, \"This is what the\n>application core protocol should look like\"; I just wanted to throw\n>something out there so that we'd have something to talk about (assuming\n>that we get a BOF at the next IETF).  \n\nSince you mentioned the subject .. does anyone know how the IETF agenda and\nBOF schedule is developing?\n\nThe IETF web site agenda has not been updated since the 9th and we are just\n2 weeks away.\n\n\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nRichard Shockey\nShockey Consulting LLC                  \n8045 Big Bend Blvd. Suite 110    \nSt. Louis, MO 63119\nVoice 314.918.9020\nFax   314.918.9015\nINTERNET Mail & IFAX : rshockey@ix.netcom.com\neFAX 815.333.1237  \n<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n\n\n", "id": "lists-007-9867865"}, {"subject": "Re: IETF Agenda's and BOF'", "content": "I think that people have to face the fact that the\nIETF is now going to become a \"trailing edge\"\norganization, not \"leading edge\". As with most\nstandards organizations, it can play a role in\ndocumenting standards long AFTER they find\nindustry acceptance. In the old days, the IETF\ncould lead. In order to do that, they had to remain\nat the leading edge. In my opinion, that is clearly\nno longer the case....\n\nJim Fleming\nUnir Corporation - UNIR and COM worlds @ http://www.activeworlds.com\nvPC + C+@ + IPv8 + 2,048 TLDs...this network solution is simple...\nhttp://www.ddj.com/articles/index/author/idx10133.htm\n\n\n-----Original Message-----\nFrom: Richard Shockey <rshockey@ix.netcom.com>\nTo: discuss@apps.ietf.org <discuss@apps.ietf.org>\nDate: Friday, February 26, 1999 9:21 AM\nSubject: Re: IETF Agenda's and BOF's\n\n\n>\n>>  I'm not trying to come down from the mountain and say, \"This is what the\n>>application core protocol should look like\"; I just wanted to throw\n>>something out there so that we'd have something to talk about (assuming\n>>that we get a BOF at the next IETF).\n>\n>Since you mentioned the subject .. does anyone know how the IETF agenda and\n>BOF schedule is developing?\n>\n>The IETF web site agenda has not been updated since the 9th and we are just\n>2 weeks away.\n>\n>\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n>Richard Shockey\n>Shockey Consulting LLC\n>8045 Big Bend Blvd. Suite 110\n>St. Louis, MO 63119\n>Voice 314.918.9020\n>Fax   314.918.9015\n>INTERNET Mail & IFAX : rshockey@ix.netcom.com\n>eFAX 815.333.1237\n><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n\n\n", "id": "lists-007-9876295"}, {"subject": "Re: IETF Agenda's and BOF'", "content": "Maybe I will get this in before the APPS ADs...\n\nThe usual exercise of changing the schedule to avoid the\nworst clashes is going on in real time. Last I heard, the\ntentative slot for Applcore was on Monday but *this may still\nchange*.\n\nBTW assuming there is a BOF it will for sure not be discussing\nspecific solutions at this stage. \n\n   Brian\n\n\n\n", "id": "lists-007-9886642"}, {"subject": "Re: IETF Agenda's and BOF'", "content": "> Since you mentioned the subject .. does anyone know how the IETF agenda and\n> BOF schedule is developing?\n\nat least for the apps area, all scheduling was still on hold until\nlast Monday.  (we had groups pencilled in for slots but we wanted \nto wait until the request deadline before announcing anything, \nbecause we knew that changes were likely)  even so we have had a \ncouple of late requests and the agenda folks are still juggling \nthings around to try to meet all of the constraints.  but I've seen \na couple of BOF announcements go out this morning, so they'll probably \nupdate the schedule soon.\n\nKeith\n\n\n\n", "id": "lists-007-9894157"}, {"subject": "Re: IETF Agenda's and BOF'", "content": "On Fri, 26 Feb 1999, Brian E Carpenter wrote:\n> BTW assuming there is a BOF it will for sure not be discussing\n> specific solutions at this stage.\n\nI concur.  The BOF will focus on scope, constraints and charter bashing.\n\nHowever, I encouraged Rob to put out his draft, because it doesn't hurt to\nhave a few strawmen around as a proof-of-concept and to show there's\ninterest in the problem.\n\n- Chris\n\n\n\n", "id": "lists-007-9901661"}, {"subject": "Re: IETF Agenda's and BOF'", "content": "Jim,\n\nIETF-bashing is not in scope for this list.\n\nKeith\n~\n\n\n\n", "id": "lists-007-9909307"}, {"subject": "Re: IETF Agenda's and BOF'", "content": "Do you feel that it is \"bad\" that the IETF is now\na trailing-edge standards organization, just like\nthe ITU, IEEE, and ANSI ?\n\nI suspect that some would find it attractive to be\nsimilar to those organizations. Clearly, many of the\nIETF members do. Those members collectively\ndefine whether the IETF is leading-edge or trailing-edge.\n\n\nJim Fleming\nUnir Corporation - UNIR and COM worlds @ http://www.activeworlds.com\nvPC + C+@ + IPv8 + 2,048 TLDs...this network solution is simple...\nhttp://www.ddj.com/articles/index/author/idx10133.htm\n\n\n-----Original Message-----\nFrom: Keith Moore <moore@cs.utk.edu>\nTo: Jim Fleming <JimFleming@prodigy.net>\nCc: discuss@apps.ietf.org <discuss@apps.ietf.org>\nDate: Friday, February 26, 1999 3:43 PM\nSubject: Re: IETF Agenda's and BOF's \n\n\n>Jim,\n>\n>IETF-bashing is not in scope for this list.\n>\n>Keith\n>~\n\n\n\n", "id": "lists-007-9916255"}, {"subject": "messages from Jim Flemin", "content": "for the indefinite future, messages from Jim Fleming will be screened\nto make sure that they are on topic for this list.\n\nfolks who wish to comment on this policy should send mail to me\nand/or Patrik. \n\nKeith\n\n\n\n", "id": "lists-007-9925098"}]